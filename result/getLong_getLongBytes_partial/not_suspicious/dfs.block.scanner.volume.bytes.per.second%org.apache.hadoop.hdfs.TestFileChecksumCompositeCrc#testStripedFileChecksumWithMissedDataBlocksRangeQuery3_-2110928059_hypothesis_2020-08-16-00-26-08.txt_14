reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657781122-172.17.0.9-1597537906210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34362,DS-34b15ffa-7b5b-441e-9869-2ee7c9532fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-31cf539b-fe3d-4f10-a97f-1010c0b6c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-f8a1690f-17fb-4c48-a26f-92c064fec6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-0d0819ef-6d4e-4791-81de-1465ad63dab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-778a7ee7-4a2c-40c4-ae74-e4848ffa6e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-a8d4d655-bfc8-416b-9dd9-a5a07199c6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-41829db9-410a-466c-90b8-7ec0759f0bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-a36d6df8-84fe-4663-bdfd-276c9a13044c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657781122-172.17.0.9-1597537906210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34362,DS-34b15ffa-7b5b-441e-9869-2ee7c9532fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-31cf539b-fe3d-4f10-a97f-1010c0b6c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-f8a1690f-17fb-4c48-a26f-92c064fec6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-0d0819ef-6d4e-4791-81de-1465ad63dab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-778a7ee7-4a2c-40c4-ae74-e4848ffa6e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-a8d4d655-bfc8-416b-9dd9-a5a07199c6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-41829db9-410a-466c-90b8-7ec0759f0bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-a36d6df8-84fe-4663-bdfd-276c9a13044c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070810645-172.17.0.9-1597538792782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-31595a05-975f-414f-b67c-19d5db63973e,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-18b7dbc4-2cd2-498d-af31-45a93a26c538,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-222f8475-c5af-4bce-b0da-b31911f87550,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-c63b1cf8-7b5c-456f-847b-b37215307a86,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-e2b58b39-e8d6-45bd-9d07-4b99933397f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-2f5fad91-ff01-4aca-8abc-7cfc2a624972,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-83cb2f15-3564-4a96-a522-0f5a7bd787a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-6d15bf47-c3b0-4eb1-93d9-222dcf30c791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070810645-172.17.0.9-1597538792782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-31595a05-975f-414f-b67c-19d5db63973e,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-18b7dbc4-2cd2-498d-af31-45a93a26c538,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-222f8475-c5af-4bce-b0da-b31911f87550,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-c63b1cf8-7b5c-456f-847b-b37215307a86,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-e2b58b39-e8d6-45bd-9d07-4b99933397f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-2f5fad91-ff01-4aca-8abc-7cfc2a624972,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-83cb2f15-3564-4a96-a522-0f5a7bd787a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-6d15bf47-c3b0-4eb1-93d9-222dcf30c791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753820537-172.17.0.9-1597538980218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-e5eb56fc-9fbe-4908-8d9a-757b61bfe221,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-d19bb8bc-de93-46a6-aafc-46f8c8ace23e,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-a1671879-32a9-4859-a528-a848468609ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-18fafb41-3f21-4198-a88d-2aec1521b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-a1718d02-181b-4e22-8271-ee095e4588aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-70e91567-e974-4a80-a7a7-d1eba95d959b,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-09bee3d4-4b5a-4cb6-8e48-167b7ef9018a,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-1912ef7b-d93e-43ed-93ab-228eced9ac05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753820537-172.17.0.9-1597538980218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-e5eb56fc-9fbe-4908-8d9a-757b61bfe221,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-d19bb8bc-de93-46a6-aafc-46f8c8ace23e,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-a1671879-32a9-4859-a528-a848468609ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-18fafb41-3f21-4198-a88d-2aec1521b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-a1718d02-181b-4e22-8271-ee095e4588aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-70e91567-e974-4a80-a7a7-d1eba95d959b,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-09bee3d4-4b5a-4cb6-8e48-167b7ef9018a,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-1912ef7b-d93e-43ed-93ab-228eced9ac05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377256434-172.17.0.9-1597540018804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-fdb90056-8949-42d7-80bd-227ae78c4ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-d4baaf32-4f12-405e-9237-1541b1ff7391,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-c4fdb94a-7fda-4b10-8bd1-6bd057b729f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-10716c0f-31b1-4346-889c-e74b5464cb75,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-ce1f3148-3020-4aac-b552-6f57972e1a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-5bbad5de-0866-4a2c-bb66-34f1ab6d1bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-cd3dd871-f8c1-452e-8915-f8f077c04805,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-8f9a37f3-b207-4c07-bc06-428635edd677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377256434-172.17.0.9-1597540018804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-fdb90056-8949-42d7-80bd-227ae78c4ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-d4baaf32-4f12-405e-9237-1541b1ff7391,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-c4fdb94a-7fda-4b10-8bd1-6bd057b729f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-10716c0f-31b1-4346-889c-e74b5464cb75,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-ce1f3148-3020-4aac-b552-6f57972e1a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-5bbad5de-0866-4a2c-bb66-34f1ab6d1bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-cd3dd871-f8c1-452e-8915-f8f077c04805,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-8f9a37f3-b207-4c07-bc06-428635edd677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544196181-172.17.0.9-1597540883722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32898,DS-87e317fd-8dfb-4c02-8e1f-bcdc37c9762e,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-2eaaa8d9-b988-404e-9d2b-e7a3bb5ccfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-f5176e83-a663-4bce-999b-4342f1871eca,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-211991c7-c92c-4db9-bbbc-cc9be9f34032,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-f0679efa-3303-4c96-80f4-044b35449d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-d133bd44-3d4b-4240-ba39-c8bb2cdb632a,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-7e94e6d8-0df0-435b-bd0a-b2b58036729a,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-be2194b5-308f-4b6b-9526-872210fdd2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544196181-172.17.0.9-1597540883722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32898,DS-87e317fd-8dfb-4c02-8e1f-bcdc37c9762e,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-2eaaa8d9-b988-404e-9d2b-e7a3bb5ccfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-f5176e83-a663-4bce-999b-4342f1871eca,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-211991c7-c92c-4db9-bbbc-cc9be9f34032,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-f0679efa-3303-4c96-80f4-044b35449d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-d133bd44-3d4b-4240-ba39-c8bb2cdb632a,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-7e94e6d8-0df0-435b-bd0a-b2b58036729a,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-be2194b5-308f-4b6b-9526-872210fdd2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272009502-172.17.0.9-1597541196245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-bb80b28a-7157-4fda-94cd-d307a3bb7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-e49510ef-a39f-4c76-a025-13681d49cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-16f4845e-d93e-4b0e-a241-a3a47591aed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-640ce87a-34bb-4e73-90ba-6361d37ea4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-78ffe61e-140f-4e55-a989-95a38918271c,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-965b0958-d804-49c8-930f-f0bc87b23527,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-c9fb0f2b-ca86-4981-8da8-c1fd71b5066d,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-784e46e6-e45f-480b-b8ff-056a2858b95a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272009502-172.17.0.9-1597541196245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-bb80b28a-7157-4fda-94cd-d307a3bb7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-e49510ef-a39f-4c76-a025-13681d49cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-16f4845e-d93e-4b0e-a241-a3a47591aed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-640ce87a-34bb-4e73-90ba-6361d37ea4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-78ffe61e-140f-4e55-a989-95a38918271c,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-965b0958-d804-49c8-930f-f0bc87b23527,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-c9fb0f2b-ca86-4981-8da8-c1fd71b5066d,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-784e46e6-e45f-480b-b8ff-056a2858b95a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137788637-172.17.0.9-1597541389024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33430,DS-56680ed2-3d8b-4fd4-a2a2-40c290e48b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-1baf6f74-4724-4f8d-aee5-d7d0b10a859e,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-c513688b-6a01-42c3-955e-a063f9b6baa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-da7c8462-e78f-438e-990a-00f40342634a,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-cccafbcc-865a-4ac0-b1b5-a3845660639c,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-5830bf3a-b237-4d42-beab-6d55275e70df,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-02cc509d-d726-47e4-ba51-352d4859e4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-7f64779f-256d-47e4-8434-af6c7cf0d511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137788637-172.17.0.9-1597541389024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33430,DS-56680ed2-3d8b-4fd4-a2a2-40c290e48b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-1baf6f74-4724-4f8d-aee5-d7d0b10a859e,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-c513688b-6a01-42c3-955e-a063f9b6baa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-da7c8462-e78f-438e-990a-00f40342634a,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-cccafbcc-865a-4ac0-b1b5-a3845660639c,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-5830bf3a-b237-4d42-beab-6d55275e70df,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-02cc509d-d726-47e4-ba51-352d4859e4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-7f64779f-256d-47e4-8434-af6c7cf0d511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628131978-172.17.0.9-1597541773393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-a9f1ab4a-a1ff-436e-8bf5-0b0a72c1323d,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-f7ba89cb-39fc-40e5-b3b6-d033eadf443e,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-7c5ea2b5-a1f7-44a4-9c07-93cce0a94c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-ac55b932-a39a-4992-a234-2557502ad884,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-5f38dcf5-4497-4990-95c8-f583ec95f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-6f4fc1ad-5079-4e19-a1d8-f4914a559d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-b5a62474-5dab-4461-9c43-223e32246d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-cdebcd72-1993-4a83-b195-6965e2fb72e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628131978-172.17.0.9-1597541773393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-a9f1ab4a-a1ff-436e-8bf5-0b0a72c1323d,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-f7ba89cb-39fc-40e5-b3b6-d033eadf443e,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-7c5ea2b5-a1f7-44a4-9c07-93cce0a94c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-ac55b932-a39a-4992-a234-2557502ad884,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-5f38dcf5-4497-4990-95c8-f583ec95f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-6f4fc1ad-5079-4e19-a1d8-f4914a559d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-b5a62474-5dab-4461-9c43-223e32246d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-cdebcd72-1993-4a83-b195-6965e2fb72e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349086520-172.17.0.9-1597541926198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45942,DS-82847c1c-9306-4df3-9389-25328a308685,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-2fa701d5-7c8e-4806-9132-04aa48e59681,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-0820ad37-8f79-4a48-ad76-b4561f905118,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-6d40a091-9ed3-4e4e-9b2d-628782062b33,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-ba892981-d42d-4f8f-af23-c6a63992aa49,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-be33e35e-f810-482f-b37f-d80d8e7f88c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-5f25a232-5065-48b1-85b9-1e06127f5646,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-955a30cd-266c-4c54-9fe9-e72c7a343aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349086520-172.17.0.9-1597541926198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45942,DS-82847c1c-9306-4df3-9389-25328a308685,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-2fa701d5-7c8e-4806-9132-04aa48e59681,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-0820ad37-8f79-4a48-ad76-b4561f905118,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-6d40a091-9ed3-4e4e-9b2d-628782062b33,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-ba892981-d42d-4f8f-af23-c6a63992aa49,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-be33e35e-f810-482f-b37f-d80d8e7f88c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-5f25a232-5065-48b1-85b9-1e06127f5646,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-955a30cd-266c-4c54-9fe9-e72c7a343aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628223839-172.17.0.9-1597541959231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-fb4b6091-d7f8-494b-bdec-2cffff9080bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-fd2da828-737e-4cb4-aca1-c72297627547,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-17332634-b8d8-4b30-ab37-54a6cabfb12d,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-ce9fb969-3954-4785-abc9-b171aabc581d,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-06f84d2b-6eb7-4738-8d00-5c5b1c903968,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-de466003-42fb-4e13-ac09-8b875bf500fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-c9a4e3bf-e45d-47d6-9e4f-86ba8fc367f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-1b232a8e-3dba-4bf2-9269-dd922272720f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628223839-172.17.0.9-1597541959231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-fb4b6091-d7f8-494b-bdec-2cffff9080bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-fd2da828-737e-4cb4-aca1-c72297627547,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-17332634-b8d8-4b30-ab37-54a6cabfb12d,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-ce9fb969-3954-4785-abc9-b171aabc581d,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-06f84d2b-6eb7-4738-8d00-5c5b1c903968,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-de466003-42fb-4e13-ac09-8b875bf500fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-c9a4e3bf-e45d-47d6-9e4f-86ba8fc367f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-1b232a8e-3dba-4bf2-9269-dd922272720f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652647918-172.17.0.9-1597542304496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-549df473-4fe4-4958-be6c-dc3e502b5ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-4588ff31-ff1d-49c6-a046-086a62a2c93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-2e0f1df0-c4a7-4456-b4e1-4038bdccd827,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-8c7ce5d9-4891-40fe-a0a1-1a26fbf6c630,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-d069498d-8925-4c5c-b5df-1ac451637ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-06c156b2-40fc-4c7d-a5ae-f0122acacda2,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-4e4fd11b-4d41-432d-a99c-926759cf55a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-38c66bfa-fe1a-4fe3-bffa-2733d1b804dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652647918-172.17.0.9-1597542304496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-549df473-4fe4-4958-be6c-dc3e502b5ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-4588ff31-ff1d-49c6-a046-086a62a2c93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-2e0f1df0-c4a7-4456-b4e1-4038bdccd827,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-8c7ce5d9-4891-40fe-a0a1-1a26fbf6c630,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-d069498d-8925-4c5c-b5df-1ac451637ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-06c156b2-40fc-4c7d-a5ae-f0122acacda2,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-4e4fd11b-4d41-432d-a99c-926759cf55a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-38c66bfa-fe1a-4fe3-bffa-2733d1b804dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530355460-172.17.0.9-1597542602407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-f3161422-411c-4388-954f-83bec0919727,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-d47a9afd-a12a-4eda-b57c-3af7e6d2838d,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-2919154c-bf0c-4cfc-8b38-26730b423945,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-ca38591a-9155-4629-a370-c5da81671413,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-e6021442-bacf-4dc3-b5bc-cd6d055d4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-bfa9bbbb-c5cd-42fe-8b82-e8427251951d,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-5d83f763-2845-4b4f-8cfd-e8161ebe3ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-21245530-998e-4cb4-a647-7b4bc4754a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530355460-172.17.0.9-1597542602407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-f3161422-411c-4388-954f-83bec0919727,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-d47a9afd-a12a-4eda-b57c-3af7e6d2838d,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-2919154c-bf0c-4cfc-8b38-26730b423945,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-ca38591a-9155-4629-a370-c5da81671413,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-e6021442-bacf-4dc3-b5bc-cd6d055d4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-bfa9bbbb-c5cd-42fe-8b82-e8427251951d,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-5d83f763-2845-4b4f-8cfd-e8161ebe3ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-21245530-998e-4cb4-a647-7b4bc4754a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5529
