reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458973126-172.17.0.21-1597487597491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36783,DS-c874e8fc-8180-42ca-95c0-a0288a906ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-3c33081e-31f8-4ffc-b2aa-bc14413f5add,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-8459fb3f-6a04-42ea-8fc2-392a3d350599,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-a40d352f-f98d-4cfa-9b7f-a5b6ee737cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-580d59b5-bce0-4850-959b-9c2c546f19fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-264e5486-3854-4d90-9caf-380db3ee110f,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-e9ee3539-3d36-43d6-b2d8-57845323fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-8137a52b-b8fa-49a8-a611-865bf08a1e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458973126-172.17.0.21-1597487597491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36783,DS-c874e8fc-8180-42ca-95c0-a0288a906ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-3c33081e-31f8-4ffc-b2aa-bc14413f5add,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-8459fb3f-6a04-42ea-8fc2-392a3d350599,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-a40d352f-f98d-4cfa-9b7f-a5b6ee737cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-580d59b5-bce0-4850-959b-9c2c546f19fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-264e5486-3854-4d90-9caf-380db3ee110f,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-e9ee3539-3d36-43d6-b2d8-57845323fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-8137a52b-b8fa-49a8-a611-865bf08a1e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556315937-172.17.0.21-1597487766181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46606,DS-f3f7dc21-f536-4047-be70-87fa064ef1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-3b46efe8-2c8c-4b2a-b7cc-dd5602687e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-24f5749e-a5f9-4cf8-b000-1041af84c8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-a1f26d53-4ec4-42ab-820d-34118a6eb125,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-4bc563b0-47bd-4be7-acde-0b437da25143,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-4acd4ed1-85ef-4631-ab2e-c0efabe3763c,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-530c11bd-763e-4a54-a1b0-e92c957f891c,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-01e6ab18-7219-4551-bbf2-d08229c4fe25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556315937-172.17.0.21-1597487766181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46606,DS-f3f7dc21-f536-4047-be70-87fa064ef1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-3b46efe8-2c8c-4b2a-b7cc-dd5602687e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-24f5749e-a5f9-4cf8-b000-1041af84c8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-a1f26d53-4ec4-42ab-820d-34118a6eb125,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-4bc563b0-47bd-4be7-acde-0b437da25143,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-4acd4ed1-85ef-4631-ab2e-c0efabe3763c,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-530c11bd-763e-4a54-a1b0-e92c957f891c,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-01e6ab18-7219-4551-bbf2-d08229c4fe25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284928104-172.17.0.21-1597488381387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-857612ed-4a0b-4ce8-8624-d84e833863fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-41b21b40-ba5f-421c-ac49-9824c2f61055,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-aeccda65-8d44-492a-aebc-a09ee3f411e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-bec3abc4-8fe4-405f-9faa-6c640e67dd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-f3971870-6927-4fd0-ae8e-5eb01cd707bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-b68825da-ccfa-44b9-bccf-066178d54268,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-31fca44d-3417-443d-81d6-e32d3b6e7c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e3f4d940-6a54-4783-9a3f-e4356aaf674b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284928104-172.17.0.21-1597488381387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-857612ed-4a0b-4ce8-8624-d84e833863fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-41b21b40-ba5f-421c-ac49-9824c2f61055,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-aeccda65-8d44-492a-aebc-a09ee3f411e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-bec3abc4-8fe4-405f-9faa-6c640e67dd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-f3971870-6927-4fd0-ae8e-5eb01cd707bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-b68825da-ccfa-44b9-bccf-066178d54268,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-31fca44d-3417-443d-81d6-e32d3b6e7c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e3f4d940-6a54-4783-9a3f-e4356aaf674b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429091231-172.17.0.21-1597488798186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-01f8f862-19cd-44d5-b05e-31d93e739fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-877a9ec3-0ef1-434f-86b8-4ab419abccab,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-694486d0-956a-4dbe-91d7-183f12ccd629,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-bc84263e-e11a-4378-a3a0-6338d20da4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-08ec6c39-1cce-4814-a029-6bee0aa700ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-47e6b645-662f-4bac-ba5a-680374a709de,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-8272d034-865e-4b0e-aac5-6eac6e6d82bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-7023378c-9dbe-4f6c-bb8c-fe40c2de5517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429091231-172.17.0.21-1597488798186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-01f8f862-19cd-44d5-b05e-31d93e739fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-877a9ec3-0ef1-434f-86b8-4ab419abccab,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-694486d0-956a-4dbe-91d7-183f12ccd629,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-bc84263e-e11a-4378-a3a0-6338d20da4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-08ec6c39-1cce-4814-a029-6bee0aa700ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-47e6b645-662f-4bac-ba5a-680374a709de,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-8272d034-865e-4b0e-aac5-6eac6e6d82bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-7023378c-9dbe-4f6c-bb8c-fe40c2de5517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139700661-172.17.0.21-1597489077864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-95669e72-7c0c-413e-aeb4-b4e9a3c1e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-37b92e81-ce03-4f02-9e5e-9695349b776c,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-480cb732-6b96-4b5d-a26d-4c1962d009df,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-9fcd888f-b945-4cf6-b61c-7f52dba79900,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-37113f8d-4c14-42ae-b782-5a7d79bd6251,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-c55fe3d1-5087-49b0-8969-d75b7a866f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-f90ac7c6-4688-4168-bba2-9822dfb4aa62,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-5d4c0945-820c-4571-9475-3ff39a7c9a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139700661-172.17.0.21-1597489077864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-95669e72-7c0c-413e-aeb4-b4e9a3c1e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-37b92e81-ce03-4f02-9e5e-9695349b776c,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-480cb732-6b96-4b5d-a26d-4c1962d009df,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-9fcd888f-b945-4cf6-b61c-7f52dba79900,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-37113f8d-4c14-42ae-b782-5a7d79bd6251,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-c55fe3d1-5087-49b0-8969-d75b7a866f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-f90ac7c6-4688-4168-bba2-9822dfb4aa62,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-5d4c0945-820c-4571-9475-3ff39a7c9a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752339713-172.17.0.21-1597489289416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-3ee11f87-e3ba-416b-8063-461e9a0f1eda,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-05ba5a86-1b5c-4c96-9394-ea43b9f9d528,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-1de22f36-6df6-4aba-b4f3-98ad230a4235,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-0942029b-4d42-4329-99ca-7a3e1dd4a38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-19a42ba6-714b-429d-b281-a065fdc970d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-0b7937d6-66c8-4384-b03c-0b09af10b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-03eba198-bfc1-4461-9744-5796af032154,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-49f0736e-cd1a-418c-ac2b-5bcea75a3fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752339713-172.17.0.21-1597489289416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-3ee11f87-e3ba-416b-8063-461e9a0f1eda,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-05ba5a86-1b5c-4c96-9394-ea43b9f9d528,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-1de22f36-6df6-4aba-b4f3-98ad230a4235,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-0942029b-4d42-4329-99ca-7a3e1dd4a38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-19a42ba6-714b-429d-b281-a065fdc970d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-0b7937d6-66c8-4384-b03c-0b09af10b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-03eba198-bfc1-4461-9744-5796af032154,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-49f0736e-cd1a-418c-ac2b-5bcea75a3fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801362119-172.17.0.21-1597489327891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-84d8c03f-4f05-49da-ba59-8b2d2e50f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-2ffbdf75-7ad5-44d4-8e03-09085feebf28,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-abbd3555-283a-4778-9dee-0bbabb31c0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-8612d38a-1677-47e0-9670-05bf3c9b870d,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-22f9ed8a-ba24-4167-82e2-b2223dbf954e,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-31f37aa3-450b-4189-8a83-b9c8888e8134,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-36f56499-b67d-4a07-925e-e06a053a5833,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-5fcc7ca0-8a8d-4bee-b7d3-62ebc63b78ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801362119-172.17.0.21-1597489327891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-84d8c03f-4f05-49da-ba59-8b2d2e50f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-2ffbdf75-7ad5-44d4-8e03-09085feebf28,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-abbd3555-283a-4778-9dee-0bbabb31c0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-8612d38a-1677-47e0-9670-05bf3c9b870d,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-22f9ed8a-ba24-4167-82e2-b2223dbf954e,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-31f37aa3-450b-4189-8a83-b9c8888e8134,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-36f56499-b67d-4a07-925e-e06a053a5833,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-5fcc7ca0-8a8d-4bee-b7d3-62ebc63b78ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838040492-172.17.0.21-1597489475079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-1898bfe4-6c0a-418c-8904-97a9c8f6c773,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-014ef915-f6ab-48a0-9881-5e1cbfab966f,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-28688a97-4c2c-4f59-a5a0-100080097be3,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-e6c81c17-c6e5-46cb-94b6-38051180f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-36aa0b18-9c0c-430c-96a6-b6071b13f512,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-e7b94a25-e958-4d7a-9d5f-28136e78c113,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-43fd75f1-8e14-48c8-9e6a-99342b832dab,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-bc8d9342-5ca7-4b82-a4c2-d90599cd6d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838040492-172.17.0.21-1597489475079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-1898bfe4-6c0a-418c-8904-97a9c8f6c773,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-014ef915-f6ab-48a0-9881-5e1cbfab966f,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-28688a97-4c2c-4f59-a5a0-100080097be3,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-e6c81c17-c6e5-46cb-94b6-38051180f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-36aa0b18-9c0c-430c-96a6-b6071b13f512,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-e7b94a25-e958-4d7a-9d5f-28136e78c113,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-43fd75f1-8e14-48c8-9e6a-99342b832dab,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-bc8d9342-5ca7-4b82-a4c2-d90599cd6d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874928011-172.17.0.21-1597489964261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38653,DS-fd36e665-ca43-4a39-821e-be97b55349cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-73f481c8-e1d9-4af7-8018-600499eb1faa,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-82c1e551-b2d4-4663-8310-751626265846,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-761adc96-b137-4c54-9fc9-1ff4fb73590d,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-24b8029c-228f-40d4-addb-86bb9c8daa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-e2872928-b5e7-477e-8d01-03fa642f607a,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-98bf0ac6-6257-489a-9395-e69ca9550c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-91876048-a9bc-4dfd-b032-211111e53d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874928011-172.17.0.21-1597489964261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38653,DS-fd36e665-ca43-4a39-821e-be97b55349cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-73f481c8-e1d9-4af7-8018-600499eb1faa,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-82c1e551-b2d4-4663-8310-751626265846,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-761adc96-b137-4c54-9fc9-1ff4fb73590d,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-24b8029c-228f-40d4-addb-86bb9c8daa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-e2872928-b5e7-477e-8d01-03fa642f607a,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-98bf0ac6-6257-489a-9395-e69ca9550c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-91876048-a9bc-4dfd-b032-211111e53d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677859067-172.17.0.21-1597490037022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44130,DS-d98f7393-e14c-49c6-9ddb-dd21a1228972,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-6ad32508-9fc7-465d-8bb8-295cd800472b,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-74b824f5-64a6-4583-8d32-9bf64b0b9a37,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-d1ab1136-cce3-414a-a649-d5ee8fe281c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-5a57dad1-705a-4fc0-8b2d-d14d7123255d,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-209cc48e-b674-48eb-87d3-f96916c79e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-d10bdbb1-f788-4d72-ae95-ccb0d8deb3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-01af9f40-d3da-40d0-af96-57f1252f5bbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677859067-172.17.0.21-1597490037022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44130,DS-d98f7393-e14c-49c6-9ddb-dd21a1228972,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-6ad32508-9fc7-465d-8bb8-295cd800472b,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-74b824f5-64a6-4583-8d32-9bf64b0b9a37,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-d1ab1136-cce3-414a-a649-d5ee8fe281c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-5a57dad1-705a-4fc0-8b2d-d14d7123255d,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-209cc48e-b674-48eb-87d3-f96916c79e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-d10bdbb1-f788-4d72-ae95-ccb0d8deb3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-01af9f40-d3da-40d0-af96-57f1252f5bbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220931439-172.17.0.21-1597490372093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-1ad82d9b-1caf-41ae-b134-da2e6e7df18f,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-84c59898-8860-4bb0-8c25-393f075884e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-5b36bf41-dc19-40d0-82fc-19a18c7040f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-8a86d693-551e-48ea-b172-d6058313a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-f318572b-87b1-4a57-a26a-8e8a864548b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-c6bf8863-77b5-4dc3-bd1e-ca02439fc6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-baacd57c-e019-4b4c-b82b-c96059ae1af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-7d8d843f-5858-4fce-a824-ad004190d474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220931439-172.17.0.21-1597490372093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-1ad82d9b-1caf-41ae-b134-da2e6e7df18f,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-84c59898-8860-4bb0-8c25-393f075884e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-5b36bf41-dc19-40d0-82fc-19a18c7040f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-8a86d693-551e-48ea-b172-d6058313a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-f318572b-87b1-4a57-a26a-8e8a864548b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-c6bf8863-77b5-4dc3-bd1e-ca02439fc6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-baacd57c-e019-4b4c-b82b-c96059ae1af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-7d8d843f-5858-4fce-a824-ad004190d474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7583018-172.17.0.21-1597490661617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-30e3e420-d258-412e-8b43-2181fe7b7a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-4478c8ae-6c73-4242-ba6e-53ec035d49a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-f85e89c9-610c-4250-a653-59092bafdab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-b2710eae-0a8a-49c9-96cb-2c72aaa615fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-cd32841e-f77d-427e-8c34-e943373d6875,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-99cd27ce-9e03-45f4-b9b0-864d48d01b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-fc2b56f5-1a61-4b91-809c-07018545ca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-b36df506-47ac-4398-8705-18aaf1db5e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7583018-172.17.0.21-1597490661617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-30e3e420-d258-412e-8b43-2181fe7b7a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-4478c8ae-6c73-4242-ba6e-53ec035d49a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-f85e89c9-610c-4250-a653-59092bafdab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-b2710eae-0a8a-49c9-96cb-2c72aaa615fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-cd32841e-f77d-427e-8c34-e943373d6875,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-99cd27ce-9e03-45f4-b9b0-864d48d01b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-fc2b56f5-1a61-4b91-809c-07018545ca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-b36df506-47ac-4398-8705-18aaf1db5e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934110017-172.17.0.21-1597490930801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33777,DS-0229e4c6-34e3-4247-b65b-f0f0782fcd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-ebff02b0-3c14-46d2-a64d-4d65e60b409d,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-1a91a469-3dfb-4fbf-a8ca-e3ffa0c4a358,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-a105ea1e-59e4-4730-ac88-2cdce31d2259,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-cad35c66-5c8d-473e-8e98-60675c9afa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-417f4f17-ca6a-4380-8e60-aa80d326cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-7ac6c2c5-5180-4fdc-80e0-0a0c73f34d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-3f8757ac-0710-4a99-8e86-e1b21c35fbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934110017-172.17.0.21-1597490930801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33777,DS-0229e4c6-34e3-4247-b65b-f0f0782fcd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-ebff02b0-3c14-46d2-a64d-4d65e60b409d,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-1a91a469-3dfb-4fbf-a8ca-e3ffa0c4a358,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-a105ea1e-59e4-4730-ac88-2cdce31d2259,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-cad35c66-5c8d-473e-8e98-60675c9afa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-417f4f17-ca6a-4380-8e60-aa80d326cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-7ac6c2c5-5180-4fdc-80e0-0a0c73f34d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-3f8757ac-0710-4a99-8e86-e1b21c35fbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574166315-172.17.0.21-1597491449865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33738,DS-94d8ccda-6029-4ba5-b21a-249f775bd025,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-0ca4d82c-2ccd-4276-bab7-3324180224c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-88feb05b-afc7-4eaf-bbd7-53e8da2820b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-a78e4325-02b4-4af8-b530-ea759e540ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-a2e4b3c9-dcd0-4d8a-8367-50c65ed91115,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-469b84c6-32fc-452b-919a-b5b966a875da,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-ce1622e0-d133-49f3-a7e9-09354d95bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-17e194dd-e95f-48da-a199-308166844372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574166315-172.17.0.21-1597491449865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33738,DS-94d8ccda-6029-4ba5-b21a-249f775bd025,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-0ca4d82c-2ccd-4276-bab7-3324180224c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-88feb05b-afc7-4eaf-bbd7-53e8da2820b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-a78e4325-02b4-4af8-b530-ea759e540ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-a2e4b3c9-dcd0-4d8a-8367-50c65ed91115,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-469b84c6-32fc-452b-919a-b5b966a875da,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-ce1622e0-d133-49f3-a7e9-09354d95bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-17e194dd-e95f-48da-a199-308166844372,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044966573-172.17.0.21-1597491854934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-372d44d0-c869-4ed3-92a1-cdef7e187d04,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-e4c08e3a-5624-4e8f-a257-b1587b9be841,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-f604f194-b80d-444b-9b8c-383ddbf3adbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-5e56170e-3c66-4036-82a9-9d3b0825c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-d8f57194-f0dd-452b-9692-ef8e0e66f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-85354b0b-6fe6-4542-a3f1-c63987b265c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-efbd1210-5bdd-4318-860a-6db3a863a558,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-0033be74-3871-4ed2-810f-cacf749f2076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044966573-172.17.0.21-1597491854934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40238,DS-372d44d0-c869-4ed3-92a1-cdef7e187d04,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-e4c08e3a-5624-4e8f-a257-b1587b9be841,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-f604f194-b80d-444b-9b8c-383ddbf3adbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-5e56170e-3c66-4036-82a9-9d3b0825c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-d8f57194-f0dd-452b-9692-ef8e0e66f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-85354b0b-6fe6-4542-a3f1-c63987b265c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-efbd1210-5bdd-4318-860a-6db3a863a558,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-0033be74-3871-4ed2-810f-cacf749f2076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468333974-172.17.0.21-1597491957537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-91ba9011-49ba-4be4-bb55-c83a6504a850,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-36517d24-9d38-4584-9979-8dcc079aec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-42be0985-5356-4250-9bc4-b686732a27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-0691bae7-bea9-47dd-bf01-f469403883fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-b5649b9c-0f91-4b7b-8a19-ec14b4a953c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-8746bf9e-e17e-40a6-bc73-5d8bab3c233e,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-81e743c1-193f-4528-84ce-b1dc36a3c052,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-f2af538e-7139-4bd6-b71e-084ce395c59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468333974-172.17.0.21-1597491957537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-91ba9011-49ba-4be4-bb55-c83a6504a850,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-36517d24-9d38-4584-9979-8dcc079aec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-42be0985-5356-4250-9bc4-b686732a27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-0691bae7-bea9-47dd-bf01-f469403883fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-b5649b9c-0f91-4b7b-8a19-ec14b4a953c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-8746bf9e-e17e-40a6-bc73-5d8bab3c233e,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-81e743c1-193f-4528-84ce-b1dc36a3c052,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-f2af538e-7139-4bd6-b71e-084ce395c59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429194308-172.17.0.21-1597492113503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-49fe4cf8-700b-445b-a027-5d1aef16032b,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-406f3d1a-1e70-4096-9822-5169d2c1f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-96057bcf-14c9-4738-91d6-12529a74eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-5468f945-6afa-4ed6-b12e-d1947bb5d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-28988cba-b1df-48ca-86d9-b99ad3c72d57,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-30456f59-6016-4a40-a0ae-f9e85d552c83,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-abfea84b-2ba8-4b6a-98bd-4424e2d610a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-446f781e-ca00-4ebd-b3e6-c1c913fa9bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429194308-172.17.0.21-1597492113503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45148,DS-49fe4cf8-700b-445b-a027-5d1aef16032b,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-406f3d1a-1e70-4096-9822-5169d2c1f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-96057bcf-14c9-4738-91d6-12529a74eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-5468f945-6afa-4ed6-b12e-d1947bb5d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-28988cba-b1df-48ca-86d9-b99ad3c72d57,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-30456f59-6016-4a40-a0ae-f9e85d552c83,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-abfea84b-2ba8-4b6a-98bd-4424e2d610a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-446f781e-ca00-4ebd-b3e6-c1c913fa9bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163126510-172.17.0.21-1597492460530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46138,DS-81ce3e3b-f242-4deb-9db1-9074bdfe0e31,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-39664a60-17da-4e7a-9eb5-beaf524eea32,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-6a7a5cfd-0452-4710-b5b3-18e844ff970f,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-f367c647-37c7-4c9b-b628-c66d4f936ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-209fd55c-717d-4552-9aa1-507ef2f66673,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-95a75bfa-4741-4e72-a96c-0612c979cb30,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-469495b5-8997-46ca-85c9-339865758a71,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-d9e154c3-3be9-4222-aefa-5361de6d035b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163126510-172.17.0.21-1597492460530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46138,DS-81ce3e3b-f242-4deb-9db1-9074bdfe0e31,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-39664a60-17da-4e7a-9eb5-beaf524eea32,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-6a7a5cfd-0452-4710-b5b3-18e844ff970f,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-f367c647-37c7-4c9b-b628-c66d4f936ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-209fd55c-717d-4552-9aa1-507ef2f66673,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-95a75bfa-4741-4e72-a96c-0612c979cb30,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-469495b5-8997-46ca-85c9-339865758a71,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-d9e154c3-3be9-4222-aefa-5361de6d035b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5464
