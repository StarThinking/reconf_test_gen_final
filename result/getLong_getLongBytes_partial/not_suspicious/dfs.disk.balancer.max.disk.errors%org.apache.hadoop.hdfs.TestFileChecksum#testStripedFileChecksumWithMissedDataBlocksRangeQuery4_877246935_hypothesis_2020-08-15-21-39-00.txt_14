reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994736551-172.17.0.6-1597527781362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-67f80de7-aa96-4088-aaf3-dcb671f3a07d,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-fa0d792b-a7af-4fe1-aed0-6f3ce2060507,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-fce55992-1455-46f1-8ea9-2b5a32ed6861,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-5e329186-6886-45f4-96e5-834f88a6cb76,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-ba7acb36-890a-44da-8dd5-7b3aeaf8dcff,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-f41053b6-39c5-4660-85b1-fc1af29c9f90,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-482a0704-2b8c-4ce0-bbe3-d879c9410bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-9d3b2432-3f38-4e4f-bbc9-44cb67e229b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994736551-172.17.0.6-1597527781362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-67f80de7-aa96-4088-aaf3-dcb671f3a07d,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-fa0d792b-a7af-4fe1-aed0-6f3ce2060507,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-fce55992-1455-46f1-8ea9-2b5a32ed6861,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-5e329186-6886-45f4-96e5-834f88a6cb76,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-ba7acb36-890a-44da-8dd5-7b3aeaf8dcff,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-f41053b6-39c5-4660-85b1-fc1af29c9f90,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-482a0704-2b8c-4ce0-bbe3-d879c9410bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-9d3b2432-3f38-4e4f-bbc9-44cb67e229b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147491678-172.17.0.6-1597527854079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44204,DS-1a346ef4-e60b-4c84-b413-14039c8a41af,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-b4b7be5a-9c8a-4ca4-96d5-1148985f862b,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-b4edf64e-ecf5-43b4-a651-c8e64514fa60,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-54f6c905-cd17-4f4f-89b5-d76e8ab41cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-d5641927-cd27-4984-9816-711cc6cad896,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-3040d757-7515-4f6a-bfc0-1a0c36deafc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-767acea2-9baf-4a6a-ad68-46139f8b9728,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-ad637dfc-91b8-4b1c-9c1b-17427bbfac6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147491678-172.17.0.6-1597527854079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44204,DS-1a346ef4-e60b-4c84-b413-14039c8a41af,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-b4b7be5a-9c8a-4ca4-96d5-1148985f862b,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-b4edf64e-ecf5-43b4-a651-c8e64514fa60,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-54f6c905-cd17-4f4f-89b5-d76e8ab41cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-d5641927-cd27-4984-9816-711cc6cad896,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-3040d757-7515-4f6a-bfc0-1a0c36deafc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-767acea2-9baf-4a6a-ad68-46139f8b9728,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-ad637dfc-91b8-4b1c-9c1b-17427bbfac6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280347985-172.17.0.6-1597528224319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41133,DS-e7d0e91f-9dc6-4f36-848b-b448cd590edf,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-6bb80303-d2a5-4e3e-907d-da7e0a2d06fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-d2ac6042-2c89-4448-a320-e504037eb481,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-bab22229-caac-42fe-a970-864f61245694,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e34ac91a-72e3-4061-9595-4de7677e1493,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-bc6814fb-4d4b-4f8b-8d65-9728572e3748,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-7914afbc-a7aa-4741-93cb-62faed5417b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-0c72a9ef-c5f9-4548-a522-1cd017ba4ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280347985-172.17.0.6-1597528224319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41133,DS-e7d0e91f-9dc6-4f36-848b-b448cd590edf,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-6bb80303-d2a5-4e3e-907d-da7e0a2d06fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-d2ac6042-2c89-4448-a320-e504037eb481,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-bab22229-caac-42fe-a970-864f61245694,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e34ac91a-72e3-4061-9595-4de7677e1493,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-bc6814fb-4d4b-4f8b-8d65-9728572e3748,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-7914afbc-a7aa-4741-93cb-62faed5417b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-0c72a9ef-c5f9-4548-a522-1cd017ba4ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766622723-172.17.0.6-1597528381921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38657,DS-971a5c24-eba4-471b-8ba2-ba2ed4e8eb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-311cfacf-0bff-4324-a917-66868a629a22,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-d5208fba-cf80-4ce7-8a10-fe573964e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-cb5ec950-b2da-48de-9a0c-42931011ad72,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-ad51eee9-a3c9-43ac-9270-513402016302,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-1a168e16-3fd1-4575-963c-d2ac819f6a33,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-842e020b-ed72-480f-bd10-263531dc76fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-ef411d23-d741-4d7a-bd0d-b7d4f88b8206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766622723-172.17.0.6-1597528381921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38657,DS-971a5c24-eba4-471b-8ba2-ba2ed4e8eb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-311cfacf-0bff-4324-a917-66868a629a22,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-d5208fba-cf80-4ce7-8a10-fe573964e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-cb5ec950-b2da-48de-9a0c-42931011ad72,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-ad51eee9-a3c9-43ac-9270-513402016302,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-1a168e16-3fd1-4575-963c-d2ac819f6a33,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-842e020b-ed72-480f-bd10-263531dc76fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-ef411d23-d741-4d7a-bd0d-b7d4f88b8206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920138298-172.17.0.6-1597528416998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32865,DS-03a687a6-b5ef-42da-8d51-bd5fa894e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-45a08792-c882-412b-8da4-32cf2a334020,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-6ca10ef3-5a82-42c3-a381-fc6bfd4d32a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-db484277-119a-47d5-ae85-1187c00c75ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-d1f7057b-7e76-4198-bd29-e8251fafec17,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-724e241a-1ecd-441c-815e-e21912fe51ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-c977cadb-f1db-4dc9-aed2-6bac4c8192ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-bf142e49-f6eb-4b87-b002-afe11ba798a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920138298-172.17.0.6-1597528416998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32865,DS-03a687a6-b5ef-42da-8d51-bd5fa894e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-45a08792-c882-412b-8da4-32cf2a334020,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-6ca10ef3-5a82-42c3-a381-fc6bfd4d32a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-db484277-119a-47d5-ae85-1187c00c75ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-d1f7057b-7e76-4198-bd29-e8251fafec17,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-724e241a-1ecd-441c-815e-e21912fe51ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-c977cadb-f1db-4dc9-aed2-6bac4c8192ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-bf142e49-f6eb-4b87-b002-afe11ba798a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641939075-172.17.0.6-1597529247386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45447,DS-04f8ba5e-5d18-4ea2-9da6-47f7e63d4f91,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-f3a156c0-e321-4543-9a73-9bd1911c0515,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-974d0c9c-cb48-425e-9b75-c6030041feb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-c6042e2d-3d3c-4f93-b8e2-bb1746e27d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-16f79df8-1780-4367-8274-b8385b4e1c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-42f8e3ec-233d-4ce3-8de2-cfdc11d3d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-06594acf-da7f-47d2-904c-4455641f4684,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-710d3a97-a3df-4039-99a3-d2763de2947a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641939075-172.17.0.6-1597529247386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45447,DS-04f8ba5e-5d18-4ea2-9da6-47f7e63d4f91,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-f3a156c0-e321-4543-9a73-9bd1911c0515,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-974d0c9c-cb48-425e-9b75-c6030041feb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-c6042e2d-3d3c-4f93-b8e2-bb1746e27d40,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-16f79df8-1780-4367-8274-b8385b4e1c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-42f8e3ec-233d-4ce3-8de2-cfdc11d3d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-06594acf-da7f-47d2-904c-4455641f4684,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-710d3a97-a3df-4039-99a3-d2763de2947a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265430420-172.17.0.6-1597529325947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42045,DS-462bcf66-afa8-45f6-882d-5e7c64be3f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-1216d980-8f1f-44ff-ac96-b1d2bd934532,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-56fa39cd-58e4-473b-aa06-c4f50d42a3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-cc28d42f-8e46-4ceb-b569-54777ec00af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-a7ba688b-dc70-4bbe-af98-d483f8263340,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-aca4d9ce-c06e-4c71-9e13-b9426899fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-219e27d9-acfb-486c-9733-f4de7c66c437,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-34cd6de8-36c3-4de5-be2c-82fcf7b7bc2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265430420-172.17.0.6-1597529325947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42045,DS-462bcf66-afa8-45f6-882d-5e7c64be3f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-1216d980-8f1f-44ff-ac96-b1d2bd934532,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-56fa39cd-58e4-473b-aa06-c4f50d42a3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-cc28d42f-8e46-4ceb-b569-54777ec00af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-a7ba688b-dc70-4bbe-af98-d483f8263340,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-aca4d9ce-c06e-4c71-9e13-b9426899fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-219e27d9-acfb-486c-9733-f4de7c66c437,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-34cd6de8-36c3-4de5-be2c-82fcf7b7bc2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962985437-172.17.0.6-1597530073067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-a46fad3c-1411-4b7b-a303-fe26ce628a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-b90197ee-4388-424a-92d4-48e876d120aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-58d8ae66-b85e-420c-ad5b-f71880910569,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-d9e4225e-c08a-428a-8a51-69c31d93bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-4efd9c4d-060e-45f6-bc91-1150177f1def,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-397e1dae-f193-4335-98fb-51c870814849,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-f0ca78e5-3a7d-4bb2-9a99-7a87e3733110,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-adfe7c12-5250-426a-bb54-c6a2b32cd672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962985437-172.17.0.6-1597530073067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-a46fad3c-1411-4b7b-a303-fe26ce628a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-b90197ee-4388-424a-92d4-48e876d120aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-58d8ae66-b85e-420c-ad5b-f71880910569,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-d9e4225e-c08a-428a-8a51-69c31d93bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-4efd9c4d-060e-45f6-bc91-1150177f1def,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-397e1dae-f193-4335-98fb-51c870814849,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-f0ca78e5-3a7d-4bb2-9a99-7a87e3733110,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-adfe7c12-5250-426a-bb54-c6a2b32cd672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590469603-172.17.0.6-1597530150376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40345,DS-5091b447-c353-44a3-8f7e-03f43277f91c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-970de6ea-7515-4e92-8178-5f04acb423fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-7520356b-e255-4867-b0ae-78cb22c9792d,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-9e6ef263-6247-413a-85cd-0ce3649d27cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-81dad04b-ccad-4690-b20c-73b1f946ef99,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-cc21a577-2d96-4a68-a294-cd45d7a7eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-ebd79f43-f99e-40f9-959e-c1b8f482ca73,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-f46b6970-b86d-45b5-947d-26187486ba70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590469603-172.17.0.6-1597530150376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40345,DS-5091b447-c353-44a3-8f7e-03f43277f91c,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-970de6ea-7515-4e92-8178-5f04acb423fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-7520356b-e255-4867-b0ae-78cb22c9792d,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-9e6ef263-6247-413a-85cd-0ce3649d27cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-81dad04b-ccad-4690-b20c-73b1f946ef99,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-cc21a577-2d96-4a68-a294-cd45d7a7eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-ebd79f43-f99e-40f9-959e-c1b8f482ca73,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-f46b6970-b86d-45b5-947d-26187486ba70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282652573-172.17.0.6-1597530193640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-5119812d-a2d0-400c-a120-61cf65022acc,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-0a3c9a98-3447-4c6e-b586-194d869b3614,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-c6d8ef31-d163-4aaa-a8a5-a56c04947e80,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-7aa49716-c71b-4362-b891-86cae1788410,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-7202a613-b985-4a04-90e7-d42015f9612f,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-27d7ac9c-6541-48d4-9874-ec769c90849f,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-a0e7de4d-28b4-41f5-9bb9-8aee8e7d2bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-0a015743-b772-4568-8ba8-a9804a333d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282652573-172.17.0.6-1597530193640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-5119812d-a2d0-400c-a120-61cf65022acc,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-0a3c9a98-3447-4c6e-b586-194d869b3614,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-c6d8ef31-d163-4aaa-a8a5-a56c04947e80,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-7aa49716-c71b-4362-b891-86cae1788410,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-7202a613-b985-4a04-90e7-d42015f9612f,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-27d7ac9c-6541-48d4-9874-ec769c90849f,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-a0e7de4d-28b4-41f5-9bb9-8aee8e7d2bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-0a015743-b772-4568-8ba8-a9804a333d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764868066-172.17.0.6-1597530314109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-6d6e679c-9cb5-4ad6-965f-b4ae10ebf1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-771c251b-6935-44a2-84f3-f59dd8e53e59,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-7c149faa-c41f-4807-ba54-fde9c0c3081a,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-e261f97b-df13-4e42-bc9e-37ad5c12adad,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-d5492fdb-a5b2-4428-8de8-b82734b7ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-41e9d7f5-9a9e-403b-aa53-fa41b81db4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-90d8d2d5-2657-4fd2-beb9-adb1bafad7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-28b54fca-78fb-4131-9c89-97463cf536fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764868066-172.17.0.6-1597530314109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-6d6e679c-9cb5-4ad6-965f-b4ae10ebf1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-771c251b-6935-44a2-84f3-f59dd8e53e59,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-7c149faa-c41f-4807-ba54-fde9c0c3081a,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-e261f97b-df13-4e42-bc9e-37ad5c12adad,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-d5492fdb-a5b2-4428-8de8-b82734b7ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-41e9d7f5-9a9e-403b-aa53-fa41b81db4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-90d8d2d5-2657-4fd2-beb9-adb1bafad7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-28b54fca-78fb-4131-9c89-97463cf536fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170343557-172.17.0.6-1597530848376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-d29a361e-4b16-49d2-8515-0c142ee09c82,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-b8a455f2-1634-4a25-9710-3d09033801bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-bcc33e43-ed09-4eac-bede-8ecde400ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-8109dfc7-c3a1-4442-a717-7ffa6bcb79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-b5d85670-2f29-441e-8eb4-5b59cbaac809,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-83f2caf7-9bb4-4fc8-ac8d-c2c52e678fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-4c583629-9c97-4507-a218-f7ea73ba85fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-a48174d1-ec68-4b82-bd4e-79048b69eae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170343557-172.17.0.6-1597530848376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-d29a361e-4b16-49d2-8515-0c142ee09c82,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-b8a455f2-1634-4a25-9710-3d09033801bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-bcc33e43-ed09-4eac-bede-8ecde400ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-8109dfc7-c3a1-4442-a717-7ffa6bcb79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-b5d85670-2f29-441e-8eb4-5b59cbaac809,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-83f2caf7-9bb4-4fc8-ac8d-c2c52e678fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-4c583629-9c97-4507-a218-f7ea73ba85fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-a48174d1-ec68-4b82-bd4e-79048b69eae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323244612-172.17.0.6-1597531045103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44377,DS-339cdb29-ad40-4f41-8a09-c3cf27f7342b,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-a069d24f-6a92-4342-9b3a-ab6cb634370f,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-baee312f-d21d-4a34-9191-879cc4708432,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-dd93ddaa-c814-4299-910d-baa118395cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-fd76c366-e55a-41a1-905a-26e334dddefa,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-02f5d23e-1f8e-4e9d-8096-aa89de9b4e16,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-aa564fdc-0355-4fc8-8986-f9b7e0d98d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-e5c35182-9b71-466a-abaf-044b8e6d549c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323244612-172.17.0.6-1597531045103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44377,DS-339cdb29-ad40-4f41-8a09-c3cf27f7342b,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-a069d24f-6a92-4342-9b3a-ab6cb634370f,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-baee312f-d21d-4a34-9191-879cc4708432,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-dd93ddaa-c814-4299-910d-baa118395cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-fd76c366-e55a-41a1-905a-26e334dddefa,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-02f5d23e-1f8e-4e9d-8096-aa89de9b4e16,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-aa564fdc-0355-4fc8-8986-f9b7e0d98d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-e5c35182-9b71-466a-abaf-044b8e6d549c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523675854-172.17.0.6-1597531122947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-2cf28332-ada9-4fee-bc12-c827b7b0e3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-94d6c9ee-1d83-4461-bec4-aec39fcf8797,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-3acd9a3c-b508-4b62-b07a-dc5d715b713e,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-6bd38d0b-6213-4c11-9e3a-df0f07cc9da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-7df87acb-3145-4edc-aaef-d9e37c285fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-4386a418-e92f-4315-b152-89db59e7fb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-ebe339cc-7960-4054-bde7-735584881552,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-640a204b-7c43-4fce-9e1d-ada38f66093d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523675854-172.17.0.6-1597531122947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-2cf28332-ada9-4fee-bc12-c827b7b0e3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-94d6c9ee-1d83-4461-bec4-aec39fcf8797,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-3acd9a3c-b508-4b62-b07a-dc5d715b713e,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-6bd38d0b-6213-4c11-9e3a-df0f07cc9da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-7df87acb-3145-4edc-aaef-d9e37c285fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-4386a418-e92f-4315-b152-89db59e7fb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-ebe339cc-7960-4054-bde7-735584881552,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-640a204b-7c43-4fce-9e1d-ada38f66093d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415569325-172.17.0.6-1597531360722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37718,DS-b2332af7-b21c-451f-b07d-ba2c8c125f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-7d067025-c607-43d8-9c16-83f829113e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-9056df3c-7132-41d3-8f98-2d6974ca35ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-4eaae075-3e43-442a-9d6d-e34621e5d748,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-3e14581b-2dbd-45c3-8ad6-827651356462,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-6cd3adfc-2ec1-4caa-84f4-f866cba62a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-f3af5b96-ec5b-40e7-91e1-3a5cecc35f32,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-cabf6cce-938b-4dd1-8dad-f589556caaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415569325-172.17.0.6-1597531360722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37718,DS-b2332af7-b21c-451f-b07d-ba2c8c125f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-7d067025-c607-43d8-9c16-83f829113e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-9056df3c-7132-41d3-8f98-2d6974ca35ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-4eaae075-3e43-442a-9d6d-e34621e5d748,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-3e14581b-2dbd-45c3-8ad6-827651356462,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-6cd3adfc-2ec1-4caa-84f4-f866cba62a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-f3af5b96-ec5b-40e7-91e1-3a5cecc35f32,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-cabf6cce-938b-4dd1-8dad-f589556caaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592716939-172.17.0.6-1597531605669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-e846398e-b88c-44b5-9042-1eb812c45282,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-4cfa60fd-f749-4ed2-b7ec-299292b1be38,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-c545ab8c-1197-4eb3-95a7-fa235a8d0430,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-faa2b8c8-9ad8-4167-b1e5-c866f6cc5ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-dee268ab-0ccf-44d2-a74d-bfba89de2327,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-dfc28976-15e7-4469-97d6-c4aba4fb915e,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-0bcc0102-dc9b-462a-b402-649a142b2405,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-1d1d08f2-4d3f-40c2-ab04-7953f3adc81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592716939-172.17.0.6-1597531605669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-e846398e-b88c-44b5-9042-1eb812c45282,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-4cfa60fd-f749-4ed2-b7ec-299292b1be38,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-c545ab8c-1197-4eb3-95a7-fa235a8d0430,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-faa2b8c8-9ad8-4167-b1e5-c866f6cc5ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-dee268ab-0ccf-44d2-a74d-bfba89de2327,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-dfc28976-15e7-4469-97d6-c4aba4fb915e,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-0bcc0102-dc9b-462a-b402-649a142b2405,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-1d1d08f2-4d3f-40c2-ab04-7953f3adc81b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530918795-172.17.0.6-1597531686508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-fcac10a9-4262-4a49-a239-db1486e56c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-5797d883-d193-4262-924c-867769d6a4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-fa7b6392-03b2-4749-9bfc-003ba836277b,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-cca16fa5-3f57-4cbb-bb5d-f2f3dd67a034,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-1e9f0c2c-1be0-48b7-95c8-e4ba57cb5825,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-67306878-5892-457e-a38b-019d7b0e76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-1546e0eb-a70d-4f4e-ac74-1d2e45538a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-e283ac56-2ccb-4f12-8ced-c869f9dca42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530918795-172.17.0.6-1597531686508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-fcac10a9-4262-4a49-a239-db1486e56c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-5797d883-d193-4262-924c-867769d6a4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-fa7b6392-03b2-4749-9bfc-003ba836277b,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-cca16fa5-3f57-4cbb-bb5d-f2f3dd67a034,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-1e9f0c2c-1be0-48b7-95c8-e4ba57cb5825,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-67306878-5892-457e-a38b-019d7b0e76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-1546e0eb-a70d-4f4e-ac74-1d2e45538a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-e283ac56-2ccb-4f12-8ced-c869f9dca42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39205470-172.17.0.6-1597531809979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-c8971f5f-83bf-4a73-b09b-e2aad229ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-3adfa567-8fa4-4ddf-93bb-dc809474a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-5f4eee50-c892-4941-ac2e-af20084dbe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-28bd04bf-d73b-44d6-a6c0-b5b35e983566,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-716a1125-a104-497d-92e4-1fc370b15d88,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-85c14403-d0b0-43dd-8c80-45d32a3cb9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-93266aae-67dc-4902-8c14-697a261dea96,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-417172ec-1391-4d53-91f7-066d7f59a008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39205470-172.17.0.6-1597531809979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-c8971f5f-83bf-4a73-b09b-e2aad229ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-3adfa567-8fa4-4ddf-93bb-dc809474a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-5f4eee50-c892-4941-ac2e-af20084dbe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-28bd04bf-d73b-44d6-a6c0-b5b35e983566,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-716a1125-a104-497d-92e4-1fc370b15d88,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-85c14403-d0b0-43dd-8c80-45d32a3cb9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-93266aae-67dc-4902-8c14-697a261dea96,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-417172ec-1391-4d53-91f7-066d7f59a008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985421830-172.17.0.6-1597532469502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37264,DS-43e234b8-82ce-439c-b968-4d4ead25fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-8704cd7d-b47f-42d1-8475-59035341dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-0e979dcb-a31f-479f-a5e0-c548c83154dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-d80ee589-c455-427a-a229-451892eb44b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-1cc77598-eba5-4cbe-89c2-ad0957db5b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-5129473a-0b1a-40ea-b7bc-a67eb2cacfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-575874e5-a6df-41f5-9208-32cac4e58a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-c6504f90-080b-409c-942d-13fb59696d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985421830-172.17.0.6-1597532469502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37264,DS-43e234b8-82ce-439c-b968-4d4ead25fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-8704cd7d-b47f-42d1-8475-59035341dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-0e979dcb-a31f-479f-a5e0-c548c83154dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-d80ee589-c455-427a-a229-451892eb44b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-1cc77598-eba5-4cbe-89c2-ad0957db5b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-5129473a-0b1a-40ea-b7bc-a67eb2cacfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-575874e5-a6df-41f5-9208-32cac4e58a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-c6504f90-080b-409c-942d-13fb59696d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412113571-172.17.0.6-1597532838057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-bca6fd27-5eb2-4cf4-a669-e922dfec85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-455dbfbe-5dde-410b-9420-33fe9b179609,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-e06f2aae-3226-47f0-9d68-93eb08b5ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-77a27b3c-15d4-4bd7-a120-989ed3e18015,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-327cdf1d-2315-41f4-9b91-448e2839a464,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-624fe4e2-fe4c-49bf-adaf-5dc71970ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-0f5350af-c963-43e1-8cb8-65b507b9a607,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-77afe79f-18a4-4697-b1fa-897d35e6c619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412113571-172.17.0.6-1597532838057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-bca6fd27-5eb2-4cf4-a669-e922dfec85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-455dbfbe-5dde-410b-9420-33fe9b179609,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-e06f2aae-3226-47f0-9d68-93eb08b5ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-77a27b3c-15d4-4bd7-a120-989ed3e18015,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-327cdf1d-2315-41f4-9b91-448e2839a464,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-624fe4e2-fe4c-49bf-adaf-5dc71970ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-0f5350af-c963-43e1-8cb8-65b507b9a607,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-77afe79f-18a4-4697-b1fa-897d35e6c619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5834
