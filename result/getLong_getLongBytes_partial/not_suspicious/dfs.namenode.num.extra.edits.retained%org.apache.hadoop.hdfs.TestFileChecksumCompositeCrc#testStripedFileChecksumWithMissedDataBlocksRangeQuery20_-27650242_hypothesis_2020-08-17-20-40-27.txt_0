reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625824796-172.17.0.17-1597697417245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-f40ccd60-5b03-4972-b325-faa74fa878d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-6a6dc67f-0070-443b-90d1-4f6637745bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-0b6d3d29-07d2-4b01-bee7-96aff88bf648,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-e90cbe92-f7be-46ee-b0ce-e37950f1dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-81aa60e6-c194-4127-bdf7-ea5e92bc12a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-6c6999c8-7100-45d2-8a2f-3334572b472e,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-0a94c789-6715-47ff-9453-eb979846976c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-37af89c1-9abe-4b7c-8c0d-cad748b0d985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625824796-172.17.0.17-1597697417245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-f40ccd60-5b03-4972-b325-faa74fa878d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-6a6dc67f-0070-443b-90d1-4f6637745bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-0b6d3d29-07d2-4b01-bee7-96aff88bf648,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-e90cbe92-f7be-46ee-b0ce-e37950f1dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-81aa60e6-c194-4127-bdf7-ea5e92bc12a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-6c6999c8-7100-45d2-8a2f-3334572b472e,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-0a94c789-6715-47ff-9453-eb979846976c,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-37af89c1-9abe-4b7c-8c0d-cad748b0d985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391330619-172.17.0.17-1597698036644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-ce62a89d-ae7c-46a9-a0da-767c3eac49c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-b9a1b181-2126-49e6-b7d3-51862d514771,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-e3121a7d-e203-4e93-87e2-b8757316e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-25670053-2b47-4f2d-b4f3-93049ad7e46f,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-3f614479-2caa-4d15-bb6e-ffe5a125d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-7ed1a1e2-ad08-4bdd-9295-c5528b0de8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-cc46f469-50ac-4b78-8de8-90a38fe11d67,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-0b93bdf2-0226-4b9e-955e-8c2bfb68abce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391330619-172.17.0.17-1597698036644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-ce62a89d-ae7c-46a9-a0da-767c3eac49c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-b9a1b181-2126-49e6-b7d3-51862d514771,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-e3121a7d-e203-4e93-87e2-b8757316e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-25670053-2b47-4f2d-b4f3-93049ad7e46f,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-3f614479-2caa-4d15-bb6e-ffe5a125d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-7ed1a1e2-ad08-4bdd-9295-c5528b0de8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-cc46f469-50ac-4b78-8de8-90a38fe11d67,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-0b93bdf2-0226-4b9e-955e-8c2bfb68abce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427288953-172.17.0.17-1597698199398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-c696923e-5fd2-49a0-bd09-2a203ef64b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-c1906236-5d52-4fcc-bf51-898a304b9f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-e4468772-8ec9-48fd-9b26-c3a96b608824,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-466929ee-f8e6-4a44-80f7-bc8162a0bca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-ee0062aa-f8f9-4fb9-a41f-0a7b0b76e631,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-7759e2d3-fa2f-47ed-8c41-6ebccdde169b,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-cb0931bd-7c42-4104-afde-866e0d245216,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-4e6f849d-a709-4c3f-bb35-601ca6f7cd2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1427288953-172.17.0.17-1597698199398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-c696923e-5fd2-49a0-bd09-2a203ef64b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-c1906236-5d52-4fcc-bf51-898a304b9f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-e4468772-8ec9-48fd-9b26-c3a96b608824,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-466929ee-f8e6-4a44-80f7-bc8162a0bca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-ee0062aa-f8f9-4fb9-a41f-0a7b0b76e631,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-7759e2d3-fa2f-47ed-8c41-6ebccdde169b,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-cb0931bd-7c42-4104-afde-866e0d245216,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-4e6f849d-a709-4c3f-bb35-601ca6f7cd2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453119101-172.17.0.17-1597698444495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45202,DS-f375c4cb-a190-4733-8b4a-f3b982e0fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-f6358085-f6e6-4c4d-8a8f-afecdffbb960,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-d85dec8b-b05f-4fc7-9dc0-a2b4451f2a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-54b3c520-61d9-426b-9cfb-8aa8e4a28200,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-7da1a8c5-852e-4f62-806f-bda39a17e880,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-e6133d04-ed4b-455c-a7a2-e2db99d799c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-5df390a4-e602-43f0-8764-ced61a3218fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-bf351126-e2cc-4be7-be02-f93285401a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453119101-172.17.0.17-1597698444495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45202,DS-f375c4cb-a190-4733-8b4a-f3b982e0fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-f6358085-f6e6-4c4d-8a8f-afecdffbb960,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-d85dec8b-b05f-4fc7-9dc0-a2b4451f2a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-54b3c520-61d9-426b-9cfb-8aa8e4a28200,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-7da1a8c5-852e-4f62-806f-bda39a17e880,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-e6133d04-ed4b-455c-a7a2-e2db99d799c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-5df390a4-e602-43f0-8764-ced61a3218fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-bf351126-e2cc-4be7-be02-f93285401a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132937050-172.17.0.17-1597698551850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40021,DS-5ebe4f34-335f-4cc5-8d19-cf955d13f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-dbfb414c-2e5d-44ec-b565-5c44f98e3e55,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-4685657a-09a6-4894-b5bd-c49d7158c196,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-6178c3f3-07e3-4156-9c04-1359b20c1f61,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-232e2657-fae7-4849-98ab-82a414e7dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-340334b3-6a4a-4cfc-b44f-0b63f8471cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-041d31cc-6a67-4d06-836f-ec5df1f86a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-fbd08e87-c35d-4931-8d58-1f17a096165f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132937050-172.17.0.17-1597698551850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40021,DS-5ebe4f34-335f-4cc5-8d19-cf955d13f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-dbfb414c-2e5d-44ec-b565-5c44f98e3e55,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-4685657a-09a6-4894-b5bd-c49d7158c196,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-6178c3f3-07e3-4156-9c04-1359b20c1f61,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-232e2657-fae7-4849-98ab-82a414e7dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-340334b3-6a4a-4cfc-b44f-0b63f8471cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-041d31cc-6a67-4d06-836f-ec5df1f86a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-fbd08e87-c35d-4931-8d58-1f17a096165f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023651272-172.17.0.17-1597698815424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38802,DS-0bda5934-fcca-4135-86ac-9a0cbc30b61e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-094d8aa6-c2be-48f8-ba97-862580ed7cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-a3992e81-3d4f-4d5e-bc58-3c9509aa9b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-ab2c4249-db44-4c17-bdec-6e0403ffb0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-73665f5c-7d78-43fe-97b5-3f1d050a2dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-5cd2acdf-f7e7-41cc-86af-f6c97b19342e,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-6ba6be32-db4c-48ff-8286-4713c6724af9,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-7edf76a5-5a2c-41a1-bb92-619f7f1e9223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023651272-172.17.0.17-1597698815424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38802,DS-0bda5934-fcca-4135-86ac-9a0cbc30b61e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-094d8aa6-c2be-48f8-ba97-862580ed7cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-a3992e81-3d4f-4d5e-bc58-3c9509aa9b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-ab2c4249-db44-4c17-bdec-6e0403ffb0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-73665f5c-7d78-43fe-97b5-3f1d050a2dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-5cd2acdf-f7e7-41cc-86af-f6c97b19342e,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-6ba6be32-db4c-48ff-8286-4713c6724af9,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-7edf76a5-5a2c-41a1-bb92-619f7f1e9223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529857373-172.17.0.17-1597698971012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39876,DS-64de6151-a292-40b4-be41-9085e7067bda,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-8fe1ca95-fcdb-4451-9d1d-a8c1cdb18969,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-9c8d3865-3b42-467e-bcf7-4f69b85095c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-baf67b3f-18da-462e-ad7b-33adabf21d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-0663d622-8e2e-4f0b-a2c2-93088e68468c,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-17e86a06-4a00-44a7-a5d8-72b44882a6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-350f0861-d285-47bc-b57e-0641a6bd2605,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-61189939-d151-4313-aa53-b857b23971be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529857373-172.17.0.17-1597698971012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39876,DS-64de6151-a292-40b4-be41-9085e7067bda,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-8fe1ca95-fcdb-4451-9d1d-a8c1cdb18969,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-9c8d3865-3b42-467e-bcf7-4f69b85095c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-baf67b3f-18da-462e-ad7b-33adabf21d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-0663d622-8e2e-4f0b-a2c2-93088e68468c,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-17e86a06-4a00-44a7-a5d8-72b44882a6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-350f0861-d285-47bc-b57e-0641a6bd2605,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-61189939-d151-4313-aa53-b857b23971be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119501963-172.17.0.17-1597699123463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-65939f9a-9de0-443a-873b-b59d90f93656,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-7b208273-e277-41ac-87de-12288066f148,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-154996ae-1219-4f97-90ed-89043197b7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-0379b8d8-54d6-48e7-95ee-0b40d0e52c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-af2a02af-d297-4cca-8226-5959c6d5c937,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-cc3f2eda-6763-4b80-ad98-ed617a0554a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-0b43f888-857e-41fc-bcfe-f4b8aec0a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-cb714963-e77f-4046-8ab6-617cecc50113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119501963-172.17.0.17-1597699123463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-65939f9a-9de0-443a-873b-b59d90f93656,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-7b208273-e277-41ac-87de-12288066f148,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-154996ae-1219-4f97-90ed-89043197b7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-0379b8d8-54d6-48e7-95ee-0b40d0e52c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-af2a02af-d297-4cca-8226-5959c6d5c937,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-cc3f2eda-6763-4b80-ad98-ed617a0554a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-0b43f888-857e-41fc-bcfe-f4b8aec0a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-cb714963-e77f-4046-8ab6-617cecc50113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298043091-172.17.0.17-1597699955090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33534,DS-67288b5d-db6d-4121-b8a7-0fdcbf10723b,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-323d14a7-9f21-413e-bdf7-6485225e8b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-80840990-ae9b-40ed-9837-5bcaa41895e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-82a0430a-88c2-4916-bff0-228250ae3954,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-f84284c1-2933-464e-9405-8fb2e6a8e572,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-129090f1-b289-4ee1-b0e3-2776162fcb20,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-7f1fa704-dbe5-4673-8240-3ca12c8133dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-78edc814-916e-4820-9129-65269f1afc59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298043091-172.17.0.17-1597699955090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33534,DS-67288b5d-db6d-4121-b8a7-0fdcbf10723b,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-323d14a7-9f21-413e-bdf7-6485225e8b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-80840990-ae9b-40ed-9837-5bcaa41895e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-82a0430a-88c2-4916-bff0-228250ae3954,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-f84284c1-2933-464e-9405-8fb2e6a8e572,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-129090f1-b289-4ee1-b0e3-2776162fcb20,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-7f1fa704-dbe5-4673-8240-3ca12c8133dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-78edc814-916e-4820-9129-65269f1afc59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271351462-172.17.0.17-1597700290248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-390a5855-074c-4a9a-85f3-8b52eff3cfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-174330fe-3646-444c-8ef2-b380ec4513b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-eff1ad8d-a36a-4f6e-a17c-16c7eaceccca,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-edabc944-b337-48ab-993a-8b712fb02084,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-3a372bdd-084c-4813-9efa-b03c7e33b1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-66e26ae5-fa03-457c-bdc3-53f20c1ec8df,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-d52c40df-0009-40fb-acae-b6766aa75e98,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-03083f4d-9081-4d3a-9cd6-d2b628e3cad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271351462-172.17.0.17-1597700290248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-390a5855-074c-4a9a-85f3-8b52eff3cfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-174330fe-3646-444c-8ef2-b380ec4513b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-eff1ad8d-a36a-4f6e-a17c-16c7eaceccca,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-edabc944-b337-48ab-993a-8b712fb02084,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-3a372bdd-084c-4813-9efa-b03c7e33b1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-66e26ae5-fa03-457c-bdc3-53f20c1ec8df,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-d52c40df-0009-40fb-acae-b6766aa75e98,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-03083f4d-9081-4d3a-9cd6-d2b628e3cad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556324281-172.17.0.17-1597700547933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38286,DS-7a1c171b-d21c-4834-97ef-f527fae2ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-cef485e6-239e-4d65-b61a-b6a0bc40780c,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-09f4d9f2-9c87-4ad4-9784-34a200402f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-f634cb07-2dd0-432b-a626-84b75c5e8b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-445d488f-807a-47a1-96d9-ad32e933c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-5597b17a-1aa6-454c-a750-e48b2ab2e917,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-ae1fc1f2-4bcd-4711-82be-6dbd9313a898,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-333c9cc5-46aa-4933-b927-ad7c46d0b210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556324281-172.17.0.17-1597700547933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38286,DS-7a1c171b-d21c-4834-97ef-f527fae2ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-cef485e6-239e-4d65-b61a-b6a0bc40780c,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-09f4d9f2-9c87-4ad4-9784-34a200402f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-f634cb07-2dd0-432b-a626-84b75c5e8b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-445d488f-807a-47a1-96d9-ad32e933c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-5597b17a-1aa6-454c-a750-e48b2ab2e917,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-ae1fc1f2-4bcd-4711-82be-6dbd9313a898,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-333c9cc5-46aa-4933-b927-ad7c46d0b210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275669345-172.17.0.17-1597700944021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-012198f5-8a6b-46a6-8ecd-d99eb550d55e,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-8c3ab06a-3ca5-4cfb-82e7-df8c844800c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-d39947f8-861c-46bd-8b9a-3d57d5ce73fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-7a05b1d0-a497-4f91-9cb4-aec438889f26,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-cf1e276e-50a9-47a1-bd75-944635215eac,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-1734c197-9413-4226-8015-cf9ee5712dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-3c180560-4378-403d-8128-7ab295fef238,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-2f362231-39f3-452f-a09e-61ce008dd470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275669345-172.17.0.17-1597700944021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-012198f5-8a6b-46a6-8ecd-d99eb550d55e,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-8c3ab06a-3ca5-4cfb-82e7-df8c844800c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-d39947f8-861c-46bd-8b9a-3d57d5ce73fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-7a05b1d0-a497-4f91-9cb4-aec438889f26,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-cf1e276e-50a9-47a1-bd75-944635215eac,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-1734c197-9413-4226-8015-cf9ee5712dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-3c180560-4378-403d-8128-7ab295fef238,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-2f362231-39f3-452f-a09e-61ce008dd470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138498684-172.17.0.17-1597701292804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-f76b7163-142b-4168-97d6-a88eb4140e80,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-4382b404-d299-43f4-bc19-75582dc9ace5,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-b7a8c793-4d1c-4e01-b6a0-0d303d626918,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-01102097-4367-4665-bf39-6c3ad8e82b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-394bcc9b-6b56-4202-951b-2339861348d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-744329e0-efd9-48d3-bbbd-7e22ad39aa54,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-e6b81d5e-48c7-409e-b279-ce7c5fb21396,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-6c7417fc-a46c-4b82-80d7-186b6063f501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138498684-172.17.0.17-1597701292804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-f76b7163-142b-4168-97d6-a88eb4140e80,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-4382b404-d299-43f4-bc19-75582dc9ace5,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-b7a8c793-4d1c-4e01-b6a0-0d303d626918,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-01102097-4367-4665-bf39-6c3ad8e82b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-394bcc9b-6b56-4202-951b-2339861348d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-744329e0-efd9-48d3-bbbd-7e22ad39aa54,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-e6b81d5e-48c7-409e-b279-ce7c5fb21396,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-6c7417fc-a46c-4b82-80d7-186b6063f501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 1000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561157368-172.17.0.17-1597701765241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-2308b459-ffab-4586-9a4f-c9d928913a79,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-fefcdded-9675-439e-ba2e-096f1d6af043,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-19d6f4bd-c6a4-4975-aaeb-add06ea0e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-e3a1662e-4b27-48aa-995c-00e4221295b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-87776070-702d-4ba8-bcc9-87bbebdcf143,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-0647cab0-6811-4252-ba4e-64ec961d20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-182e4622-b262-43a8-9dea-9847d505664e,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-6101bb0f-b2b0-4452-856a-3eef0738a953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561157368-172.17.0.17-1597701765241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-2308b459-ffab-4586-9a4f-c9d928913a79,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-fefcdded-9675-439e-ba2e-096f1d6af043,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-19d6f4bd-c6a4-4975-aaeb-add06ea0e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-e3a1662e-4b27-48aa-995c-00e4221295b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-87776070-702d-4ba8-bcc9-87bbebdcf143,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-0647cab0-6811-4252-ba4e-64ec961d20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-182e4622-b262-43a8-9dea-9847d505664e,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-6101bb0f-b2b0-4452-856a-3eef0738a953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5382
