reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088199077-172.17.0.8-1597410841899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-ce200da7-3db4-4230-b968-d93f99b8e686,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-4d20c525-b6c4-4e08-826d-9cc3d21da6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-38a75052-ec8b-49f1-a5cd-193881abdae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-801ad46b-40f2-4a53-ad92-ec82b74fb284,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-6245f764-e238-4ac6-96c3-e45b29f5059d,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-ad434a37-5c5f-4363-8e0e-04a45dac0d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-13c1efe2-ab8d-434c-b431-321bfe3f13b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-e438883b-9f9d-4e63-acb5-a580d5ef3b88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088199077-172.17.0.8-1597410841899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33993,DS-ce200da7-3db4-4230-b968-d93f99b8e686,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-4d20c525-b6c4-4e08-826d-9cc3d21da6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-38a75052-ec8b-49f1-a5cd-193881abdae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-801ad46b-40f2-4a53-ad92-ec82b74fb284,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-6245f764-e238-4ac6-96c3-e45b29f5059d,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-ad434a37-5c5f-4363-8e0e-04a45dac0d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-13c1efe2-ab8d-434c-b431-321bfe3f13b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-e438883b-9f9d-4e63-acb5-a580d5ef3b88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396693907-172.17.0.8-1597411292344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-712d7515-2c27-4177-a6a4-40d54914e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-d7f716c0-4a28-4c30-8f90-ff8a5e70eec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-abb21809-a18e-4a33-b0df-20df98aa1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-4e9eb218-8de6-4bfa-9011-86bf49ebd60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-156a3293-a51b-4717-899a-389d93f7102d,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-331e282b-9a15-4d4a-aed5-daa81ace34ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-9b9bf73f-1dcb-4af0-9d6f-2a1f4c840d04,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-ec88fba8-c9b6-46cd-928c-df7b91e6fa61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396693907-172.17.0.8-1597411292344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-712d7515-2c27-4177-a6a4-40d54914e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-d7f716c0-4a28-4c30-8f90-ff8a5e70eec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-abb21809-a18e-4a33-b0df-20df98aa1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-4e9eb218-8de6-4bfa-9011-86bf49ebd60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-156a3293-a51b-4717-899a-389d93f7102d,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-331e282b-9a15-4d4a-aed5-daa81ace34ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-9b9bf73f-1dcb-4af0-9d6f-2a1f4c840d04,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-ec88fba8-c9b6-46cd-928c-df7b91e6fa61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924332936-172.17.0.8-1597411499642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37854,DS-9432e966-92ab-4e52-8b91-d229a2c87202,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-e7caefec-2149-46e4-acc6-2b5a65fecb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-f8f89d4c-2979-4bae-999e-ae28c77debea,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-4b54e327-e0bc-426b-9337-873c0d4b37fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-a65d7e92-a3d3-49b1-9689-3f07365440ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-bee4cfa3-16bb-4b54-99a9-9833f169b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-ab38b9fa-32b1-4ee2-9a7a-b9094688fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-a1d86660-0180-44f8-96d0-1bc2b55de25b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924332936-172.17.0.8-1597411499642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37854,DS-9432e966-92ab-4e52-8b91-d229a2c87202,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-e7caefec-2149-46e4-acc6-2b5a65fecb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-f8f89d4c-2979-4bae-999e-ae28c77debea,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-4b54e327-e0bc-426b-9337-873c0d4b37fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-a65d7e92-a3d3-49b1-9689-3f07365440ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-bee4cfa3-16bb-4b54-99a9-9833f169b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-ab38b9fa-32b1-4ee2-9a7a-b9094688fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-a1d86660-0180-44f8-96d0-1bc2b55de25b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519652416-172.17.0.8-1597411702461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44881,DS-1565c3b2-f45d-4498-9b6c-abe7691bee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-22bc4593-7dc3-4f9e-bc60-bc983618d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-36b9ce2a-d4b0-40b8-b1d5-3c426b50482a,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-2ec832e2-3263-4e17-8fc2-01ec26751720,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-fac0de43-b41a-4918-a084-a6ba51a530ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-c91b673b-0961-4513-b5cf-2867c60010f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-d04a0fcd-9fc3-45db-af4f-8768fc236abc,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-1df0f6e0-cc23-4424-b200-446b481b1898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519652416-172.17.0.8-1597411702461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44881,DS-1565c3b2-f45d-4498-9b6c-abe7691bee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-22bc4593-7dc3-4f9e-bc60-bc983618d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-36b9ce2a-d4b0-40b8-b1d5-3c426b50482a,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-2ec832e2-3263-4e17-8fc2-01ec26751720,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-fac0de43-b41a-4918-a084-a6ba51a530ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-c91b673b-0961-4513-b5cf-2867c60010f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-d04a0fcd-9fc3-45db-af4f-8768fc236abc,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-1df0f6e0-cc23-4424-b200-446b481b1898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918692169-172.17.0.8-1597412756238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-a537ba27-5da7-4f29-b090-81d789e2cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-9dd2f512-712e-4a0e-be13-1f032c8c8a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-c9c1ebe3-bdf6-4730-b49e-e885a5a424fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-b580464d-18f1-4565-9804-9a07d1d6d8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-83ec66e1-fb11-4e06-9553-98b4dedbd9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-3bf2f804-1458-4e41-9044-995ffdcf43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-32cb290f-58da-4dfe-88dc-c72d38134af6,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-78579447-7791-47a8-94bf-9fb247c8e69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918692169-172.17.0.8-1597412756238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-a537ba27-5da7-4f29-b090-81d789e2cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-9dd2f512-712e-4a0e-be13-1f032c8c8a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-c9c1ebe3-bdf6-4730-b49e-e885a5a424fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-b580464d-18f1-4565-9804-9a07d1d6d8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-83ec66e1-fb11-4e06-9553-98b4dedbd9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-3bf2f804-1458-4e41-9044-995ffdcf43d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-32cb290f-58da-4dfe-88dc-c72d38134af6,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-78579447-7791-47a8-94bf-9fb247c8e69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361201544-172.17.0.8-1597413298903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33233,DS-afd90332-b9e0-4105-b7d6-98aaed3727e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-ee3f5f8a-92b9-4bcb-8826-26eadeb889ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-417781c3-fd5b-44b4-ab83-4b54829a7776,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-b9545707-980d-48b6-bb24-11659101b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-7b7c872c-023a-495b-8b59-3a523456e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-ccd37045-77ca-4a1c-a099-bd76d6cb53f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-637ea90d-59f9-4668-bb47-ae931763d55f,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-aad70f2a-b096-4bd4-bc77-bf311f33d271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361201544-172.17.0.8-1597413298903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33233,DS-afd90332-b9e0-4105-b7d6-98aaed3727e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-ee3f5f8a-92b9-4bcb-8826-26eadeb889ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-417781c3-fd5b-44b4-ab83-4b54829a7776,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-b9545707-980d-48b6-bb24-11659101b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-7b7c872c-023a-495b-8b59-3a523456e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-ccd37045-77ca-4a1c-a099-bd76d6cb53f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-637ea90d-59f9-4668-bb47-ae931763d55f,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-aad70f2a-b096-4bd4-bc77-bf311f33d271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887071812-172.17.0.8-1597413348637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32865,DS-ab066ad5-6829-4535-a44c-347adf662aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-b830b2bf-d5a1-495e-870b-0829ad535b60,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-7959dba1-90f8-4a8f-8744-6478eda6faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-750e8c2d-d747-4707-980f-80dfc37da2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-9240333f-be14-469a-888c-0707e643994e,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-1bcd7062-2388-4dec-8d29-a7d1a740f8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-563a68e3-7b6d-479c-bd7c-1c82e21203ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-23013e8d-04e3-44cc-bcb0-11b735f93f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887071812-172.17.0.8-1597413348637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32865,DS-ab066ad5-6829-4535-a44c-347adf662aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-b830b2bf-d5a1-495e-870b-0829ad535b60,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-7959dba1-90f8-4a8f-8744-6478eda6faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-750e8c2d-d747-4707-980f-80dfc37da2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-9240333f-be14-469a-888c-0707e643994e,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-1bcd7062-2388-4dec-8d29-a7d1a740f8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-563a68e3-7b6d-479c-bd7c-1c82e21203ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-23013e8d-04e3-44cc-bcb0-11b735f93f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705902230-172.17.0.8-1597413763181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-c49cec05-3648-48d4-8215-6e41eebdd201,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-85b3c8fd-3c38-46a1-a093-3c9de06b0109,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-46799278-ed5f-43a7-8d65-bfea280f059f,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-0e0d565a-cb7a-4795-943a-5e4489708610,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-67db7173-13ec-4991-97de-90e6bf4afef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-447c9721-902b-4a32-a225-9d1c47e720fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-b07baaa6-670e-47cb-9140-53300e49775d,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-3ac74cde-29c0-42e1-94c7-300b5d662322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705902230-172.17.0.8-1597413763181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-c49cec05-3648-48d4-8215-6e41eebdd201,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-85b3c8fd-3c38-46a1-a093-3c9de06b0109,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-46799278-ed5f-43a7-8d65-bfea280f059f,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-0e0d565a-cb7a-4795-943a-5e4489708610,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-67db7173-13ec-4991-97de-90e6bf4afef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-447c9721-902b-4a32-a225-9d1c47e720fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-b07baaa6-670e-47cb-9140-53300e49775d,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-3ac74cde-29c0-42e1-94c7-300b5d662322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589970754-172.17.0.8-1597413969145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-7b4fbdf8-b372-48bd-a94d-12610ea98c93,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-aac41c0e-9ea7-442d-875a-d594d2b12305,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-f34f9d3b-af73-4c68-bba9-f083919918c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-c74cb2aa-90d7-42c4-887d-f3ff5ba3c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-5a3be4e7-b7c5-4ce4-b345-ea6be45ebfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-f8ebd58e-9145-4559-9d6f-5d8a647a4314,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-6a29d5a5-3a1c-4be4-ab38-4758444ce007,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-28103265-2f53-42c7-870b-5c5546aeabcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589970754-172.17.0.8-1597413969145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-7b4fbdf8-b372-48bd-a94d-12610ea98c93,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-aac41c0e-9ea7-442d-875a-d594d2b12305,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-f34f9d3b-af73-4c68-bba9-f083919918c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-c74cb2aa-90d7-42c4-887d-f3ff5ba3c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-5a3be4e7-b7c5-4ce4-b345-ea6be45ebfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-f8ebd58e-9145-4559-9d6f-5d8a647a4314,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-6a29d5a5-3a1c-4be4-ab38-4758444ce007,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-28103265-2f53-42c7-870b-5c5546aeabcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029836986-172.17.0.8-1597414845674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-a867483e-d3df-421b-926e-31e304431ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-b6bfb01f-adda-44b0-8ad0-e35a36d11941,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-58cc7ce0-bb2e-4a36-b254-1fb681a4e61d,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-8aa54899-13f5-47e5-b7a4-d779fee6d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-1b8a2fae-bdb7-4992-858c-62f6e4229e41,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-0d19b126-a073-478d-89bf-25ddfa90ee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-99a6b095-820f-4ecc-bc46-3b281319b5be,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-ec72c437-28a1-435e-9f54-e66359267477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029836986-172.17.0.8-1597414845674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-a867483e-d3df-421b-926e-31e304431ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-b6bfb01f-adda-44b0-8ad0-e35a36d11941,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-58cc7ce0-bb2e-4a36-b254-1fb681a4e61d,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-8aa54899-13f5-47e5-b7a4-d779fee6d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-1b8a2fae-bdb7-4992-858c-62f6e4229e41,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-0d19b126-a073-478d-89bf-25ddfa90ee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-99a6b095-820f-4ecc-bc46-3b281319b5be,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-ec72c437-28a1-435e-9f54-e66359267477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436628141-172.17.0.8-1597414979691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37399,DS-8726f20c-c992-4916-ae40-a6a3d52f95c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-9cbb6c01-1530-499c-bbaf-b6c0bc17de19,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-3f98fc3d-22f6-41ba-80a7-8c85820f8a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-a90f4d89-1807-47f6-9128-d4643d7b0954,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-2b05c6eb-8567-4ad5-86c7-bf02f9ee05be,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-e458fb10-c2e6-4512-aede-1c07132edbed,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-9ec8fb3f-5292-4f9d-9419-aa0c51d404f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-f70cba4e-8640-46d5-a09d-fbefdf2061a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436628141-172.17.0.8-1597414979691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37399,DS-8726f20c-c992-4916-ae40-a6a3d52f95c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-9cbb6c01-1530-499c-bbaf-b6c0bc17de19,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-3f98fc3d-22f6-41ba-80a7-8c85820f8a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-a90f4d89-1807-47f6-9128-d4643d7b0954,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-2b05c6eb-8567-4ad5-86c7-bf02f9ee05be,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-e458fb10-c2e6-4512-aede-1c07132edbed,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-9ec8fb3f-5292-4f9d-9419-aa0c51d404f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-f70cba4e-8640-46d5-a09d-fbefdf2061a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984944298-172.17.0.8-1597415025794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34918,DS-11545d00-0315-4c04-9e35-491ccf676b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-33af043f-4c2f-4461-90b1-6b7393dcd8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-df1023c3-d90b-4aaa-8de7-215835235c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-d6e348cb-08fc-42ae-adb0-1c0170638c35,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-0052a962-c46f-4042-8591-3de5995deeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-cf77c5a6-69ef-4003-82f3-2021202608e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-15b6bfb4-8add-4302-8b9e-b0823d297035,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-cfab541b-0c9a-46ea-86d6-ee46bd5b042f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984944298-172.17.0.8-1597415025794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34918,DS-11545d00-0315-4c04-9e35-491ccf676b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-33af043f-4c2f-4461-90b1-6b7393dcd8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-df1023c3-d90b-4aaa-8de7-215835235c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-d6e348cb-08fc-42ae-adb0-1c0170638c35,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-0052a962-c46f-4042-8591-3de5995deeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-cf77c5a6-69ef-4003-82f3-2021202608e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-15b6bfb4-8add-4302-8b9e-b0823d297035,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-cfab541b-0c9a-46ea-86d6-ee46bd5b042f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169616384-172.17.0.8-1597415405880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-3555290d-f216-4b93-9dfb-a6fda19a953c,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-3ca7ac1e-1e14-4cfe-9f9f-d6c26fa9edf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-21c29361-b678-4c69-bd08-4bed19583a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-b811d32b-c8ea-4390-965a-cd62cd02a579,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-ac2dad23-54b5-4aa3-866f-08d8d87c216c,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-c254b002-7f1e-4e67-aed1-8e11ee5c2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-93d35b15-2761-4c44-a5ba-3ee24bf631fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-a6d748f8-606f-4a25-aaed-3c38cea927af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169616384-172.17.0.8-1597415405880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-3555290d-f216-4b93-9dfb-a6fda19a953c,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-3ca7ac1e-1e14-4cfe-9f9f-d6c26fa9edf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-21c29361-b678-4c69-bd08-4bed19583a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-b811d32b-c8ea-4390-965a-cd62cd02a579,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-ac2dad23-54b5-4aa3-866f-08d8d87c216c,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-c254b002-7f1e-4e67-aed1-8e11ee5c2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-93d35b15-2761-4c44-a5ba-3ee24bf631fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-a6d748f8-606f-4a25-aaed-3c38cea927af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888322531-172.17.0.8-1597415492360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40151,DS-d534c06d-3d8c-4b53-86cf-785f4717eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-21ef3e14-4c17-4073-99ba-c0a1ef17ff98,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-33401de5-0c90-4395-9463-62bb11e1deba,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-6d636a3b-7d4e-4e73-aecb-aee46f827699,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-a1b7fc8c-9349-4701-a6e5-f967b67b230f,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-3ce37be0-754d-43d9-90b3-e62ecccc844f,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-98045027-1dca-4679-86f0-eb8c3c671bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-35306ea7-f6d5-4570-8909-90623abb2da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888322531-172.17.0.8-1597415492360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40151,DS-d534c06d-3d8c-4b53-86cf-785f4717eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-21ef3e14-4c17-4073-99ba-c0a1ef17ff98,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-33401de5-0c90-4395-9463-62bb11e1deba,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-6d636a3b-7d4e-4e73-aecb-aee46f827699,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-a1b7fc8c-9349-4701-a6e5-f967b67b230f,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-3ce37be0-754d-43d9-90b3-e62ecccc844f,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-98045027-1dca-4679-86f0-eb8c3c671bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-35306ea7-f6d5-4570-8909-90623abb2da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032240488-172.17.0.8-1597415585874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-e3eef876-2a67-4eea-ad7a-69c42134b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-9335de4a-ecac-4020-af89-f68316315efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-39056636-0a8a-4c5d-8109-a19f252e7f08,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-4ad78b67-7e1f-4919-91a6-7f6ba4498a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-a606c7c8-6329-443d-ae14-82f969bea618,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-27ea716f-5a3b-4dff-b61d-aee19f55bc77,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-14d09dcc-5ea2-466c-bb0a-cfdbbeea85e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-0aae59c8-ad13-4893-bc1c-2f7260c87173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032240488-172.17.0.8-1597415585874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-e3eef876-2a67-4eea-ad7a-69c42134b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-9335de4a-ecac-4020-af89-f68316315efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-39056636-0a8a-4c5d-8109-a19f252e7f08,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-4ad78b67-7e1f-4919-91a6-7f6ba4498a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-a606c7c8-6329-443d-ae14-82f969bea618,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-27ea716f-5a3b-4dff-b61d-aee19f55bc77,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-14d09dcc-5ea2-466c-bb0a-cfdbbeea85e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-0aae59c8-ad13-4893-bc1c-2f7260c87173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491374561-172.17.0.8-1597415754839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34551,DS-da2451cd-7ba8-4a44-a6f1-8c837b26eaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-6235b6d6-dea8-41b5-942e-f36be974ddd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-6b954a47-9429-4fc8-9e1d-e719ae4f76cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-a49f99d5-4e15-4d34-95df-5bcba0f0448c,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-67af7095-85e0-4a35-b097-db6d858791f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-02a150a0-badf-4bc5-a881-0a019ac9b149,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-b7bca7fe-6c60-426e-be0e-6a19e64af1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-51089a56-0084-4344-a1eb-c36eeac273c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491374561-172.17.0.8-1597415754839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34551,DS-da2451cd-7ba8-4a44-a6f1-8c837b26eaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-6235b6d6-dea8-41b5-942e-f36be974ddd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-6b954a47-9429-4fc8-9e1d-e719ae4f76cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-a49f99d5-4e15-4d34-95df-5bcba0f0448c,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-67af7095-85e0-4a35-b097-db6d858791f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-02a150a0-badf-4bc5-a881-0a019ac9b149,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-b7bca7fe-6c60-426e-be0e-6a19e64af1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-51089a56-0084-4344-a1eb-c36eeac273c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813397653-172.17.0.8-1597416128649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-a5cba666-ca06-4e5c-b525-66abeb985e76,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-8050d328-6f4b-426f-922f-b0b31c26ee75,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-546cd3e3-5bf7-47fe-804d-29e78095a7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-d00cff97-40d5-4a06-82b7-6a3dfe27ed20,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-ee927b18-068d-4b07-aad5-75aaf45d292e,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-98ed8591-0845-43d2-9dc0-15d434df4b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-a6348379-d0dd-44a9-8cc4-cb5c6e875f34,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-c347f401-ce16-4c0d-bef8-558e71200873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813397653-172.17.0.8-1597416128649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-a5cba666-ca06-4e5c-b525-66abeb985e76,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-8050d328-6f4b-426f-922f-b0b31c26ee75,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-546cd3e3-5bf7-47fe-804d-29e78095a7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-d00cff97-40d5-4a06-82b7-6a3dfe27ed20,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-ee927b18-068d-4b07-aad5-75aaf45d292e,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-98ed8591-0845-43d2-9dc0-15d434df4b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-a6348379-d0dd-44a9-8cc4-cb5c6e875f34,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-c347f401-ce16-4c0d-bef8-558e71200873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054643998-172.17.0.8-1597416205524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-1af1c477-7cb9-4f41-aced-c1b0c441c148,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-7d8e78ae-fed9-41ba-bd34-e997d4f3f178,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-8df2ff25-32fb-4c1a-b77a-b12f9d5bf922,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-460f3289-80ae-4d5e-b4e6-515759b5e73f,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-b62cd763-002d-4395-a53c-97d36913cfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-bcc244a9-0843-44b4-9c81-f9b46b8d7892,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-5bfd3935-f330-4780-a3c0-77b33a4ca88a,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-a5d2297a-1b62-48b8-b7a7-96c123e88d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054643998-172.17.0.8-1597416205524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-1af1c477-7cb9-4f41-aced-c1b0c441c148,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-7d8e78ae-fed9-41ba-bd34-e997d4f3f178,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-8df2ff25-32fb-4c1a-b77a-b12f9d5bf922,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-460f3289-80ae-4d5e-b4e6-515759b5e73f,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-b62cd763-002d-4395-a53c-97d36913cfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-bcc244a9-0843-44b4-9c81-f9b46b8d7892,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-5bfd3935-f330-4780-a3c0-77b33a4ca88a,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-a5d2297a-1b62-48b8-b7a7-96c123e88d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183755057-172.17.0.8-1597416661673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35889,DS-888c0f2f-36d4-4093-9456-7eeb1a76d74e,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-91230e74-c7b2-4d26-8a02-6445100aec97,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-dd47b5a5-075f-4255-9270-6ca8c2292f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-3ab60b85-4f75-4589-be90-20edc3c575b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-f0f9842b-275f-43da-aff9-833107bbdd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-e9039cca-3181-4831-b164-e4717f4b048d,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-af1664df-8d64-4a5b-964a-1416634970a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-c80f0434-4417-4879-b919-84b3c2b2017b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183755057-172.17.0.8-1597416661673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35889,DS-888c0f2f-36d4-4093-9456-7eeb1a76d74e,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-91230e74-c7b2-4d26-8a02-6445100aec97,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-dd47b5a5-075f-4255-9270-6ca8c2292f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-3ab60b85-4f75-4589-be90-20edc3c575b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-f0f9842b-275f-43da-aff9-833107bbdd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-e9039cca-3181-4831-b164-e4717f4b048d,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-af1664df-8d64-4a5b-964a-1416634970a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-c80f0434-4417-4879-b919-84b3c2b2017b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6371
