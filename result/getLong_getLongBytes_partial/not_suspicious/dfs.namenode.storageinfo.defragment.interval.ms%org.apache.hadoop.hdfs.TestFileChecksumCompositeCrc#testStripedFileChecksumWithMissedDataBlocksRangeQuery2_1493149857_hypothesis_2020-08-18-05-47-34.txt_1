reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769475096-172.17.0.9-1597729877016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-b9229309-184b-43f6-b37a-5924803cfc13,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-ad538ebd-611b-42cb-9d07-ded324505a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-fbc978db-edbb-4a11-95c6-d9033fd73c80,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-414dddcc-5a68-44a5-9070-57b2b5906abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-7ec8e200-34d7-41d8-a4b6-e16797b04628,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-eeeae259-dd8b-4a92-923c-7e0148228e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-3e691a76-3fdb-4169-b78e-14fb9a89aeab,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-c355ab4c-810d-4ba8-b936-635838e7ce4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769475096-172.17.0.9-1597729877016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34682,DS-b9229309-184b-43f6-b37a-5924803cfc13,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-ad538ebd-611b-42cb-9d07-ded324505a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-fbc978db-edbb-4a11-95c6-d9033fd73c80,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-414dddcc-5a68-44a5-9070-57b2b5906abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-7ec8e200-34d7-41d8-a4b6-e16797b04628,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-eeeae259-dd8b-4a92-923c-7e0148228e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-3e691a76-3fdb-4169-b78e-14fb9a89aeab,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-c355ab4c-810d-4ba8-b936-635838e7ce4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69897568-172.17.0.9-1597730987183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-f97501af-2205-4fa7-a3b5-08fe054117a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-461989c8-92b2-49a5-b3ad-0d5a1ce7767d,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-5f4c779c-ab13-4c43-b8d1-3a139ae91d44,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-72fe96a6-1ba5-47ca-b903-14b6d4c184e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-a6dd6297-8b06-430e-9470-ff5b16e49bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-9bebfa36-5078-41f1-bf68-a455a9fecdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-1f368dc2-2902-49a1-8726-8c5f255d28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-063f6952-e298-47a3-8c55-2f655d4389db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69897568-172.17.0.9-1597730987183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-f97501af-2205-4fa7-a3b5-08fe054117a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-461989c8-92b2-49a5-b3ad-0d5a1ce7767d,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-5f4c779c-ab13-4c43-b8d1-3a139ae91d44,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-72fe96a6-1ba5-47ca-b903-14b6d4c184e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-a6dd6297-8b06-430e-9470-ff5b16e49bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-9bebfa36-5078-41f1-bf68-a455a9fecdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-1f368dc2-2902-49a1-8726-8c5f255d28e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-063f6952-e298-47a3-8c55-2f655d4389db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888805508-172.17.0.9-1597731312274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34514,DS-2118eda5-b942-4a05-a87d-bfff6dbc383c,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-ad03681c-15fc-4a10-a5d3-39e2843100a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-2d13b668-df11-4e56-a34b-ce41810c89c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-e45ba99b-bf00-4b92-aecb-4aeffc3cd0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-872f7345-d1e2-4b06-8d45-be634781f439,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-cd6282fa-b9f3-4ab3-b98c-485451eef0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-39dedb5a-bf73-4a27-b144-038260ab7dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-29de69ce-fee9-4f59-8dc8-8c96befe5ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888805508-172.17.0.9-1597731312274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34514,DS-2118eda5-b942-4a05-a87d-bfff6dbc383c,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-ad03681c-15fc-4a10-a5d3-39e2843100a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-2d13b668-df11-4e56-a34b-ce41810c89c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-e45ba99b-bf00-4b92-aecb-4aeffc3cd0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-872f7345-d1e2-4b06-8d45-be634781f439,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-cd6282fa-b9f3-4ab3-b98c-485451eef0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-39dedb5a-bf73-4a27-b144-038260ab7dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-29de69ce-fee9-4f59-8dc8-8c96befe5ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314345071-172.17.0.9-1597731546982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-e2332ee3-8b71-4b9d-a72d-bd81d0fd2bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-d5868be1-0b1a-437b-9b1e-c2264df7b35c,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-15881c4e-2846-45b2-8f76-4cc762a1f72b,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-f9b2258a-7043-4d81-9f46-4dd9bb10c767,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-3f3d7700-80a8-48c9-b48d-d6490c2830b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-7118107e-b98c-4a53-a27a-3852220029a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-031e9f6f-b30d-4627-ad14-33460fedac8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-f30c253d-7c4c-45db-aafd-432c1e5962e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314345071-172.17.0.9-1597731546982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-e2332ee3-8b71-4b9d-a72d-bd81d0fd2bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-d5868be1-0b1a-437b-9b1e-c2264df7b35c,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-15881c4e-2846-45b2-8f76-4cc762a1f72b,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-f9b2258a-7043-4d81-9f46-4dd9bb10c767,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-3f3d7700-80a8-48c9-b48d-d6490c2830b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-7118107e-b98c-4a53-a27a-3852220029a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-031e9f6f-b30d-4627-ad14-33460fedac8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-f30c253d-7c4c-45db-aafd-432c1e5962e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954933729-172.17.0.9-1597731834872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39407,DS-f2b01b4d-c9c9-476d-98cc-dead378e12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-e0d3e281-cffc-43b9-ae4c-3168ea5e9ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-941a8f34-1c21-4cf4-a304-1500106619f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-cedfab95-382b-4e97-9aa1-3150e37c336f,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-4ec9b9a5-4de4-4537-96a6-daced698d0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-06495e94-f09d-4806-a6af-325f675b4a17,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-13371cbc-928e-4a4d-b067-1a271a4b0fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-ee62cc8d-acce-4330-9455-c07939ee0adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954933729-172.17.0.9-1597731834872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39407,DS-f2b01b4d-c9c9-476d-98cc-dead378e12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-e0d3e281-cffc-43b9-ae4c-3168ea5e9ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-941a8f34-1c21-4cf4-a304-1500106619f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-cedfab95-382b-4e97-9aa1-3150e37c336f,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-4ec9b9a5-4de4-4537-96a6-daced698d0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-06495e94-f09d-4806-a6af-325f675b4a17,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-13371cbc-928e-4a4d-b067-1a271a4b0fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-ee62cc8d-acce-4330-9455-c07939ee0adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736291947-172.17.0.9-1597731909491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-194c2c99-1e4d-43f0-baea-0d435b48a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-2cd9f809-8517-4d96-9284-83b831fdfc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-334e02da-9e74-4aeb-90c4-2e5871f935da,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-533fec91-8915-482e-8206-d75b17bb3398,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-3f482617-13fa-42c3-bf81-f9b480c20993,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-4297c000-1b66-44a4-80f7-a909e7c96f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-b4d0fde5-a575-4eef-b112-e64d6d488a50,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-c8dae801-3134-4d92-8fde-c445f5f59fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736291947-172.17.0.9-1597731909491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-194c2c99-1e4d-43f0-baea-0d435b48a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-2cd9f809-8517-4d96-9284-83b831fdfc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-334e02da-9e74-4aeb-90c4-2e5871f935da,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-533fec91-8915-482e-8206-d75b17bb3398,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-3f482617-13fa-42c3-bf81-f9b480c20993,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-4297c000-1b66-44a4-80f7-a909e7c96f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-b4d0fde5-a575-4eef-b112-e64d6d488a50,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-c8dae801-3134-4d92-8fde-c445f5f59fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131807193-172.17.0.9-1597732061011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-cf30c4a7-a832-4146-abc7-e768c076c40a,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-2c91fd8c-d167-45a7-a2fa-d40016dbdb66,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-c8ba0e4c-da14-4cab-bfb5-b27fc19e5915,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-1b778041-fc53-4bad-a80c-1e8b35c211f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-92766c4c-a39e-4c8b-91f7-67fdd7a069c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-7b07e77d-53dc-45bf-9172-edfadf125c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-b7b1dc7b-68d6-42a4-89ff-c8b12efd51ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-3fe027bd-7297-45b4-9cdb-f57a0f8c0dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131807193-172.17.0.9-1597732061011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-cf30c4a7-a832-4146-abc7-e768c076c40a,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-2c91fd8c-d167-45a7-a2fa-d40016dbdb66,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-c8ba0e4c-da14-4cab-bfb5-b27fc19e5915,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-1b778041-fc53-4bad-a80c-1e8b35c211f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-92766c4c-a39e-4c8b-91f7-67fdd7a069c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-7b07e77d-53dc-45bf-9172-edfadf125c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-b7b1dc7b-68d6-42a4-89ff-c8b12efd51ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-3fe027bd-7297-45b4-9cdb-f57a0f8c0dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544740917-172.17.0.9-1597732087011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-f5d3dd25-904b-4850-b91b-6fe0007fd5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-36983098-b4ab-469b-9900-ae0a5b7345fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-1c2bb6c4-e4ba-4dc2-841a-31e559b2c933,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-5756186b-0736-4487-98e7-760eb78d14ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-0859d4c8-59b4-443c-81db-403986225a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-5749e22e-8946-4618-b497-17ff817a2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-3d312984-430f-43c7-8f58-4c912a6c30d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-8387ca8b-2db9-4604-a853-a7ad4c93b2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544740917-172.17.0.9-1597732087011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-f5d3dd25-904b-4850-b91b-6fe0007fd5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-36983098-b4ab-469b-9900-ae0a5b7345fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-1c2bb6c4-e4ba-4dc2-841a-31e559b2c933,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-5756186b-0736-4487-98e7-760eb78d14ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-0859d4c8-59b4-443c-81db-403986225a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-5749e22e-8946-4618-b497-17ff817a2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-3d312984-430f-43c7-8f58-4c912a6c30d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-8387ca8b-2db9-4604-a853-a7ad4c93b2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785053097-172.17.0.9-1597732194009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42123,DS-e9e33c56-c13b-4b36-a06d-710724e6e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-7081d53c-e519-42e9-8b13-e715c70112eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-559c9483-ba86-43a6-af49-f4bf43795c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-496c82b1-5cad-4635-9d25-818af1a5038a,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-30e9d3e5-a239-4f16-93de-0630c22cd1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-a39266d1-7085-42ec-8768-61191cf0b891,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-fba9f24d-0ca3-4062-8606-181e52604d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-538d62c6-3001-4534-8986-f0f8311d7a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785053097-172.17.0.9-1597732194009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42123,DS-e9e33c56-c13b-4b36-a06d-710724e6e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-7081d53c-e519-42e9-8b13-e715c70112eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-559c9483-ba86-43a6-af49-f4bf43795c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-496c82b1-5cad-4635-9d25-818af1a5038a,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-30e9d3e5-a239-4f16-93de-0630c22cd1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-a39266d1-7085-42ec-8768-61191cf0b891,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-fba9f24d-0ca3-4062-8606-181e52604d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-538d62c6-3001-4534-8986-f0f8311d7a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863065381-172.17.0.9-1597732357707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38486,DS-f1ff7c7c-c69e-4e50-93d0-55de41c0b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-c8171db4-b7bb-4cf2-8d93-1ff766e2ef26,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-6b9a15ae-3d45-4df9-9e79-c45958e52df2,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-69890e9a-1b5e-440e-bba3-d8ed34e15cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-59c1c7e5-783e-46c4-ad22-d46d95989917,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-360f4a8b-01a1-487c-af70-0680d2691701,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-e905e715-c68c-4021-aed9-a3fa1bd9fcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-b0033897-408d-46f9-a2cd-5a73c2b76bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863065381-172.17.0.9-1597732357707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38486,DS-f1ff7c7c-c69e-4e50-93d0-55de41c0b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-c8171db4-b7bb-4cf2-8d93-1ff766e2ef26,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-6b9a15ae-3d45-4df9-9e79-c45958e52df2,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-69890e9a-1b5e-440e-bba3-d8ed34e15cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-59c1c7e5-783e-46c4-ad22-d46d95989917,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-360f4a8b-01a1-487c-af70-0680d2691701,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-e905e715-c68c-4021-aed9-a3fa1bd9fcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-b0033897-408d-46f9-a2cd-5a73c2b76bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873964986-172.17.0.9-1597732939523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-bc54e3aa-ca14-4d52-a20b-b82d92404f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-db803324-690d-4162-a772-64920a6b4c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-55d14233-c9c0-49cd-93f2-21fcf19b0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-f47de810-ae1a-4c07-abcf-b2af69d873c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-6b5f53b8-080c-43b3-883a-f4615dcb0e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-6fb14b22-e96a-45f1-9163-8841432049c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-75840f80-cef1-4a0a-b3d1-8486f2634042,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-6f5f6869-a6fa-4dc0-9437-a0c5b1126240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873964986-172.17.0.9-1597732939523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-bc54e3aa-ca14-4d52-a20b-b82d92404f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-db803324-690d-4162-a772-64920a6b4c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-55d14233-c9c0-49cd-93f2-21fcf19b0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-f47de810-ae1a-4c07-abcf-b2af69d873c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-6b5f53b8-080c-43b3-883a-f4615dcb0e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-6fb14b22-e96a-45f1-9163-8841432049c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-75840f80-cef1-4a0a-b3d1-8486f2634042,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-6f5f6869-a6fa-4dc0-9437-a0c5b1126240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873691361-172.17.0.9-1597733224955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-75406679-8960-48dc-9585-bbd8f81f9f83,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-48022f9b-bfb9-4cca-8d7a-584d9499ad42,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-f0f7ac90-d2a5-4af9-9e61-7f741c863812,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-6458387d-7f11-4a87-9d47-b1040ff9f28d,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-4035f063-c699-4167-a217-423ad218687e,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-9a98a719-9a16-4618-96c6-ea56cf266958,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-b26ff0a7-c3c4-439f-b3f7-d86522d0ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-6e5de203-86f4-4f12-877a-001bdbf38ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873691361-172.17.0.9-1597733224955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-75406679-8960-48dc-9585-bbd8f81f9f83,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-48022f9b-bfb9-4cca-8d7a-584d9499ad42,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-f0f7ac90-d2a5-4af9-9e61-7f741c863812,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-6458387d-7f11-4a87-9d47-b1040ff9f28d,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-4035f063-c699-4167-a217-423ad218687e,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-9a98a719-9a16-4618-96c6-ea56cf266958,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-b26ff0a7-c3c4-439f-b3f7-d86522d0ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-6e5de203-86f4-4f12-877a-001bdbf38ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965123078-172.17.0.9-1597733295094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-8afe7964-28c5-4596-b261-9717ec37e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-fe040ca2-ead5-4f31-b62b-4ee367dac035,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-8023b6db-ce53-4258-ba8e-8c6fa2554c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-7105db9c-4edd-4bee-a887-4d8c58ac7d66,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-6214a87e-2059-4a66-aa18-53890b85d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-bc072a8d-402c-4069-9518-77ea27591948,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-45cc64ff-182b-4479-96fc-59cdddd188cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-32eff0a5-094e-4b15-afff-6c2073a56b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965123078-172.17.0.9-1597733295094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-8afe7964-28c5-4596-b261-9717ec37e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-fe040ca2-ead5-4f31-b62b-4ee367dac035,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-8023b6db-ce53-4258-ba8e-8c6fa2554c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-7105db9c-4edd-4bee-a887-4d8c58ac7d66,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-6214a87e-2059-4a66-aa18-53890b85d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-bc072a8d-402c-4069-9518-77ea27591948,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-45cc64ff-182b-4479-96fc-59cdddd188cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-32eff0a5-094e-4b15-afff-6c2073a56b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459942728-172.17.0.9-1597733451035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34592,DS-6124408f-c7b2-4c5b-8e9b-6601722d3c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-a3e3b7db-f27a-448b-8cd2-24b27ec9af6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-f1b5e7d9-5fb7-41fb-a524-bb0e828340af,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-4190334a-9bbd-4d0f-a42b-e03d9e5da6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-1cefab3d-a3d9-4938-8e91-0f951592e980,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-0b95af3a-32a1-4dcc-b9bb-b98fa16518f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-534455de-67a0-434a-a883-36c28f5c3079,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-9837329f-38df-4c19-abf7-69d5c0e501e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459942728-172.17.0.9-1597733451035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34592,DS-6124408f-c7b2-4c5b-8e9b-6601722d3c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-a3e3b7db-f27a-448b-8cd2-24b27ec9af6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-f1b5e7d9-5fb7-41fb-a524-bb0e828340af,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-4190334a-9bbd-4d0f-a42b-e03d9e5da6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-1cefab3d-a3d9-4938-8e91-0f951592e980,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-0b95af3a-32a1-4dcc-b9bb-b98fa16518f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-534455de-67a0-434a-a883-36c28f5c3079,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-9837329f-38df-4c19-abf7-69d5c0e501e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490467574-172.17.0.9-1597733951731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44584,DS-0b8f6992-be68-45f6-9df8-67c42a6228c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-161d17cd-6d40-4efa-a487-07a2e837c5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-5221405f-0fdc-4df4-9884-6c752468c504,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-06b4ed2f-826f-45ba-ba8f-47f1c91f419e,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-351fd408-c7d5-4f9b-8767-fa816768e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-587d6af6-ee56-4907-879f-e4d3c018f5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-6f43b580-7c15-4b5c-8019-c75b0db1c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-03e7c6fd-cd34-49be-bed5-472299ce6e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490467574-172.17.0.9-1597733951731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44584,DS-0b8f6992-be68-45f6-9df8-67c42a6228c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-161d17cd-6d40-4efa-a487-07a2e837c5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-5221405f-0fdc-4df4-9884-6c752468c504,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-06b4ed2f-826f-45ba-ba8f-47f1c91f419e,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-351fd408-c7d5-4f9b-8767-fa816768e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-587d6af6-ee56-4907-879f-e4d3c018f5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-6f43b580-7c15-4b5c-8019-c75b0db1c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-03e7c6fd-cd34-49be-bed5-472299ce6e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665608786-172.17.0.9-1597734717195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45803,DS-e462c8cc-1137-4cb8-acc3-8322004dd885,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-80cd6c9d-f077-40c6-bede-398f8a8197de,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-b79e9d88-672d-47f3-8143-71556cccaa45,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-48c86053-4c41-4a74-b7ad-1adbe451cf99,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-f5a3baea-872b-4880-8e02-1e465f0a1a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-cdac0cb4-da0b-42fa-aa62-323160b33905,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-c1634a8a-bfcf-4264-9bd7-99f24e9179c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-87ab15a5-b9bd-4c5e-b7f7-09b90c15cdf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665608786-172.17.0.9-1597734717195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45803,DS-e462c8cc-1137-4cb8-acc3-8322004dd885,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-80cd6c9d-f077-40c6-bede-398f8a8197de,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-b79e9d88-672d-47f3-8143-71556cccaa45,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-48c86053-4c41-4a74-b7ad-1adbe451cf99,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-f5a3baea-872b-4880-8e02-1e465f0a1a15,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-cdac0cb4-da0b-42fa-aa62-323160b33905,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-c1634a8a-bfcf-4264-9bd7-99f24e9179c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-87ab15a5-b9bd-4c5e-b7f7-09b90c15cdf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985855243-172.17.0.9-1597734855398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43476,DS-b02b2bb3-a9a9-42f6-9ca3-92d7ffb7af95,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-b74912c2-11c9-4a52-9024-5d5dff41426e,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-dd46bd96-4477-49da-a650-2f7572468bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-ac7230e8-ee5c-467d-bcb2-57887477ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-e4bdb9f8-8335-4a3b-a97e-faccf55dd786,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-e0608403-76f9-4519-8f15-ce0180655641,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-1715eaf1-0729-4fd3-8764-fd46e3d35504,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-35893148-7125-4e33-99af-66bc4b9aa9c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985855243-172.17.0.9-1597734855398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43476,DS-b02b2bb3-a9a9-42f6-9ca3-92d7ffb7af95,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-b74912c2-11c9-4a52-9024-5d5dff41426e,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-dd46bd96-4477-49da-a650-2f7572468bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-ac7230e8-ee5c-467d-bcb2-57887477ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-e4bdb9f8-8335-4a3b-a97e-faccf55dd786,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-e0608403-76f9-4519-8f15-ce0180655641,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-1715eaf1-0729-4fd3-8764-fd46e3d35504,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-35893148-7125-4e33-99af-66bc4b9aa9c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 600000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78947807-172.17.0.9-1597734895028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-e125119a-c1fd-46ec-81c5-fc4998d6e706,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-12ee0349-6ef4-4d01-be16-80f10fc2c0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-50e77b50-8f49-42c2-98b1-cd3453738180,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-8a5ea698-ba52-4e18-92c2-33b29fdae153,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-014b7e8c-354d-4af9-af2b-b4a0624381af,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-cb10cdd0-2de8-44e0-aceb-bde5f9862820,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-d0dbe9a1-aeeb-468f-93bf-89aa8c003e10,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-1833b625-8e54-44b7-bdd9-154bc0e5ceaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78947807-172.17.0.9-1597734895028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-e125119a-c1fd-46ec-81c5-fc4998d6e706,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-12ee0349-6ef4-4d01-be16-80f10fc2c0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-50e77b50-8f49-42c2-98b1-cd3453738180,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-8a5ea698-ba52-4e18-92c2-33b29fdae153,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-014b7e8c-354d-4af9-af2b-b4a0624381af,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-cb10cdd0-2de8-44e0-aceb-bde5f9862820,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-d0dbe9a1-aeeb-468f-93bf-89aa8c003e10,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-1833b625-8e54-44b7-bdd9-154bc0e5ceaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5430
