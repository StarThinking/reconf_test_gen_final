reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190599787-172.17.0.4-1597685746923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-f63fac18-914d-4456-9225-728375760dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-891db20c-d749-43ed-ba62-2cf99baad1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-934a2c2c-234c-4abd-a2d5-f2af91afe09e,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-33026d74-841c-4541-aaa8-16e188348778,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-8e3b867e-8423-4f51-ae98-383fe8f53c59,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-949f85fd-3236-43ed-bb88-ae4b78081605,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-6d83449b-4d66-4c4f-952c-6abf6a1ca563,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-41d186a5-8cf5-4bb7-a2e6-320b5abf6be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190599787-172.17.0.4-1597685746923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-f63fac18-914d-4456-9225-728375760dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-891db20c-d749-43ed-ba62-2cf99baad1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-934a2c2c-234c-4abd-a2d5-f2af91afe09e,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-33026d74-841c-4541-aaa8-16e188348778,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-8e3b867e-8423-4f51-ae98-383fe8f53c59,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-949f85fd-3236-43ed-bb88-ae4b78081605,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-6d83449b-4d66-4c4f-952c-6abf6a1ca563,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-41d186a5-8cf5-4bb7-a2e6-320b5abf6be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371192967-172.17.0.4-1597685792091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37967,DS-1442c44d-63f9-4ca3-8ff9-c37c422b17a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f7477fcf-cb98-4e66-8af1-626f02b7e16d,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-81e9e2a2-2eff-46fd-b38e-2829ffb785f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-fcdd7cb2-d495-4d1b-b716-4cebb93614dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-9443f847-9ca9-49b5-9596-5a60606c2890,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-75f8c154-8fd6-4ea2-96fe-df398eef9215,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-5bc6b275-178a-4563-9bd3-1772af7e8314,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-6903501b-883a-4cbd-8043-84cca6850cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371192967-172.17.0.4-1597685792091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37967,DS-1442c44d-63f9-4ca3-8ff9-c37c422b17a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f7477fcf-cb98-4e66-8af1-626f02b7e16d,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-81e9e2a2-2eff-46fd-b38e-2829ffb785f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-fcdd7cb2-d495-4d1b-b716-4cebb93614dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-9443f847-9ca9-49b5-9596-5a60606c2890,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-75f8c154-8fd6-4ea2-96fe-df398eef9215,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-5bc6b275-178a-4563-9bd3-1772af7e8314,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-6903501b-883a-4cbd-8043-84cca6850cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671971904-172.17.0.4-1597686332050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-d5aa914b-1d9d-4a07-9bf8-60bf94c028c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-1c5d67a9-8cd4-4541-a58b-de5247c7032e,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-cec18314-0ffe-4c1e-ac4b-a4cd91dadf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-38fdfefd-0d04-4a63-acef-973d6d1d6aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-d5cf8adc-b93f-45e8-8ade-73fda6e1bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-ef831b5e-6a51-4b2a-995b-d25400691cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-35a8f5bf-577c-4dcb-b46c-3858a8864a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-5b8447c9-352f-4417-b965-82cd45bbefdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671971904-172.17.0.4-1597686332050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-d5aa914b-1d9d-4a07-9bf8-60bf94c028c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-1c5d67a9-8cd4-4541-a58b-de5247c7032e,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-cec18314-0ffe-4c1e-ac4b-a4cd91dadf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-38fdfefd-0d04-4a63-acef-973d6d1d6aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-d5cf8adc-b93f-45e8-8ade-73fda6e1bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-ef831b5e-6a51-4b2a-995b-d25400691cca,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-35a8f5bf-577c-4dcb-b46c-3858a8864a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-5b8447c9-352f-4417-b965-82cd45bbefdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319531165-172.17.0.4-1597686532064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44125,DS-79841284-ce8a-4d83-989c-f27b01da0ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-6cba4a39-3214-4237-a4c6-b45b217e1058,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-0afa9dbf-632f-4229-9711-4b5aa6124245,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-97e5a99c-a061-44f7-80ad-dc468ac1e410,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-34e40a96-445e-47a3-8adc-17d3de3f95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-19db33a2-68ba-4628-b2f7-dbaf8fd3c61c,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-a3a955f3-9e9a-4b14-b34d-69126e3bcc95,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-33eebf6a-450e-4362-b0fa-51a5732fd834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319531165-172.17.0.4-1597686532064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44125,DS-79841284-ce8a-4d83-989c-f27b01da0ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-6cba4a39-3214-4237-a4c6-b45b217e1058,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-0afa9dbf-632f-4229-9711-4b5aa6124245,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-97e5a99c-a061-44f7-80ad-dc468ac1e410,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-34e40a96-445e-47a3-8adc-17d3de3f95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-19db33a2-68ba-4628-b2f7-dbaf8fd3c61c,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-a3a955f3-9e9a-4b14-b34d-69126e3bcc95,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-33eebf6a-450e-4362-b0fa-51a5732fd834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714469163-172.17.0.4-1597687790165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43198,DS-77fca9fa-3e17-4cdd-8d1a-1087c2eec1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-78542065-43ff-476d-be88-286c196cae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-d41cfbd9-5424-4a63-9dfe-0d3d36bc4d35,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-27b3d46d-9baf-4580-bc81-05edb9be7e82,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-4e28c219-3ee1-4c13-8b72-05841b70b332,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-65a9722f-0d41-4c38-a2f8-0751afcc4db2,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-b686072d-a8b0-478c-a871-bfd808439aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-49a73468-dfe5-4058-b819-6221fa99dbce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714469163-172.17.0.4-1597687790165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43198,DS-77fca9fa-3e17-4cdd-8d1a-1087c2eec1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-78542065-43ff-476d-be88-286c196cae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-d41cfbd9-5424-4a63-9dfe-0d3d36bc4d35,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-27b3d46d-9baf-4580-bc81-05edb9be7e82,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-4e28c219-3ee1-4c13-8b72-05841b70b332,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-65a9722f-0d41-4c38-a2f8-0751afcc4db2,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-b686072d-a8b0-478c-a871-bfd808439aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-49a73468-dfe5-4058-b819-6221fa99dbce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842952213-172.17.0.4-1597687925657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44307,DS-3107c1db-776f-4a80-b21c-ca2c27c32d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-9cf3fb9a-e727-489e-8b30-4ff9a93803a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-182c1de1-a33c-43d8-ae29-6ba3635238ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-80ffbbe6-bfdd-4722-9f32-e99a22a3d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-59b1daaa-cddc-4efc-a6c4-dc98db754aab,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-0a4e75aa-a876-447e-944a-06634d6c2203,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-6061f437-8c8e-4734-ba29-befd25611b67,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-bdff3edb-41e4-4779-8f8a-3e5f7edb33fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842952213-172.17.0.4-1597687925657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44307,DS-3107c1db-776f-4a80-b21c-ca2c27c32d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-9cf3fb9a-e727-489e-8b30-4ff9a93803a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-182c1de1-a33c-43d8-ae29-6ba3635238ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-80ffbbe6-bfdd-4722-9f32-e99a22a3d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-59b1daaa-cddc-4efc-a6c4-dc98db754aab,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-0a4e75aa-a876-447e-944a-06634d6c2203,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-6061f437-8c8e-4734-ba29-befd25611b67,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-bdff3edb-41e4-4779-8f8a-3e5f7edb33fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360764731-172.17.0.4-1597688023285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-2a7ce884-ac4e-44e9-9764-9b6ce464bab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-f0eac4d1-29fb-4379-95d2-394d35a0075f,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-45f6097d-340e-42de-9825-f796436b27f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-78cfa62d-6752-4913-bc62-a42b3c322bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-ca3cf156-ce4a-407f-beec-39e77888be7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-d166b790-1e23-46fa-aca6-8b5676a5eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-79238725-54d1-4fbd-b51d-3e393d163058,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-004e93e0-f984-4ea7-a210-db46b5a3698d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360764731-172.17.0.4-1597688023285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-2a7ce884-ac4e-44e9-9764-9b6ce464bab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-f0eac4d1-29fb-4379-95d2-394d35a0075f,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-45f6097d-340e-42de-9825-f796436b27f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-78cfa62d-6752-4913-bc62-a42b3c322bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-ca3cf156-ce4a-407f-beec-39e77888be7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-d166b790-1e23-46fa-aca6-8b5676a5eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-79238725-54d1-4fbd-b51d-3e393d163058,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-004e93e0-f984-4ea7-a210-db46b5a3698d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196263839-172.17.0.4-1597688215030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-0d652a5c-d148-4be0-9113-40302ef2c1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-22259bf3-ec27-4500-86a7-4009f2931ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-528b58c4-5425-4299-8213-99d3dd39dd03,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-5a60047d-eba9-4c62-b7ed-d6243b08e0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-c2e5a334-f8d2-46d6-a49b-92896c8dfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-4686015e-c9dc-4c2a-91c9-beafb756dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-789f49e4-218e-4df9-bd0f-c43a792e40b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-956e7603-f9be-42ac-88f2-30216c115038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196263839-172.17.0.4-1597688215030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-0d652a5c-d148-4be0-9113-40302ef2c1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-22259bf3-ec27-4500-86a7-4009f2931ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-528b58c4-5425-4299-8213-99d3dd39dd03,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-5a60047d-eba9-4c62-b7ed-d6243b08e0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-c2e5a334-f8d2-46d6-a49b-92896c8dfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-4686015e-c9dc-4c2a-91c9-beafb756dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-789f49e4-218e-4df9-bd0f-c43a792e40b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-956e7603-f9be-42ac-88f2-30216c115038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141359129-172.17.0.4-1597688290151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-545c0c24-29b5-434e-b49e-778355d8f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-e25e09d2-aa95-4cf4-8979-1aa953a533d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-cb7680c9-6390-45dd-9fd8-71b017054db8,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-9b963ddf-7930-400a-b5ba-a0682ca156a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-d929b944-3b20-4754-a323-275ea3d5506d,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-7bee7af3-31de-40b2-b62f-c65170356020,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-9fc6ff72-a127-4612-b970-2803ea1b0da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-b5e31c73-6c34-4890-8c2b-3e9441c64b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141359129-172.17.0.4-1597688290151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-545c0c24-29b5-434e-b49e-778355d8f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-e25e09d2-aa95-4cf4-8979-1aa953a533d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-cb7680c9-6390-45dd-9fd8-71b017054db8,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-9b963ddf-7930-400a-b5ba-a0682ca156a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-d929b944-3b20-4754-a323-275ea3d5506d,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-7bee7af3-31de-40b2-b62f-c65170356020,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-9fc6ff72-a127-4612-b970-2803ea1b0da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-b5e31c73-6c34-4890-8c2b-3e9441c64b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438544303-172.17.0.4-1597688653726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34487,DS-40863af8-0d2a-462b-a3f7-daa84a645561,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-560f406e-4ec5-40f9-a730-8d23e0dbc93c,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-36725c41-8a2b-42cb-985d-57f0e174ff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-57b12f3d-cb8d-4665-95df-8c6b76199646,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-1b8ca62c-a8f8-4868-9dca-e91e5b989d13,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-2e0a848a-03d8-49a5-b30e-cac4c6799ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-d7517193-dea6-44b4-b8f6-e461ac6c0fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-6fd31e86-f2e6-41ff-8092-f741e80d8b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438544303-172.17.0.4-1597688653726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34487,DS-40863af8-0d2a-462b-a3f7-daa84a645561,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-560f406e-4ec5-40f9-a730-8d23e0dbc93c,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-36725c41-8a2b-42cb-985d-57f0e174ff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-57b12f3d-cb8d-4665-95df-8c6b76199646,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-1b8ca62c-a8f8-4868-9dca-e91e5b989d13,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-2e0a848a-03d8-49a5-b30e-cac4c6799ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-d7517193-dea6-44b4-b8f6-e461ac6c0fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-6fd31e86-f2e6-41ff-8092-f741e80d8b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726456002-172.17.0.4-1597688833295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39566,DS-ac7739d9-c02a-461d-a4f1-c8f24e2bd725,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-0ceedb5c-ef45-4f03-843e-661156b9b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-c4d308f6-4369-4384-818f-32d51770f71c,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-977adb11-a424-479e-8d91-a105f5e9d07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-e486743c-0fe8-4eee-bad6-5ef36761e560,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-2f5c08ca-090c-4235-a794-46338b401cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-a95c2d2b-921c-4a96-b3b9-f58e288cdff9,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-f28fbb59-c492-468d-804a-7054d3f5df5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726456002-172.17.0.4-1597688833295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39566,DS-ac7739d9-c02a-461d-a4f1-c8f24e2bd725,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-0ceedb5c-ef45-4f03-843e-661156b9b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-c4d308f6-4369-4384-818f-32d51770f71c,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-977adb11-a424-479e-8d91-a105f5e9d07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-e486743c-0fe8-4eee-bad6-5ef36761e560,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-2f5c08ca-090c-4235-a794-46338b401cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-a95c2d2b-921c-4a96-b3b9-f58e288cdff9,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-f28fbb59-c492-468d-804a-7054d3f5df5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774269565-172.17.0.4-1597689523562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41204,DS-64d8825d-2120-4251-bf92-c933a281d769,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-7f5e184b-a45e-4fc0-b461-04fa35cbe92e,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-ea8df01e-ac12-4306-85aa-58ea65985c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-a20b3419-d5b1-45fb-8829-72c6a1cec7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-2fda401a-68d9-45aa-a189-52936e60fbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-67cddf2b-8b3a-4f9d-b7dd-07a694f41d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-a7fc5ba1-40ad-4b61-adda-213416aec87f,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-dcc21564-577a-44d1-89cc-7e94fadb76db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774269565-172.17.0.4-1597689523562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41204,DS-64d8825d-2120-4251-bf92-c933a281d769,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-7f5e184b-a45e-4fc0-b461-04fa35cbe92e,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-ea8df01e-ac12-4306-85aa-58ea65985c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-a20b3419-d5b1-45fb-8829-72c6a1cec7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-2fda401a-68d9-45aa-a189-52936e60fbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-67cddf2b-8b3a-4f9d-b7dd-07a694f41d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-a7fc5ba1-40ad-4b61-adda-213416aec87f,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-dcc21564-577a-44d1-89cc-7e94fadb76db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545742835-172.17.0.4-1597690526447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-9df35963-39c0-4345-8405-11caf4a4f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-7f18f64f-40bd-48e1-96aa-533453212bec,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-ba4f5075-bb2a-44fa-9074-4cfd9ebed4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-c2844ed6-7274-49b5-a639-6b67ebf3619d,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-756788d4-95c5-4a06-bb91-ada0e37a3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-5349d0b4-2e88-4a27-94c8-39bb654d33f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-165d6e68-bf52-4c6e-bf58-a4c1cf913312,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-4f494f06-a0b2-4818-893c-100c1e2769eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1545742835-172.17.0.4-1597690526447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-9df35963-39c0-4345-8405-11caf4a4f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-7f18f64f-40bd-48e1-96aa-533453212bec,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-ba4f5075-bb2a-44fa-9074-4cfd9ebed4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-c2844ed6-7274-49b5-a639-6b67ebf3619d,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-756788d4-95c5-4a06-bb91-ada0e37a3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-5349d0b4-2e88-4a27-94c8-39bb654d33f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-165d6e68-bf52-4c6e-bf58-a4c1cf913312,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-4f494f06-a0b2-4818-893c-100c1e2769eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049408434-172.17.0.4-1597690576099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-4f138ae7-ba50-42ce-b90b-a6d6e74c7bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-d83d03f3-5e6e-4960-bca9-a8dc4f49ac91,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-338d69d3-0033-4765-9a12-1c020cc998a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-1201456f-8e15-4ce7-8c8a-3243aa35e02c,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-41b0c1c7-a5fc-41d3-ade2-29886c5f7c52,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-1b06e199-81ea-4f14-a257-3703b1f9ce59,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-5aca6f32-042e-44d8-921f-35ecb8aeddde,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-345d2ee5-39eb-469b-ad75-62a581471b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049408434-172.17.0.4-1597690576099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-4f138ae7-ba50-42ce-b90b-a6d6e74c7bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-d83d03f3-5e6e-4960-bca9-a8dc4f49ac91,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-338d69d3-0033-4765-9a12-1c020cc998a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-1201456f-8e15-4ce7-8c8a-3243aa35e02c,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-41b0c1c7-a5fc-41d3-ade2-29886c5f7c52,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-1b06e199-81ea-4f14-a257-3703b1f9ce59,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-5aca6f32-042e-44d8-921f-35ecb8aeddde,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-345d2ee5-39eb-469b-ad75-62a581471b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578167868-172.17.0.4-1597690940564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41183,DS-ee510659-81b0-4c17-98b5-0c4fd362b040,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-9586f536-abba-487d-83e5-93b7e255e5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-a3bbce28-a23a-404e-a5c7-f0eae74557f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-17fe9a64-f4e9-42c4-b044-eff1af4f723b,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-3ab97a70-db35-4d42-9c52-2f17fe5fe708,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-f4ec5b2d-9fbe-41e1-b57d-dba9d8d536de,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-9332a8bb-7726-4d66-a131-b36a87575365,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-e5625f9f-ae38-47ac-b5f5-687269895905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578167868-172.17.0.4-1597690940564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41183,DS-ee510659-81b0-4c17-98b5-0c4fd362b040,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-9586f536-abba-487d-83e5-93b7e255e5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-a3bbce28-a23a-404e-a5c7-f0eae74557f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-17fe9a64-f4e9-42c4-b044-eff1af4f723b,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-3ab97a70-db35-4d42-9c52-2f17fe5fe708,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-f4ec5b2d-9fbe-41e1-b57d-dba9d8d536de,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-9332a8bb-7726-4d66-a131-b36a87575365,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-e5625f9f-ae38-47ac-b5f5-687269895905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895020259-172.17.0.4-1597691839510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33629,DS-df2f5613-9e63-4107-9314-2adf9e99e5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-3149b9f1-58de-4985-8724-3fa56111d031,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-21815c76-6c2c-4108-a267-7d8f03e2299e,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-ec0ad981-a6c1-4219-8049-e6a9c4e7f88c,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-d9794144-b023-40f2-b0ba-32a6ac1d0cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-54597476-7480-478b-a3a9-8f5f91578174,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-436ffbed-578a-4c7e-93f1-906fb3fca0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-96f17b60-7722-4a24-a674-428cedce0f24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895020259-172.17.0.4-1597691839510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33629,DS-df2f5613-9e63-4107-9314-2adf9e99e5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-3149b9f1-58de-4985-8724-3fa56111d031,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-21815c76-6c2c-4108-a267-7d8f03e2299e,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-ec0ad981-a6c1-4219-8049-e6a9c4e7f88c,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-d9794144-b023-40f2-b0ba-32a6ac1d0cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-54597476-7480-478b-a3a9-8f5f91578174,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-436ffbed-578a-4c7e-93f1-906fb3fca0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-96f17b60-7722-4a24-a674-428cedce0f24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87026891-172.17.0.4-1597691886187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-da5adaa2-5b6d-4d0e-9c0c-97913eba3325,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-5a6bc2f2-8f0a-4aa7-8288-079d6d3c13d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-1262e6e0-9423-415b-b25f-7c6c4707bdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-06e1df86-2c8d-4ccc-b88d-9418b6fc5345,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-9d4e4728-23fc-49a5-b549-0d7bdee895d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-62e73282-7863-475c-ae22-462fb0d8f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-0609f15b-1ffa-456d-94af-643f1ea140a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-a77224a4-a7b6-415a-89c4-8d1552762f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87026891-172.17.0.4-1597691886187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-da5adaa2-5b6d-4d0e-9c0c-97913eba3325,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-5a6bc2f2-8f0a-4aa7-8288-079d6d3c13d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-1262e6e0-9423-415b-b25f-7c6c4707bdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-06e1df86-2c8d-4ccc-b88d-9418b6fc5345,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-9d4e4728-23fc-49a5-b549-0d7bdee895d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-62e73282-7863-475c-ae22-462fb0d8f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-0609f15b-1ffa-456d-94af-643f1ea140a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-a77224a4-a7b6-415a-89c4-8d1552762f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069401079-172.17.0.4-1597692024562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43333,DS-59977d82-f293-46c4-95be-93813085855c,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-eb4d166b-bc0e-484c-b269-1a2a69ab2436,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-79c083aa-ccf1-4db8-87d2-99848ff1a8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-d83400b3-8152-4d12-bf52-b67390c203a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-083ddf1e-b18b-4fa2-804e-6a22ae159e13,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-8b028892-b9c2-4304-9d7d-90fec21f850d,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-52a66c70-a156-4c48-96ab-e160ec0fed27,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-38b18374-6f2d-496c-afc7-b55732b08031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069401079-172.17.0.4-1597692024562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43333,DS-59977d82-f293-46c4-95be-93813085855c,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-eb4d166b-bc0e-484c-b269-1a2a69ab2436,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-79c083aa-ccf1-4db8-87d2-99848ff1a8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-d83400b3-8152-4d12-bf52-b67390c203a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-083ddf1e-b18b-4fa2-804e-6a22ae159e13,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-8b028892-b9c2-4304-9d7d-90fec21f850d,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-52a66c70-a156-4c48-96ab-e160ec0fed27,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-38b18374-6f2d-496c-afc7-b55732b08031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 7057
