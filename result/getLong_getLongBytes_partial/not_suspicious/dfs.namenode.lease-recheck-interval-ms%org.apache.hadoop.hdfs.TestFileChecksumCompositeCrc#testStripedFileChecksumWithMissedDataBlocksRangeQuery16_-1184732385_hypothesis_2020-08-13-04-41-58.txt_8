reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706876537-172.17.0.18-1597293736801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43243,DS-597c1692-6bdc-4848-bff6-b11db1511a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-b24fe32a-062c-4702-8065-93f4b9856dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-0fef37e2-b504-4265-b645-bca5a2f780fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-feca2b06-14ff-418a-9695-b6cf56ccbda9,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-ebb3d3c6-a9c0-4424-99a6-c140230f9aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-3e2c62f8-6db3-471d-a6bd-86edbdaa5743,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-8e439507-e9c1-4740-8e90-4be016b05dec,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-72291501-1173-4dc2-8aed-40bd142b1d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706876537-172.17.0.18-1597293736801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43243,DS-597c1692-6bdc-4848-bff6-b11db1511a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-b24fe32a-062c-4702-8065-93f4b9856dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-0fef37e2-b504-4265-b645-bca5a2f780fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-feca2b06-14ff-418a-9695-b6cf56ccbda9,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-ebb3d3c6-a9c0-4424-99a6-c140230f9aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-3e2c62f8-6db3-471d-a6bd-86edbdaa5743,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-8e439507-e9c1-4740-8e90-4be016b05dec,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-72291501-1173-4dc2-8aed-40bd142b1d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631119783-172.17.0.18-1597294298524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42455,DS-4f0c5d5f-b339-4370-b2b1-db08bd96b080,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-8730a17b-18dd-43d6-bc7c-598934324c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-1f92282b-deac-412a-97b7-b2bcf4a6d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-62dd5c5e-4b5a-4db0-9b74-03de2264ebdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-6d46ca13-2948-43a3-ba75-5c4ecc69d282,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-6f3c0249-b676-409d-8a34-2e10bdd2439f,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-c6a7082a-0414-4ae2-bc49-7bdb62ca699f,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-95f97769-9f08-46ce-ab61-be4cf5949a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1631119783-172.17.0.18-1597294298524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42455,DS-4f0c5d5f-b339-4370-b2b1-db08bd96b080,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-8730a17b-18dd-43d6-bc7c-598934324c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-1f92282b-deac-412a-97b7-b2bcf4a6d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-62dd5c5e-4b5a-4db0-9b74-03de2264ebdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-6d46ca13-2948-43a3-ba75-5c4ecc69d282,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-6f3c0249-b676-409d-8a34-2e10bdd2439f,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-c6a7082a-0414-4ae2-bc49-7bdb62ca699f,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-95f97769-9f08-46ce-ab61-be4cf5949a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067444923-172.17.0.18-1597294659505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33789,DS-902de137-dc70-42c1-b0e9-d19185e28990,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-c4f290d3-141a-48f1-9b68-0ae7dd21c415,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-780306fa-9377-4385-989c-222a4c5a8aba,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-9b2cc07b-aca0-448d-99a8-cf78e1dfc51f,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-ed5858e5-8225-4e8c-884f-d84450340528,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-be4e3eb4-a45f-4b10-be15-799101e5d5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-e8ecae18-024d-49cb-b745-a01cee5282e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-1df16782-11cc-4d51-8c1a-e0fbf34d7aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067444923-172.17.0.18-1597294659505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33789,DS-902de137-dc70-42c1-b0e9-d19185e28990,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-c4f290d3-141a-48f1-9b68-0ae7dd21c415,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-780306fa-9377-4385-989c-222a4c5a8aba,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-9b2cc07b-aca0-448d-99a8-cf78e1dfc51f,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-ed5858e5-8225-4e8c-884f-d84450340528,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-be4e3eb4-a45f-4b10-be15-799101e5d5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-e8ecae18-024d-49cb-b745-a01cee5282e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-1df16782-11cc-4d51-8c1a-e0fbf34d7aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60418230-172.17.0.18-1597294847705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39112,DS-93ec5375-038c-4b37-875e-05fcfa2e9ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-aa95d545-f8e4-4888-aa5f-03d929296653,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-f92df4be-419d-4c3a-8c31-97634d225720,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-94a68c45-4edc-4692-916a-a4bc59a1978e,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-eec6025d-a107-4efe-b537-9a2055d6b947,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-b6cafd02-ea26-4e49-9720-30d99138ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-b803d625-6ce0-4d71-befc-b731257e51d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-3ea53228-2459-4223-b09c-4d9dfa6deea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60418230-172.17.0.18-1597294847705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39112,DS-93ec5375-038c-4b37-875e-05fcfa2e9ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-aa95d545-f8e4-4888-aa5f-03d929296653,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-f92df4be-419d-4c3a-8c31-97634d225720,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-94a68c45-4edc-4692-916a-a4bc59a1978e,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-eec6025d-a107-4efe-b537-9a2055d6b947,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-b6cafd02-ea26-4e49-9720-30d99138ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-b803d625-6ce0-4d71-befc-b731257e51d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-3ea53228-2459-4223-b09c-4d9dfa6deea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528447966-172.17.0.18-1597294995604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-14848f1c-85a5-47a2-af39-64ec6b25d66f,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-93a32313-4a2f-4a7a-8c8b-970fc11cafad,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-74523438-be75-43d5-9b71-7fed20060168,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-56095eb2-3d05-4a23-a6f0-4332b03e8365,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-72e4dd56-1a1b-4de6-a86c-592368b549b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-aa61d2fe-cabd-4431-911c-8a789d8887d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-398c7e87-771a-4260-83cd-4ea36bc1815d,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-1f9d1d21-c251-4935-a794-8674c0b0b066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528447966-172.17.0.18-1597294995604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-14848f1c-85a5-47a2-af39-64ec6b25d66f,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-93a32313-4a2f-4a7a-8c8b-970fc11cafad,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-74523438-be75-43d5-9b71-7fed20060168,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-56095eb2-3d05-4a23-a6f0-4332b03e8365,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-72e4dd56-1a1b-4de6-a86c-592368b549b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-aa61d2fe-cabd-4431-911c-8a789d8887d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-398c7e87-771a-4260-83cd-4ea36bc1815d,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-1f9d1d21-c251-4935-a794-8674c0b0b066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637458192-172.17.0.18-1597295074121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-6e86b189-39d4-459a-b035-12e81e9f6116,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-f508e7db-e9fa-47d0-a2c3-918fef4f97a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-57641b11-6463-4ebd-a8e2-d461bb7aa1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-8a461bf9-2f40-40b4-a41f-f29c7598f4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-db3ebd03-2f2f-4734-a497-145bff6b1ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-659b68c6-25b1-4cb5-81a1-0aa316faf17d,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-e98b5bbc-2d28-4323-b5b1-5e5dce6dfac1,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-2437e29b-54e0-4c95-9029-5bf135e93697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637458192-172.17.0.18-1597295074121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-6e86b189-39d4-459a-b035-12e81e9f6116,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-f508e7db-e9fa-47d0-a2c3-918fef4f97a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-57641b11-6463-4ebd-a8e2-d461bb7aa1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-8a461bf9-2f40-40b4-a41f-f29c7598f4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-db3ebd03-2f2f-4734-a497-145bff6b1ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-659b68c6-25b1-4cb5-81a1-0aa316faf17d,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-e98b5bbc-2d28-4323-b5b1-5e5dce6dfac1,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-2437e29b-54e0-4c95-9029-5bf135e93697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791430002-172.17.0.18-1597295444512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-e700a5db-f3fe-402a-87c3-0b3a3b742cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-baf876b9-a68b-41d7-84da-4b2c759ea657,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-404c291f-a449-40a4-823f-8534295891c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-c0f3d6ac-262f-4ade-aa06-1e370618478f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-48f3fcec-e142-47f2-bfa3-5ef884727f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1ca8b67f-eb15-4a52-92b9-4f3bbcef40db,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-f5c3c3b9-5ff9-4c06-8aea-c0c056454365,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-e9e6d6fb-e8aa-45ec-8d3a-8cdd25da70aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791430002-172.17.0.18-1597295444512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-e700a5db-f3fe-402a-87c3-0b3a3b742cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-baf876b9-a68b-41d7-84da-4b2c759ea657,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-404c291f-a449-40a4-823f-8534295891c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-c0f3d6ac-262f-4ade-aa06-1e370618478f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-48f3fcec-e142-47f2-bfa3-5ef884727f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1ca8b67f-eb15-4a52-92b9-4f3bbcef40db,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-f5c3c3b9-5ff9-4c06-8aea-c0c056454365,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-e9e6d6fb-e8aa-45ec-8d3a-8cdd25da70aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334704825-172.17.0.18-1597295677942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-36651091-b4cb-45ef-b0e8-c95ce3f0ceba,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-463aaac4-d64b-4567-a569-ce3522f3350f,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-afa1b7b8-82da-4aa6-9c55-067fa341e142,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-47f77b77-c9a0-4d8e-b14d-1ad1298e14c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-3f4b6b04-8330-4fc2-a0a0-186ce3011050,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-fe467799-e189-4b43-aefb-b299fd11e988,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-81e080cd-9c26-4545-b101-f6e2bf33ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-bd9a734d-ce6f-4976-af98-5185a341803e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334704825-172.17.0.18-1597295677942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-36651091-b4cb-45ef-b0e8-c95ce3f0ceba,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-463aaac4-d64b-4567-a569-ce3522f3350f,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-afa1b7b8-82da-4aa6-9c55-067fa341e142,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-47f77b77-c9a0-4d8e-b14d-1ad1298e14c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-3f4b6b04-8330-4fc2-a0a0-186ce3011050,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-fe467799-e189-4b43-aefb-b299fd11e988,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-81e080cd-9c26-4545-b101-f6e2bf33ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-bd9a734d-ce6f-4976-af98-5185a341803e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176294220-172.17.0.18-1597296187984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36726,DS-97a3cbf0-3fa3-43c0-b6e7-0c22584a9a13,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-b500f950-db40-4cf1-a567-11c7cc3206be,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-f24585dd-65c5-44d2-92e3-68822ac79b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-271477aa-1356-4bf6-b61f-3907caf0d82f,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-2636af73-3729-445d-a716-1e516a6a06d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-7662d19f-a08f-4d95-b056-ff01b7847418,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-f259f516-832f-4350-9b0e-3a9f48025c39,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-cce59d90-dc23-490b-957b-2ba6220d6493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176294220-172.17.0.18-1597296187984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36726,DS-97a3cbf0-3fa3-43c0-b6e7-0c22584a9a13,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-b500f950-db40-4cf1-a567-11c7cc3206be,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-f24585dd-65c5-44d2-92e3-68822ac79b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-271477aa-1356-4bf6-b61f-3907caf0d82f,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-2636af73-3729-445d-a716-1e516a6a06d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-7662d19f-a08f-4d95-b056-ff01b7847418,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-f259f516-832f-4350-9b0e-3a9f48025c39,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-cce59d90-dc23-490b-957b-2ba6220d6493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341483066-172.17.0.18-1597296531067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-73963fdf-5aa2-4a7f-a10f-386ac403e13e,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-71d7d014-cef3-4c92-ae4c-e00f878625b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-5236ab45-8c7c-419a-b67a-07bbada70ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-93cdac2a-ae2a-489d-9620-c84f0d6644bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-cc6de9e5-1661-4d23-89ea-4fe9fcb92287,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-29f6bfe3-1c82-415d-8755-25a53bf6f60c,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-a17ac0b6-7824-4624-ad21-c31e6e59acc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-fb634d85-325a-40a9-9f06-7fb34de9f9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341483066-172.17.0.18-1597296531067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41610,DS-73963fdf-5aa2-4a7f-a10f-386ac403e13e,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-71d7d014-cef3-4c92-ae4c-e00f878625b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-5236ab45-8c7c-419a-b67a-07bbada70ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-93cdac2a-ae2a-489d-9620-c84f0d6644bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-cc6de9e5-1661-4d23-89ea-4fe9fcb92287,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-29f6bfe3-1c82-415d-8755-25a53bf6f60c,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-a17ac0b6-7824-4624-ad21-c31e6e59acc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-fb634d85-325a-40a9-9f06-7fb34de9f9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004501945-172.17.0.18-1597297329282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38808,DS-f3288c1c-d711-4f99-8341-173424be9966,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-b7e07d6b-801c-4630-86f0-5e913f395bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-9c8fbb97-cf1a-4b47-b45f-1e544b2bf541,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-3321934a-3eaa-47fc-9ba3-8a8477e0b2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-a79a260f-c978-48e1-b913-4baea2df981b,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-5fe24183-a6e4-426d-9a24-b5db904bad93,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-f4c04a30-d016-436f-b083-efde6b201626,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-a87d6f4b-d31d-44d7-a6a5-e5b8c2475c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004501945-172.17.0.18-1597297329282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38808,DS-f3288c1c-d711-4f99-8341-173424be9966,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-b7e07d6b-801c-4630-86f0-5e913f395bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-9c8fbb97-cf1a-4b47-b45f-1e544b2bf541,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-3321934a-3eaa-47fc-9ba3-8a8477e0b2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-a79a260f-c978-48e1-b913-4baea2df981b,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-5fe24183-a6e4-426d-9a24-b5db904bad93,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-f4c04a30-d016-436f-b083-efde6b201626,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-a87d6f4b-d31d-44d7-a6a5-e5b8c2475c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637572793-172.17.0.18-1597297609278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40879,DS-bc00e8f2-ee79-471f-812e-580485a002fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-0d248c5b-911f-4dfe-974d-fdc8a9b17323,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-ef2f1829-4c6c-4b82-bd15-ae383fbaff20,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-46dd2d70-b943-4102-a1e3-7233fa5f317e,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-f93f40e0-d811-4cb2-828e-701b2d6176a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-befaa2ea-7d5c-49f0-9116-9c719404cf38,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-e729f08c-5aec-4bee-9080-dcffaf2e3073,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-a67c6e1f-a238-4745-9449-917ffe8bb484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637572793-172.17.0.18-1597297609278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40879,DS-bc00e8f2-ee79-471f-812e-580485a002fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-0d248c5b-911f-4dfe-974d-fdc8a9b17323,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-ef2f1829-4c6c-4b82-bd15-ae383fbaff20,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-46dd2d70-b943-4102-a1e3-7233fa5f317e,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-f93f40e0-d811-4cb2-828e-701b2d6176a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-befaa2ea-7d5c-49f0-9116-9c719404cf38,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-e729f08c-5aec-4bee-9080-dcffaf2e3073,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-a67c6e1f-a238-4745-9449-917ffe8bb484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338530581-172.17.0.18-1597298168959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-0ba2a868-be5b-4838-a0b7-d85bb14f134c,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-49c9a27e-e227-4c17-8b2a-0ebdf955f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-d08e834c-a32c-4dc3-b1da-b10a0721f178,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-9aa2accf-de0e-43cf-b9e8-34b47799572d,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-3560d1e6-595f-4c3f-9298-8de5a5bd7357,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-2e374ff3-135a-469a-950c-6855d82f78d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-90bf9e21-1a05-4341-aa29-f612bcad7cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-20299048-644f-4dc5-aff9-d87e664aeb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338530581-172.17.0.18-1597298168959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-0ba2a868-be5b-4838-a0b7-d85bb14f134c,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-49c9a27e-e227-4c17-8b2a-0ebdf955f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-d08e834c-a32c-4dc3-b1da-b10a0721f178,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-9aa2accf-de0e-43cf-b9e8-34b47799572d,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-3560d1e6-595f-4c3f-9298-8de5a5bd7357,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-2e374ff3-135a-469a-950c-6855d82f78d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-90bf9e21-1a05-4341-aa29-f612bcad7cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-20299048-644f-4dc5-aff9-d87e664aeb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627741877-172.17.0.18-1597299309624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-b49a1f18-27a2-430c-ba7b-f69428079816,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-414fbb77-5287-4377-9b40-803c875a6e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-2f322739-0c88-4de9-8a06-04c177af447b,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-6f1563b8-979c-4a6a-b882-5c4bc27ea30f,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-04c2a372-9856-49bf-a11e-0defa44e8b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-4ac0c7ea-8b2c-4cf7-9a31-1695581a3518,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-11708fd4-ebf6-4fe9-9371-66fd069b3378,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-031dc3d2-721d-4af7-aac9-b033a5336b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627741877-172.17.0.18-1597299309624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-b49a1f18-27a2-430c-ba7b-f69428079816,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-414fbb77-5287-4377-9b40-803c875a6e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-2f322739-0c88-4de9-8a06-04c177af447b,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-6f1563b8-979c-4a6a-b882-5c4bc27ea30f,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-04c2a372-9856-49bf-a11e-0defa44e8b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-4ac0c7ea-8b2c-4cf7-9a31-1695581a3518,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-11708fd4-ebf6-4fe9-9371-66fd069b3378,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-031dc3d2-721d-4af7-aac9-b033a5336b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5759
