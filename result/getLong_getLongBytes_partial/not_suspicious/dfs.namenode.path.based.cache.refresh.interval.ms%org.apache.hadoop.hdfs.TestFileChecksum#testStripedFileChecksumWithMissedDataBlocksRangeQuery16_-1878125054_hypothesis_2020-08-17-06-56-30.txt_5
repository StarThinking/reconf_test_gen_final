reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519924523-172.17.0.19-1597647478097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39202,DS-75f2a509-c81f-4f30-8f09-0c836dfd94b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-fe161868-1ef3-4de2-9455-035fa383b70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-fe6bdf80-e42f-4057-a4ea-ce260d39f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-31f27b3e-5936-4537-be8e-16f393cb8a79,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-51f5d1f3-516e-4b67-87ef-cc80d18a673b,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-15601eb6-0d16-45aa-a601-6cfb0a40cf04,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-e3502892-ef19-45d7-b1d5-75fd8a152089,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-92f633f0-1c76-41e4-ab77-72afab6437c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519924523-172.17.0.19-1597647478097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39202,DS-75f2a509-c81f-4f30-8f09-0c836dfd94b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-fe161868-1ef3-4de2-9455-035fa383b70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-fe6bdf80-e42f-4057-a4ea-ce260d39f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-31f27b3e-5936-4537-be8e-16f393cb8a79,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-51f5d1f3-516e-4b67-87ef-cc80d18a673b,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-15601eb6-0d16-45aa-a601-6cfb0a40cf04,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-e3502892-ef19-45d7-b1d5-75fd8a152089,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-92f633f0-1c76-41e4-ab77-72afab6437c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999406745-172.17.0.19-1597647548059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33506,DS-94e0e354-e7d8-4baf-a414-4ba1a13a7375,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-e8c1abf1-27f7-4db0-bdad-762ef948c2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-92796d47-e323-488c-8498-64b7c49c3fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-2cb1ca68-e3aa-4121-b6a3-0e09a4a75967,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-b45b3f39-7d45-4f2e-8546-2e89264ae197,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-ca7e5d09-b13d-4bca-b5f9-c9e17d2d6387,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-1710d3df-45ea-45b8-9645-08913a84150d,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-0a4b277d-390c-4f26-912a-268998d35cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999406745-172.17.0.19-1597647548059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33506,DS-94e0e354-e7d8-4baf-a414-4ba1a13a7375,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-e8c1abf1-27f7-4db0-bdad-762ef948c2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-92796d47-e323-488c-8498-64b7c49c3fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-2cb1ca68-e3aa-4121-b6a3-0e09a4a75967,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-b45b3f39-7d45-4f2e-8546-2e89264ae197,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-ca7e5d09-b13d-4bca-b5f9-c9e17d2d6387,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-1710d3df-45ea-45b8-9645-08913a84150d,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-0a4b277d-390c-4f26-912a-268998d35cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113072276-172.17.0.19-1597649409436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-7ff8f3dd-7ea7-4004-b479-f13e265ac235,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-973d13af-1cee-4344-a81a-31446a62887f,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-affcda88-48b8-4169-9597-536a7660b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-e4217dd2-537d-42eb-921a-533f1de624ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-dbc5c518-7690-4347-b7e0-6d8e3d411b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-fd524c52-475d-4ef7-bf84-7f6502e4313b,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-7dbcb6d8-5abf-4224-91d0-f471930c1e78,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-9de38986-ff20-498e-b447-618e01a8f1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113072276-172.17.0.19-1597649409436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-7ff8f3dd-7ea7-4004-b479-f13e265ac235,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-973d13af-1cee-4344-a81a-31446a62887f,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-affcda88-48b8-4169-9597-536a7660b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-e4217dd2-537d-42eb-921a-533f1de624ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-dbc5c518-7690-4347-b7e0-6d8e3d411b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-fd524c52-475d-4ef7-bf84-7f6502e4313b,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-7dbcb6d8-5abf-4224-91d0-f471930c1e78,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-9de38986-ff20-498e-b447-618e01a8f1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384149086-172.17.0.19-1597649443146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-685764cd-a1fe-4cdf-a7e9-a24d7a952f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-2fc86316-e2ba-49cc-a1cd-70e46203bd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-55a9164a-ab90-4283-8c16-61e1f1b6702f,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-83080bd8-a0bd-419e-99af-a0335b818b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-1b79b204-4ac8-4cd9-ac9b-9d8f531e3d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-caa9d37c-e85f-401f-83bd-2396a6b6f6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-9ac92d32-f56c-431e-b0bb-4f67fcd40d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-dd2d1588-2fa7-444b-b5fe-167642d5d240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384149086-172.17.0.19-1597649443146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-685764cd-a1fe-4cdf-a7e9-a24d7a952f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-2fc86316-e2ba-49cc-a1cd-70e46203bd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-55a9164a-ab90-4283-8c16-61e1f1b6702f,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-83080bd8-a0bd-419e-99af-a0335b818b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-1b79b204-4ac8-4cd9-ac9b-9d8f531e3d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-caa9d37c-e85f-401f-83bd-2396a6b6f6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-9ac92d32-f56c-431e-b0bb-4f67fcd40d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-dd2d1588-2fa7-444b-b5fe-167642d5d240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377211891-172.17.0.19-1597649737731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44278,DS-0be4e665-6faf-4f9f-816f-c900c9a58693,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-50d6db5a-0b94-4e26-a8f9-bdfedf03b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-98a34d27-3df4-4344-a29c-df572ee57f91,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-0c974d8f-65b1-45e6-88b9-160fd1996931,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-46422e4a-a6c7-40c2-af7e-9dec333a4b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-465bfa0e-34a2-4831-ac6b-8e480c8c82e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-656188fa-412f-437e-8ef2-ae1f9343a6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-6c226496-2c41-44c3-92a8-0097b97b9e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377211891-172.17.0.19-1597649737731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44278,DS-0be4e665-6faf-4f9f-816f-c900c9a58693,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-50d6db5a-0b94-4e26-a8f9-bdfedf03b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-98a34d27-3df4-4344-a29c-df572ee57f91,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-0c974d8f-65b1-45e6-88b9-160fd1996931,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-46422e4a-a6c7-40c2-af7e-9dec333a4b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-465bfa0e-34a2-4831-ac6b-8e480c8c82e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-656188fa-412f-437e-8ef2-ae1f9343a6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-6c226496-2c41-44c3-92a8-0097b97b9e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568316293-172.17.0.19-1597649773559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42816,DS-fa67d44c-470b-4167-a4c5-325365571119,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-df704461-0767-4aef-bc39-2a2625f832bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-67cc426c-ad1c-480f-9687-d1e7d3954ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-15ad68b0-7051-46ac-81bb-a209ac0c1562,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-8f232b67-e8ad-4c22-ad24-0dc894ff6ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-6e8d4ca3-a697-4dd9-b1dd-ba225718e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-3d739c35-d3ac-48b1-a328-72e052ab6c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-c01e1283-6c97-40c3-80d5-d6d437ecd722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568316293-172.17.0.19-1597649773559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42816,DS-fa67d44c-470b-4167-a4c5-325365571119,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-df704461-0767-4aef-bc39-2a2625f832bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-67cc426c-ad1c-480f-9687-d1e7d3954ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-15ad68b0-7051-46ac-81bb-a209ac0c1562,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-8f232b67-e8ad-4c22-ad24-0dc894ff6ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-6e8d4ca3-a697-4dd9-b1dd-ba225718e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-3d739c35-d3ac-48b1-a328-72e052ab6c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-c01e1283-6c97-40c3-80d5-d6d437ecd722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244579235-172.17.0.19-1597649914885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36107,DS-2cd1e74b-a2bd-4048-8f14-adae5459848d,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-48e16fec-aa7d-44e1-b45b-6f873f038246,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-509bc6eb-cc2d-4c4d-a86e-a84b7c1af959,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-267b81ca-aff9-459a-8293-061aaf5f63fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-88e88272-f499-4d1b-8f27-0e69961dddd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-0aa2a928-c52b-4396-b4ac-77d4159df867,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-55243c9c-d416-4d99-8dcf-2a40b58c2f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-66ef7fa4-034b-4c53-aa51-c7a5a325345d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244579235-172.17.0.19-1597649914885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36107,DS-2cd1e74b-a2bd-4048-8f14-adae5459848d,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-48e16fec-aa7d-44e1-b45b-6f873f038246,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-509bc6eb-cc2d-4c4d-a86e-a84b7c1af959,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-267b81ca-aff9-459a-8293-061aaf5f63fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-88e88272-f499-4d1b-8f27-0e69961dddd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-0aa2a928-c52b-4396-b4ac-77d4159df867,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-55243c9c-d416-4d99-8dcf-2a40b58c2f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-66ef7fa4-034b-4c53-aa51-c7a5a325345d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264104636-172.17.0.19-1597650769923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40360,DS-09fd5ed5-5dd4-4a6b-a4c2-60db3c63d78b,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-36fef894-8878-4b7b-a5c9-b071c5c549b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-a6efcc17-2f16-4c23-bc51-df4bf0f679ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-87096e6e-183b-4a44-83ea-65c8772d7439,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-ade56c2f-4bb5-4c64-aa4c-1c07aa30e26c,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-581f9451-be67-41bb-98fc-56f05867b672,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-fa1a45f9-0c25-47e6-abc1-70cbee78d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-0cc77d48-8e54-43ad-934b-ccbe9beb221d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264104636-172.17.0.19-1597650769923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40360,DS-09fd5ed5-5dd4-4a6b-a4c2-60db3c63d78b,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-36fef894-8878-4b7b-a5c9-b071c5c549b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-a6efcc17-2f16-4c23-bc51-df4bf0f679ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-87096e6e-183b-4a44-83ea-65c8772d7439,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-ade56c2f-4bb5-4c64-aa4c-1c07aa30e26c,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-581f9451-be67-41bb-98fc-56f05867b672,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-fa1a45f9-0c25-47e6-abc1-70cbee78d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-0cc77d48-8e54-43ad-934b-ccbe9beb221d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286668087-172.17.0.19-1597651171507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39502,DS-c145e7b0-d890-428c-b727-f4659bbd8cba,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-4ec534fe-25f5-4bb4-900e-5445b4dc036c,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-433b790d-25b1-46b6-8265-5508fb3c2293,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-1664d851-badf-4f54-8037-19fec3b724b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-aed94d22-b2b3-44dc-abf0-fd587f8f67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-e8b77234-5bc7-4941-98c4-4e60b1226d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-d9d58d7e-513c-4ab8-ae34-66cb7e5cb2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-170bd58e-7e4f-4541-8f91-a4f667a811f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286668087-172.17.0.19-1597651171507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39502,DS-c145e7b0-d890-428c-b727-f4659bbd8cba,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-4ec534fe-25f5-4bb4-900e-5445b4dc036c,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-433b790d-25b1-46b6-8265-5508fb3c2293,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-1664d851-badf-4f54-8037-19fec3b724b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-aed94d22-b2b3-44dc-abf0-fd587f8f67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-e8b77234-5bc7-4941-98c4-4e60b1226d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-d9d58d7e-513c-4ab8-ae34-66cb7e5cb2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-170bd58e-7e4f-4541-8f91-a4f667a811f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194255105-172.17.0.19-1597651581020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-c9d20761-3eb6-4a0f-ad3e-7595ad88592e,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-e27f6673-5ebe-4caa-8b2d-c3686dc0b09d,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-4343a42d-1fbd-46ff-a844-d0e894a7dd88,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-79d0454c-9281-474f-ba10-d5618b2c70a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-88ae83d5-7afc-44c8-9e44-1d2230a9c161,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-b38d25e2-186e-433b-8cba-8f6f2f43ea15,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-3cb3e0f8-4057-4d69-b199-4e67aa446eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-9d55dbf0-73b6-4caf-a6fe-9cf286f9609b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194255105-172.17.0.19-1597651581020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-c9d20761-3eb6-4a0f-ad3e-7595ad88592e,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-e27f6673-5ebe-4caa-8b2d-c3686dc0b09d,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-4343a42d-1fbd-46ff-a844-d0e894a7dd88,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-79d0454c-9281-474f-ba10-d5618b2c70a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-88ae83d5-7afc-44c8-9e44-1d2230a9c161,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-b38d25e2-186e-433b-8cba-8f6f2f43ea15,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-3cb3e0f8-4057-4d69-b199-4e67aa446eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-9d55dbf0-73b6-4caf-a6fe-9cf286f9609b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969049824-172.17.0.19-1597651800227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39145,DS-6e26e108-f1ba-45d0-a35d-b1de7a8c9065,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-9d54b565-bca5-40e1-92c0-e9ff23f1d051,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-00f42e1f-dfa8-4ecc-abea-53a52d3868b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-29f7f5b6-c1d0-4282-a236-b71ebe3c1cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-b38f3006-0763-43f0-be98-9746898c034f,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-0e3dbf53-3f47-49f9-a1af-340008d8c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-3d9ae5e1-942d-499a-a2d9-c3f202705bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-f8f4bce3-6b2d-4e0f-8dff-b9a3a22db38c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969049824-172.17.0.19-1597651800227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39145,DS-6e26e108-f1ba-45d0-a35d-b1de7a8c9065,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-9d54b565-bca5-40e1-92c0-e9ff23f1d051,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-00f42e1f-dfa8-4ecc-abea-53a52d3868b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-29f7f5b6-c1d0-4282-a236-b71ebe3c1cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-b38f3006-0763-43f0-be98-9746898c034f,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-0e3dbf53-3f47-49f9-a1af-340008d8c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-3d9ae5e1-942d-499a-a2d9-c3f202705bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-f8f4bce3-6b2d-4e0f-8dff-b9a3a22db38c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374807099-172.17.0.19-1597652409180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-60c30627-d1aa-4431-87da-0e6daf2469b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-0afb0b61-00d7-4bb2-b2af-f0bc56f959d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-0d1261b0-88b3-4914-80da-08c7dfca709b,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-dde8aca7-4ace-499d-b845-9f26b5c21c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-064c3d36-52cc-46ef-8b08-6f941a614c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-afeffddf-dd76-4246-847c-c30338b0a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-77fde628-acea-499a-a759-8818190b9699,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-6cc34a08-f9a4-4c5f-9368-3af31bd6cbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374807099-172.17.0.19-1597652409180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-60c30627-d1aa-4431-87da-0e6daf2469b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-0afb0b61-00d7-4bb2-b2af-f0bc56f959d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-0d1261b0-88b3-4914-80da-08c7dfca709b,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-dde8aca7-4ace-499d-b845-9f26b5c21c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-064c3d36-52cc-46ef-8b08-6f941a614c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-afeffddf-dd76-4246-847c-c30338b0a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-77fde628-acea-499a-a759-8818190b9699,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-6cc34a08-f9a4-4c5f-9368-3af31bd6cbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5366
