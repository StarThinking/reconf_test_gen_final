reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816842268-172.17.0.19-1597376447358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33435,DS-3644691d-0dca-465a-b131-c1d1bb8ee443,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-b362bfcd-5041-481c-a126-5b0f33b14238,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-2c11010d-e35f-4d93-9344-38580d3facf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-1cb7c277-b6f6-4f3c-b857-ce603aaecfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-8f102477-6d74-41fa-aba8-7002688fc443,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-22dd9543-7287-4a24-9c82-dc23e43566d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-c8dc95bb-fddb-4b35-942c-6e7275716404,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-f8d24bb3-b60b-4643-b69a-736f0c61aff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816842268-172.17.0.19-1597376447358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33435,DS-3644691d-0dca-465a-b131-c1d1bb8ee443,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-b362bfcd-5041-481c-a126-5b0f33b14238,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-2c11010d-e35f-4d93-9344-38580d3facf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-1cb7c277-b6f6-4f3c-b857-ce603aaecfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-8f102477-6d74-41fa-aba8-7002688fc443,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-22dd9543-7287-4a24-9c82-dc23e43566d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-c8dc95bb-fddb-4b35-942c-6e7275716404,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-f8d24bb3-b60b-4643-b69a-736f0c61aff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017148828-172.17.0.19-1597376853427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-9280c1c4-a41e-472e-b041-3201a35e05a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-553bcc7a-53cb-481c-8d9b-0f6132fa52cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-08876ab5-5478-4fcb-8e42-4619e895880c,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-d920948f-312a-45f6-96b7-084e6f83cc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-6c72c3d7-0a2a-476f-a362-d075eb5e5da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-a07528f0-505b-44a5-8300-78690c450024,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-d56b6e29-b494-4663-bf49-f5e25cd786f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-8681f0b9-b059-476c-9b7b-f37a1439bb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017148828-172.17.0.19-1597376853427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-9280c1c4-a41e-472e-b041-3201a35e05a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-553bcc7a-53cb-481c-8d9b-0f6132fa52cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-08876ab5-5478-4fcb-8e42-4619e895880c,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-d920948f-312a-45f6-96b7-084e6f83cc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-6c72c3d7-0a2a-476f-a362-d075eb5e5da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-a07528f0-505b-44a5-8300-78690c450024,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-d56b6e29-b494-4663-bf49-f5e25cd786f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-8681f0b9-b059-476c-9b7b-f37a1439bb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373162532-172.17.0.19-1597377297010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36079,DS-1c08ac38-f5af-4a6b-878c-6c24aece138f,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-6e813777-9909-4e4b-a557-00c50b71a8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-885ca54f-06ef-4780-a290-b3ed6959cf49,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-3a213f4a-6a01-4d6c-88b2-de251097f056,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f8730754-dd8d-4b1f-adfb-004bc6e44904,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-7932f547-976c-4e32-85ef-284d485cc162,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-1ac081a0-30ee-4a12-bc76-e91bcea2d3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-d8ae646f-1977-481e-94dc-9000909fc99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373162532-172.17.0.19-1597377297010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36079,DS-1c08ac38-f5af-4a6b-878c-6c24aece138f,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-6e813777-9909-4e4b-a557-00c50b71a8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-885ca54f-06ef-4780-a290-b3ed6959cf49,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-3a213f4a-6a01-4d6c-88b2-de251097f056,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f8730754-dd8d-4b1f-adfb-004bc6e44904,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-7932f547-976c-4e32-85ef-284d485cc162,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-1ac081a0-30ee-4a12-bc76-e91bcea2d3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-d8ae646f-1977-481e-94dc-9000909fc99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050883592-172.17.0.19-1597377528536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-12385970-26c1-4177-8ec8-c4e760f1c775,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-4e1ef66e-c2ad-4502-a57a-f1c5bec04e65,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-7d288559-860f-448b-b35f-84c369e0fcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-3efe5f81-aa6c-446a-8b3a-eac52199364f,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-852c34d5-17d1-4d6c-bdf9-9997c8d74efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-3d5ee970-dcb5-4721-b70b-cef7911b114e,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-6ad7ac08-63a8-48bf-97b6-6cff1edff593,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-4db0d3b2-c3c0-442e-b768-46632ee8e1de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050883592-172.17.0.19-1597377528536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-12385970-26c1-4177-8ec8-c4e760f1c775,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-4e1ef66e-c2ad-4502-a57a-f1c5bec04e65,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-7d288559-860f-448b-b35f-84c369e0fcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-3efe5f81-aa6c-446a-8b3a-eac52199364f,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-852c34d5-17d1-4d6c-bdf9-9997c8d74efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-3d5ee970-dcb5-4721-b70b-cef7911b114e,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-6ad7ac08-63a8-48bf-97b6-6cff1edff593,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-4db0d3b2-c3c0-442e-b768-46632ee8e1de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083052592-172.17.0.19-1597377871484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44748,DS-8f005c97-0512-4ad4-9170-ca3e59550b76,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-04c4cebf-72be-4b31-85b8-febd3526fd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-6cc6c92f-8769-4a22-9dbe-59788a20ccea,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-5cf5f4de-4327-4958-861a-908a667a0ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-e9c531f2-838e-4098-a360-6ff428c94fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-52ce434f-eec7-4dfe-955a-64852d72b7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-1ca8fc41-07b8-4f0c-91a7-d136f0ccb960,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-af1c0f03-ec5b-4129-b72a-0b162953d177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083052592-172.17.0.19-1597377871484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44748,DS-8f005c97-0512-4ad4-9170-ca3e59550b76,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-04c4cebf-72be-4b31-85b8-febd3526fd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-6cc6c92f-8769-4a22-9dbe-59788a20ccea,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-5cf5f4de-4327-4958-861a-908a667a0ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-e9c531f2-838e-4098-a360-6ff428c94fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-52ce434f-eec7-4dfe-955a-64852d72b7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-1ca8fc41-07b8-4f0c-91a7-d136f0ccb960,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-af1c0f03-ec5b-4129-b72a-0b162953d177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552623253-172.17.0.19-1597378332745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43830,DS-b9d20c8f-6860-4348-aac6-a9bf95c75a80,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-685df8f8-830e-4f14-8d4d-d66ea61d0aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-875a7f67-b1cc-48e9-a819-69b4615d5470,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-f062b927-af19-4b1b-96cf-e3e4f2e6f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-4d55e3d4-ff5c-48c8-bbd2-06f53ab6c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-0dea5cdd-382f-44e4-b18e-93e73ea1add3,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-5ae5f2e7-00b8-4908-bef9-d4ec19e4f18a,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-46a9b764-4c65-47ec-abb8-822d24b1646a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552623253-172.17.0.19-1597378332745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43830,DS-b9d20c8f-6860-4348-aac6-a9bf95c75a80,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-685df8f8-830e-4f14-8d4d-d66ea61d0aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-875a7f67-b1cc-48e9-a819-69b4615d5470,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-f062b927-af19-4b1b-96cf-e3e4f2e6f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-4d55e3d4-ff5c-48c8-bbd2-06f53ab6c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-0dea5cdd-382f-44e4-b18e-93e73ea1add3,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-5ae5f2e7-00b8-4908-bef9-d4ec19e4f18a,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-46a9b764-4c65-47ec-abb8-822d24b1646a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075329134-172.17.0.19-1597378714456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-dcd02c07-efa1-485e-b906-4780eed84062,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-c3fff4c7-947a-4030-b90a-43ab3207c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-ebb5a246-c3b2-4010-bc4e-2c8bde89b578,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-27fc9896-ef7d-4987-9c33-bb471e2198ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-be654028-2090-490d-85a9-c3d50aa81376,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-fcd24360-dea2-4164-a89c-678ef9d9be69,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-f7833f06-3014-4832-8065-fae72182d35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-865365bf-beef-4754-9f23-6286bab963b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075329134-172.17.0.19-1597378714456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-dcd02c07-efa1-485e-b906-4780eed84062,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-c3fff4c7-947a-4030-b90a-43ab3207c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-ebb5a246-c3b2-4010-bc4e-2c8bde89b578,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-27fc9896-ef7d-4987-9c33-bb471e2198ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-be654028-2090-490d-85a9-c3d50aa81376,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-fcd24360-dea2-4164-a89c-678ef9d9be69,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-f7833f06-3014-4832-8065-fae72182d35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-865365bf-beef-4754-9f23-6286bab963b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689269991-172.17.0.19-1597378843066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42704,DS-7e4b5bca-9c4c-4fb1-bd0f-b80cb6789189,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-8efdb593-7d1f-41f2-af98-4b8c64482e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-f8a13cad-7b78-43bc-a9ee-114b1e497e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-776d0ce0-1705-4e78-a2b0-f93a093b9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-b3ab8235-9b4f-43e3-9d31-99819a8c198e,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-af789c57-8039-42a3-9b09-5a742682a809,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e652c429-f32a-4b90-91e7-83137d91ca10,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-ce207d2c-b333-4a9a-8482-296cc0e98588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689269991-172.17.0.19-1597378843066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42704,DS-7e4b5bca-9c4c-4fb1-bd0f-b80cb6789189,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-8efdb593-7d1f-41f2-af98-4b8c64482e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-f8a13cad-7b78-43bc-a9ee-114b1e497e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-776d0ce0-1705-4e78-a2b0-f93a093b9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-b3ab8235-9b4f-43e3-9d31-99819a8c198e,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-af789c57-8039-42a3-9b09-5a742682a809,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e652c429-f32a-4b90-91e7-83137d91ca10,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-ce207d2c-b333-4a9a-8482-296cc0e98588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406745719-172.17.0.19-1597379811210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35195,DS-04ff0234-f627-4efb-87db-4ee85c415411,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-d7fc334f-1cf3-4892-9278-3f97efc7ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-b81a928c-464a-4b9d-a3d6-429a0907d14e,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-a159e64e-3ce2-4012-8cd6-463feb465c76,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-133c5172-1891-49b5-896f-0a6d375844ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-74268bb3-4df8-4733-b7c6-6d72b450f6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-2e09a813-6523-4cc4-a8ba-6ce946973d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-2ad60d2f-22a6-476e-bca9-8c356c841f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406745719-172.17.0.19-1597379811210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35195,DS-04ff0234-f627-4efb-87db-4ee85c415411,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-d7fc334f-1cf3-4892-9278-3f97efc7ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-b81a928c-464a-4b9d-a3d6-429a0907d14e,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-a159e64e-3ce2-4012-8cd6-463feb465c76,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-133c5172-1891-49b5-896f-0a6d375844ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-74268bb3-4df8-4733-b7c6-6d72b450f6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-2e09a813-6523-4cc4-a8ba-6ce946973d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-2ad60d2f-22a6-476e-bca9-8c356c841f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732103398-172.17.0.19-1597380127508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-45147834-f9f4-4bad-96a6-2004c2b2bf79,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-6d2254f4-377f-43cb-9082-94f2751d2473,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-05c7d6cd-25c6-45d0-bd93-3fc8869a93cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-dc787fc3-0917-4941-a56e-662affc164c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-1f2ca82a-ac5e-4399-acc9-2aea24c0ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-a0163c70-79d5-4f54-b0f1-abdba174876c,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-3be6e48b-81ed-42a7-b9c1-b596ac739b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-0cde45d0-5efa-486d-aebf-ba8573047aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732103398-172.17.0.19-1597380127508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-45147834-f9f4-4bad-96a6-2004c2b2bf79,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-6d2254f4-377f-43cb-9082-94f2751d2473,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-05c7d6cd-25c6-45d0-bd93-3fc8869a93cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-dc787fc3-0917-4941-a56e-662affc164c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-1f2ca82a-ac5e-4399-acc9-2aea24c0ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-a0163c70-79d5-4f54-b0f1-abdba174876c,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-3be6e48b-81ed-42a7-b9c1-b596ac739b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-0cde45d0-5efa-486d-aebf-ba8573047aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225743781-172.17.0.19-1597380657974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33694,DS-89108578-ad12-4b0b-8b2c-f88588d30c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-7f857456-7315-4d75-a619-5fa50ea12c79,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-a542c3a3-8383-4688-a9b9-21f9875e16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-ca2d2ef3-9cd9-44db-9295-a6a91b8ef719,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-16f1ae5b-0415-43ee-8c6c-87cdb4736271,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-c299f4d7-c1ef-4808-bf86-2bf0c08507e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-a6f9eb0b-17fc-49f4-8413-28c61fc94abe,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-4659c474-e78c-4527-b137-fd323bd86d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225743781-172.17.0.19-1597380657974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33694,DS-89108578-ad12-4b0b-8b2c-f88588d30c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-7f857456-7315-4d75-a619-5fa50ea12c79,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-a542c3a3-8383-4688-a9b9-21f9875e16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-ca2d2ef3-9cd9-44db-9295-a6a91b8ef719,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-16f1ae5b-0415-43ee-8c6c-87cdb4736271,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-c299f4d7-c1ef-4808-bf86-2bf0c08507e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-a6f9eb0b-17fc-49f4-8413-28c61fc94abe,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-4659c474-e78c-4527-b137-fd323bd86d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354053972-172.17.0.19-1597380720260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42038,DS-bba3a991-aa92-4723-b62d-a123ac5c5bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-9ed4985d-8e10-4011-b2cb-54ac3b4e3cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-24249999-554e-4d86-9dbf-d5ca86f2ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-76542e4f-9cbc-477b-a2df-9ce8fb061a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-d7dff21b-d54f-4dc9-957f-5fbf1f3c5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-4b7469c6-7063-4f25-9aaa-0f12de6f4334,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-5bc480d2-fe5b-4876-a5e6-68f47f64c662,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-4f733736-9f6d-4f32-ab49-efb83531eb18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354053972-172.17.0.19-1597380720260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42038,DS-bba3a991-aa92-4723-b62d-a123ac5c5bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-9ed4985d-8e10-4011-b2cb-54ac3b4e3cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-24249999-554e-4d86-9dbf-d5ca86f2ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-76542e4f-9cbc-477b-a2df-9ce8fb061a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-d7dff21b-d54f-4dc9-957f-5fbf1f3c5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-4b7469c6-7063-4f25-9aaa-0f12de6f4334,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-5bc480d2-fe5b-4876-a5e6-68f47f64c662,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-4f733736-9f6d-4f32-ab49-efb83531eb18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268103624-172.17.0.19-1597380875091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37074,DS-7c0c8c06-06ed-4c32-a2ce-05cc1c73989d,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-2f51cd5f-fe37-4dec-bfbd-be0fac2510e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-9f39773d-3466-418a-a83c-adb4a749889f,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-5e2354fc-fc00-4e66-978a-09e5a792bb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-ec427b33-de67-41aa-931b-567ad2c976a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-fb5c1606-8113-42d8-96bc-858100b0791a,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-123201ec-8ce4-467d-992b-473344d56564,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-98812287-21c9-4490-b9d6-4568e946c869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268103624-172.17.0.19-1597380875091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37074,DS-7c0c8c06-06ed-4c32-a2ce-05cc1c73989d,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-2f51cd5f-fe37-4dec-bfbd-be0fac2510e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-9f39773d-3466-418a-a83c-adb4a749889f,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-5e2354fc-fc00-4e66-978a-09e5a792bb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-ec427b33-de67-41aa-931b-567ad2c976a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-fb5c1606-8113-42d8-96bc-858100b0791a,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-123201ec-8ce4-467d-992b-473344d56564,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-98812287-21c9-4490-b9d6-4568e946c869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455791181-172.17.0.19-1597380922372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40515,DS-96101083-62d6-482c-bf5b-ff6a5e527c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-89fa6475-e9a9-46ce-9fb9-ec92394c4e42,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-99a763ad-3b72-4597-bc75-168ab7616a02,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-58097efb-a061-4a67-b306-4323f8b439e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-34050828-08c5-4039-9dfc-260e2c0f2eec,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-b3027a74-a3cf-40ca-aab4-ffa977018d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-412ec750-f6b9-455c-8946-b854a4a2ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-3ef2a178-7ba0-497d-9de3-d8ef923ca2b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455791181-172.17.0.19-1597380922372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40515,DS-96101083-62d6-482c-bf5b-ff6a5e527c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-89fa6475-e9a9-46ce-9fb9-ec92394c4e42,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-99a763ad-3b72-4597-bc75-168ab7616a02,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-58097efb-a061-4a67-b306-4323f8b439e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-34050828-08c5-4039-9dfc-260e2c0f2eec,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-b3027a74-a3cf-40ca-aab4-ffa977018d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-412ec750-f6b9-455c-8946-b854a4a2ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-3ef2a178-7ba0-497d-9de3-d8ef923ca2b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373898036-172.17.0.19-1597380979146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-ee41e393-6d3c-4404-9373-4c0ac1205096,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-b2e6a734-319a-4c64-8805-2244fb9f90ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-74be499b-5974-452b-9b94-547d54e2927f,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-c6f3a342-0e44-4e32-9a2e-4eeb2ebe8aab,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-3c530098-4a03-4e28-a594-46d35ebe8ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-58163332-f9e7-4a5a-8792-66ced0ffbfce,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-30060a14-ddf0-40c5-a61f-70494e72bd01,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-f0e11783-bb80-40ad-8cb1-e31c2f121edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373898036-172.17.0.19-1597380979146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-ee41e393-6d3c-4404-9373-4c0ac1205096,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-b2e6a734-319a-4c64-8805-2244fb9f90ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-74be499b-5974-452b-9b94-547d54e2927f,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-c6f3a342-0e44-4e32-9a2e-4eeb2ebe8aab,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-3c530098-4a03-4e28-a594-46d35ebe8ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-58163332-f9e7-4a5a-8792-66ced0ffbfce,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-30060a14-ddf0-40c5-a61f-70494e72bd01,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-f0e11783-bb80-40ad-8cb1-e31c2f121edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989288669-172.17.0.19-1597381801173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37899,DS-329b8f8c-3f70-42d5-9f98-9f3e5a8e598e,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-bd1b90e7-cf8f-4dcf-aff5-4e1dff903167,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-cf4ba934-6b3f-4d96-8a0b-95b5ac494dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-042876b6-b70f-4865-91bf-e3d3791dd262,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-3af51003-6bb5-4b46-97b9-f49c0de5ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-cd999807-478c-4b1b-ae85-32b4b7a91a45,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-9185d604-232d-41e8-9948-54ce590f13d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-3966eb1d-e893-40f0-b55d-ad6e1379385e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989288669-172.17.0.19-1597381801173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37899,DS-329b8f8c-3f70-42d5-9f98-9f3e5a8e598e,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-bd1b90e7-cf8f-4dcf-aff5-4e1dff903167,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-cf4ba934-6b3f-4d96-8a0b-95b5ac494dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-042876b6-b70f-4865-91bf-e3d3791dd262,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-3af51003-6bb5-4b46-97b9-f49c0de5ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-cd999807-478c-4b1b-ae85-32b4b7a91a45,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-9185d604-232d-41e8-9948-54ce590f13d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-3966eb1d-e893-40f0-b55d-ad6e1379385e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417075925-172.17.0.19-1597382246845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44764,DS-a5561ed1-697d-4e8d-a3bb-69af8d233b37,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-e9cf1524-1dd4-47b2-8c64-84805f8a8deb,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-5cda178c-5785-4e3a-9cda-290072d1bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-e0c66644-3c70-4ee7-862d-6b01ac546d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-878054a6-6735-485d-a2fb-3453143e7e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-10481f7e-625e-46d5-8b7d-7f54712cb6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-6f5916d4-f5e4-4667-924c-fb7ea3f5be52,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-a5056164-c380-4208-a7bd-a2b94acf5748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417075925-172.17.0.19-1597382246845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44764,DS-a5561ed1-697d-4e8d-a3bb-69af8d233b37,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-e9cf1524-1dd4-47b2-8c64-84805f8a8deb,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-5cda178c-5785-4e3a-9cda-290072d1bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-e0c66644-3c70-4ee7-862d-6b01ac546d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-878054a6-6735-485d-a2fb-3453143e7e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-10481f7e-625e-46d5-8b7d-7f54712cb6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-6f5916d4-f5e4-4667-924c-fb7ea3f5be52,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-a5056164-c380-4208-a7bd-a2b94acf5748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501600577-172.17.0.19-1597382709380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43520,DS-789197fc-d14f-48d1-bd95-671994110c57,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-4e0911a1-2930-445c-a991-a98e5fd6583b,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-c81fdfd6-f0f7-4987-bbd0-d7c31e89d436,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-769b1407-2e74-46c3-a8b4-f44aae78f2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-a12d3c5a-285f-442d-ae54-2614e762fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-2f35577e-e740-49ae-9dde-f109ca774aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-4234158c-84d9-4a2a-9724-6d8fadba0972,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-2f035907-096a-4701-a17a-c10a29517c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501600577-172.17.0.19-1597382709380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43520,DS-789197fc-d14f-48d1-bd95-671994110c57,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-4e0911a1-2930-445c-a991-a98e5fd6583b,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-c81fdfd6-f0f7-4987-bbd0-d7c31e89d436,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-769b1407-2e74-46c3-a8b4-f44aae78f2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-a12d3c5a-285f-442d-ae54-2614e762fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-2f35577e-e740-49ae-9dde-f109ca774aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-4234158c-84d9-4a2a-9724-6d8fadba0972,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-2f035907-096a-4701-a17a-c10a29517c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416940021-172.17.0.19-1597382809160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41606,DS-cd9dd65e-cfb3-40ca-a569-1c1ddd5efeff,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-42165cd2-9028-4ee2-ad89-cea3a31835f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-0dfcb117-6a19-4290-80e7-3542d3b0c32b,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-4e649e53-f848-4c02-b6de-96b63d11c597,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-1ffb59e0-3189-45d0-b302-d23415b88f54,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-01d10444-c11a-4a3f-845a-592a9cb436f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-4fd3b1f9-09c1-44b5-9531-0459e0c3a969,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-b06c36be-864b-4b74-a28d-184f7eb7dde2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416940021-172.17.0.19-1597382809160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41606,DS-cd9dd65e-cfb3-40ca-a569-1c1ddd5efeff,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-42165cd2-9028-4ee2-ad89-cea3a31835f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-0dfcb117-6a19-4290-80e7-3542d3b0c32b,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-4e649e53-f848-4c02-b6de-96b63d11c597,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-1ffb59e0-3189-45d0-b302-d23415b88f54,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-01d10444-c11a-4a3f-845a-592a9cb436f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-4fd3b1f9-09c1-44b5-9531-0459e0c3a969,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-b06c36be-864b-4b74-a28d-184f7eb7dde2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7037
