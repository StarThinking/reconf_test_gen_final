reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99472080-172.17.0.3-1597530043930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33916,DS-c9cf4449-fbe8-482d-aa3b-06773d8006ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-768ae160-2bdd-4f3f-b6f4-7a846ee2c9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-65c7555f-0550-4b51-9e72-03c47e18e883,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-3dda8fb4-ec56-4210-bc1a-6c36bb49d1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-1c2ce3e3-f430-490b-9c40-69f5ea79ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-85b8c69e-77f5-4c25-9705-5dd4cce3d296,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-3399614e-061b-4197-a011-6fcbbde3be51,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-8f914be1-1d89-4bc8-8186-7a711b966cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99472080-172.17.0.3-1597530043930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33916,DS-c9cf4449-fbe8-482d-aa3b-06773d8006ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-768ae160-2bdd-4f3f-b6f4-7a846ee2c9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-65c7555f-0550-4b51-9e72-03c47e18e883,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-3dda8fb4-ec56-4210-bc1a-6c36bb49d1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-1c2ce3e3-f430-490b-9c40-69f5ea79ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-85b8c69e-77f5-4c25-9705-5dd4cce3d296,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-3399614e-061b-4197-a011-6fcbbde3be51,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-8f914be1-1d89-4bc8-8186-7a711b966cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412206616-172.17.0.3-1597530148692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-27d50f4f-bb31-42e4-835d-f706715533f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-d48b9556-9752-48a4-82e0-518e35c46999,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-1afedac8-3394-428d-8ffd-435f308f994f,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-21539316-fabf-40a2-bc53-fa771e20f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-f7c2b564-063d-44c1-ae3a-fe494864e1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-95dd458d-56ff-40d4-bee7-2f9a0f183303,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-350f2bf4-20ec-43d2-8e72-e5bd5fda1770,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-be01612c-870f-4f41-9434-3ddf41f41b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412206616-172.17.0.3-1597530148692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-27d50f4f-bb31-42e4-835d-f706715533f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-d48b9556-9752-48a4-82e0-518e35c46999,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-1afedac8-3394-428d-8ffd-435f308f994f,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-21539316-fabf-40a2-bc53-fa771e20f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-f7c2b564-063d-44c1-ae3a-fe494864e1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-95dd458d-56ff-40d4-bee7-2f9a0f183303,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-350f2bf4-20ec-43d2-8e72-e5bd5fda1770,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-be01612c-870f-4f41-9434-3ddf41f41b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921299286-172.17.0.3-1597530290577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32938,DS-7324492e-47ac-41bd-a17c-197dec1d7921,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-f229a73f-93e0-43d8-9899-a282db4e3ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-0cd55d91-9a8a-4d7d-9e5c-1a3e8e61877b,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-f0917669-de8e-4b07-8dd3-5c879773fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-b7b97a4b-1d5e-40f7-9e6a-ca122388ad6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-05c6bcb0-ba7b-473e-bb15-92e8941d8e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-a4a13cfb-3980-4e7d-ad81-f68d5bfdf86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-ab64a5ec-11a7-4204-b4b6-d3f19cbe7259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921299286-172.17.0.3-1597530290577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32938,DS-7324492e-47ac-41bd-a17c-197dec1d7921,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-f229a73f-93e0-43d8-9899-a282db4e3ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-0cd55d91-9a8a-4d7d-9e5c-1a3e8e61877b,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-f0917669-de8e-4b07-8dd3-5c879773fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-b7b97a4b-1d5e-40f7-9e6a-ca122388ad6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-05c6bcb0-ba7b-473e-bb15-92e8941d8e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-a4a13cfb-3980-4e7d-ad81-f68d5bfdf86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-ab64a5ec-11a7-4204-b4b6-d3f19cbe7259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531572358-172.17.0.3-1597530483127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-3c172046-5513-451a-9f57-d590a87b93dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-bc8e17a2-844b-4633-9205-604f59a8f803,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-657809ee-712a-4147-9f78-4956a52db9da,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-0da9b0a2-d8cd-4a77-baf1-ba0374a37029,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-516069dc-61ae-4111-a4bb-4f2f139c6233,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-a36cbbc2-f80d-4f3e-9383-6c10a0c6cd37,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-9b55c94e-e919-4981-8958-a96bcb5e041d,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-c3be87df-f4f5-4055-8399-f8e0eb2e5e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531572358-172.17.0.3-1597530483127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-3c172046-5513-451a-9f57-d590a87b93dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-bc8e17a2-844b-4633-9205-604f59a8f803,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-657809ee-712a-4147-9f78-4956a52db9da,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-0da9b0a2-d8cd-4a77-baf1-ba0374a37029,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-516069dc-61ae-4111-a4bb-4f2f139c6233,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-a36cbbc2-f80d-4f3e-9383-6c10a0c6cd37,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-9b55c94e-e919-4981-8958-a96bcb5e041d,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-c3be87df-f4f5-4055-8399-f8e0eb2e5e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324633030-172.17.0.3-1597531057246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-ea6279b3-0652-4a73-af29-c257661ee600,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-8b422623-952e-4527-a0be-17b14365537c,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-dabbe067-480e-47e5-adc2-abd28c308481,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-494d3ada-6e1f-45a7-884a-ad8d838452fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-48ebf07a-86e4-4cea-8b01-8644f751f9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-e3f42d32-4f13-4ca1-96c4-413d143fa93c,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-9133f0d0-332b-4ffc-930e-c909a3f95e46,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-04a1537c-885f-48d5-9154-5a99a76d8a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324633030-172.17.0.3-1597531057246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-ea6279b3-0652-4a73-af29-c257661ee600,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-8b422623-952e-4527-a0be-17b14365537c,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-dabbe067-480e-47e5-adc2-abd28c308481,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-494d3ada-6e1f-45a7-884a-ad8d838452fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-48ebf07a-86e4-4cea-8b01-8644f751f9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-e3f42d32-4f13-4ca1-96c4-413d143fa93c,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-9133f0d0-332b-4ffc-930e-c909a3f95e46,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-04a1537c-885f-48d5-9154-5a99a76d8a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436022970-172.17.0.3-1597531208458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-7bf8ae3d-6eca-4bb6-829e-2634f6e10750,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-1a31a2bd-6c90-4eed-b3c3-b9305d754ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-01072cf4-6e27-4ddd-bc3b-fd8cb43e295a,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-e4771db8-4d8e-46f0-84cc-6b642475f3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-2dcff0a2-dc83-4b7d-bd9c-87eaf8cc896f,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-1585a7f0-e843-4f82-ba0b-3b5b3d795a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-8ff88a92-e323-4b7b-acd2-aa24b8be9ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-72b7054d-3a0b-42e7-ae8b-49b544bc460a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436022970-172.17.0.3-1597531208458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-7bf8ae3d-6eca-4bb6-829e-2634f6e10750,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-1a31a2bd-6c90-4eed-b3c3-b9305d754ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-01072cf4-6e27-4ddd-bc3b-fd8cb43e295a,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-e4771db8-4d8e-46f0-84cc-6b642475f3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-2dcff0a2-dc83-4b7d-bd9c-87eaf8cc896f,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-1585a7f0-e843-4f82-ba0b-3b5b3d795a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-8ff88a92-e323-4b7b-acd2-aa24b8be9ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-72b7054d-3a0b-42e7-ae8b-49b544bc460a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660839225-172.17.0.3-1597531262424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-d3d4df16-e4a1-4f3d-88a8-f15f9d6d30e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-37722959-da68-44e0-bb31-cdd69ec3a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-9fc4f11e-a782-4ccd-a044-ef29d5e31d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-e00395ae-d195-4d11-8f5d-be5a4f1c2ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-d47cf310-66ae-4731-a24c-2ebb135eee10,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-95f949de-4476-4105-9a93-dc457bdc9f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-d665e439-d126-4640-801c-e86616af90c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-d0147f76-1d5a-4cb4-84ac-6e0fd9cb3abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660839225-172.17.0.3-1597531262424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-d3d4df16-e4a1-4f3d-88a8-f15f9d6d30e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-37722959-da68-44e0-bb31-cdd69ec3a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-9fc4f11e-a782-4ccd-a044-ef29d5e31d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-e00395ae-d195-4d11-8f5d-be5a4f1c2ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-d47cf310-66ae-4731-a24c-2ebb135eee10,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-95f949de-4476-4105-9a93-dc457bdc9f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-d665e439-d126-4640-801c-e86616af90c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-d0147f76-1d5a-4cb4-84ac-6e0fd9cb3abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703337456-172.17.0.3-1597531885499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46330,DS-cc38b7c3-5aa2-40da-afda-354474e3501e,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-29bf1631-62ab-4a59-8654-64a8e74cfb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-944373da-5f41-47be-abb5-489fcfecc015,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-f623c513-7a20-4eda-9aba-afc857afdd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-6e76f964-5a31-41e8-b7d2-715739e4e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-08314f5c-0c54-4be0-a08e-a1059ba37bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-1c243a73-54d8-42b2-8c72-ca5c55fac086,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-fc677b02-a34c-4514-b6b0-f8bcfef401b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703337456-172.17.0.3-1597531885499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46330,DS-cc38b7c3-5aa2-40da-afda-354474e3501e,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-29bf1631-62ab-4a59-8654-64a8e74cfb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-944373da-5f41-47be-abb5-489fcfecc015,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-f623c513-7a20-4eda-9aba-afc857afdd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-6e76f964-5a31-41e8-b7d2-715739e4e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-08314f5c-0c54-4be0-a08e-a1059ba37bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-1c243a73-54d8-42b2-8c72-ca5c55fac086,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-fc677b02-a34c-4514-b6b0-f8bcfef401b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870558960-172.17.0.3-1597532350992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-134335f7-da03-4ba4-b33e-3464da213ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-1c3c222e-7fa4-40c4-9848-486f5f7270cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-0d6f7b7c-bb2e-4dec-9ae9-2c22616e0739,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-95e36b8b-587d-4db4-9efb-fdccb19667ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-db9f824e-1cc7-4032-9303-b8f1b002cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-f82782c5-5255-4558-81c8-2921d0523b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-a0cfacbf-eeaa-458e-ba29-a497243f20b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-84eed7d5-c83a-4c55-956a-ea4c1f35792c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870558960-172.17.0.3-1597532350992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-134335f7-da03-4ba4-b33e-3464da213ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-1c3c222e-7fa4-40c4-9848-486f5f7270cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-0d6f7b7c-bb2e-4dec-9ae9-2c22616e0739,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-95e36b8b-587d-4db4-9efb-fdccb19667ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-db9f824e-1cc7-4032-9303-b8f1b002cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-f82782c5-5255-4558-81c8-2921d0523b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-a0cfacbf-eeaa-458e-ba29-a497243f20b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-84eed7d5-c83a-4c55-956a-ea4c1f35792c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687318132-172.17.0.3-1597533257809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43924,DS-adfc09da-278a-413a-9a53-91f2a0092de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-2e0cb4b9-c607-43d7-be1d-ab33b08c0e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-6899aa9b-6f35-432f-97b5-c634a29add53,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-81d65e86-8fdd-4945-9d92-0b5d5cdd94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-090666f6-e450-4301-90ca-9705326592b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-860ecd79-cc2b-4125-b84d-10484628eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-85ba3b7a-b470-4944-9afa-137202e42655,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-d1799b36-0eab-444e-8306-10704c917fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687318132-172.17.0.3-1597533257809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43924,DS-adfc09da-278a-413a-9a53-91f2a0092de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-2e0cb4b9-c607-43d7-be1d-ab33b08c0e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-6899aa9b-6f35-432f-97b5-c634a29add53,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-81d65e86-8fdd-4945-9d92-0b5d5cdd94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-090666f6-e450-4301-90ca-9705326592b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-860ecd79-cc2b-4125-b84d-10484628eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-85ba3b7a-b470-4944-9afa-137202e42655,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-d1799b36-0eab-444e-8306-10704c917fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115856172-172.17.0.3-1597533854261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-ec53210b-6e2e-4400-9298-e24f48ac5a38,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-81c728d7-51a5-48ce-8d63-fe194a06fd63,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-34c4379d-e2a3-4f0a-ab4d-a16f830bca15,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-7f0a21fb-2f0b-4fb2-876b-9facda6e7bba,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-23871ad4-55c7-4f8e-b033-91f975af370d,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-f1c6dcbf-4f0d-4ecb-817d-bcfcdefeb803,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-418a01b0-ade0-435a-bc2c-f9b1302b6a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-7cd1fba8-a155-4cee-969c-d36fd71c3330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115856172-172.17.0.3-1597533854261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-ec53210b-6e2e-4400-9298-e24f48ac5a38,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-81c728d7-51a5-48ce-8d63-fe194a06fd63,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-34c4379d-e2a3-4f0a-ab4d-a16f830bca15,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-7f0a21fb-2f0b-4fb2-876b-9facda6e7bba,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-23871ad4-55c7-4f8e-b033-91f975af370d,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-f1c6dcbf-4f0d-4ecb-817d-bcfcdefeb803,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-418a01b0-ade0-435a-bc2c-f9b1302b6a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-7cd1fba8-a155-4cee-969c-d36fd71c3330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437656867-172.17.0.3-1597534344461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45932,DS-507dc58e-74e4-45c2-b989-9ed6a209651e,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-9ef7b690-2222-4e9e-96bf-70efc7ffe507,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-e4079eba-2196-4652-bf02-8cb4cc724f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-c6f47fcb-37bb-4ec5-bbb9-101ae676e319,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-16cef594-6cbc-4c00-a443-2b75e94ba909,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-3fadd95b-154a-446b-a459-26744755fc51,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-9d6c2ff3-eeee-4166-8ad2-09f8e344205e,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-c16e280e-3c86-4bd1-a54b-1c661fa36a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437656867-172.17.0.3-1597534344461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45932,DS-507dc58e-74e4-45c2-b989-9ed6a209651e,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-9ef7b690-2222-4e9e-96bf-70efc7ffe507,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-e4079eba-2196-4652-bf02-8cb4cc724f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-c6f47fcb-37bb-4ec5-bbb9-101ae676e319,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-16cef594-6cbc-4c00-a443-2b75e94ba909,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-3fadd95b-154a-446b-a459-26744755fc51,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-9d6c2ff3-eeee-4166-8ad2-09f8e344205e,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-c16e280e-3c86-4bd1-a54b-1c661fa36a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350142601-172.17.0.3-1597534425530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-f5321806-f0f1-467b-a3c4-1f0052d1ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-bc2667df-6aca-4ab9-9cbe-9d674262fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-177bb24a-80c3-47e5-908e-8ba56f646cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-52261ba1-8333-43e3-84b0-369968b93228,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-ab9bb5ab-5e08-42b6-9aef-45e42945fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-976a32d3-765e-42fd-8999-060400aeb6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-d64dd469-88b9-48ea-b501-cd48233c478c,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-d427e707-61dd-4139-bdf8-60681e3fdf7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350142601-172.17.0.3-1597534425530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-f5321806-f0f1-467b-a3c4-1f0052d1ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-bc2667df-6aca-4ab9-9cbe-9d674262fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-177bb24a-80c3-47e5-908e-8ba56f646cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-52261ba1-8333-43e3-84b0-369968b93228,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-ab9bb5ab-5e08-42b6-9aef-45e42945fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-976a32d3-765e-42fd-8999-060400aeb6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-d64dd469-88b9-48ea-b501-cd48233c478c,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-d427e707-61dd-4139-bdf8-60681e3fdf7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342519510-172.17.0.3-1597534621435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-bb60fb8e-3689-44c6-afcb-d56e18e7f5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-d6916a47-e489-4cd6-a378-2b3f5e03c8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-0113890a-80db-497c-afe2-0987c26940fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-518a13c5-4ddb-4523-b121-5bb24c65bbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-931aebc5-bae3-498c-92cd-b2debafda3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-445b7081-dd5e-4ba4-bc0d-d60e76b84d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-99d6385d-75a6-49f9-8924-3eb305f1970a,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-96ea86c5-0466-4a5a-9d80-2691d5eae4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342519510-172.17.0.3-1597534621435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-bb60fb8e-3689-44c6-afcb-d56e18e7f5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-d6916a47-e489-4cd6-a378-2b3f5e03c8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-0113890a-80db-497c-afe2-0987c26940fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-518a13c5-4ddb-4523-b121-5bb24c65bbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-931aebc5-bae3-498c-92cd-b2debafda3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-445b7081-dd5e-4ba4-bc0d-d60e76b84d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-99d6385d-75a6-49f9-8924-3eb305f1970a,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-96ea86c5-0466-4a5a-9d80-2691d5eae4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366599787-172.17.0.3-1597534994460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-0a5768fe-d7d4-41b5-95bc-62288d1c5431,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-3b212f94-5ee0-4340-89a0-e0d369bbd26a,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-eddbbd5e-cd8b-4a59-a55c-aae72b27dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-5d7858d8-3841-4664-94f6-aae52776ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-1095a42a-8f42-428f-b9a6-fbe712aac53a,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-09eff662-1690-4f9a-8e42-511935825a06,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-f56eecec-6983-4081-87b2-f1aac580c780,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-6d416030-4908-4164-b129-e6b93849c23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366599787-172.17.0.3-1597534994460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-0a5768fe-d7d4-41b5-95bc-62288d1c5431,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-3b212f94-5ee0-4340-89a0-e0d369bbd26a,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-eddbbd5e-cd8b-4a59-a55c-aae72b27dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-5d7858d8-3841-4664-94f6-aae52776ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-1095a42a-8f42-428f-b9a6-fbe712aac53a,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-09eff662-1690-4f9a-8e42-511935825a06,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-f56eecec-6983-4081-87b2-f1aac580c780,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-6d416030-4908-4164-b129-e6b93849c23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576060722-172.17.0.3-1597535105424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41902,DS-155115e4-fe11-4d67-897f-957457e2c650,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-8d31d5f2-8735-4227-99b7-a0efb59b8b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-6b2fbcd2-61c0-45d4-8e4a-75ac0c34c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-7b46f313-6e61-4467-90e5-e35721a78f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-897e5ec9-c2cc-47eb-958a-65e047016869,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-7763c930-bd77-4ada-aff4-9f1cf8fb822f,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-dcf284db-53f0-4910-8873-0a0bc9ab8c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-de2fb609-886b-4925-a981-f512147b0db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576060722-172.17.0.3-1597535105424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41902,DS-155115e4-fe11-4d67-897f-957457e2c650,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-8d31d5f2-8735-4227-99b7-a0efb59b8b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-6b2fbcd2-61c0-45d4-8e4a-75ac0c34c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-7b46f313-6e61-4467-90e5-e35721a78f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-897e5ec9-c2cc-47eb-958a-65e047016869,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-7763c930-bd77-4ada-aff4-9f1cf8fb822f,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-dcf284db-53f0-4910-8873-0a0bc9ab8c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-de2fb609-886b-4925-a981-f512147b0db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6957
