reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448064837-172.17.0.14-1597428773426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-1e4d9b2b-4e5f-42c6-b4d5-9961481d66bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-47ee2c8c-4a1f-4c4b-834e-37f69a3d1f53,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-7fd302bf-93b3-47c4-ae49-4f6d5790adce,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-3ed7dc85-88c4-41f1-9c9b-23aaa7a2739b,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-3041059f-ac64-4962-9e72-bceb276b05c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-2ab0fb12-2c65-4598-8545-dd7fac0ed183,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-8367024b-7418-4faa-a3ee-328391cdad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-63d11313-86e1-4fd9-a66c-db71bfb0eaf9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448064837-172.17.0.14-1597428773426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-1e4d9b2b-4e5f-42c6-b4d5-9961481d66bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-47ee2c8c-4a1f-4c4b-834e-37f69a3d1f53,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-7fd302bf-93b3-47c4-ae49-4f6d5790adce,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-3ed7dc85-88c4-41f1-9c9b-23aaa7a2739b,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-3041059f-ac64-4962-9e72-bceb276b05c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-2ab0fb12-2c65-4598-8545-dd7fac0ed183,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-8367024b-7418-4faa-a3ee-328391cdad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-63d11313-86e1-4fd9-a66c-db71bfb0eaf9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813244360-172.17.0.14-1597428931352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-e1b8de45-286c-4b4d-b1c5-17ab95f7c52e,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-4446fa3f-4e2f-4f7c-bbb7-953672d46f73,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-97d52bb1-9ed2-4391-9710-e4dec51d8239,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-57e51b22-31e9-49ab-a3b4-0b908246caed,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-5562a44c-5d8f-4535-93a9-20c57452f210,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-142fc5b2-191f-4b9f-97d8-8813d515bd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-0188bebf-31c9-47b2-bf5c-16aa76964436,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-28124184-39bf-45af-8e9a-1dac79c0950f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813244360-172.17.0.14-1597428931352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-e1b8de45-286c-4b4d-b1c5-17ab95f7c52e,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-4446fa3f-4e2f-4f7c-bbb7-953672d46f73,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-97d52bb1-9ed2-4391-9710-e4dec51d8239,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-57e51b22-31e9-49ab-a3b4-0b908246caed,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-5562a44c-5d8f-4535-93a9-20c57452f210,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-142fc5b2-191f-4b9f-97d8-8813d515bd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-0188bebf-31c9-47b2-bf5c-16aa76964436,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-28124184-39bf-45af-8e9a-1dac79c0950f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890540831-172.17.0.14-1597429255373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-52d5bb9c-7035-471f-a986-663abb763804,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-3d9b0a82-8061-4fb6-be01-cd2374560ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-d2291e46-e3c9-4522-99af-3a734694a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-9e9b9303-f1ac-4488-b591-9dfcf7388f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-86fef995-64f8-48c5-ae0d-3db6423f8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-da70864e-0095-4be5-8b22-80164fb0b2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-8e0cd3eb-2705-448e-9075-daa3d6842c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-e12436e9-b83c-464b-877d-5d992f4b2155,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890540831-172.17.0.14-1597429255373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-52d5bb9c-7035-471f-a986-663abb763804,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-3d9b0a82-8061-4fb6-be01-cd2374560ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-d2291e46-e3c9-4522-99af-3a734694a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-9e9b9303-f1ac-4488-b591-9dfcf7388f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-86fef995-64f8-48c5-ae0d-3db6423f8b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-da70864e-0095-4be5-8b22-80164fb0b2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-8e0cd3eb-2705-448e-9075-daa3d6842c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-e12436e9-b83c-464b-877d-5d992f4b2155,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560788519-172.17.0.14-1597429338723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35726,DS-913a03c7-f7df-4eb2-8042-9df64575b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-1e286d20-9fe5-4de0-ad6d-c7872f89e00e,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-99f04f4f-12ea-4be7-868f-9738e3ec3057,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-a89bb2d2-b018-4485-83de-ffcfe6373213,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-815cd220-4850-4452-b141-9f3159706d01,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-f8018bed-ce03-47a4-b118-a3383f0b558e,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-812da5a0-261f-465a-949c-260c66c4fc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-298d2b50-50fb-4389-abc1-74287b2be138,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560788519-172.17.0.14-1597429338723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35726,DS-913a03c7-f7df-4eb2-8042-9df64575b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-1e286d20-9fe5-4de0-ad6d-c7872f89e00e,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-99f04f4f-12ea-4be7-868f-9738e3ec3057,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-a89bb2d2-b018-4485-83de-ffcfe6373213,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-815cd220-4850-4452-b141-9f3159706d01,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-f8018bed-ce03-47a4-b118-a3383f0b558e,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-812da5a0-261f-465a-949c-260c66c4fc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-298d2b50-50fb-4389-abc1-74287b2be138,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673062962-172.17.0.14-1597429521055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40024,DS-6fa0f38a-e3f5-4567-8a0f-3a21bd139e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-4c33fcef-6312-45ec-86e0-cc47a5168f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-c388a3e5-27a8-49ef-b2b6-597b6a818fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-20239e8c-dda0-4f92-9c93-9c8f1cb722f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-977c2174-154a-4296-a4a9-45328562cd39,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-bb80f31a-e47e-4206-b1b9-05f56594a539,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-d67e3310-f11d-45cf-a977-cc3b375abdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-176780c2-08c7-4a41-bdec-d2ecc8cbce69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673062962-172.17.0.14-1597429521055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40024,DS-6fa0f38a-e3f5-4567-8a0f-3a21bd139e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-4c33fcef-6312-45ec-86e0-cc47a5168f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-c388a3e5-27a8-49ef-b2b6-597b6a818fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-20239e8c-dda0-4f92-9c93-9c8f1cb722f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-977c2174-154a-4296-a4a9-45328562cd39,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-bb80f31a-e47e-4206-b1b9-05f56594a539,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-d67e3310-f11d-45cf-a977-cc3b375abdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-176780c2-08c7-4a41-bdec-d2ecc8cbce69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054981606-172.17.0.14-1597429539641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-b745efda-f09d-47f9-9b51-3669daf77527,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-8e6c4cea-fd3e-4cbc-87ee-809756b1ce95,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-8bf1e0e6-25a2-432b-9686-caec81996722,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-82580857-ee82-40c9-9f14-ef25edb8f509,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-0e6ef580-94cd-4f04-bb4b-803daec28f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-13c7bd7c-d76c-45fb-ab29-4187ec358a96,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-e20b4982-1979-4804-94e7-0de64b50abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-d0a075b3-f1f3-4c4f-956e-3e57681f9629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054981606-172.17.0.14-1597429539641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-b745efda-f09d-47f9-9b51-3669daf77527,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-8e6c4cea-fd3e-4cbc-87ee-809756b1ce95,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-8bf1e0e6-25a2-432b-9686-caec81996722,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-82580857-ee82-40c9-9f14-ef25edb8f509,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-0e6ef580-94cd-4f04-bb4b-803daec28f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-13c7bd7c-d76c-45fb-ab29-4187ec358a96,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-e20b4982-1979-4804-94e7-0de64b50abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-d0a075b3-f1f3-4c4f-956e-3e57681f9629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240471008-172.17.0.14-1597429890827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-fb6888a3-01ae-4c31-8096-b18134987f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-0a54955a-d868-43bd-90ab-418ec045ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-ebfe5940-2354-4861-82f2-124e96645929,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-8495e018-f72d-4ac2-8d3c-59d10fe8a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-fa96ca49-951f-48c5-871a-762de58c803a,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-0ce87165-7125-40c6-9abd-2c203bf6cceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-072dc34f-ab4c-422a-9e42-18723050ceb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-324f396e-27a2-42fa-9fed-d126dccb6f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240471008-172.17.0.14-1597429890827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-fb6888a3-01ae-4c31-8096-b18134987f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-0a54955a-d868-43bd-90ab-418ec045ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-ebfe5940-2354-4861-82f2-124e96645929,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-8495e018-f72d-4ac2-8d3c-59d10fe8a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-fa96ca49-951f-48c5-871a-762de58c803a,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-0ce87165-7125-40c6-9abd-2c203bf6cceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-072dc34f-ab4c-422a-9e42-18723050ceb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-324f396e-27a2-42fa-9fed-d126dccb6f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886899338-172.17.0.14-1597429908175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-d4742b30-2cd0-4579-9f6e-72a61d90a83e,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-6f41a530-0ad1-4865-93f3-192a0496bdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-04a21e77-592f-47e6-abce-59c9ed350dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-81ac6dc4-bf3e-4118-9377-3a7ab707d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-67e5b471-2e30-44d5-991e-12816c269da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-1bdf3c58-5707-44c3-8968-4890656ca8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-007dcc5c-e0da-4825-a29a-f6f3de2cc680,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-0b410f4a-e46e-4e2d-a84d-656921a574a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886899338-172.17.0.14-1597429908175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-d4742b30-2cd0-4579-9f6e-72a61d90a83e,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-6f41a530-0ad1-4865-93f3-192a0496bdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-04a21e77-592f-47e6-abce-59c9ed350dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-81ac6dc4-bf3e-4118-9377-3a7ab707d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-67e5b471-2e30-44d5-991e-12816c269da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-1bdf3c58-5707-44c3-8968-4890656ca8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-007dcc5c-e0da-4825-a29a-f6f3de2cc680,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-0b410f4a-e46e-4e2d-a84d-656921a574a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751705103-172.17.0.14-1597430266803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46020,DS-789770da-eb18-496b-af5b-052bf7a35f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-8b3e1f60-7138-4c4a-84f0-546d9236aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-1447ba84-edd5-4819-8650-4c4b1ec03048,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-b1e83a35-1eb5-495e-bb08-587c02dc4ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-7e0da111-06ff-4065-8eb4-e543d2125641,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-1f4a8489-fa2d-41a2-8125-5b9ee4cd68f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-9204ba7e-f2e3-4109-8318-c7c7623db14f,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-ea7d4273-3618-4091-b4c1-ed8d912ff002,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751705103-172.17.0.14-1597430266803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46020,DS-789770da-eb18-496b-af5b-052bf7a35f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-8b3e1f60-7138-4c4a-84f0-546d9236aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-1447ba84-edd5-4819-8650-4c4b1ec03048,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-b1e83a35-1eb5-495e-bb08-587c02dc4ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-7e0da111-06ff-4065-8eb4-e543d2125641,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-1f4a8489-fa2d-41a2-8125-5b9ee4cd68f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-9204ba7e-f2e3-4109-8318-c7c7623db14f,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-ea7d4273-3618-4091-b4c1-ed8d912ff002,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552491788-172.17.0.14-1597430432539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-4c313780-aeb0-4d95-81dc-85070e7b211a,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-903f6289-960f-4bb9-8e47-bc9048c02c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-4cd1e7f8-0794-4ba3-abcf-6d4cd472c65b,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-5976eb81-d266-469d-82ff-20bb3039dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-fdcda170-929a-4480-8046-9a5296890bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-60cc0e47-a026-4097-ac39-37aa1d0430d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-3e455df9-7d56-4cb4-9067-1391df05dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-82f5d0f9-ebf6-4b41-9e74-5e7c48d502a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552491788-172.17.0.14-1597430432539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-4c313780-aeb0-4d95-81dc-85070e7b211a,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-903f6289-960f-4bb9-8e47-bc9048c02c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-4cd1e7f8-0794-4ba3-abcf-6d4cd472c65b,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-5976eb81-d266-469d-82ff-20bb3039dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-fdcda170-929a-4480-8046-9a5296890bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-60cc0e47-a026-4097-ac39-37aa1d0430d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-3e455df9-7d56-4cb4-9067-1391df05dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-82f5d0f9-ebf6-4b41-9e74-5e7c48d502a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661702009-172.17.0.14-1597430526908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42862,DS-35466ad1-caa5-4bc9-a4a4-a7b262b61e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-760f83db-6ba3-40cb-a544-6615aa19a4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-3ae81995-d0c4-4405-886b-7d7bb4e5db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-4f624b41-7632-4b8a-be1e-740e44efcc94,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-f5bb0302-9b59-4459-91ef-9c2be9c89691,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-aaaa6737-4fd5-4c18-bbd5-e8cf2ca4b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-a169681f-f682-4981-839b-9765f9672736,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-7831c4a9-0825-4523-a6e2-37079b1f6567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661702009-172.17.0.14-1597430526908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42862,DS-35466ad1-caa5-4bc9-a4a4-a7b262b61e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-760f83db-6ba3-40cb-a544-6615aa19a4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-3ae81995-d0c4-4405-886b-7d7bb4e5db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-4f624b41-7632-4b8a-be1e-740e44efcc94,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-f5bb0302-9b59-4459-91ef-9c2be9c89691,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-aaaa6737-4fd5-4c18-bbd5-e8cf2ca4b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-a169681f-f682-4981-839b-9765f9672736,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-7831c4a9-0825-4523-a6e2-37079b1f6567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926453576-172.17.0.14-1597430542889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-ad0cda2d-1237-4fcc-a158-9a2494f9c276,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-3434088a-efa2-4eaf-868a-6786853f6a49,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-9f9860e5-e86c-4d04-a034-8c202c5c6fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-14d1b671-ae0f-44c0-8a71-057e12ec2227,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-ea52cc1e-d08c-43b5-b307-fd14d6f4e351,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-a260a7c0-54ba-4fef-9350-1dd7c16ea259,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-770b210c-cde0-421e-94f3-0a795836d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-3af6ebb5-33d9-44f9-9cb1-d72d6b4458f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926453576-172.17.0.14-1597430542889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-ad0cda2d-1237-4fcc-a158-9a2494f9c276,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-3434088a-efa2-4eaf-868a-6786853f6a49,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-9f9860e5-e86c-4d04-a034-8c202c5c6fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-14d1b671-ae0f-44c0-8a71-057e12ec2227,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-ea52cc1e-d08c-43b5-b307-fd14d6f4e351,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-a260a7c0-54ba-4fef-9350-1dd7c16ea259,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-770b210c-cde0-421e-94f3-0a795836d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-3af6ebb5-33d9-44f9-9cb1-d72d6b4458f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049562938-172.17.0.14-1597430559250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-bfc0d98b-85d9-4b1b-833c-70ffc6c65a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-f0e52ace-f1fd-4987-8661-2389d1519d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-af7a906f-9415-4c96-90ef-c3b567abefd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-788e0a23-39a5-4d1b-a2df-2745c21f68b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-d73f3b39-a2b7-455e-8eda-b92a92c11fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-37b0f07a-1cd3-46b1-80c8-b50f96107a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-2fe55676-2a40-4e0f-8881-989ddc4bd634,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-c42d6332-c376-4d9e-9afa-70f620786056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049562938-172.17.0.14-1597430559250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-bfc0d98b-85d9-4b1b-833c-70ffc6c65a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-f0e52ace-f1fd-4987-8661-2389d1519d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-af7a906f-9415-4c96-90ef-c3b567abefd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-788e0a23-39a5-4d1b-a2df-2745c21f68b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-d73f3b39-a2b7-455e-8eda-b92a92c11fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-37b0f07a-1cd3-46b1-80c8-b50f96107a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-2fe55676-2a40-4e0f-8881-989ddc4bd634,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-c42d6332-c376-4d9e-9afa-70f620786056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451802199-172.17.0.14-1597430575023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-ac54b47a-948f-4c08-b0a2-f571faf37999,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-4aff83f9-13f7-4600-aa34-3dc32900d917,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-4d9144ce-a146-4ef1-8502-67ca37581483,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-98f36269-d01a-49da-b09c-e770d90b59da,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-024a2074-5552-4924-b4f8-824057e1d3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-5484e973-8428-4be5-8b0d-b680f0565e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-b0f9ba9b-8e15-498e-b06b-669840ff81aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-db7ae891-de46-4a24-91ed-a6c3123fb876,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451802199-172.17.0.14-1597430575023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-ac54b47a-948f-4c08-b0a2-f571faf37999,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-4aff83f9-13f7-4600-aa34-3dc32900d917,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-4d9144ce-a146-4ef1-8502-67ca37581483,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-98f36269-d01a-49da-b09c-e770d90b59da,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-024a2074-5552-4924-b4f8-824057e1d3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-5484e973-8428-4be5-8b0d-b680f0565e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-b0f9ba9b-8e15-498e-b06b-669840ff81aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-db7ae891-de46-4a24-91ed-a6c3123fb876,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868192696-172.17.0.14-1597430717953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-36110cff-035e-4ac2-ba00-11eeaaae1367,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-bc54fdc7-2c1c-40a1-98d4-4b4508758aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-f26c5029-6211-4361-ad40-cc243cbdb64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-c518e8b5-5552-41ce-873f-121001d88c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-91f46521-f9f2-4aa5-a903-fa05c132cb07,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-742d920d-00ba-482e-bd08-76c05d720632,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-4e87b2d4-efa9-474b-bd1c-86b1f45c25f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-01d3bd37-acc4-4fd1-859b-099d94fe1612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868192696-172.17.0.14-1597430717953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-36110cff-035e-4ac2-ba00-11eeaaae1367,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-bc54fdc7-2c1c-40a1-98d4-4b4508758aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-f26c5029-6211-4361-ad40-cc243cbdb64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-c518e8b5-5552-41ce-873f-121001d88c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-91f46521-f9f2-4aa5-a903-fa05c132cb07,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-742d920d-00ba-482e-bd08-76c05d720632,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-4e87b2d4-efa9-474b-bd1c-86b1f45c25f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-01d3bd37-acc4-4fd1-859b-099d94fe1612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689838123-172.17.0.14-1597430813235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35319,DS-4b98a7f6-b658-43a4-bf6d-6c7263c051c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-b85e30cc-2f8b-490c-a51c-60cdc60cd9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-19236883-9dfe-40cd-9d26-fc966abfe98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-91647d60-1055-493f-9119-6aed3ac1ad87,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-bf4936a2-b18f-45ac-b760-2789cccb6540,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-a8a5350f-e184-4f06-b2e3-4e5286774000,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-82c0521a-7d49-42a0-add3-bcd4b9c8db04,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-f034d178-ef7e-4200-85c3-1b11c0e2b14e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689838123-172.17.0.14-1597430813235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35319,DS-4b98a7f6-b658-43a4-bf6d-6c7263c051c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-b85e30cc-2f8b-490c-a51c-60cdc60cd9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-19236883-9dfe-40cd-9d26-fc966abfe98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-91647d60-1055-493f-9119-6aed3ac1ad87,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-bf4936a2-b18f-45ac-b760-2789cccb6540,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-a8a5350f-e184-4f06-b2e3-4e5286774000,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-82c0521a-7d49-42a0-add3-bcd4b9c8db04,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-f034d178-ef7e-4200-85c3-1b11c0e2b14e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084342254-172.17.0.14-1597430924179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35401,DS-4885527b-67c7-47dd-bd64-fe01c58d1296,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-f50980d1-0d73-495a-825d-0f02f11ca6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-49d96637-7c52-4818-9ff3-680b41dbf3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-3a7080ed-4790-4d4a-881e-bcda4a473392,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-ea634e51-23bb-4ccb-9b48-fddaf12e6ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-8ac52070-a98d-4e22-aab1-d44f950908db,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-6a938004-d84b-4a84-961a-3b2d98848f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-952d540f-26e6-458f-aa28-2556f084c3d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084342254-172.17.0.14-1597430924179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35401,DS-4885527b-67c7-47dd-bd64-fe01c58d1296,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-f50980d1-0d73-495a-825d-0f02f11ca6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-49d96637-7c52-4818-9ff3-680b41dbf3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-3a7080ed-4790-4d4a-881e-bcda4a473392,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-ea634e51-23bb-4ccb-9b48-fddaf12e6ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-8ac52070-a98d-4e22-aab1-d44f950908db,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-6a938004-d84b-4a84-961a-3b2d98848f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-952d540f-26e6-458f-aa28-2556f084c3d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700839085-172.17.0.14-1597431003168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-e21edfea-3733-4369-b9f7-e7b1d2e26125,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-931920b5-e8b1-4919-a929-86f38fbccc63,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-88b2b753-b3d9-4a1a-b2a8-3efee2b76b17,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-b6b98cb4-47c7-4f89-83ee-cb1b25117320,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-2a39eab4-8e85-4a4c-98a4-2ecce9b3eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-981d330b-6bec-4dee-817f-304d31bb1c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-6a0608d4-89de-4939-893b-f2684b019156,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-87545a7e-4f09-41f7-bb92-2d25ed08079e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700839085-172.17.0.14-1597431003168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-e21edfea-3733-4369-b9f7-e7b1d2e26125,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-931920b5-e8b1-4919-a929-86f38fbccc63,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-88b2b753-b3d9-4a1a-b2a8-3efee2b76b17,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-b6b98cb4-47c7-4f89-83ee-cb1b25117320,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-2a39eab4-8e85-4a4c-98a4-2ecce9b3eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-981d330b-6bec-4dee-817f-304d31bb1c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-6a0608d4-89de-4939-893b-f2684b019156,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-87545a7e-4f09-41f7-bb92-2d25ed08079e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062645100-172.17.0.14-1597431034369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-4284e672-d73b-4781-bc2b-65739adabd71,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-2534ca15-f714-4cb6-9f38-b61a40175175,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-53614e02-8996-47ad-9601-baefc3f7d616,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-557fb7f5-30d9-42e2-8bab-e8fbf2252982,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-4d44fdbb-1fb8-4c6b-b426-daab218420d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-69bf1d95-f307-4128-9fb4-63065c0b4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-7918e1e9-992a-4c1e-9afc-8c429bdd9d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-0dc9d2df-72e8-465b-8f3f-89d7430c791e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062645100-172.17.0.14-1597431034369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-4284e672-d73b-4781-bc2b-65739adabd71,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-2534ca15-f714-4cb6-9f38-b61a40175175,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-53614e02-8996-47ad-9601-baefc3f7d616,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-557fb7f5-30d9-42e2-8bab-e8fbf2252982,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-4d44fdbb-1fb8-4c6b-b426-daab218420d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-69bf1d95-f307-4128-9fb4-63065c0b4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-7918e1e9-992a-4c1e-9afc-8c429bdd9d29,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-0dc9d2df-72e8-465b-8f3f-89d7430c791e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250615698-172.17.0.14-1597431097782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-fb81fb9b-46c8-44e5-901c-225a9f0ef9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-f59632ac-f674-4fda-b6d4-cd29b6ee5688,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-ec7ec9e1-ad36-4adb-bfa6-b1c9fc1723ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-8e1be1de-8f79-44b4-a3f8-3cfcd7c108de,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-b7fd18c3-7af9-47e1-84ca-1bfd61861988,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-f451c2b8-6389-4ceb-826c-55d9beee0012,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-ae84c982-a53c-43dd-88be-91dfc62647e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-ab5f3f65-193c-450b-a11b-baa29e1ec91e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250615698-172.17.0.14-1597431097782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-fb81fb9b-46c8-44e5-901c-225a9f0ef9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-f59632ac-f674-4fda-b6d4-cd29b6ee5688,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-ec7ec9e1-ad36-4adb-bfa6-b1c9fc1723ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-8e1be1de-8f79-44b4-a3f8-3cfcd7c108de,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-b7fd18c3-7af9-47e1-84ca-1bfd61861988,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-f451c2b8-6389-4ceb-826c-55d9beee0012,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-ae84c982-a53c-43dd-88be-91dfc62647e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-ab5f3f65-193c-450b-a11b-baa29e1ec91e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516798024-172.17.0.14-1597431145679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46328,DS-ab0fb465-4828-4124-915a-4d4741c0ce39,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-a60b141e-eff7-4f60-adeb-36d1e0628f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-1095b5d7-3b8b-4443-ae26-f17dd00a9ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-ffc5c05c-098f-4b34-815c-b29aaaafd3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-a6a90208-e66f-4b02-a590-0e76d8cac69a,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-17ab5688-b7ee-451e-b0b2-f25fbe032f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-6b23c9fc-fdaa-47de-9a32-7433c0133cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-38e00b52-ea39-44f2-bdeb-017a9af37757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516798024-172.17.0.14-1597431145679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46328,DS-ab0fb465-4828-4124-915a-4d4741c0ce39,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-a60b141e-eff7-4f60-adeb-36d1e0628f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-1095b5d7-3b8b-4443-ae26-f17dd00a9ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-ffc5c05c-098f-4b34-815c-b29aaaafd3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-a6a90208-e66f-4b02-a590-0e76d8cac69a,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-17ab5688-b7ee-451e-b0b2-f25fbe032f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-6b23c9fc-fdaa-47de-9a32-7433c0133cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-38e00b52-ea39-44f2-bdeb-017a9af37757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454785807-172.17.0.14-1597431289833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43827,DS-7c2f0aee-bc63-4fb7-a135-bbaf5c67dba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-f2908c1f-0c3b-4e4e-b3f8-d3d230b2efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-e8fc4fa6-666c-4763-8cb3-bd653304d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-7351270c-b785-4345-ab39-a21a03f87e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-6af55400-7afa-45b5-b809-5d6008147a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-2e24ef66-219b-4848-a332-7a2801bd6774,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-4fb6136e-17d7-46f6-9349-0ed40defea41,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-783f74ba-92dd-45b5-9b30-e9d19232070d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454785807-172.17.0.14-1597431289833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43827,DS-7c2f0aee-bc63-4fb7-a135-bbaf5c67dba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-f2908c1f-0c3b-4e4e-b3f8-d3d230b2efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-e8fc4fa6-666c-4763-8cb3-bd653304d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-7351270c-b785-4345-ab39-a21a03f87e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-6af55400-7afa-45b5-b809-5d6008147a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-2e24ef66-219b-4848-a332-7a2801bd6774,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-4fb6136e-17d7-46f6-9349-0ed40defea41,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-783f74ba-92dd-45b5-9b30-e9d19232070d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779532407-172.17.0.14-1597431353621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43705,DS-dd61b939-534a-4ef1-94a5-a9e8c6cb4b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-bddd775f-96e5-4840-850f-d8f33950e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-82c70103-c55a-4470-9a09-65f3a482b18f,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-d10948a1-4b01-494b-9d30-28608b0763db,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-8a17b652-22a3-4d4b-911e-9cfadbfb9cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-789309c9-97fc-4b9b-9ca1-9abda299c916,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-b74a3595-b418-4673-9230-3927330df665,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-5996d8d2-b521-44e4-a1a7-2fa92e4125d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779532407-172.17.0.14-1597431353621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43705,DS-dd61b939-534a-4ef1-94a5-a9e8c6cb4b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-bddd775f-96e5-4840-850f-d8f33950e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-82c70103-c55a-4470-9a09-65f3a482b18f,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-d10948a1-4b01-494b-9d30-28608b0763db,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-8a17b652-22a3-4d4b-911e-9cfadbfb9cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-789309c9-97fc-4b9b-9ca1-9abda299c916,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-b74a3595-b418-4673-9230-3927330df665,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-5996d8d2-b521-44e4-a1a7-2fa92e4125d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932831740-172.17.0.14-1597431464666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-33b2c8dc-a58f-4cf4-975a-c68d37965a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-587da7de-1825-4212-9fa3-27a1abfad3db,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-d042aa75-1939-4bdf-b575-45012f5c785c,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-efcc9de6-6354-4d3f-b6af-a26b90710afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-c955a7ff-7857-4546-8a02-7857aa709089,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-f9d2284e-5b2a-4236-94cf-35164b347a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-dd769f41-43d1-43da-9e46-7e69592da492,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-fcafd027-e315-4981-946b-33d759dcaade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932831740-172.17.0.14-1597431464666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-33b2c8dc-a58f-4cf4-975a-c68d37965a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-587da7de-1825-4212-9fa3-27a1abfad3db,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-d042aa75-1939-4bdf-b575-45012f5c785c,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-efcc9de6-6354-4d3f-b6af-a26b90710afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-c955a7ff-7857-4546-8a02-7857aa709089,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-f9d2284e-5b2a-4236-94cf-35164b347a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-dd769f41-43d1-43da-9e46-7e69592da492,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-fcafd027-e315-4981-946b-33d759dcaade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 1000000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052085696-172.17.0.14-1597431544163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46461,DS-71983467-94c5-4a37-adca-0b1bbd5d3f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-0f73d37d-a221-4024-af4c-d6bd0cebfd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-07b5d035-19ad-4737-a532-dcf5a3a2f142,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-c0310340-6679-4cc2-9b4a-107cd9b0511c,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-dc9b9dad-f86a-4999-bfbf-52c4267bc8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-106d97d3-c75d-480e-a5bd-c2be358e5132,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-9fe9878f-e9a3-4a35-8f4b-87f8611cb686,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-ff34f268-aa9e-4892-9f3e-ff388702482d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052085696-172.17.0.14-1597431544163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46461,DS-71983467-94c5-4a37-adca-0b1bbd5d3f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-0f73d37d-a221-4024-af4c-d6bd0cebfd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-07b5d035-19ad-4737-a532-dcf5a3a2f142,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-c0310340-6679-4cc2-9b4a-107cd9b0511c,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-dc9b9dad-f86a-4999-bfbf-52c4267bc8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-106d97d3-c75d-480e-a5bd-c2be358e5132,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-9fe9878f-e9a3-4a35-8f4b-87f8611cb686,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-ff34f268-aa9e-4892-9f3e-ff388702482d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 2960
