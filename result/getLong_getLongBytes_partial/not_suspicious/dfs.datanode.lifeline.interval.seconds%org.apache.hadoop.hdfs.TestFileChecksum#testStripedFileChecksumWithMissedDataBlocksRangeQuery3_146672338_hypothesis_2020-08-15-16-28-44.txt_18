reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682433544-172.17.0.3-1597509427180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33191,DS-9c01fe33-2df9-4719-864e-0ef9ffbae86a,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fc2e9857-e218-45af-a32d-203582be7bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-45c6e85b-9102-41f6-a9a8-dc1474884551,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-b59d412d-8fac-4bad-80ac-9ddd9c2d5ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-5eb5f891-f6b4-41bd-afb9-adb343c08c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-0ccfae74-dcc5-4bf6-a681-9d93113d444f,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-f30d6d51-bc10-4278-8df2-dafa3b3443e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-73be005e-3916-4c3e-8fab-f43605a32737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682433544-172.17.0.3-1597509427180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33191,DS-9c01fe33-2df9-4719-864e-0ef9ffbae86a,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fc2e9857-e218-45af-a32d-203582be7bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-45c6e85b-9102-41f6-a9a8-dc1474884551,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-b59d412d-8fac-4bad-80ac-9ddd9c2d5ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-5eb5f891-f6b4-41bd-afb9-adb343c08c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-0ccfae74-dcc5-4bf6-a681-9d93113d444f,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-f30d6d51-bc10-4278-8df2-dafa3b3443e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-73be005e-3916-4c3e-8fab-f43605a32737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742186279-172.17.0.3-1597510480323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-39f8f2c8-0cb4-4d83-acbf-3727dc21c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-9c0ccbc0-6544-4143-aa5d-1c8d0bb28b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-8fbdb99e-979c-422e-a42e-da5bc3d5d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-8d390047-3043-4fb6-9adf-4701ff66599f,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-002f8963-4a20-491d-beaf-c9674ed42857,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-e65db7dd-844f-488e-aa86-99da9274f507,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-71ab563b-f41b-4570-9a31-0248445e4b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-aabc1c60-f43e-4ea3-9a4a-c7a4bcd86e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742186279-172.17.0.3-1597510480323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-39f8f2c8-0cb4-4d83-acbf-3727dc21c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-9c0ccbc0-6544-4143-aa5d-1c8d0bb28b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-8fbdb99e-979c-422e-a42e-da5bc3d5d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-8d390047-3043-4fb6-9adf-4701ff66599f,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-002f8963-4a20-491d-beaf-c9674ed42857,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-e65db7dd-844f-488e-aa86-99da9274f507,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-71ab563b-f41b-4570-9a31-0248445e4b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-aabc1c60-f43e-4ea3-9a4a-c7a4bcd86e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627798384-172.17.0.3-1597511006983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34499,DS-6034b94d-8916-447d-b5a1-c87a72a1d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-108b55f0-d496-49f1-9e4e-2a3d2a94216f,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-acbae4f2-3e39-4254-bfe8-931d27cfb93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-65e3c547-f8c4-420c-a26c-71524df1b0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-010d7a27-855c-4861-a788-63631a2e27a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-732c79da-f266-47f5-b9d7-5844ed61aa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-78a5ab77-a1f0-4a08-856c-51f4898bad80,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-8a4ee7a2-8fe9-43f1-9474-fed3d372ab05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627798384-172.17.0.3-1597511006983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34499,DS-6034b94d-8916-447d-b5a1-c87a72a1d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-108b55f0-d496-49f1-9e4e-2a3d2a94216f,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-acbae4f2-3e39-4254-bfe8-931d27cfb93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-65e3c547-f8c4-420c-a26c-71524df1b0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-010d7a27-855c-4861-a788-63631a2e27a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-732c79da-f266-47f5-b9d7-5844ed61aa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-78a5ab77-a1f0-4a08-856c-51f4898bad80,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-8a4ee7a2-8fe9-43f1-9474-fed3d372ab05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749150119-172.17.0.3-1597511246752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33586,DS-c9cbeee0-5426-43e8-8905-93786f0bf86e,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-9c00015b-af46-4eaf-b9dd-21cd5703b4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-bbc98065-782a-4098-b5f5-cc5db2ed5b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-8c42c3be-a6ca-4bb4-aae1-a0fa884c5943,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-fb4f062e-6015-4e1c-b76c-1ba01fdcb651,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-8820eebc-de13-48c3-9f13-b6ad95ddbb30,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-21909fcc-6d3a-49c2-9239-b458a08ca3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-853274c5-f475-4d6f-a8e5-a847f1e8a692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749150119-172.17.0.3-1597511246752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33586,DS-c9cbeee0-5426-43e8-8905-93786f0bf86e,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-9c00015b-af46-4eaf-b9dd-21cd5703b4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-bbc98065-782a-4098-b5f5-cc5db2ed5b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-8c42c3be-a6ca-4bb4-aae1-a0fa884c5943,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-fb4f062e-6015-4e1c-b76c-1ba01fdcb651,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-8820eebc-de13-48c3-9f13-b6ad95ddbb30,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-21909fcc-6d3a-49c2-9239-b458a08ca3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-853274c5-f475-4d6f-a8e5-a847f1e8a692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335693432-172.17.0.3-1597511490206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41065,DS-6758459c-821c-489f-a051-b9d8c409b214,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-7a55c41e-d4fd-4298-a4fe-66f0d8e6e2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-76df82fa-a34c-438b-bd30-87b1c9f2d230,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-5d254920-4c69-4c6f-88a1-59c53b5c886f,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-bba2ca6d-77b0-4e07-994d-17e123927d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-b84b2405-18f3-4cde-8b78-2fe70b18e42a,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-7a8f1686-b2be-4203-ad74-e80e8e0be761,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-bbd4f357-9113-4185-b564-16164cd39970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335693432-172.17.0.3-1597511490206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41065,DS-6758459c-821c-489f-a051-b9d8c409b214,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-7a55c41e-d4fd-4298-a4fe-66f0d8e6e2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-76df82fa-a34c-438b-bd30-87b1c9f2d230,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-5d254920-4c69-4c6f-88a1-59c53b5c886f,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-bba2ca6d-77b0-4e07-994d-17e123927d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-b84b2405-18f3-4cde-8b78-2fe70b18e42a,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-7a8f1686-b2be-4203-ad74-e80e8e0be761,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-bbd4f357-9113-4185-b564-16164cd39970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938290392-172.17.0.3-1597511865632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-60289116-e781-4a0a-a6f9-52e9415d42f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-fb9a6209-365e-4bef-acbb-76ae40fc198a,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-a2cdee1c-97fc-421b-ae5c-08bd40570846,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-a4539cdc-aad6-4532-a61e-1fc0c12697a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-b3456816-7e0e-4239-8496-73846196daee,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-8ed119eb-6484-4894-9c5d-3d4ba9918c46,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-8e0b81da-ff22-42a7-932f-751d5d395ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-d6106c40-1302-4bba-9499-96dbfc644ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938290392-172.17.0.3-1597511865632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-60289116-e781-4a0a-a6f9-52e9415d42f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-fb9a6209-365e-4bef-acbb-76ae40fc198a,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-a2cdee1c-97fc-421b-ae5c-08bd40570846,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-a4539cdc-aad6-4532-a61e-1fc0c12697a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-b3456816-7e0e-4239-8496-73846196daee,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-8ed119eb-6484-4894-9c5d-3d4ba9918c46,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-8e0b81da-ff22-42a7-932f-751d5d395ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-d6106c40-1302-4bba-9499-96dbfc644ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171833355-172.17.0.3-1597511914528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-13e02302-d1f4-4b06-aee4-69764c36c010,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-8c016276-3364-43d6-8f6e-f9aff37e348f,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-dcb10912-6453-4004-9c5c-9892df50b9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-c6b9688d-a59d-481e-b462-11d28ff6db78,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-9b473041-a7a1-4690-af45-5c5ffc9bbcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-7e7ea383-b5fc-4016-b240-97f8bf2b47cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-64175d1d-7172-44c3-b70b-b1a8ee1ef65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-fd8b3ef4-ff3e-42cf-87b4-2f93fead9242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171833355-172.17.0.3-1597511914528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-13e02302-d1f4-4b06-aee4-69764c36c010,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-8c016276-3364-43d6-8f6e-f9aff37e348f,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-dcb10912-6453-4004-9c5c-9892df50b9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-c6b9688d-a59d-481e-b462-11d28ff6db78,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-9b473041-a7a1-4690-af45-5c5ffc9bbcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-7e7ea383-b5fc-4016-b240-97f8bf2b47cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-64175d1d-7172-44c3-b70b-b1a8ee1ef65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-fd8b3ef4-ff3e-42cf-87b4-2f93fead9242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023472988-172.17.0.3-1597512009021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-499a655f-b4dd-4f18-920f-dce5ce1693eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-9c0a4f68-a237-41ca-baaa-d21721f3857e,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-10380405-a4cf-4fcd-af50-659d6b101d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-41ef7d71-4e6b-490d-bc6d-eaeacfa2cadb,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-b75ded21-1b67-4df3-8533-978dbf409e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-23128d48-51a7-4d7a-a492-969882f12840,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-2445f9b1-6944-4a46-97d3-45530c5bf27e,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-a7ab6cd5-7675-4343-9cbc-309db2337149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023472988-172.17.0.3-1597512009021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-499a655f-b4dd-4f18-920f-dce5ce1693eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-9c0a4f68-a237-41ca-baaa-d21721f3857e,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-10380405-a4cf-4fcd-af50-659d6b101d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-41ef7d71-4e6b-490d-bc6d-eaeacfa2cadb,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-b75ded21-1b67-4df3-8533-978dbf409e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-23128d48-51a7-4d7a-a492-969882f12840,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-2445f9b1-6944-4a46-97d3-45530c5bf27e,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-a7ab6cd5-7675-4343-9cbc-309db2337149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605102519-172.17.0.3-1597512430486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41481,DS-b624fffb-8392-43c0-a5c1-5de4f5c3c884,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-c30c2f05-0242-42f9-8407-9e8bcd3a3efc,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-bf5c4705-edac-4886-ae57-cfb29d9fe72a,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-2277e669-6be1-4884-8237-9841dae9b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-eaafcf95-6407-4f1f-8c4b-211f5cc43110,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-b88cc8e8-2c4d-4e93-b9a8-78cac2134e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-3de2e218-b171-408b-9761-abde8510532e,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-29f899a5-552f-4144-bbe0-124bcb42f122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605102519-172.17.0.3-1597512430486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41481,DS-b624fffb-8392-43c0-a5c1-5de4f5c3c884,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-c30c2f05-0242-42f9-8407-9e8bcd3a3efc,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-bf5c4705-edac-4886-ae57-cfb29d9fe72a,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-2277e669-6be1-4884-8237-9841dae9b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-eaafcf95-6407-4f1f-8c4b-211f5cc43110,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-b88cc8e8-2c4d-4e93-b9a8-78cac2134e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-3de2e218-b171-408b-9761-abde8510532e,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-29f899a5-552f-4144-bbe0-124bcb42f122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095513983-172.17.0.3-1597512519223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42928,DS-910e4e5e-c2c2-44e5-9ab7-883786c361cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-ad075a3e-f0b7-44c9-a801-b6cfcad01a55,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-6cc2bd53-e57b-4a70-9cbd-1ed2b77a03d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-923b8ef3-0e4c-4f7d-9667-8bad899dcea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-45221559-e912-4ad7-baf5-0532160cdbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-681a6b45-2a36-48a4-89c6-21cc4595a0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-629a3b97-d292-4715-b5ad-4e4e70708693,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-4fed12e7-347a-4d55-bea4-88e978c80f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095513983-172.17.0.3-1597512519223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42928,DS-910e4e5e-c2c2-44e5-9ab7-883786c361cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-ad075a3e-f0b7-44c9-a801-b6cfcad01a55,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-6cc2bd53-e57b-4a70-9cbd-1ed2b77a03d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-923b8ef3-0e4c-4f7d-9667-8bad899dcea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-45221559-e912-4ad7-baf5-0532160cdbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-681a6b45-2a36-48a4-89c6-21cc4595a0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-629a3b97-d292-4715-b5ad-4e4e70708693,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-4fed12e7-347a-4d55-bea4-88e978c80f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462349765-172.17.0.3-1597513059217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43002,DS-483c969c-51a9-4151-bc96-3a8f3ae83578,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-38285a8d-427c-47c9-9a7f-ff57e71d6383,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-e138acbe-eee8-4d00-924a-08396a5301ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-672f3819-9f31-44e1-9158-ecf02836ec6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-5c0dd882-0751-4ca5-8a7c-701e21f8ed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-fffcdec4-dd04-4067-b8a0-ddfaad4d70ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-e3805666-db0f-4d40-a4ad-ecd160bb8134,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-688b4ff8-8c39-4c67-b8c5-58cb08f79e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462349765-172.17.0.3-1597513059217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43002,DS-483c969c-51a9-4151-bc96-3a8f3ae83578,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-38285a8d-427c-47c9-9a7f-ff57e71d6383,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-e138acbe-eee8-4d00-924a-08396a5301ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-672f3819-9f31-44e1-9158-ecf02836ec6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-5c0dd882-0751-4ca5-8a7c-701e21f8ed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-fffcdec4-dd04-4067-b8a0-ddfaad4d70ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-e3805666-db0f-4d40-a4ad-ecd160bb8134,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-688b4ff8-8c39-4c67-b8c5-58cb08f79e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969288016-172.17.0.3-1597513259016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-f7c45acd-fd30-48e2-977e-82f751012f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-36da071c-d618-4eac-a89c-5242a3a2272b,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-40fbdbfc-fe34-4c46-9df3-d28af963ac96,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-b0b079f2-3be6-4a43-99c8-ba32c06c5333,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-1a5a8e9a-8cd1-49e6-8851-0d8f1fd233b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-98970365-cfda-46af-b939-db0da7dd982a,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-08031466-23dd-4701-9aa2-e0d2ca950c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-b7fa931d-20b4-4ff4-a0f1-393bbee85e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969288016-172.17.0.3-1597513259016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-f7c45acd-fd30-48e2-977e-82f751012f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-36da071c-d618-4eac-a89c-5242a3a2272b,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-40fbdbfc-fe34-4c46-9df3-d28af963ac96,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-b0b079f2-3be6-4a43-99c8-ba32c06c5333,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-1a5a8e9a-8cd1-49e6-8851-0d8f1fd233b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-98970365-cfda-46af-b939-db0da7dd982a,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-08031466-23dd-4701-9aa2-e0d2ca950c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-b7fa931d-20b4-4ff4-a0f1-393bbee85e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594176148-172.17.0.3-1597513718367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46052,DS-f4d6414f-f2ae-4585-8d3d-e9f0a444d625,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-4c93dc90-c8bd-448c-b959-c87dc7cf4dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-6eef0641-4cfc-414f-a439-cb193666325b,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-786b0a4b-48d4-4406-be2b-f4455f3f4429,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-a45f07b3-e6e3-4d6d-8ac7-2d8b2b908e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-0f1e34c7-1e10-4709-b392-342619ea277c,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-0457a86b-116f-4b67-9a82-1df04315745d,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-549a55c0-590e-4d08-8514-7087128e7d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594176148-172.17.0.3-1597513718367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46052,DS-f4d6414f-f2ae-4585-8d3d-e9f0a444d625,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-4c93dc90-c8bd-448c-b959-c87dc7cf4dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-6eef0641-4cfc-414f-a439-cb193666325b,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-786b0a4b-48d4-4406-be2b-f4455f3f4429,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-a45f07b3-e6e3-4d6d-8ac7-2d8b2b908e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-0f1e34c7-1e10-4709-b392-342619ea277c,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-0457a86b-116f-4b67-9a82-1df04315745d,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-549a55c0-590e-4d08-8514-7087128e7d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956167864-172.17.0.3-1597513817019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-1f0f78ba-1a62-46d6-9c1d-b138a107c95b,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-02d64f27-b8aa-4ac5-aa8c-bf3e861b7701,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-a8287271-5800-4d0f-867d-06099acab8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-c7d5f721-d389-4cf6-9714-623f6e7f484f,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-ca945955-6132-4b07-b3cf-af112daf1928,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-672513b1-ee99-490b-8dd7-b3439b9a26e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-6acedb98-2c58-4e3e-b0f0-d050961d4bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-dc139fcc-a444-4d66-809a-69c143bdab62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956167864-172.17.0.3-1597513817019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-1f0f78ba-1a62-46d6-9c1d-b138a107c95b,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-02d64f27-b8aa-4ac5-aa8c-bf3e861b7701,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-a8287271-5800-4d0f-867d-06099acab8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-c7d5f721-d389-4cf6-9714-623f6e7f484f,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-ca945955-6132-4b07-b3cf-af112daf1928,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-672513b1-ee99-490b-8dd7-b3439b9a26e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-6acedb98-2c58-4e3e-b0f0-d050961d4bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-dc139fcc-a444-4d66-809a-69c143bdab62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761312363-172.17.0.3-1597513858277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35812,DS-82f6d5f2-593a-4400-9356-169b511d0788,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-5f4f8d75-b836-4cfa-9fbf-98820034f8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-126bc68d-31d8-48b7-a1fc-bb0bcb96e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-3d41ba34-59b5-429a-bb55-7ca3b53043ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-baba7fd4-a201-4945-a1cf-0c0caafbc5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-3dfd368c-7da0-480b-8ec0-472b270302e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-76a7a871-fd98-453d-8d2d-f9080f515563,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-3607547d-c009-4469-bb14-25c43866af93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761312363-172.17.0.3-1597513858277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35812,DS-82f6d5f2-593a-4400-9356-169b511d0788,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-5f4f8d75-b836-4cfa-9fbf-98820034f8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-126bc68d-31d8-48b7-a1fc-bb0bcb96e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-3d41ba34-59b5-429a-bb55-7ca3b53043ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-baba7fd4-a201-4945-a1cf-0c0caafbc5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-3dfd368c-7da0-480b-8ec0-472b270302e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-76a7a871-fd98-453d-8d2d-f9080f515563,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-3607547d-c009-4469-bb14-25c43866af93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295319398-172.17.0.3-1597514175326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34332,DS-f59b8347-3852-4db6-b83c-b68c93ddad94,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-0ce2d519-857d-478e-8913-9b7b0f68b1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-1b2aafbe-1382-4f44-b9af-430b886d32d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-8b3f4b3f-6484-4980-8254-a59075c5aef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-c7ba9341-9705-4481-bdaf-d939ffe4cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-1ad51d1c-d8bc-46ce-bc78-d5543a333a98,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-481a3490-a9b8-4f37-96b1-8d4e28891cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-8b446f02-af3e-4846-a882-f615e99b1805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295319398-172.17.0.3-1597514175326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34332,DS-f59b8347-3852-4db6-b83c-b68c93ddad94,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-0ce2d519-857d-478e-8913-9b7b0f68b1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-1b2aafbe-1382-4f44-b9af-430b886d32d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-8b3f4b3f-6484-4980-8254-a59075c5aef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-c7ba9341-9705-4481-bdaf-d939ffe4cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-1ad51d1c-d8bc-46ce-bc78-d5543a333a98,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-481a3490-a9b8-4f37-96b1-8d4e28891cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-8b446f02-af3e-4846-a882-f615e99b1805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090820413-172.17.0.3-1597514276574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-f6b63125-0cef-4291-848d-b28430f66991,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-7320680f-34a4-4e96-8e2d-9fe7738939b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-783f43df-44d6-404c-9e6f-e53434b766b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-ed06646d-931e-48a8-b9c6-157cf7aca903,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-8ec9d0b6-457e-4883-a0a9-0e91740b539d,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-5c4455aa-ec05-45ab-b7a8-c8f8d6416a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-ca86d743-a729-42be-87e9-9e16a509d857,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-a9670203-0402-4258-b7a6-3884f91bbf1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090820413-172.17.0.3-1597514276574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-f6b63125-0cef-4291-848d-b28430f66991,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-7320680f-34a4-4e96-8e2d-9fe7738939b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-783f43df-44d6-404c-9e6f-e53434b766b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-ed06646d-931e-48a8-b9c6-157cf7aca903,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-8ec9d0b6-457e-4883-a0a9-0e91740b539d,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-5c4455aa-ec05-45ab-b7a8-c8f8d6416a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-ca86d743-a729-42be-87e9-9e16a509d857,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-a9670203-0402-4258-b7a6-3884f91bbf1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766681252-172.17.0.3-1597514479980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46342,DS-c0d696ed-0e92-4dfb-b106-74e268e6edf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-fd8c6d79-9e59-43bf-9e6c-1166ef8df307,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-d58815fe-f154-4889-b5ef-3b7c75755573,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-c20ee95e-b929-481d-897e-7b3e6c20bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-e33c6c94-0c57-4556-b5c6-245ebaa58f72,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-07dad666-16c5-4071-97ed-1f67bbcbdbae,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-a7073904-1868-453f-a666-23135db35241,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-be567d17-5b54-4dff-a0fe-6bdf7308f5d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766681252-172.17.0.3-1597514479980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46342,DS-c0d696ed-0e92-4dfb-b106-74e268e6edf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-fd8c6d79-9e59-43bf-9e6c-1166ef8df307,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-d58815fe-f154-4889-b5ef-3b7c75755573,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-c20ee95e-b929-481d-897e-7b3e6c20bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-e33c6c94-0c57-4556-b5c6-245ebaa58f72,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-07dad666-16c5-4071-97ed-1f67bbcbdbae,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-a7073904-1868-453f-a666-23135db35241,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-be567d17-5b54-4dff-a0fe-6bdf7308f5d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906328380-172.17.0.3-1597514563128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38396,DS-8aad7635-cab1-4ac3-bd3c-0875b9f9f8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-8e4abb1e-d41b-43fb-b0bb-a5f35c25c4df,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-8bb6751b-95b6-4f15-b0ab-233f921882f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-46193cb0-d561-43f4-b2ad-bd33a8906144,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-126da6c8-0f94-49b5-b1dc-fac6ef51a238,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-73ab719f-906a-4e27-905c-53f4c9a744d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-e405b8ac-9ad2-46da-82a7-5b049d2db412,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-856a6616-5c45-4386-9439-d9d9a6cf2175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906328380-172.17.0.3-1597514563128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38396,DS-8aad7635-cab1-4ac3-bd3c-0875b9f9f8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-8e4abb1e-d41b-43fb-b0bb-a5f35c25c4df,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-8bb6751b-95b6-4f15-b0ab-233f921882f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-46193cb0-d561-43f4-b2ad-bd33a8906144,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-126da6c8-0f94-49b5-b1dc-fac6ef51a238,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-73ab719f-906a-4e27-905c-53f4c9a744d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-e405b8ac-9ad2-46da-82a7-5b049d2db412,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-856a6616-5c45-4386-9439-d9d9a6cf2175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447859406-172.17.0.3-1597514720561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-f0142ad9-b1b7-4b78-bb98-194320860886,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-34c2af00-db01-49bf-a1f1-b39619fc9422,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-20c4a611-08f9-4579-bb17-003ec0166665,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-fa4daece-6071-4831-84b4-a418b5c9695a,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-b43d5721-845e-4bb7-9083-839276d6e859,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-f25c59f8-8fa6-4b94-8174-d0c8f61c7dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-3711071b-d45b-436b-ad4b-794529df1785,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-e39ec5c1-f09c-4231-8bed-a30fa304ce59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447859406-172.17.0.3-1597514720561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-f0142ad9-b1b7-4b78-bb98-194320860886,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-34c2af00-db01-49bf-a1f1-b39619fc9422,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-20c4a611-08f9-4579-bb17-003ec0166665,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-fa4daece-6071-4831-84b4-a418b5c9695a,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-b43d5721-845e-4bb7-9083-839276d6e859,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-f25c59f8-8fa6-4b94-8174-d0c8f61c7dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-3711071b-d45b-436b-ad4b-794529df1785,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-e39ec5c1-f09c-4231-8bed-a30fa304ce59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123557546-172.17.0.3-1597515258353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-e0c537fc-9719-489c-b965-1ddea86bdcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-a150b284-de50-42f9-b1fe-e7091b119409,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-409782e2-e6bb-4fd0-95a9-6fdcfae0baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-330eceef-f654-499f-9c8a-3d69c592cd01,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-eca72648-13a1-4766-af69-22beeb0957b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-8889cb42-523c-4026-bce0-449cb53b8dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-2bea18e6-8a67-4cc1-ab8d-1cf13de229bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-1e43f724-fa58-409d-97d0-2a4fb6874927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123557546-172.17.0.3-1597515258353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-e0c537fc-9719-489c-b965-1ddea86bdcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-a150b284-de50-42f9-b1fe-e7091b119409,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-409782e2-e6bb-4fd0-95a9-6fdcfae0baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-330eceef-f654-499f-9c8a-3d69c592cd01,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-eca72648-13a1-4766-af69-22beeb0957b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-8889cb42-523c-4026-bce0-449cb53b8dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-2bea18e6-8a67-4cc1-ab8d-1cf13de229bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-1e43f724-fa58-409d-97d0-2a4fb6874927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6937
