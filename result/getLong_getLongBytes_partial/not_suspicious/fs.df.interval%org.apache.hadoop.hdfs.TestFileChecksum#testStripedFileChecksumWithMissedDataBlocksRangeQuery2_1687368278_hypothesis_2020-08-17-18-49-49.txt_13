reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182523416-172.17.0.20-1597690273933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33233,DS-32cbca82-5a96-4a30-9d65-fe3aef529049,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-a50948da-a2fa-490b-b3aa-e6726c792879,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-effc5ffb-3192-44b4-a185-09ca553f3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-768373ac-3063-4fc5-be00-f7edfd169f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-c925876d-9094-4395-96b2-f117a6df2e91,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-3b1b78bb-a219-4b9b-b2a2-90c1eeaa5f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-e97b1fc0-6156-47df-a640-0becf7dfb613,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-09b1ed83-ee8e-4af2-8bcd-f4c8ce771c79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182523416-172.17.0.20-1597690273933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33233,DS-32cbca82-5a96-4a30-9d65-fe3aef529049,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-a50948da-a2fa-490b-b3aa-e6726c792879,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-effc5ffb-3192-44b4-a185-09ca553f3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-768373ac-3063-4fc5-be00-f7edfd169f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-c925876d-9094-4395-96b2-f117a6df2e91,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-3b1b78bb-a219-4b9b-b2a2-90c1eeaa5f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-e97b1fc0-6156-47df-a640-0becf7dfb613,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-09b1ed83-ee8e-4af2-8bcd-f4c8ce771c79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131907616-172.17.0.20-1597690453940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41805,DS-5481d88f-e74a-45ac-bdf0-32958e2d685a,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-f67b5589-2bad-4303-b2a5-730ec7187100,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-cc196288-bf13-43e5-859b-1b980649d563,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-aafec071-dcc3-475f-bc12-aee5a747b1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-6b0da883-29ea-49a9-bbbb-ae4675b9b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-70d75f5b-3fe4-42c8-b590-4e11af475b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-a38a17f4-5dce-4439-85af-77052422db55,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-04909725-7a46-42b5-9694-e4970d7ca6e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131907616-172.17.0.20-1597690453940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41805,DS-5481d88f-e74a-45ac-bdf0-32958e2d685a,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-f67b5589-2bad-4303-b2a5-730ec7187100,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-cc196288-bf13-43e5-859b-1b980649d563,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-aafec071-dcc3-475f-bc12-aee5a747b1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-6b0da883-29ea-49a9-bbbb-ae4675b9b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-70d75f5b-3fe4-42c8-b590-4e11af475b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-a38a17f4-5dce-4439-85af-77052422db55,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-04909725-7a46-42b5-9694-e4970d7ca6e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731784948-172.17.0.20-1597690601146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33090,DS-dd566c03-0f80-486f-afa6-49dd87e5ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-0642b3f1-d128-41c2-b406-c86e18e338bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-6437d526-10c7-4db1-8e05-ddde019a4bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-ee9d4ed8-9ba3-4fb4-921b-7e3619b98e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-f6a4d888-fbb1-4ee9-aa87-d2fab404650d,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-b49d98ca-e108-48c2-9eb5-78812b5e3056,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-4b0bc617-bfa0-456d-aa1f-1200bf92f56e,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-b9d33e21-c838-4ea8-83ad-1a983c161034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731784948-172.17.0.20-1597690601146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33090,DS-dd566c03-0f80-486f-afa6-49dd87e5ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-0642b3f1-d128-41c2-b406-c86e18e338bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-6437d526-10c7-4db1-8e05-ddde019a4bba,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-ee9d4ed8-9ba3-4fb4-921b-7e3619b98e01,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-f6a4d888-fbb1-4ee9-aa87-d2fab404650d,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-b49d98ca-e108-48c2-9eb5-78812b5e3056,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-4b0bc617-bfa0-456d-aa1f-1200bf92f56e,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-b9d33e21-c838-4ea8-83ad-1a983c161034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724038385-172.17.0.20-1597690639731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-85f2fa29-30da-47b0-808c-054cc15140df,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-87e9780e-d141-4dad-93aa-ed18c20145da,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-c7b9dd53-fb64-4035-aab2-b245ed5bfedf,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-78bebbf0-d98e-4f8c-abfe-0998494adb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-e055a6bc-e679-4361-bd19-824facdd2008,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-5fa777b5-89df-48fd-801f-8b3f60030242,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-41fe7da4-bbca-4821-8cbe-6f7e5c0fde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-027ab4a6-250e-4b56-9308-050c38b81570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724038385-172.17.0.20-1597690639731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-85f2fa29-30da-47b0-808c-054cc15140df,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-87e9780e-d141-4dad-93aa-ed18c20145da,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-c7b9dd53-fb64-4035-aab2-b245ed5bfedf,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-78bebbf0-d98e-4f8c-abfe-0998494adb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-e055a6bc-e679-4361-bd19-824facdd2008,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-5fa777b5-89df-48fd-801f-8b3f60030242,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-41fe7da4-bbca-4821-8cbe-6f7e5c0fde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-027ab4a6-250e-4b56-9308-050c38b81570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475903308-172.17.0.20-1597691103059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43918,DS-cc7a7205-046c-49b6-8b9a-6ad06181af28,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-31b18116-19d4-4bc7-858f-2a64b506648e,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-69f71d29-46d8-4dd4-bfc8-3607b479f9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-fdd612d7-3d8d-4cf6-9170-998e8902814e,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-6db910c8-ec84-4d6d-834d-7dd96b5ec34b,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-77807434-c9b8-4da5-9a83-8519b998d751,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-b44e1c52-99b0-4461-9454-a657cb14f69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-47c88a12-e032-4fea-8c0d-ed16bb7a455a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475903308-172.17.0.20-1597691103059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43918,DS-cc7a7205-046c-49b6-8b9a-6ad06181af28,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-31b18116-19d4-4bc7-858f-2a64b506648e,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-69f71d29-46d8-4dd4-bfc8-3607b479f9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-fdd612d7-3d8d-4cf6-9170-998e8902814e,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-6db910c8-ec84-4d6d-834d-7dd96b5ec34b,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-77807434-c9b8-4da5-9a83-8519b998d751,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-b44e1c52-99b0-4461-9454-a657cb14f69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-47c88a12-e032-4fea-8c0d-ed16bb7a455a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30094781-172.17.0.20-1597691649406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-b5bba113-8aa0-4a3a-a763-3f303621edbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-9fde2d09-848a-486a-9008-db1423ba33f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-a0286625-e60d-4854-8fe5-ebf17571f85f,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-1ac1be22-e4e1-4cee-add6-eab6466a1b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-25884488-2ef6-44b3-a501-4c87d78937d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-b9238162-ddbf-4586-9fbe-a89ee9dcd50d,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-fc8b6a0a-aa62-40a2-931b-80fd7a8e65e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-56ab66dd-6070-4a12-a29b-0d437aa04302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30094781-172.17.0.20-1597691649406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-b5bba113-8aa0-4a3a-a763-3f303621edbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-9fde2d09-848a-486a-9008-db1423ba33f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-a0286625-e60d-4854-8fe5-ebf17571f85f,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-1ac1be22-e4e1-4cee-add6-eab6466a1b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-25884488-2ef6-44b3-a501-4c87d78937d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-b9238162-ddbf-4586-9fbe-a89ee9dcd50d,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-fc8b6a0a-aa62-40a2-931b-80fd7a8e65e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-56ab66dd-6070-4a12-a29b-0d437aa04302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016502449-172.17.0.20-1597691684806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37801,DS-8165e37d-4025-498b-969e-c075c1f83cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-3b11cc14-eaf5-4c87-9b95-799041f6eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-7f2b33d6-a999-445f-8233-d6be1062e11f,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-8475bc29-e6d8-4c04-b347-99e3c633662b,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-9e856d0d-2713-4df7-9824-90b746804ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-b1f59608-93a5-4976-b050-fda6ccb03151,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-a5496b97-d810-443e-bd62-d535ba48d7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-0861f69c-8c5c-49ae-b0e6-2fef1ce23f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016502449-172.17.0.20-1597691684806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37801,DS-8165e37d-4025-498b-969e-c075c1f83cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-3b11cc14-eaf5-4c87-9b95-799041f6eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-7f2b33d6-a999-445f-8233-d6be1062e11f,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-8475bc29-e6d8-4c04-b347-99e3c633662b,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-9e856d0d-2713-4df7-9824-90b746804ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-b1f59608-93a5-4976-b050-fda6ccb03151,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-a5496b97-d810-443e-bd62-d535ba48d7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-0861f69c-8c5c-49ae-b0e6-2fef1ce23f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404889832-172.17.0.20-1597691989317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35050,DS-6db8c342-6eca-49f5-a421-3ee08fcf6257,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-2d7886d0-a5a5-43e0-b21b-fa6bf0076a68,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-a8e6630c-1a25-464f-ac6b-c305e8559669,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-91dbebf2-9657-405e-9fa0-46b3c4c346b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-784267b5-f533-46c7-a795-66554614c31d,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-632564b1-6187-4425-a233-b818a59622d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-2700b1a5-e034-44c9-8f2f-d0778e436741,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-66bc2cd5-d1cc-43a4-8ab4-cff79353f751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404889832-172.17.0.20-1597691989317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35050,DS-6db8c342-6eca-49f5-a421-3ee08fcf6257,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-2d7886d0-a5a5-43e0-b21b-fa6bf0076a68,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-a8e6630c-1a25-464f-ac6b-c305e8559669,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-91dbebf2-9657-405e-9fa0-46b3c4c346b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-784267b5-f533-46c7-a795-66554614c31d,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-632564b1-6187-4425-a233-b818a59622d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-2700b1a5-e034-44c9-8f2f-d0778e436741,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-66bc2cd5-d1cc-43a4-8ab4-cff79353f751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862845888-172.17.0.20-1597692396613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40687,DS-24733309-ef01-4609-901f-ac97ddd61c56,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-9556aa8b-6375-4ce0-b790-1ad50be760ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-23fc0687-08ca-4723-bddb-92c5b8906f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-4611b7fd-3d63-4074-aaf5-c55c0081b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-04ba30ee-cc5f-4090-b228-33350adb6b50,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-c6254c9a-2851-4b37-809c-933cc86f4f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-71205624-4a47-4495-abff-72b147224442,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-4b8b4372-89f8-4689-927e-219dad80e0f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862845888-172.17.0.20-1597692396613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40687,DS-24733309-ef01-4609-901f-ac97ddd61c56,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-9556aa8b-6375-4ce0-b790-1ad50be760ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-23fc0687-08ca-4723-bddb-92c5b8906f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-4611b7fd-3d63-4074-aaf5-c55c0081b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-04ba30ee-cc5f-4090-b228-33350adb6b50,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-c6254c9a-2851-4b37-809c-933cc86f4f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-71205624-4a47-4495-abff-72b147224442,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-4b8b4372-89f8-4689-927e-219dad80e0f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939953588-172.17.0.20-1597692573715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-9a28acae-4688-425b-b4f4-4ccca1086f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-1419f5e8-1948-485d-9f93-e39ee8f40f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-ead24cbe-3594-485a-bf5f-dc2a0b26a791,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-53081759-0633-4068-96f2-73dbdbea9222,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-efe23387-9918-437d-8a98-f10dba6df298,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-39ff9e97-0b18-49a4-bd8e-a114819d6529,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-93ae88a6-9707-4829-818e-ee907b195fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-5f3c3c93-07ef-43a0-9498-0e741ccab999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939953588-172.17.0.20-1597692573715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-9a28acae-4688-425b-b4f4-4ccca1086f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-1419f5e8-1948-485d-9f93-e39ee8f40f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-ead24cbe-3594-485a-bf5f-dc2a0b26a791,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-53081759-0633-4068-96f2-73dbdbea9222,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-efe23387-9918-437d-8a98-f10dba6df298,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-39ff9e97-0b18-49a4-bd8e-a114819d6529,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-93ae88a6-9707-4829-818e-ee907b195fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-5f3c3c93-07ef-43a0-9498-0e741ccab999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032584520-172.17.0.20-1597692649146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-3bb617cd-b222-4316-afa4-ba9116af4606,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-308af7a4-784a-49cd-9c51-64c98f9770b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-7cee3d6d-f3bc-410b-9896-3f7a5cb70b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-c6946e00-c67a-4c79-bb6f-799baf37e4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-13e20b12-bbb0-4fdf-8bce-18f665b4cdce,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-038f38fa-dde3-4f66-83d0-3b2f50a18bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-ce325b8a-8673-4592-82fd-e88f340b6223,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-2c27aeb3-1b92-4ccb-9508-5dc9db8bb0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032584520-172.17.0.20-1597692649146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46494,DS-3bb617cd-b222-4316-afa4-ba9116af4606,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-308af7a4-784a-49cd-9c51-64c98f9770b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-7cee3d6d-f3bc-410b-9896-3f7a5cb70b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-c6946e00-c67a-4c79-bb6f-799baf37e4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-13e20b12-bbb0-4fdf-8bce-18f665b4cdce,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-038f38fa-dde3-4f66-83d0-3b2f50a18bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-ce325b8a-8673-4592-82fd-e88f340b6223,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-2c27aeb3-1b92-4ccb-9508-5dc9db8bb0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508226854-172.17.0.20-1597693299526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43693,DS-ff4336bb-500d-4ceb-a189-0ecdbedd0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-9eb1d1bc-ef2f-4537-a734-50d0929edc36,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-8b86314e-72de-4ce7-92a6-de267eb7e742,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-5e7e763d-a4cc-40d1-955c-6da1ffae5d00,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-033515a7-1df1-4dd8-a740-a902fc887909,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-2b7e903f-827e-4aff-8d1d-c92281eb6fba,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-eb684252-d088-4e81-8b96-7d2536407263,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-8dc21ff8-ec21-4d4a-a2b5-fac0daf0ced0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508226854-172.17.0.20-1597693299526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43693,DS-ff4336bb-500d-4ceb-a189-0ecdbedd0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-9eb1d1bc-ef2f-4537-a734-50d0929edc36,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-8b86314e-72de-4ce7-92a6-de267eb7e742,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-5e7e763d-a4cc-40d1-955c-6da1ffae5d00,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-033515a7-1df1-4dd8-a740-a902fc887909,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-2b7e903f-827e-4aff-8d1d-c92281eb6fba,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-eb684252-d088-4e81-8b96-7d2536407263,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-8dc21ff8-ec21-4d4a-a2b5-fac0daf0ced0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355829094-172.17.0.20-1597693451700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-d4ae7606-bb2a-49f8-980c-b92574ea0fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-e9d5ab8b-4244-4316-bfb1-04e175fd83de,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-d69a91f8-88ce-4223-b104-1a5b7afa0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-ae8cfcb8-2f34-4c6a-9c61-8210e453b60b,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-d4d9399b-bdcd-45e6-b185-f5edb208265d,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-c876c105-50ca-4a34-a5cc-026f0a7a31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-5aa73cd2-aadf-4be6-b186-f209a1315483,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-a9f760ec-5136-4ef5-b698-760054f497a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355829094-172.17.0.20-1597693451700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-d4ae7606-bb2a-49f8-980c-b92574ea0fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-e9d5ab8b-4244-4316-bfb1-04e175fd83de,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-d69a91f8-88ce-4223-b104-1a5b7afa0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-ae8cfcb8-2f34-4c6a-9c61-8210e453b60b,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-d4d9399b-bdcd-45e6-b185-f5edb208265d,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-c876c105-50ca-4a34-a5cc-026f0a7a31a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-5aa73cd2-aadf-4be6-b186-f209a1315483,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-a9f760ec-5136-4ef5-b698-760054f497a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371805172-172.17.0.20-1597693565930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-b78eb358-a82a-4caa-83b8-02f9d8e71c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-55dff57b-1c18-4f21-baa6-0cf6dcc27e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-35993bb9-50f2-44fc-9b90-ab217bcb4847,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-1cf01afe-7fec-4637-9b6e-92b099871477,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-2556bf1e-0120-4df5-b7a4-b100e64cdcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-6d359aa6-5ffa-41a3-b7ce-6190ed16cffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-a2613b49-5b03-42be-b573-bdc83eb4198d,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-32a2910f-83f9-4437-a939-7f738e52e73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371805172-172.17.0.20-1597693565930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-b78eb358-a82a-4caa-83b8-02f9d8e71c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-55dff57b-1c18-4f21-baa6-0cf6dcc27e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-35993bb9-50f2-44fc-9b90-ab217bcb4847,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-1cf01afe-7fec-4637-9b6e-92b099871477,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-2556bf1e-0120-4df5-b7a4-b100e64cdcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-6d359aa6-5ffa-41a3-b7ce-6190ed16cffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-a2613b49-5b03-42be-b573-bdc83eb4198d,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-32a2910f-83f9-4437-a939-7f738e52e73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918162633-172.17.0.20-1597693637904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33223,DS-2872a2a4-5326-4276-b106-792d42e02898,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-2418dc19-0f2f-461e-8b3d-10b86ec1495f,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-0d66643a-e6b1-478d-9cc0-17fa44e25804,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-5c261be9-2129-4ee1-8664-ff39b10f4018,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-09d68b81-faaa-4258-8a3b-7155605c9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-2a379fa3-aa2f-47f9-aa73-fbe8107d3ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-cd156aa8-1d65-463f-aa18-2980a49c6f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-5efb1ea0-c6fe-4800-8e65-14878f322878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918162633-172.17.0.20-1597693637904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33223,DS-2872a2a4-5326-4276-b106-792d42e02898,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-2418dc19-0f2f-461e-8b3d-10b86ec1495f,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-0d66643a-e6b1-478d-9cc0-17fa44e25804,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-5c261be9-2129-4ee1-8664-ff39b10f4018,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-09d68b81-faaa-4258-8a3b-7155605c9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-2a379fa3-aa2f-47f9-aa73-fbe8107d3ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-cd156aa8-1d65-463f-aa18-2980a49c6f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-5efb1ea0-c6fe-4800-8e65-14878f322878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23726397-172.17.0.20-1597693757998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-6e1be0cb-3e0a-46bd-bb17-4290121b85ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-cae2422c-21df-46f3-9888-172d9349df53,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-135f253c-570a-41aa-b2e0-74883b1c3c18,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-6ef19d75-8f41-4d1e-93f0-9b9889069bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-9ddb3265-8c75-45c1-ae05-f2766ebd2891,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-b8e824c5-026c-4cec-8e44-2014596780a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-e356abce-6350-4516-8e64-d8044064f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-2db6e86e-3c4c-4300-a80f-f8713a893ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23726397-172.17.0.20-1597693757998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-6e1be0cb-3e0a-46bd-bb17-4290121b85ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-cae2422c-21df-46f3-9888-172d9349df53,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-135f253c-570a-41aa-b2e0-74883b1c3c18,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-6ef19d75-8f41-4d1e-93f0-9b9889069bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-9ddb3265-8c75-45c1-ae05-f2766ebd2891,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-b8e824c5-026c-4cec-8e44-2014596780a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-e356abce-6350-4516-8e64-d8044064f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-2db6e86e-3c4c-4300-a80f-f8713a893ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905073535-172.17.0.20-1597694101443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-3714c835-d7fb-405c-8679-df125f338cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-c962e268-96f1-417a-8252-a4634b76b158,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-7111adcb-f869-4235-9500-53d85da6db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-caa01022-1057-4cb2-8c1d-566f6efb91bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-d9497689-aca5-4c20-ac46-8e0e97029a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-2a130313-0bf1-49b0-89ea-938758918fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-c4414afa-f064-4ab2-bc49-caddff17e39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-6fc30f4f-8417-42db-975f-5bdc4627bfa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905073535-172.17.0.20-1597694101443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-3714c835-d7fb-405c-8679-df125f338cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-c962e268-96f1-417a-8252-a4634b76b158,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-7111adcb-f869-4235-9500-53d85da6db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-caa01022-1057-4cb2-8c1d-566f6efb91bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-d9497689-aca5-4c20-ac46-8e0e97029a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-2a130313-0bf1-49b0-89ea-938758918fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-c4414afa-f064-4ab2-bc49-caddff17e39c,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-6fc30f4f-8417-42db-975f-5bdc4627bfa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861018505-172.17.0.20-1597694275041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38240,DS-57fbce32-1388-4f59-842f-7329e940e027,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-fb7737fd-14c5-48c5-a5bf-69087fc897a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-b837eb73-e1b0-49b2-b418-f57ebc1e08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-1e895f69-0516-4e4d-b2b0-f797a0472a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-a005b1b8-f974-4364-9248-b689e4176944,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-df25f6b3-800d-4805-b996-3a4efb35357d,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-256b99ee-f01c-4a4c-ae47-2876ec074f76,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-21250af9-cd03-4e8f-bf1d-aab032a3c8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861018505-172.17.0.20-1597694275041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38240,DS-57fbce32-1388-4f59-842f-7329e940e027,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-fb7737fd-14c5-48c5-a5bf-69087fc897a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-b837eb73-e1b0-49b2-b418-f57ebc1e08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-1e895f69-0516-4e4d-b2b0-f797a0472a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-a005b1b8-f974-4364-9248-b689e4176944,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-df25f6b3-800d-4805-b996-3a4efb35357d,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-256b99ee-f01c-4a4c-ae47-2876ec074f76,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-21250af9-cd03-4e8f-bf1d-aab032a3c8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983082345-172.17.0.20-1597694311869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34618,DS-75e1e5f5-f9b6-442d-88f1-ac3b456bbb27,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-b559e408-4fef-4f39-a642-7b4201494b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-0fbad474-0c9f-43a7-9afc-e17d9fbc6402,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-bdb023d1-653f-4f6c-877c-43ca59323489,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-5d09a46f-e816-4dc9-bf76-8fdc140af966,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-16beb372-2cca-43fe-8e31-9b7800a4c4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-613f513b-4dc4-42d6-9561-805ad89a6905,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-1555c609-8a91-45fc-9eb5-e248de5075fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983082345-172.17.0.20-1597694311869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34618,DS-75e1e5f5-f9b6-442d-88f1-ac3b456bbb27,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-b559e408-4fef-4f39-a642-7b4201494b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-0fbad474-0c9f-43a7-9afc-e17d9fbc6402,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-bdb023d1-653f-4f6c-877c-43ca59323489,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-5d09a46f-e816-4dc9-bf76-8fdc140af966,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-16beb372-2cca-43fe-8e31-9b7800a4c4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-613f513b-4dc4-42d6-9561-805ad89a6905,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-1555c609-8a91-45fc-9eb5-e248de5075fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525801936-172.17.0.20-1597694351543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-043d1468-aac6-4ca4-b28b-ebdb49cc4c05,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-830f1d9b-7321-4da8-b87d-fc76f8e03b47,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-158f704b-e415-4c63-987b-8fdf9d5673ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-152d9c16-9028-42b1-847e-f04a62b20987,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-501999e1-0423-42ed-9ae3-1b705e0415e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-cf9716d6-e8a2-41c0-ab39-832bac95bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-4a7bf529-5d25-4234-ab8d-c236379a86af,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-2178d360-7074-4817-aa2d-127837319c5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525801936-172.17.0.20-1597694351543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-043d1468-aac6-4ca4-b28b-ebdb49cc4c05,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-830f1d9b-7321-4da8-b87d-fc76f8e03b47,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-158f704b-e415-4c63-987b-8fdf9d5673ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-152d9c16-9028-42b1-847e-f04a62b20987,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-501999e1-0423-42ed-9ae3-1b705e0415e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-cf9716d6-e8a2-41c0-ab39-832bac95bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-4a7bf529-5d25-4234-ab8d-c236379a86af,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-2178d360-7074-4817-aa2d-127837319c5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028218091-172.17.0.20-1597694426520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-f88cd813-ef7d-4ae0-bfec-d4afe35d3346,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-ded1aa91-eb31-451d-911e-4c6b46d09839,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-af074bd7-b27a-400e-b6d1-0b2be518d159,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-132df713-34cf-4703-ac84-51a677b8b5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-190bc3a5-6bb0-4acd-92ae-5e09a7af9ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-b0d214e7-fd3f-40b6-932d-ba45cb0d719d,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-480c1cc9-7d71-460e-b9a6-e3e9c0b14ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-2ec951ae-0b35-4f9a-9ec7-48e50228758b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028218091-172.17.0.20-1597694426520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-f88cd813-ef7d-4ae0-bfec-d4afe35d3346,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-ded1aa91-eb31-451d-911e-4c6b46d09839,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-af074bd7-b27a-400e-b6d1-0b2be518d159,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-132df713-34cf-4703-ac84-51a677b8b5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-190bc3a5-6bb0-4acd-92ae-5e09a7af9ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-b0d214e7-fd3f-40b6-932d-ba45cb0d719d,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-480c1cc9-7d71-460e-b9a6-e3e9c0b14ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-2ec951ae-0b35-4f9a-9ec7-48e50228758b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85502800-172.17.0.20-1597694874364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42887,DS-46b5485c-7bfc-4934-8271-ed09999bb532,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-e1479e59-00c5-4a1b-9fdf-13febaf74f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-9a3e6071-7dc1-43de-b1e0-920c8c92519a,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-86c9b4bf-dcf5-4e15-a769-b5622c28543d,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-2330ebec-965b-4e12-acf8-22c8afa85e36,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-351a367b-cacf-4e29-9ccc-65cc0083a603,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-f2c36b81-29c3-4a06-8619-06dce72371d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-a57cd149-9a37-480e-be9b-ad313c5ffe55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85502800-172.17.0.20-1597694874364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42887,DS-46b5485c-7bfc-4934-8271-ed09999bb532,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-e1479e59-00c5-4a1b-9fdf-13febaf74f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-9a3e6071-7dc1-43de-b1e0-920c8c92519a,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-86c9b4bf-dcf5-4e15-a769-b5622c28543d,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-2330ebec-965b-4e12-acf8-22c8afa85e36,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-351a367b-cacf-4e29-9ccc-65cc0083a603,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-f2c36b81-29c3-4a06-8619-06dce72371d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-a57cd149-9a37-480e-be9b-ad313c5ffe55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021079474-172.17.0.20-1597694906972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38704,DS-954e14b5-a947-42cd-89c8-b2e45c66c639,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-39d172ae-46ad-4089-afc0-2556ff8a5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-95a6065f-c299-4e40-b431-701662d1b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-95615846-d846-4e58-a989-d040ff8ba9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-151f447e-d105-45a1-8bd2-0255dea9e389,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-521bdfa7-652e-498c-b608-c18024e32ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-6da24375-b2e2-4933-834e-2512eb32b0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-6039477a-f44e-4ee0-b019-06a4ce8306f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021079474-172.17.0.20-1597694906972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38704,DS-954e14b5-a947-42cd-89c8-b2e45c66c639,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-39d172ae-46ad-4089-afc0-2556ff8a5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-95a6065f-c299-4e40-b431-701662d1b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-95615846-d846-4e58-a989-d040ff8ba9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-151f447e-d105-45a1-8bd2-0255dea9e389,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-521bdfa7-652e-498c-b608-c18024e32ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-6da24375-b2e2-4933-834e-2512eb32b0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-6039477a-f44e-4ee0-b019-06a4ce8306f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117779521-172.17.0.20-1597695366281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37052,DS-01a06fe3-730d-439a-9c0e-f4e2a398a869,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-f13ed248-779a-42f5-8647-979f7cdfde72,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-f02711cb-462e-4328-9980-26a59beebfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-c8093880-9a67-4054-90e0-f20a1554aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-b65d5487-0385-4f08-b024-47f67f96c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-a7104bf7-fba3-4425-b699-2d35731b58b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-a55965e8-eb77-41f4-ac00-e2c14b2dabb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-732ceb12-e483-4e8c-a455-e3194b81d842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117779521-172.17.0.20-1597695366281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37052,DS-01a06fe3-730d-439a-9c0e-f4e2a398a869,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-f13ed248-779a-42f5-8647-979f7cdfde72,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-f02711cb-462e-4328-9980-26a59beebfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-c8093880-9a67-4054-90e0-f20a1554aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-b65d5487-0385-4f08-b024-47f67f96c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-a7104bf7-fba3-4425-b699-2d35731b58b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-a55965e8-eb77-41f4-ac00-e2c14b2dabb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-732ceb12-e483-4e8c-a455-e3194b81d842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019065500-172.17.0.20-1597695905493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32884,DS-33419dcb-423d-40e6-829f-a98b8c0ca605,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-70b3ea10-e184-4cec-b93c-047cf6f57f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-4c657d58-753a-4c9f-8064-9fb7b6fe1564,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-2ba780b3-2120-444d-8ccd-e6d3d8f02fff,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-89e03f67-20aa-4edd-aaaf-feaffccc73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-97842e84-470d-4f2a-a2c1-83fc7645b3db,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-45c5ccfc-2d98-4d03-8782-f2eeca615b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-3ea00bea-8cac-485e-baf1-c82e881e4098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019065500-172.17.0.20-1597695905493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32884,DS-33419dcb-423d-40e6-829f-a98b8c0ca605,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-70b3ea10-e184-4cec-b93c-047cf6f57f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-4c657d58-753a-4c9f-8064-9fb7b6fe1564,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-2ba780b3-2120-444d-8ccd-e6d3d8f02fff,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-89e03f67-20aa-4edd-aaaf-feaffccc73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-97842e84-470d-4f2a-a2c1-83fc7645b3db,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-45c5ccfc-2d98-4d03-8782-f2eeca615b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-3ea00bea-8cac-485e-baf1-c82e881e4098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5745
