reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646869291-172.17.0.20-1597273758547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43066,DS-b2ed4abe-039f-4eb6-99ed-06a6a40218fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-bee92c29-b2e9-4735-9fc8-ddec3bd88c41,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-f55d1f2e-c1dd-416b-90cb-af1c0fec2146,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-b34d0295-7314-47e4-a40e-d6515e657f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-da99fd72-0e40-4fcb-a17b-a407670dd545,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-7a670fc4-0e0a-4dc5-92f0-356326ad9e74,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-99d63c0a-4c5f-4c9e-abe0-fb5569b892b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-3a55bb02-9331-4b37-b82d-418438492f0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646869291-172.17.0.20-1597273758547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43066,DS-b2ed4abe-039f-4eb6-99ed-06a6a40218fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-bee92c29-b2e9-4735-9fc8-ddec3bd88c41,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-f55d1f2e-c1dd-416b-90cb-af1c0fec2146,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-b34d0295-7314-47e4-a40e-d6515e657f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-da99fd72-0e40-4fcb-a17b-a407670dd545,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-7a670fc4-0e0a-4dc5-92f0-356326ad9e74,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-99d63c0a-4c5f-4c9e-abe0-fb5569b892b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-3a55bb02-9331-4b37-b82d-418438492f0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647248408-172.17.0.20-1597274104057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41742,DS-e688bc1d-8b64-4412-a948-ccfd564ec780,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-bacd74c0-af29-44c4-ae6f-d71fa27f77c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-e24e79b1-0e5b-419c-bab4-c55699317750,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-4e607da0-ebb3-4628-a7cd-04629d15e3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-b967494b-69b2-4d1a-a358-2970251f29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-c674edc5-9acc-435d-bc47-dfddb97673c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-651e41fd-c32f-4f48-9c84-dc3bb0b714e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-3273f76a-fd22-4514-b012-141eb41c2da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647248408-172.17.0.20-1597274104057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41742,DS-e688bc1d-8b64-4412-a948-ccfd564ec780,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-bacd74c0-af29-44c4-ae6f-d71fa27f77c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-e24e79b1-0e5b-419c-bab4-c55699317750,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-4e607da0-ebb3-4628-a7cd-04629d15e3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-b967494b-69b2-4d1a-a358-2970251f29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-c674edc5-9acc-435d-bc47-dfddb97673c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-651e41fd-c32f-4f48-9c84-dc3bb0b714e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-3273f76a-fd22-4514-b012-141eb41c2da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525726211-172.17.0.20-1597274138335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-39065434-bc39-4627-97d7-e8b42f01c572,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-293b8cbd-9267-452b-813c-e02a38dd0c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-96630daa-8dd8-4c3a-8d82-e17f187795e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-e903ba2b-c470-4047-97cb-15b2ca921015,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-cefd143b-576b-439d-8ddf-e9e82ae1e8be,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-71fe2186-42de-4529-aa90-8fcb3505a194,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-d1cea754-33f7-4076-8816-98e967e13f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-a0526b52-338e-4081-a7d1-e3c0d6ee43ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525726211-172.17.0.20-1597274138335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-39065434-bc39-4627-97d7-e8b42f01c572,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-293b8cbd-9267-452b-813c-e02a38dd0c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-96630daa-8dd8-4c3a-8d82-e17f187795e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-e903ba2b-c470-4047-97cb-15b2ca921015,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-cefd143b-576b-439d-8ddf-e9e82ae1e8be,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-71fe2186-42de-4529-aa90-8fcb3505a194,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-d1cea754-33f7-4076-8816-98e967e13f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-a0526b52-338e-4081-a7d1-e3c0d6ee43ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770719069-172.17.0.20-1597274224473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-9aca641b-6879-434b-9cfe-a0aafcab40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-481fdf1c-a001-4a88-b828-06610aca80e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-c0242390-2fe9-465c-846e-ca2b56d495cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-d4898339-218b-4af5-9b27-12023828a7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-5db2b64c-3630-42af-82ff-7b1d2febaed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-bedb0075-3e16-47d7-9338-cbaeae204bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-67258aad-ace7-4341-9e81-561811631cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-12cf550c-b947-414d-9f5b-4a9a6e235804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770719069-172.17.0.20-1597274224473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-9aca641b-6879-434b-9cfe-a0aafcab40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-481fdf1c-a001-4a88-b828-06610aca80e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-c0242390-2fe9-465c-846e-ca2b56d495cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-d4898339-218b-4af5-9b27-12023828a7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-5db2b64c-3630-42af-82ff-7b1d2febaed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-bedb0075-3e16-47d7-9338-cbaeae204bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-67258aad-ace7-4341-9e81-561811631cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-12cf550c-b947-414d-9f5b-4a9a6e235804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100623274-172.17.0.20-1597274964226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-529e10c7-6bbd-434c-8709-568c8abe306d,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-9a5d86a4-d5d5-4b43-b1f2-f227ec2d8314,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-b545eafb-050a-4036-8475-947289df7b51,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e695385d-ce23-4901-ae44-d583ea0fd1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-2bd2dd02-53cf-463c-968c-f82314316fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-50b863e8-3b7b-4da0-a95c-cde943e56bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-c12eea5c-fc05-4adb-a462-ea163f4d356a,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-22495a75-7e6a-4bb4-92bf-59dc363ebb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100623274-172.17.0.20-1597274964226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-529e10c7-6bbd-434c-8709-568c8abe306d,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-9a5d86a4-d5d5-4b43-b1f2-f227ec2d8314,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-b545eafb-050a-4036-8475-947289df7b51,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e695385d-ce23-4901-ae44-d583ea0fd1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-2bd2dd02-53cf-463c-968c-f82314316fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-50b863e8-3b7b-4da0-a95c-cde943e56bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-c12eea5c-fc05-4adb-a462-ea163f4d356a,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-22495a75-7e6a-4bb4-92bf-59dc363ebb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995866267-172.17.0.20-1597275010899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-f94f95a7-5304-4286-bfcc-4c8a3cbcb5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-17616c48-1fb2-40c9-81f7-73116769baed,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-ebe4de47-876c-4070-b3ba-70215f793cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-089a826f-a931-4830-bbe9-033dcbef355f,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-83096dc2-4e21-403a-9988-74670e5d82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-f6a1fda8-843d-425e-9fa9-7431633949dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-51493c1d-9e49-49b1-b92f-d5087a49f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-6637f886-ff3d-4099-983c-577b97681e60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995866267-172.17.0.20-1597275010899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-f94f95a7-5304-4286-bfcc-4c8a3cbcb5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-17616c48-1fb2-40c9-81f7-73116769baed,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-ebe4de47-876c-4070-b3ba-70215f793cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-089a826f-a931-4830-bbe9-033dcbef355f,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-83096dc2-4e21-403a-9988-74670e5d82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-f6a1fda8-843d-425e-9fa9-7431633949dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-51493c1d-9e49-49b1-b92f-d5087a49f2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-6637f886-ff3d-4099-983c-577b97681e60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806084677-172.17.0.20-1597275364569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44254,DS-670b2e60-310e-4912-aeae-8ef493a3fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-3a71f8fc-a424-49b9-95a9-d08604fb537c,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-ba0653c8-db3c-476f-91ad-edff2d550caf,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-32ab71e3-2d07-4abf-b195-3abd9668b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-11363849-9e25-45cc-bb48-9fb42058ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-e05a0a83-2723-4a6a-9327-3427af4b41d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-f5cec6fa-baaa-466f-8475-9342b556a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-6c1644c7-ba2e-4ea6-aad8-dd5149982b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806084677-172.17.0.20-1597275364569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44254,DS-670b2e60-310e-4912-aeae-8ef493a3fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-3a71f8fc-a424-49b9-95a9-d08604fb537c,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-ba0653c8-db3c-476f-91ad-edff2d550caf,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-32ab71e3-2d07-4abf-b195-3abd9668b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-11363849-9e25-45cc-bb48-9fb42058ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-e05a0a83-2723-4a6a-9327-3427af4b41d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-f5cec6fa-baaa-466f-8475-9342b556a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-6c1644c7-ba2e-4ea6-aad8-dd5149982b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881936692-172.17.0.20-1597275965715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35274,DS-312d5eb9-19b6-4bc6-bdd6-607b48fcf423,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-bcc42733-a7a4-4073-8551-fdce8e270404,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-cbee3a73-003a-4d65-89f8-c9c13b8caf11,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-09e7be54-41be-4bb4-94f3-e160f604caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-45053294-62cc-4c81-be94-2a016a36591b,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-dde7699a-7388-4dc3-9a55-07fd1afca626,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-04a28828-b9d1-4cd2-a624-ba26210b06e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-020b5f2d-e92e-4543-8b48-624804536dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881936692-172.17.0.20-1597275965715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35274,DS-312d5eb9-19b6-4bc6-bdd6-607b48fcf423,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-bcc42733-a7a4-4073-8551-fdce8e270404,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-cbee3a73-003a-4d65-89f8-c9c13b8caf11,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-09e7be54-41be-4bb4-94f3-e160f604caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-45053294-62cc-4c81-be94-2a016a36591b,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-dde7699a-7388-4dc3-9a55-07fd1afca626,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-04a28828-b9d1-4cd2-a624-ba26210b06e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-020b5f2d-e92e-4543-8b48-624804536dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527212027-172.17.0.20-1597276239471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41864,DS-9dd735d1-78d2-4caf-b51f-15823983589b,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-b13a1fde-1d08-43aa-bb07-3bbcb24c2ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-345b523a-3b7a-43b3-851c-319aef2b883f,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-c6271c63-db2c-4a0a-8aa6-2e13d3354bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-42b5d3cb-f279-4eb1-994f-e3c56e46b133,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-e1a6c3b1-5975-4706-9030-87f4bdecccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-d5c74204-ba41-4881-823b-fc79678385f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-8f0f1412-2da6-4a0b-ae09-2b5201c5dbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527212027-172.17.0.20-1597276239471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41864,DS-9dd735d1-78d2-4caf-b51f-15823983589b,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-b13a1fde-1d08-43aa-bb07-3bbcb24c2ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-345b523a-3b7a-43b3-851c-319aef2b883f,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-c6271c63-db2c-4a0a-8aa6-2e13d3354bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-42b5d3cb-f279-4eb1-994f-e3c56e46b133,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-e1a6c3b1-5975-4706-9030-87f4bdecccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-d5c74204-ba41-4881-823b-fc79678385f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-8f0f1412-2da6-4a0b-ae09-2b5201c5dbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514412808-172.17.0.20-1597276288389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34846,DS-5045f3a6-0443-4eb4-95db-82138e02c32d,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-09337092-8d73-49da-95ab-f6fa02f05072,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-49a0e16d-e927-445c-b3b9-d8420cfbb998,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-166e00fc-3e07-4678-93eb-a620bb3b56f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-b3530817-4c67-4c61-a7d8-2a6fe88bf188,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-3940e89a-b5b6-4183-92e8-8dfd8fe4f88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-ee3b8094-1a8d-4a31-be32-6cdecd21d541,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-715f6f42-0556-4aa5-a1a2-42a4288611e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514412808-172.17.0.20-1597276288389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34846,DS-5045f3a6-0443-4eb4-95db-82138e02c32d,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-09337092-8d73-49da-95ab-f6fa02f05072,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-49a0e16d-e927-445c-b3b9-d8420cfbb998,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-166e00fc-3e07-4678-93eb-a620bb3b56f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-b3530817-4c67-4c61-a7d8-2a6fe88bf188,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-3940e89a-b5b6-4183-92e8-8dfd8fe4f88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-ee3b8094-1a8d-4a31-be32-6cdecd21d541,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-715f6f42-0556-4aa5-a1a2-42a4288611e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888326150-172.17.0.20-1597276877814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-f9086bda-8b05-4d0b-9a78-1cdcbec999ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-fd38577d-245c-4911-b371-f056e2a69862,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-e17ef27c-c877-4c94-bd24-c05c9e483dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-e345cb6a-54b2-4290-95e2-0dd3039f884d,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-21aee2e9-9933-4356-80cd-2c6d4be57e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-7f386f39-fb20-4268-9089-21066f15328d,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-ed64bbd4-5495-4f4e-a31a-2e0a0a1d8fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-1f67ac17-73f0-4a41-9412-708247488a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888326150-172.17.0.20-1597276877814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-f9086bda-8b05-4d0b-9a78-1cdcbec999ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-fd38577d-245c-4911-b371-f056e2a69862,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-e17ef27c-c877-4c94-bd24-c05c9e483dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-e345cb6a-54b2-4290-95e2-0dd3039f884d,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-21aee2e9-9933-4356-80cd-2c6d4be57e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-7f386f39-fb20-4268-9089-21066f15328d,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-ed64bbd4-5495-4f4e-a31a-2e0a0a1d8fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-1f67ac17-73f0-4a41-9412-708247488a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301638531-172.17.0.20-1597277192496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-16e04b61-626c-4bc8-8708-10a7797451d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-5962e599-88cb-4c6d-accc-8845ae8d270a,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-ee43ddc1-1d65-4dff-bd0d-02909154cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-53146132-c072-49e9-943f-74742a9e2528,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-55fb7392-9214-409c-ba3d-4f8e12cadacd,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-d9c106a5-485e-43c5-a305-4bcd972deacc,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-f39b3a57-2a67-4e1b-a693-6301a422b9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-13a260a4-5395-45cb-9afe-9bfc85860556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301638531-172.17.0.20-1597277192496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-16e04b61-626c-4bc8-8708-10a7797451d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-5962e599-88cb-4c6d-accc-8845ae8d270a,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-ee43ddc1-1d65-4dff-bd0d-02909154cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-53146132-c072-49e9-943f-74742a9e2528,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-55fb7392-9214-409c-ba3d-4f8e12cadacd,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-d9c106a5-485e-43c5-a305-4bcd972deacc,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-f39b3a57-2a67-4e1b-a693-6301a422b9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-13a260a4-5395-45cb-9afe-9bfc85860556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117182123-172.17.0.20-1597277240972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46458,DS-d43f51bc-4602-4918-8624-4181fe558e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-ca18faa3-c43b-49df-8605-cf292ae73775,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-cd231575-e7ac-49bb-9661-9e94a83af0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-5d7073b7-28c9-4d47-b4be-c83c3b635521,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-6855054c-0eca-4c9b-8b63-f1ed22832518,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-377c55bc-dc04-4959-a4a4-12194f3b6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-01c34368-2f13-4074-9609-5edb110dfc71,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-0863ac90-aeff-48f0-b8df-1889a0f0066e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117182123-172.17.0.20-1597277240972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46458,DS-d43f51bc-4602-4918-8624-4181fe558e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-ca18faa3-c43b-49df-8605-cf292ae73775,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-cd231575-e7ac-49bb-9661-9e94a83af0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-5d7073b7-28c9-4d47-b4be-c83c3b635521,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-6855054c-0eca-4c9b-8b63-f1ed22832518,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-377c55bc-dc04-4959-a4a4-12194f3b6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-01c34368-2f13-4074-9609-5edb110dfc71,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-0863ac90-aeff-48f0-b8df-1889a0f0066e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312734620-172.17.0.20-1597277369828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32891,DS-d2b3f04a-1bd0-47a1-bd70-3304a7ba6ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-b1a8f2e2-774b-459b-a104-dcaa8649a024,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-ef8e2792-11aa-4294-a6ac-64923d45d723,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-7e21b9cb-b8a9-41a6-9fa6-8604d357f18c,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-8b21a8a5-5d0d-4b29-8b26-4a5303cd66d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-9bdc727a-c5cf-453d-99bf-bc833cab33d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-c0e330e7-2124-44e8-aef7-349d15261266,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-175b80d5-f9aa-45dc-991a-62b68b2e5fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312734620-172.17.0.20-1597277369828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32891,DS-d2b3f04a-1bd0-47a1-bd70-3304a7ba6ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-b1a8f2e2-774b-459b-a104-dcaa8649a024,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-ef8e2792-11aa-4294-a6ac-64923d45d723,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-7e21b9cb-b8a9-41a6-9fa6-8604d357f18c,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-8b21a8a5-5d0d-4b29-8b26-4a5303cd66d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-9bdc727a-c5cf-453d-99bf-bc833cab33d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-c0e330e7-2124-44e8-aef7-349d15261266,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-175b80d5-f9aa-45dc-991a-62b68b2e5fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84799165-172.17.0.20-1597277753849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-7fee4017-ee5b-4ec4-bc86-59a98a789b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-d266343a-f75a-4370-98fd-b4f8c5f9316d,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-ba57b702-e3f4-4008-888e-2b5c86546c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-0cbff8c0-5c9b-48ef-b58f-3768746765e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-351c8fe9-fdef-4b7c-8fb4-8923c968873b,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-c23b84d4-fc87-4337-bf89-e9c58a89782c,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-504ec1c6-9368-4ea3-8949-b323cc12b597,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-dfa2c48f-c3fa-4244-b919-00c71fc2dc1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84799165-172.17.0.20-1597277753849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-7fee4017-ee5b-4ec4-bc86-59a98a789b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-d266343a-f75a-4370-98fd-b4f8c5f9316d,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-ba57b702-e3f4-4008-888e-2b5c86546c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-0cbff8c0-5c9b-48ef-b58f-3768746765e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-351c8fe9-fdef-4b7c-8fb4-8923c968873b,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-c23b84d4-fc87-4337-bf89-e9c58a89782c,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-504ec1c6-9368-4ea3-8949-b323cc12b597,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-dfa2c48f-c3fa-4244-b919-00c71fc2dc1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529612055-172.17.0.20-1597278309021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35236,DS-d1e3a413-fa40-4f90-b63e-253e338c2bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-0a113a3c-8bb7-456e-9746-d44ec5b14d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-c0884d9f-3c5f-43ca-87a6-961702d928c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-c855edf5-a307-4a08-b0ef-5f65827466ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-94bf0c46-a9b4-4916-88d9-2721617e9437,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-0d022701-6d8b-4b14-a82f-99677ace20a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-646c3bf7-184f-4eeb-9df2-b7f46b6a3c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-3b556134-0901-4e40-8d4d-227a09405bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529612055-172.17.0.20-1597278309021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35236,DS-d1e3a413-fa40-4f90-b63e-253e338c2bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-0a113a3c-8bb7-456e-9746-d44ec5b14d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-c0884d9f-3c5f-43ca-87a6-961702d928c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-c855edf5-a307-4a08-b0ef-5f65827466ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-94bf0c46-a9b4-4916-88d9-2721617e9437,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-0d022701-6d8b-4b14-a82f-99677ace20a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-646c3bf7-184f-4eeb-9df2-b7f46b6a3c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-3b556134-0901-4e40-8d4d-227a09405bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031765231-172.17.0.20-1597278436452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45895,DS-3947fdf4-5587-4808-b776-ff2d7a327c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-d90475e0-7b00-4768-b294-35d756961d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-f7d8fedb-cdb6-4626-98c9-f6a47b053d89,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-34f00cf8-cf4d-4451-bc85-c72e28489bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-0f1b0448-73ae-4819-8eb3-40e3bfbc1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-c939d1f2-3ea2-404c-881b-f2e28cd434f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-9435c5d8-506d-415f-a948-a0bd7dcccdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-4f6e712e-d0a5-41a6-be4e-d0b4bcdddb46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031765231-172.17.0.20-1597278436452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45895,DS-3947fdf4-5587-4808-b776-ff2d7a327c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-d90475e0-7b00-4768-b294-35d756961d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-f7d8fedb-cdb6-4626-98c9-f6a47b053d89,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-34f00cf8-cf4d-4451-bc85-c72e28489bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-0f1b0448-73ae-4819-8eb3-40e3bfbc1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-c939d1f2-3ea2-404c-881b-f2e28cd434f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-9435c5d8-506d-415f-a948-a0bd7dcccdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-4f6e712e-d0a5-41a6-be4e-d0b4bcdddb46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875764449-172.17.0.20-1597278471719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-083f5dae-c298-41df-993f-5a535dc7719d,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-eb695d64-6dfe-45b8-a2c0-f34b5ce6eae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-6edbe99e-a3b0-4acb-a219-77a706fa5f22,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-6a7d26c9-d056-4d6b-bbfa-f2faa9a45d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-70c434eb-f73a-4586-9231-2c2474f3327b,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-059f9bd8-7b1d-425e-8ea1-05de53e45d97,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-9ee6e4fe-d8a8-4ae9-a432-c326ac6b21e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-94db5e6f-aba5-401b-970e-407f0fd2ec1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875764449-172.17.0.20-1597278471719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-083f5dae-c298-41df-993f-5a535dc7719d,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-eb695d64-6dfe-45b8-a2c0-f34b5ce6eae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-6edbe99e-a3b0-4acb-a219-77a706fa5f22,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-6a7d26c9-d056-4d6b-bbfa-f2faa9a45d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-70c434eb-f73a-4586-9231-2c2474f3327b,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-059f9bd8-7b1d-425e-8ea1-05de53e45d97,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-9ee6e4fe-d8a8-4ae9-a432-c326ac6b21e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-94db5e6f-aba5-401b-970e-407f0fd2ec1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775496231-172.17.0.20-1597279410960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-829a6084-5f53-4990-a601-44496cb28a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-73047993-3b34-4678-aaaf-e2f5856a12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-4ed5c341-3be1-4860-b597-1a2b4b58fd84,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-197bd271-d645-417c-8b39-41d01bcdeff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-ba210f4c-fdc9-4b48-813d-cea143a9fd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-81cce752-c6a1-427f-a67d-9e3c3312660a,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-0c2793d2-fc6f-4206-b2d2-3b3199dccc45,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-a07f16e3-bd50-4b20-bef4-e499eb9d6ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775496231-172.17.0.20-1597279410960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-829a6084-5f53-4990-a601-44496cb28a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-73047993-3b34-4678-aaaf-e2f5856a12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-4ed5c341-3be1-4860-b597-1a2b4b58fd84,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-197bd271-d645-417c-8b39-41d01bcdeff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-ba210f4c-fdc9-4b48-813d-cea143a9fd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-81cce752-c6a1-427f-a67d-9e3c3312660a,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-0c2793d2-fc6f-4206-b2d2-3b3199dccc45,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-a07f16e3-bd50-4b20-bef4-e499eb9d6ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009254802-172.17.0.20-1597279770960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35457,DS-2f0f5d62-eefb-47b1-a800-161f89f9f504,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-17ed550d-7cf0-4d2e-bb49-80c42cac137a,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-1c37e12c-83ab-4558-a0f4-baa26eda97ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-caf712e7-4210-4f2d-bbba-4a5cf3ce4534,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-64cb8b3b-9a0d-40b4-86a5-bdf724838131,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-599b1deb-3252-4513-9759-649d67df0690,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-d30f8424-06f7-4d3b-b9cb-52f54f1b14d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-6e9a346d-a218-43e9-892f-4b5a64e7ffbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009254802-172.17.0.20-1597279770960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35457,DS-2f0f5d62-eefb-47b1-a800-161f89f9f504,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-17ed550d-7cf0-4d2e-bb49-80c42cac137a,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-1c37e12c-83ab-4558-a0f4-baa26eda97ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-caf712e7-4210-4f2d-bbba-4a5cf3ce4534,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-64cb8b3b-9a0d-40b4-86a5-bdf724838131,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-599b1deb-3252-4513-9759-649d67df0690,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-d30f8424-06f7-4d3b-b9cb-52f54f1b14d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-6e9a346d-a218-43e9-892f-4b5a64e7ffbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6775
