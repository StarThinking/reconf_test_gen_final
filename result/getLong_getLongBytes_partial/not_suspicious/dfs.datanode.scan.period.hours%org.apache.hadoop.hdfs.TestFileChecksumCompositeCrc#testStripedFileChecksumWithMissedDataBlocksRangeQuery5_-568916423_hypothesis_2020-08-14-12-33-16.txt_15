reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046469643-172.17.0.8-1597408609106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-21a286d1-3039-4f3b-89a0-b8f94999b165,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-74eb7f63-e7e3-4507-a451-386684dfeb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-1725b2ae-f95c-4e5a-8502-264541c8ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-4724cb59-8976-40f4-9913-280582d7c9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-8c5530e8-bfcc-4c2f-ab9e-f0e461049fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-6f08e614-635a-4eb1-8588-aca2537a9e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-68cd6ac6-516b-4c36-993f-534c708f99f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-350ea4cf-127b-4b65-80fd-8d0e8b136d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046469643-172.17.0.8-1597408609106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-21a286d1-3039-4f3b-89a0-b8f94999b165,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-74eb7f63-e7e3-4507-a451-386684dfeb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-1725b2ae-f95c-4e5a-8502-264541c8ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-4724cb59-8976-40f4-9913-280582d7c9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-8c5530e8-bfcc-4c2f-ab9e-f0e461049fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-6f08e614-635a-4eb1-8588-aca2537a9e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-68cd6ac6-516b-4c36-993f-534c708f99f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-350ea4cf-127b-4b65-80fd-8d0e8b136d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473884458-172.17.0.8-1597408751427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41052,DS-71d041e4-ecb2-4b14-bb41-7540263a8e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-fd5f102c-5723-4853-a924-3f09ad32db76,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-141a3d63-4a67-4a3b-abd0-e2c4f2826c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-49786679-9d92-47e1-93cb-18537333eaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-6479c4d6-0862-4b12-945e-15b514a47048,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-49aa70bd-ede3-48c8-9c7f-c251cb6862d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-c66f3ae5-15bd-4fda-88bd-0ff15fe18b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-09affe6f-7b2f-4bf7-8829-14783e88198e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473884458-172.17.0.8-1597408751427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41052,DS-71d041e4-ecb2-4b14-bb41-7540263a8e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-fd5f102c-5723-4853-a924-3f09ad32db76,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-141a3d63-4a67-4a3b-abd0-e2c4f2826c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-49786679-9d92-47e1-93cb-18537333eaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-6479c4d6-0862-4b12-945e-15b514a47048,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-49aa70bd-ede3-48c8-9c7f-c251cb6862d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-c66f3ae5-15bd-4fda-88bd-0ff15fe18b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-09affe6f-7b2f-4bf7-8829-14783e88198e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412968707-172.17.0.8-1597409004612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34233,DS-90fd9f37-e7a4-4d09-a4c3-32836be7e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-b0f72430-d068-4742-9922-a59e9d53564e,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-ce646498-7548-4c57-8a8f-7d3d88054849,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-7d68dc59-ed58-4284-b3f3-290fb0d2095b,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-8559fe53-1a27-4826-bc04-ed3853740195,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-187465ad-0bc5-42ac-8eb9-dbae93def0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-a3c92737-3c3b-41ab-ae61-8448e108e954,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-6ef07fba-9fdf-4278-ae35-91687010df0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412968707-172.17.0.8-1597409004612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34233,DS-90fd9f37-e7a4-4d09-a4c3-32836be7e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-b0f72430-d068-4742-9922-a59e9d53564e,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-ce646498-7548-4c57-8a8f-7d3d88054849,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-7d68dc59-ed58-4284-b3f3-290fb0d2095b,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-8559fe53-1a27-4826-bc04-ed3853740195,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-187465ad-0bc5-42ac-8eb9-dbae93def0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-a3c92737-3c3b-41ab-ae61-8448e108e954,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-6ef07fba-9fdf-4278-ae35-91687010df0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586605490-172.17.0.8-1597409100855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42112,DS-5b81eb1e-1b8f-4a8f-bd6a-40cfb435c608,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-14c52fe8-d755-41a0-ac40-27211a279c01,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-84bb5323-7533-4f9f-b4ce-ce69c30d66d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-30f938a7-7cec-473f-bc7a-da3251520895,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-a5212c81-3d08-4c45-9dce-5eaf3f9b331b,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-355f8eab-6e6d-48c6-9e7c-3bf17a7e4c70,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-c02656b1-b555-4ef0-9a10-5b8ecc351a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-b4c5ceb8-e4cd-4ff5-923c-c45fdc01e07b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586605490-172.17.0.8-1597409100855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42112,DS-5b81eb1e-1b8f-4a8f-bd6a-40cfb435c608,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-14c52fe8-d755-41a0-ac40-27211a279c01,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-84bb5323-7533-4f9f-b4ce-ce69c30d66d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-30f938a7-7cec-473f-bc7a-da3251520895,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-a5212c81-3d08-4c45-9dce-5eaf3f9b331b,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-355f8eab-6e6d-48c6-9e7c-3bf17a7e4c70,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-c02656b1-b555-4ef0-9a10-5b8ecc351a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-b4c5ceb8-e4cd-4ff5-923c-c45fdc01e07b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456320755-172.17.0.8-1597409673686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40343,DS-58c731ca-7620-427f-ad46-0342df72865e,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-dbfe6a19-660c-4d27-be77-0dd6e91b3c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-a15d17bd-9916-4d5e-97c3-99629fffef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-7959b998-7759-420f-8cfa-ae7e96da031d,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-82d02f40-c575-42cd-997a-243e94e6e097,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-e6faa33a-1d14-43f6-9484-5e78e7863d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-c66b8b7c-1be5-4a31-89c1-940c940c1897,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-054481b9-ffc1-48da-a5f8-85855bb562c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456320755-172.17.0.8-1597409673686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40343,DS-58c731ca-7620-427f-ad46-0342df72865e,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-dbfe6a19-660c-4d27-be77-0dd6e91b3c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-a15d17bd-9916-4d5e-97c3-99629fffef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-7959b998-7759-420f-8cfa-ae7e96da031d,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-82d02f40-c575-42cd-997a-243e94e6e097,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-e6faa33a-1d14-43f6-9484-5e78e7863d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-c66b8b7c-1be5-4a31-89c1-940c940c1897,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-054481b9-ffc1-48da-a5f8-85855bb562c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327469656-172.17.0.8-1597410126677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-7a207ee5-f146-4400-812a-bdca87da8923,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-4b201daa-e98c-4b3a-84e5-2c6a86edb2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-68ac1afb-fffd-47d4-adb6-b0825351f7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-766a764a-b36f-4ba5-b0bf-a1d9978ba16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-be39f7e4-328e-4a8f-aebd-5721cacc9673,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-b0b44582-d948-43bc-a02c-141422194439,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-3cdfe30a-ec5e-4b32-8b4f-18f78799e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-a789652a-6676-42db-b4a1-eae0f4a00879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327469656-172.17.0.8-1597410126677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-7a207ee5-f146-4400-812a-bdca87da8923,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-4b201daa-e98c-4b3a-84e5-2c6a86edb2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-68ac1afb-fffd-47d4-adb6-b0825351f7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-766a764a-b36f-4ba5-b0bf-a1d9978ba16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-be39f7e4-328e-4a8f-aebd-5721cacc9673,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-b0b44582-d948-43bc-a02c-141422194439,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-3cdfe30a-ec5e-4b32-8b4f-18f78799e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-a789652a-6676-42db-b4a1-eae0f4a00879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842651889-172.17.0.8-1597410400988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42394,DS-77096dc2-a66d-483d-8b50-65b5736669c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-4e67a39c-2c14-4ff4-a4be-fab5cae4e129,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-bcdc47cf-a437-4228-8d92-657725c56003,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-d8372ddf-227b-4698-9fd4-7929bd07e655,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-ca28b462-92b6-4622-b8ac-b0a3abb5ee75,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-9f027550-289b-4317-9610-cfea12ba0273,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-d9506e04-1374-4c99-838a-07b67cbe5d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-29a72f42-3633-4aac-80e9-91a687651734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842651889-172.17.0.8-1597410400988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42394,DS-77096dc2-a66d-483d-8b50-65b5736669c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-4e67a39c-2c14-4ff4-a4be-fab5cae4e129,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-bcdc47cf-a437-4228-8d92-657725c56003,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-d8372ddf-227b-4698-9fd4-7929bd07e655,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-ca28b462-92b6-4622-b8ac-b0a3abb5ee75,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-9f027550-289b-4317-9610-cfea12ba0273,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-d9506e04-1374-4c99-838a-07b67cbe5d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-29a72f42-3633-4aac-80e9-91a687651734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639374382-172.17.0.8-1597410452934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-ba28376d-46b7-442e-b10c-c757a7378ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-d25be3eb-cc4b-4159-bb58-02e05b8b2794,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-8401df53-6483-4261-b590-05646fe396ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-395179c7-3c65-4655-99fd-b4056eb147df,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-dc37bfd0-b946-4b45-ba65-d617b37917d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-867ebd1b-462c-4f50-b3dc-2a5468c45bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-1398c16b-b1e5-4394-a43b-c4b781abfe94,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-bfb3b6d9-3d3d-4c64-b83e-ef26bb3b739b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639374382-172.17.0.8-1597410452934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-ba28376d-46b7-442e-b10c-c757a7378ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-d25be3eb-cc4b-4159-bb58-02e05b8b2794,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-8401df53-6483-4261-b590-05646fe396ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-395179c7-3c65-4655-99fd-b4056eb147df,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-dc37bfd0-b946-4b45-ba65-d617b37917d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-867ebd1b-462c-4f50-b3dc-2a5468c45bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-1398c16b-b1e5-4394-a43b-c4b781abfe94,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-bfb3b6d9-3d3d-4c64-b83e-ef26bb3b739b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213346098-172.17.0.8-1597410677101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37890,DS-d3368d33-af13-4aea-8e18-efabdae397c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-090fd520-70ee-4b20-b288-c666a98b6a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-57a7f296-9ad9-44e3-8306-7b8715164300,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-c029ae67-6d58-4228-9e66-720faadf38d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-de94ee9d-c2c3-43c1-bebc-8c23406e3a68,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-7245040a-5a4e-4d7c-86c8-8658ed9dfecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-a4d2d520-a2e5-4bc0-b39e-7045309996f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-9877e29e-9b66-4b54-b055-0ff32446d980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213346098-172.17.0.8-1597410677101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37890,DS-d3368d33-af13-4aea-8e18-efabdae397c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-090fd520-70ee-4b20-b288-c666a98b6a45,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-57a7f296-9ad9-44e3-8306-7b8715164300,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-c029ae67-6d58-4228-9e66-720faadf38d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-de94ee9d-c2c3-43c1-bebc-8c23406e3a68,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-7245040a-5a4e-4d7c-86c8-8658ed9dfecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-a4d2d520-a2e5-4bc0-b39e-7045309996f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-9877e29e-9b66-4b54-b055-0ff32446d980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111661976-172.17.0.8-1597412345470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-3241967a-0287-4743-979f-783b6aef9dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-fb047d03-61ac-4e58-87ba-4d09d268f241,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-088163fa-57bd-4345-b5d9-6bbb00c4c234,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-6102285a-ca2e-40a8-b054-2c0b8828cadc,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-be488701-7eb7-4d41-8a88-9fd2bb10fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-beca81d7-607d-4f48-8a2c-945cb4edf0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-6ce66be0-0beb-46cb-87f2-9f534690adf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-c424eded-4b25-4275-9477-7e9badf38b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111661976-172.17.0.8-1597412345470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-3241967a-0287-4743-979f-783b6aef9dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-fb047d03-61ac-4e58-87ba-4d09d268f241,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-088163fa-57bd-4345-b5d9-6bbb00c4c234,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-6102285a-ca2e-40a8-b054-2c0b8828cadc,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-be488701-7eb7-4d41-8a88-9fd2bb10fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-beca81d7-607d-4f48-8a2c-945cb4edf0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-6ce66be0-0beb-46cb-87f2-9f534690adf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-c424eded-4b25-4275-9477-7e9badf38b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812594800-172.17.0.8-1597412384826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-9e34b988-5be3-4860-9821-6011c816cf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-a4c66331-c20b-4e2a-95f6-0da88b9b3add,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-09af3ab1-d9eb-40cd-ab20-c96f5f99878f,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-1beb167a-ac2a-432a-8069-ddeedc888d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-85b4de51-8225-423e-bcb4-519437c59929,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-f04bae66-f4d5-4abc-94b8-9e427dc56268,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-d438f216-7ed9-4dcd-90f2-3194fdfe13d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-fc639959-a507-4ba4-8d8c-710011955bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812594800-172.17.0.8-1597412384826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-9e34b988-5be3-4860-9821-6011c816cf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-a4c66331-c20b-4e2a-95f6-0da88b9b3add,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-09af3ab1-d9eb-40cd-ab20-c96f5f99878f,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-1beb167a-ac2a-432a-8069-ddeedc888d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-85b4de51-8225-423e-bcb4-519437c59929,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-f04bae66-f4d5-4abc-94b8-9e427dc56268,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-d438f216-7ed9-4dcd-90f2-3194fdfe13d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-fc639959-a507-4ba4-8d8c-710011955bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75199531-172.17.0.8-1597412700376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-58345938-195a-42b5-b112-a24f526e3062,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-d99755c7-8d0a-46f8-aacc-7cc76ceed951,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-e5278343-e945-4673-afa4-9612139b04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-74b70d95-f1b2-4364-ba2c-c06f5fa61c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-29a4536b-176c-4c02-95b4-77bb24a68be4,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-384efb64-2043-4de9-85c9-b57b2b619663,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-0f758f09-7858-45b7-ad09-3a101f1a51b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-8af3afe5-c3eb-4bc4-820b-1b36e69adb4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75199531-172.17.0.8-1597412700376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-58345938-195a-42b5-b112-a24f526e3062,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-d99755c7-8d0a-46f8-aacc-7cc76ceed951,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-e5278343-e945-4673-afa4-9612139b04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-74b70d95-f1b2-4364-ba2c-c06f5fa61c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-29a4536b-176c-4c02-95b4-77bb24a68be4,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-384efb64-2043-4de9-85c9-b57b2b619663,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-0f758f09-7858-45b7-ad09-3a101f1a51b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-8af3afe5-c3eb-4bc4-820b-1b36e69adb4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502975184-172.17.0.8-1597412876269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-f3d3e9df-2fd9-48ab-9466-93bfd51229fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-0c2f3f63-599e-492e-9473-1e3b4b003541,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-3e708e7e-5323-4f47-9d13-ff1f5f758049,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-30cdfc81-f373-4733-a144-a63698f095b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-aad7194c-27de-4eb4-a31a-5e5dcf49f7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-4d03956f-ba19-4ddc-9b4a-4ecc566a9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d2fec759-956c-476a-b81b-fea4b377cae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-6143b7ac-b2f1-4d9d-83b4-f57498f28f76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502975184-172.17.0.8-1597412876269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-f3d3e9df-2fd9-48ab-9466-93bfd51229fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-0c2f3f63-599e-492e-9473-1e3b4b003541,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-3e708e7e-5323-4f47-9d13-ff1f5f758049,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-30cdfc81-f373-4733-a144-a63698f095b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-aad7194c-27de-4eb4-a31a-5e5dcf49f7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-4d03956f-ba19-4ddc-9b4a-4ecc566a9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d2fec759-956c-476a-b81b-fea4b377cae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-6143b7ac-b2f1-4d9d-83b4-f57498f28f76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597299820-172.17.0.8-1597413109285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-b6fbfd4c-5ca1-41d7-95f7-0a7ba55778c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-7d347a72-a466-45d3-a9a1-ef0a05715e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-24a20a69-e08e-4cd3-8ddc-8ec4c54cee0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-b7550edf-20f9-4177-aba5-7d4daa9c59a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-42fcff2f-d991-4a48-a332-4797d5c3c629,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-6e841452-e6c9-449c-ba53-f03d68c2bd06,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-b40536b8-7565-4f48-b37b-5aba5be461a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-8735aaba-ffa3-4531-aed9-43a89dffb910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597299820-172.17.0.8-1597413109285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-b6fbfd4c-5ca1-41d7-95f7-0a7ba55778c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-7d347a72-a466-45d3-a9a1-ef0a05715e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-24a20a69-e08e-4cd3-8ddc-8ec4c54cee0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-b7550edf-20f9-4177-aba5-7d4daa9c59a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-42fcff2f-d991-4a48-a332-4797d5c3c629,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-6e841452-e6c9-449c-ba53-f03d68c2bd06,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-b40536b8-7565-4f48-b37b-5aba5be461a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-8735aaba-ffa3-4531-aed9-43a89dffb910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222279400-172.17.0.8-1597413579412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-178bb36b-b0cb-4b1a-9228-7c2e3b646806,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-b64295b8-238e-4070-afcd-bfc72bbc6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-397ec577-33ad-4b08-8d02-e009c4ab51b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-085544f3-312e-45a6-8b7c-df54edcd4066,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-799c3968-0731-4bcc-8c5b-86bfeb226cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-db1ca3c5-a967-49e1-a594-d3869205aa67,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-3f4d4441-e3ed-481c-92cf-dcd75f787673,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-fc1767e9-9082-486b-bae5-2343392f3d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222279400-172.17.0.8-1597413579412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-178bb36b-b0cb-4b1a-9228-7c2e3b646806,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-b64295b8-238e-4070-afcd-bfc72bbc6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-397ec577-33ad-4b08-8d02-e009c4ab51b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-085544f3-312e-45a6-8b7c-df54edcd4066,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-799c3968-0731-4bcc-8c5b-86bfeb226cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-db1ca3c5-a967-49e1-a594-d3869205aa67,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-3f4d4441-e3ed-481c-92cf-dcd75f787673,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-fc1767e9-9082-486b-bae5-2343392f3d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063554321-172.17.0.8-1597413674751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-d742a3a4-338a-46c5-a2d1-eff83ec5b2df,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-80fb594f-441c-466f-af32-63efcda201c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-88466d8b-2973-4c8e-832d-ee5997933c13,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-56ffc0df-b91a-454e-88e7-ae85a6a11ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-084c7f94-530e-454d-95c4-fa82fa9160eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-255a8020-fd29-4d2c-8a34-6c7110fef949,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-32fcc090-f4bc-4186-bb93-607589f80de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-d4a6058c-3fd8-4b60-a9fc-9e214d7b6653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063554321-172.17.0.8-1597413674751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-d742a3a4-338a-46c5-a2d1-eff83ec5b2df,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-80fb594f-441c-466f-af32-63efcda201c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-88466d8b-2973-4c8e-832d-ee5997933c13,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-56ffc0df-b91a-454e-88e7-ae85a6a11ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-084c7f94-530e-454d-95c4-fa82fa9160eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-255a8020-fd29-4d2c-8a34-6c7110fef949,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-32fcc090-f4bc-4186-bb93-607589f80de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-d4a6058c-3fd8-4b60-a9fc-9e214d7b6653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558575341-172.17.0.8-1597413843053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-dff3b443-47a8-4526-8415-a574be1b20cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-b8148554-e7db-4745-9f38-e8af7c661ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-8c4acd04-8f4d-4852-9c78-439f62b9905e,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e38bd4dc-9e00-45dc-ab46-d0758efb8f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-c6fcb03d-dfa3-4543-8bf8-2804a20d02cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-c9d591ae-86b9-4c29-8e1c-a561b8a7c738,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-90683478-8e86-4bf7-9e09-4b1e6036f982,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-79b62290-f198-4b37-80ba-bbe9b68ac185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558575341-172.17.0.8-1597413843053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-dff3b443-47a8-4526-8415-a574be1b20cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-b8148554-e7db-4745-9f38-e8af7c661ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-8c4acd04-8f4d-4852-9c78-439f62b9905e,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e38bd4dc-9e00-45dc-ab46-d0758efb8f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-c6fcb03d-dfa3-4543-8bf8-2804a20d02cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-c9d591ae-86b9-4c29-8e1c-a561b8a7c738,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-90683478-8e86-4bf7-9e09-4b1e6036f982,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-79b62290-f198-4b37-80ba-bbe9b68ac185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273789055-172.17.0.8-1597414082615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46104,DS-bc1abae9-3b57-4e55-a835-41f7484bd0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-ea24c67a-b1dc-487f-9d6c-e2336f8e704e,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-43605d4d-d4ed-4916-913e-ffefed8d3327,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-e5bf8ad5-d04a-4c88-9bd7-19c6fe1b7d15,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-147ac408-c33b-4a3a-87a2-66700005bae1,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-66e800b4-2feb-43ee-87e9-f338b7c4e19b,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-2210fc63-47e4-405f-bf7b-d56d4d891228,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-abeb3295-2777-4e70-82df-7f96a7a8530f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273789055-172.17.0.8-1597414082615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46104,DS-bc1abae9-3b57-4e55-a835-41f7484bd0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-ea24c67a-b1dc-487f-9d6c-e2336f8e704e,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-43605d4d-d4ed-4916-913e-ffefed8d3327,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-e5bf8ad5-d04a-4c88-9bd7-19c6fe1b7d15,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-147ac408-c33b-4a3a-87a2-66700005bae1,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-66e800b4-2feb-43ee-87e9-f338b7c4e19b,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-2210fc63-47e4-405f-bf7b-d56d4d891228,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-abeb3295-2777-4e70-82df-7f96a7a8530f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626269181-172.17.0.8-1597414368768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43072,DS-74ed5195-0306-4332-b8f6-bb177f93c465,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-736223af-8334-4a5b-8b33-bf8593061deb,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-d2f704bd-e96f-49fd-8fa5-fb7863ccef40,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-1035ff9f-6f56-479b-8eae-9cca7bb9214b,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-c63c608e-768e-4ce6-8c16-a5df809e2c63,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-1357e4e6-1361-473f-ab31-6b72c6183e05,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-d61333b1-a16e-43db-8b89-42fefb7635a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-9cc9f79c-3c7d-416d-aa99-99711416a090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626269181-172.17.0.8-1597414368768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43072,DS-74ed5195-0306-4332-b8f6-bb177f93c465,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-736223af-8334-4a5b-8b33-bf8593061deb,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-d2f704bd-e96f-49fd-8fa5-fb7863ccef40,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-1035ff9f-6f56-479b-8eae-9cca7bb9214b,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-c63c608e-768e-4ce6-8c16-a5df809e2c63,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-1357e4e6-1361-473f-ab31-6b72c6183e05,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-d61333b1-a16e-43db-8b89-42fefb7635a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-9cc9f79c-3c7d-416d-aa99-99711416a090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192262229-172.17.0.8-1597414704812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35347,DS-a5da17e1-4931-45f4-83d8-d007f6dc1bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-becf7c14-f100-4a16-ae4c-a8e3477f78bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-2ea70cad-22f5-40cd-be6f-a186b15d25e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-fa392469-37b6-4da8-b710-ce1af4a134cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-058855f5-ceae-47fa-942c-cbea26b1dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-1fa84d65-1d24-4f34-a149-e3a272666322,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-728dcad7-e8d6-4bb4-930d-49cfa8efc529,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-c26f959f-cc01-4ea9-a97d-2f6be42e835b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192262229-172.17.0.8-1597414704812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35347,DS-a5da17e1-4931-45f4-83d8-d007f6dc1bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-becf7c14-f100-4a16-ae4c-a8e3477f78bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-2ea70cad-22f5-40cd-be6f-a186b15d25e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-fa392469-37b6-4da8-b710-ce1af4a134cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-058855f5-ceae-47fa-942c-cbea26b1dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-1fa84d65-1d24-4f34-a149-e3a272666322,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-728dcad7-e8d6-4bb4-930d-49cfa8efc529,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-c26f959f-cc01-4ea9-a97d-2f6be42e835b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995099890-172.17.0.8-1597414900169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-b5e42d58-4a54-494b-abfb-a6d682dddf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-c922cd6d-9338-4611-be79-17da13c3c0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-1fedb8d1-ae1c-46af-9917-577d131bd11b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-c25cb82a-df2d-4431-ab72-a31c8bf23946,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-0955ec7b-fffd-4a3e-a09a-123fd7ef394c,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-96b838cf-05f4-4001-9833-1aed1fc42eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-ebf6cca5-a180-41d3-9ebd-c09f43064efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-f053dfac-1fb0-462f-9b56-072008e04b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995099890-172.17.0.8-1597414900169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-b5e42d58-4a54-494b-abfb-a6d682dddf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-c922cd6d-9338-4611-be79-17da13c3c0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-1fedb8d1-ae1c-46af-9917-577d131bd11b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-c25cb82a-df2d-4431-ab72-a31c8bf23946,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-0955ec7b-fffd-4a3e-a09a-123fd7ef394c,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-96b838cf-05f4-4001-9833-1aed1fc42eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-ebf6cca5-a180-41d3-9ebd-c09f43064efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-f053dfac-1fb0-462f-9b56-072008e04b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193505320-172.17.0.8-1597415182307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-dca25fd7-cdbd-482e-b156-70057631820b,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-84057a92-484a-42e1-bbff-d812c2aaf4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-42569a88-4d8b-4170-a6d4-d20dd1ae19c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-adaecf17-0ba8-40ec-906b-c81981c7e083,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-c9714f9d-fd40-404e-a66a-ff68cfebc46c,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-f3401153-1f2c-4338-b29c-1c369f71fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-bb462431-8495-4d93-b26e-15f166d04859,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-31a3d408-9818-4e19-9ae0-5a03d6417f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193505320-172.17.0.8-1597415182307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-dca25fd7-cdbd-482e-b156-70057631820b,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-84057a92-484a-42e1-bbff-d812c2aaf4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-42569a88-4d8b-4170-a6d4-d20dd1ae19c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-adaecf17-0ba8-40ec-906b-c81981c7e083,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-c9714f9d-fd40-404e-a66a-ff68cfebc46c,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-f3401153-1f2c-4338-b29c-1c369f71fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-bb462431-8495-4d93-b26e-15f166d04859,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-31a3d408-9818-4e19-9ae0-5a03d6417f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882267848-172.17.0.8-1597415263121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38208,DS-dc875748-d1f8-402a-b982-f5900e1f9872,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-c3acfd14-d5fa-4921-9007-9cd3a4b5e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-4d5f0c5b-75a9-483f-b522-39e599115394,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-f1fb82f8-79a0-48b4-9486-96e1f9ad0048,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-b44af4f9-d93d-46a6-806e-c4ccbab5341a,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-d5abf805-565d-4704-9225-a78d9a5de97c,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-0e11f91f-e675-44e0-8a57-b5063a95a665,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-d6ab3dc9-e185-4de3-b70e-fe196ab823f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882267848-172.17.0.8-1597415263121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38208,DS-dc875748-d1f8-402a-b982-f5900e1f9872,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-c3acfd14-d5fa-4921-9007-9cd3a4b5e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-4d5f0c5b-75a9-483f-b522-39e599115394,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-f1fb82f8-79a0-48b4-9486-96e1f9ad0048,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-b44af4f9-d93d-46a6-806e-c4ccbab5341a,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-d5abf805-565d-4704-9225-a78d9a5de97c,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-0e11f91f-e675-44e0-8a57-b5063a95a665,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-d6ab3dc9-e185-4de3-b70e-fe196ab823f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6940
