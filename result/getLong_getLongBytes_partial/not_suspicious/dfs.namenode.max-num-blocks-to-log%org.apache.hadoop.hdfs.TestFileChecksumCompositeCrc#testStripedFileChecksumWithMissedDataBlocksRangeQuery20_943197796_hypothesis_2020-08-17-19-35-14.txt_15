reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352025888-172.17.0.13-1597693299483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-0d43997e-02ba-4150-b270-f85e4a60e8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-1f05e2f1-cd47-4ea6-a525-250d90e44b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-ade57776-f0e7-4cea-a271-f3205f23cac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-039fc50a-0aae-4b6e-afc8-b400b3595910,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-166b0cba-49f8-4c75-b89d-2a666acf291b,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-94346a31-c8c3-4d31-8722-1febe565eecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-89d3ae33-559d-422b-ae0a-15520fa7395e,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-c2a32afd-586e-418f-8755-dfa3be1118a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352025888-172.17.0.13-1597693299483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-0d43997e-02ba-4150-b270-f85e4a60e8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-1f05e2f1-cd47-4ea6-a525-250d90e44b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-ade57776-f0e7-4cea-a271-f3205f23cac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-039fc50a-0aae-4b6e-afc8-b400b3595910,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-166b0cba-49f8-4c75-b89d-2a666acf291b,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-94346a31-c8c3-4d31-8722-1febe565eecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-89d3ae33-559d-422b-ae0a-15520fa7395e,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-c2a32afd-586e-418f-8755-dfa3be1118a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450696228-172.17.0.13-1597693367706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37155,DS-3e9069a1-ed4a-4627-801c-0751f2d61333,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-91e3b0d9-5670-44b1-9c5b-48c0fb4d072e,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-331263fe-8b72-4f2b-8a68-3635b0f47bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-4e44ff3b-a427-457c-992f-fd1e754faeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-a9c39cab-bf80-4d78-b2a6-197676daf70d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-35c2240f-80a4-46ca-b766-1f991c8387dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-ec11377f-7d5d-4e8a-9c28-e8f9332e8467,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-9fbcdd3b-36e6-4c35-8174-d5f446a4e447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450696228-172.17.0.13-1597693367706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37155,DS-3e9069a1-ed4a-4627-801c-0751f2d61333,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-91e3b0d9-5670-44b1-9c5b-48c0fb4d072e,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-331263fe-8b72-4f2b-8a68-3635b0f47bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-4e44ff3b-a427-457c-992f-fd1e754faeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-a9c39cab-bf80-4d78-b2a6-197676daf70d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-35c2240f-80a4-46ca-b766-1f991c8387dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-ec11377f-7d5d-4e8a-9c28-e8f9332e8467,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-9fbcdd3b-36e6-4c35-8174-d5f446a4e447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496606649-172.17.0.13-1597694043721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38418,DS-805cbbc9-b734-44a7-9888-65d945742433,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-75995065-2375-407e-8789-fe89464db46d,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-90f7adf0-64df-41fa-b4e8-40a77b0d8152,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-b5aa5a4c-fb3b-4962-b83c-65a860d18d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-b2f16320-0130-455c-b087-c5554af14b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-f5edbab4-5ad2-40f6-8c71-5f26a26b20db,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-7b517d71-202f-4b8d-bbf4-b396dab6dd51,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-0b9b5adb-db30-478b-a794-bf288b2dc261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496606649-172.17.0.13-1597694043721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38418,DS-805cbbc9-b734-44a7-9888-65d945742433,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-75995065-2375-407e-8789-fe89464db46d,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-90f7adf0-64df-41fa-b4e8-40a77b0d8152,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-b5aa5a4c-fb3b-4962-b83c-65a860d18d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-b2f16320-0130-455c-b087-c5554af14b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-f5edbab4-5ad2-40f6-8c71-5f26a26b20db,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-7b517d71-202f-4b8d-bbf4-b396dab6dd51,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-0b9b5adb-db30-478b-a794-bf288b2dc261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844522810-172.17.0.13-1597694192393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46073,DS-497550ac-4f54-42af-b97e-21d3631b1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-15f17c69-10ab-4c0f-bb56-ff576b2deccb,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-4b55b4d3-f0ca-4d18-9488-c199fc98f76e,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-42366320-f9e8-44d4-8b5a-801701791e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-b4919e9b-a641-4211-9c50-2a3f29d29790,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-bb79b4da-acbd-4dc5-b2b5-89236071b124,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-dbc22f24-41ce-42e4-ac44-2bc3aeae1442,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-24ae8849-87f8-458e-b901-c8df562f829d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844522810-172.17.0.13-1597694192393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46073,DS-497550ac-4f54-42af-b97e-21d3631b1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-15f17c69-10ab-4c0f-bb56-ff576b2deccb,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-4b55b4d3-f0ca-4d18-9488-c199fc98f76e,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-42366320-f9e8-44d4-8b5a-801701791e62,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-b4919e9b-a641-4211-9c50-2a3f29d29790,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-bb79b4da-acbd-4dc5-b2b5-89236071b124,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-dbc22f24-41ce-42e4-ac44-2bc3aeae1442,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-24ae8849-87f8-458e-b901-c8df562f829d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439687576-172.17.0.13-1597694473807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38437,DS-caebb716-1940-4997-8b65-9f9f40bc8807,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-72e22775-1525-4ba8-9d38-6c7ed5877c74,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-9550d096-3aed-425d-af05-1c57a279f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-ec80c7b5-f246-4852-9ee4-a0b5adbbb849,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-0cfee864-3a1d-46ce-bdf3-3411cf56c2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-45644b48-07cd-46ba-ac5d-64d18f2302fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-5a9d075e-b3a0-4d0e-8e17-efcdadd35d65,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-3fa2a4e2-d685-4196-99e8-6970c8e1e6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439687576-172.17.0.13-1597694473807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38437,DS-caebb716-1940-4997-8b65-9f9f40bc8807,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-72e22775-1525-4ba8-9d38-6c7ed5877c74,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-9550d096-3aed-425d-af05-1c57a279f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-ec80c7b5-f246-4852-9ee4-a0b5adbbb849,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-0cfee864-3a1d-46ce-bdf3-3411cf56c2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-45644b48-07cd-46ba-ac5d-64d18f2302fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-5a9d075e-b3a0-4d0e-8e17-efcdadd35d65,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-3fa2a4e2-d685-4196-99e8-6970c8e1e6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651746435-172.17.0.13-1597694755154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46717,DS-3c4a3ab5-0928-4754-8c74-6c9176ae4ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-7c5f2aac-6a8c-486f-bd11-436433e219fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-8bd50bbb-c40c-4aad-a00d-3e51f74cf0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-8ba1dd79-86f8-4be2-adfb-0969a1d83b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-90b4439e-eca5-4e4e-aeb2-d12d4fbb95cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-f984c49f-04b2-4991-90e7-428ae5b281ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-c93648d4-a260-40d8-8de3-fec3dbc64288,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-d42251c0-0b0d-465a-ac50-ca81a563690d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651746435-172.17.0.13-1597694755154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46717,DS-3c4a3ab5-0928-4754-8c74-6c9176ae4ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-7c5f2aac-6a8c-486f-bd11-436433e219fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-8bd50bbb-c40c-4aad-a00d-3e51f74cf0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-8ba1dd79-86f8-4be2-adfb-0969a1d83b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-90b4439e-eca5-4e4e-aeb2-d12d4fbb95cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-f984c49f-04b2-4991-90e7-428ae5b281ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-c93648d4-a260-40d8-8de3-fec3dbc64288,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-d42251c0-0b0d-465a-ac50-ca81a563690d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471708380-172.17.0.13-1597694789276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-117a7cdd-2f11-4e80-9093-998826351cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-643478ae-9567-4634-9d5e-77a29aed38c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-3189165e-445d-496d-beec-44d85ccc7087,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-ffa64677-61a4-4f2c-a5be-1f71b0796b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-0ef854db-7358-4939-96c2-f523bdeb9bff,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-8cf58cda-5d0e-4a0f-bda3-6c7bf66a445a,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-a767f7a1-aaf0-43f1-b846-cee9724692cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-382e2c62-966b-4c2b-a74e-27add99dff1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471708380-172.17.0.13-1597694789276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38292,DS-117a7cdd-2f11-4e80-9093-998826351cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-643478ae-9567-4634-9d5e-77a29aed38c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-3189165e-445d-496d-beec-44d85ccc7087,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-ffa64677-61a4-4f2c-a5be-1f71b0796b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-0ef854db-7358-4939-96c2-f523bdeb9bff,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-8cf58cda-5d0e-4a0f-bda3-6c7bf66a445a,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-a767f7a1-aaf0-43f1-b846-cee9724692cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-382e2c62-966b-4c2b-a74e-27add99dff1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584113816-172.17.0.13-1597695143107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35180,DS-503b42a9-c122-4930-be67-d5d2a082d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-2f1bb21e-5aee-4313-8e13-15af03e5b9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-8da965cd-888f-46fc-b26c-097e30ff440e,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-fd10cd16-b31c-4c94-b091-c303d6ed10eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-a4829e64-359d-4209-8253-7c0e74398a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-8695b730-65ed-45fa-b9c1-f4a3da88cad9,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-6f6d827b-3d55-4676-9135-66e365e7e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-8666212c-0baa-4e78-a8af-d2f38b4d604d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584113816-172.17.0.13-1597695143107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35180,DS-503b42a9-c122-4930-be67-d5d2a082d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-2f1bb21e-5aee-4313-8e13-15af03e5b9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-8da965cd-888f-46fc-b26c-097e30ff440e,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-fd10cd16-b31c-4c94-b091-c303d6ed10eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-a4829e64-359d-4209-8253-7c0e74398a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-8695b730-65ed-45fa-b9c1-f4a3da88cad9,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-6f6d827b-3d55-4676-9135-66e365e7e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-8666212c-0baa-4e78-a8af-d2f38b4d604d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090856359-172.17.0.13-1597695564231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-cbf92a1f-dfe6-45ac-99a5-b092af5289dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-4fb102d8-a9cf-4718-8851-ca28b309f5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-a46dba91-170b-4326-a2b0-c54cb2b0a6af,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-908e99ae-8a39-4fac-bb2c-e57a493790e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-6bfd8352-ee2c-4ad5-9dab-54ea2ee5f095,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-c49a5084-9ea5-4d34-905c-ac7df2bed3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-18ab6d40-0154-4ef6-b068-ed6f09980343,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-6962e63e-f2af-4373-bb97-5d2e516c574b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090856359-172.17.0.13-1597695564231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-cbf92a1f-dfe6-45ac-99a5-b092af5289dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-4fb102d8-a9cf-4718-8851-ca28b309f5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-a46dba91-170b-4326-a2b0-c54cb2b0a6af,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-908e99ae-8a39-4fac-bb2c-e57a493790e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-6bfd8352-ee2c-4ad5-9dab-54ea2ee5f095,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-c49a5084-9ea5-4d34-905c-ac7df2bed3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-18ab6d40-0154-4ef6-b068-ed6f09980343,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-6962e63e-f2af-4373-bb97-5d2e516c574b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124099701-172.17.0.13-1597695868172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-0cf140da-a001-47d1-b3d8-7957913feee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-9d629a2b-6a83-4e52-84ee-ca391e701264,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-514f8f62-9d06-4669-8911-e1f737ebaa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-a60c8da6-c7ed-4440-9f47-fcaaa8dfcd03,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-7d1e1705-ee2f-48a2-aeab-8e6d0f7d857c,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-72174041-5b45-4f8a-8fb6-2cbfe4c571d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-0f6c7fba-80d5-44c6-a6e0-c558dd508276,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-228b5edd-43c6-4e29-ab64-1742a8cc8736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124099701-172.17.0.13-1597695868172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-0cf140da-a001-47d1-b3d8-7957913feee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-9d629a2b-6a83-4e52-84ee-ca391e701264,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-514f8f62-9d06-4669-8911-e1f737ebaa4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-a60c8da6-c7ed-4440-9f47-fcaaa8dfcd03,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-7d1e1705-ee2f-48a2-aeab-8e6d0f7d857c,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-72174041-5b45-4f8a-8fb6-2cbfe4c571d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-0f6c7fba-80d5-44c6-a6e0-c558dd508276,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-228b5edd-43c6-4e29-ab64-1742a8cc8736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278369877-172.17.0.13-1597696022802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45249,DS-baba3383-2018-470c-bfa3-454ec99e9207,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-36caf141-04cd-40de-a67c-c06709d05dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-8d00186c-fc30-4808-a5cd-ff55048d5255,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-2173c449-e341-4764-b4d6-c10906d37a48,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-2ac2098f-5f8f-4e00-9904-c09c706bcbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-f87dc155-017a-4404-87f2-1bcc3a825517,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-f074793f-9169-47e8-ab11-16ca65c9a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-bfeca089-18c2-49a0-8d19-5537a9cd56ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-278369877-172.17.0.13-1597696022802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45249,DS-baba3383-2018-470c-bfa3-454ec99e9207,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-36caf141-04cd-40de-a67c-c06709d05dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-8d00186c-fc30-4808-a5cd-ff55048d5255,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-2173c449-e341-4764-b4d6-c10906d37a48,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-2ac2098f-5f8f-4e00-9904-c09c706bcbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-f87dc155-017a-4404-87f2-1bcc3a825517,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-f074793f-9169-47e8-ab11-16ca65c9a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-bfeca089-18c2-49a0-8d19-5537a9cd56ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94024312-172.17.0.13-1597696240308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-7adb4439-3fd9-45a0-a191-8eb93c4f9160,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-fa3f4ea3-bc00-4737-b72c-1c2d34c47d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-506c06d1-06ae-45d0-8f5a-0eabf11f8b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-e2fb049c-ee86-4ad1-a196-2b8dbb5fd35d,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-a32a1526-353d-4b58-83af-49b33570e412,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-7b6cf14e-444d-4bbf-9cc9-7d6f69c26a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-04a5cf45-56dd-4ae3-8931-ddb011c58f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-86961e67-c9c6-4082-8bba-a4473f2fe7b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94024312-172.17.0.13-1597696240308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43197,DS-7adb4439-3fd9-45a0-a191-8eb93c4f9160,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-fa3f4ea3-bc00-4737-b72c-1c2d34c47d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-506c06d1-06ae-45d0-8f5a-0eabf11f8b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-e2fb049c-ee86-4ad1-a196-2b8dbb5fd35d,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-a32a1526-353d-4b58-83af-49b33570e412,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-7b6cf14e-444d-4bbf-9cc9-7d6f69c26a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-04a5cf45-56dd-4ae3-8931-ddb011c58f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-86961e67-c9c6-4082-8bba-a4473f2fe7b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608365366-172.17.0.13-1597696271420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-07efffbf-03fe-4bcf-95cb-a80c7ff9398b,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-01fbd7d1-0606-4b04-afcc-bc6ad720b1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-0c2365a7-7e0a-443e-a545-3303e691df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-19cafe21-87da-48d3-a5d2-6917fea1b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-077525c9-db59-4615-9d1d-0d3a04edc9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-6e4a844d-5caa-4f53-b92c-d3515ede90ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-52d13384-cfc7-4e9c-93f7-8a4c5e9e7224,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-7d243beb-bf13-4be5-b980-bdaa0c10d3e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608365366-172.17.0.13-1597696271420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-07efffbf-03fe-4bcf-95cb-a80c7ff9398b,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-01fbd7d1-0606-4b04-afcc-bc6ad720b1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-0c2365a7-7e0a-443e-a545-3303e691df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-19cafe21-87da-48d3-a5d2-6917fea1b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-077525c9-db59-4615-9d1d-0d3a04edc9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-6e4a844d-5caa-4f53-b92c-d3515ede90ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-52d13384-cfc7-4e9c-93f7-8a4c5e9e7224,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-7d243beb-bf13-4be5-b980-bdaa0c10d3e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413658315-172.17.0.13-1597697838475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-e7481f76-8b0e-4c10-a8f9-f5d8e7dac34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-a9577414-daf5-46cf-b602-79bd45b4e777,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-4979efe8-786e-4b0f-bf5a-ab54d6a03e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-f5fb5637-4284-4420-ae9b-7319aeb8d8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-f44d06cf-75ce-4cb7-b43d-55563ae44f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-3fd18552-6951-4577-bb8d-97353adc385b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-dc16ea3d-1f4b-4b46-96e4-3a9d1e49067e,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-68510fea-26f9-40b8-92b2-5d40539ad659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413658315-172.17.0.13-1597697838475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-e7481f76-8b0e-4c10-a8f9-f5d8e7dac34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-a9577414-daf5-46cf-b602-79bd45b4e777,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-4979efe8-786e-4b0f-bf5a-ab54d6a03e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-f5fb5637-4284-4420-ae9b-7319aeb8d8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-f44d06cf-75ce-4cb7-b43d-55563ae44f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-3fd18552-6951-4577-bb8d-97353adc385b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-dc16ea3d-1f4b-4b46-96e4-3a9d1e49067e,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-68510fea-26f9-40b8-92b2-5d40539ad659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021358717-172.17.0.13-1597697994691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38878,DS-1034b895-ce22-4269-b4b6-fd93147f295c,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-0765fd2a-a518-4bb9-8ebe-0ea12804173a,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-ce58564b-9446-4885-a728-f0edcd7c052b,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-3128c300-4484-414f-b471-85b7517cfe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-7467a0cd-5652-43c3-bb11-e7fb65580cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-d0fdc879-5b5c-4d45-b720-f899bbd66e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-a13c6647-5a99-41d4-beae-2cb66b5ce6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-9dc700b2-fa01-4189-9c6c-bad2fb35cb66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021358717-172.17.0.13-1597697994691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38878,DS-1034b895-ce22-4269-b4b6-fd93147f295c,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-0765fd2a-a518-4bb9-8ebe-0ea12804173a,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-ce58564b-9446-4885-a728-f0edcd7c052b,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-3128c300-4484-414f-b471-85b7517cfe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-7467a0cd-5652-43c3-bb11-e7fb65580cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-d0fdc879-5b5c-4d45-b720-f899bbd66e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-a13c6647-5a99-41d4-beae-2cb66b5ce6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-9dc700b2-fa01-4189-9c6c-bad2fb35cb66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601392385-172.17.0.13-1597698146346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40490,DS-075281d4-b436-456e-b2fb-b57cd500a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-46d18dce-9653-4aa5-ad3f-64e20c2951e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-2159d718-5f78-43bd-8f9c-116320d44218,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-86a187be-361a-4ee7-b476-30fb07fa8cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-a5303dd8-13b8-47a4-9c78-5ce8701ad88d,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-b685fc41-ba76-4f70-9858-187e2ac5089d,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-201b1b25-b457-4181-adc0-0de17495fa99,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-98e3b1e5-c672-4e42-9ec8-4c466a31e3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601392385-172.17.0.13-1597698146346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40490,DS-075281d4-b436-456e-b2fb-b57cd500a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-46d18dce-9653-4aa5-ad3f-64e20c2951e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-2159d718-5f78-43bd-8f9c-116320d44218,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-86a187be-361a-4ee7-b476-30fb07fa8cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-a5303dd8-13b8-47a4-9c78-5ce8701ad88d,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-b685fc41-ba76-4f70-9858-187e2ac5089d,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-201b1b25-b457-4181-adc0-0de17495fa99,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-98e3b1e5-c672-4e42-9ec8-4c466a31e3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397515587-172.17.0.13-1597698409217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-9282fe6b-ef8a-40ac-a3df-324e67a1c096,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-1696f70e-2a58-4dfe-87d6-a0bacfe1e588,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-08d7fa43-5f0b-4cb8-8f24-7ba6fe1b7234,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-1d7bbf6f-f135-463b-a62a-5db35ae03654,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-7d2074af-30fd-4a48-9904-f597f5469d54,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-6829485c-7c7b-4e33-b759-37f67d40062e,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-f46f2fc2-f16b-4700-b4e7-34f4e1c8f219,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-3a5d4609-6daf-49bf-97cb-94a61c635250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397515587-172.17.0.13-1597698409217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-9282fe6b-ef8a-40ac-a3df-324e67a1c096,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-1696f70e-2a58-4dfe-87d6-a0bacfe1e588,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-08d7fa43-5f0b-4cb8-8f24-7ba6fe1b7234,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-1d7bbf6f-f135-463b-a62a-5db35ae03654,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-7d2074af-30fd-4a48-9904-f597f5469d54,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-6829485c-7c7b-4e33-b759-37f67d40062e,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-f46f2fc2-f16b-4700-b4e7-34f4e1c8f219,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-3a5d4609-6daf-49bf-97cb-94a61c635250,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5519
