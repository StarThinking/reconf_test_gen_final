reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137463904-172.17.0.3-1597378071347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-51d3278c-c5f6-45d1-8bfd-f4f6570cbe04,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-98ea2797-7e89-4445-ab31-0baf9bb03d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-362605b4-7eb7-4a9c-b6bd-18ff0a160457,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-bcd1e6bb-d7ba-4083-8744-76918253050f,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-603f4578-715c-46ed-bbdf-4642e21bb453,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-667d4290-3a74-43c5-b7ff-f32e4a326f06,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-99b7aefa-8e9b-42c0-8e16-8ca730e6892a,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-5af6f316-a01c-428a-9ee1-f02f8eea25db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137463904-172.17.0.3-1597378071347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-51d3278c-c5f6-45d1-8bfd-f4f6570cbe04,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-98ea2797-7e89-4445-ab31-0baf9bb03d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-362605b4-7eb7-4a9c-b6bd-18ff0a160457,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-bcd1e6bb-d7ba-4083-8744-76918253050f,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-603f4578-715c-46ed-bbdf-4642e21bb453,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-667d4290-3a74-43c5-b7ff-f32e4a326f06,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-99b7aefa-8e9b-42c0-8e16-8ca730e6892a,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-5af6f316-a01c-428a-9ee1-f02f8eea25db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982911076-172.17.0.3-1597378266719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-26dfdf6a-3dec-4fa1-8b7a-29d2a53a4564,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-5133bc63-4728-409b-aa2a-272608012656,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-3db9aa49-c7cd-4b9c-94e0-55daac0bd07b,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-f40d6d50-8ab8-469d-acd2-e8195d97c470,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-f58d3e15-2260-4622-8d59-e6794b3b32a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-9125958b-c76d-47f3-9f9d-dcb8a65f5b65,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-85654f00-8f34-4dd0-987d-1fe6daa60380,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-de1b6a17-86e7-454a-b254-4f364cf11517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982911076-172.17.0.3-1597378266719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-26dfdf6a-3dec-4fa1-8b7a-29d2a53a4564,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-5133bc63-4728-409b-aa2a-272608012656,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-3db9aa49-c7cd-4b9c-94e0-55daac0bd07b,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-f40d6d50-8ab8-469d-acd2-e8195d97c470,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-f58d3e15-2260-4622-8d59-e6794b3b32a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-9125958b-c76d-47f3-9f9d-dcb8a65f5b65,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-85654f00-8f34-4dd0-987d-1fe6daa60380,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-de1b6a17-86e7-454a-b254-4f364cf11517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390664019-172.17.0.3-1597379077438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36025,DS-8119a92a-0f31-48fd-8937-ab38781e5bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-b254d6bb-a7d2-49c6-abec-9961bccc91df,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-388a2c22-1a91-4603-baa2-67293a887022,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-304034f7-c36e-43b0-a99f-7bebb5d6ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-9f4aa4d7-b48b-4aeb-babe-b07794260f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-716ee68d-68ed-4883-b17a-99787e0c6bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-02ea751a-fe8a-4e8b-b8fa-91c85e3e28a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-7b786bb9-4346-4292-ac95-e67d54c8f2b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390664019-172.17.0.3-1597379077438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36025,DS-8119a92a-0f31-48fd-8937-ab38781e5bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-b254d6bb-a7d2-49c6-abec-9961bccc91df,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-388a2c22-1a91-4603-baa2-67293a887022,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-304034f7-c36e-43b0-a99f-7bebb5d6ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-9f4aa4d7-b48b-4aeb-babe-b07794260f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-716ee68d-68ed-4883-b17a-99787e0c6bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-02ea751a-fe8a-4e8b-b8fa-91c85e3e28a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-7b786bb9-4346-4292-ac95-e67d54c8f2b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487449848-172.17.0.3-1597379275248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34964,DS-a854c3b4-035e-47b5-b311-474596555942,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-f8eed92e-1778-4371-8f09-6bf507f5451f,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-0dcc4310-ee61-4640-896d-854801645d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-593340c1-c3de-44f3-ad13-7a295b3d1296,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-1985be69-8421-44a2-9eaf-ca2d70b868f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-3b1a7d07-593a-4941-bd60-601a755efbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-944fa47c-6686-466c-afcb-52baa148b4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-75adc564-a083-4eaf-99c8-dca49a602942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487449848-172.17.0.3-1597379275248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34964,DS-a854c3b4-035e-47b5-b311-474596555942,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-f8eed92e-1778-4371-8f09-6bf507f5451f,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-0dcc4310-ee61-4640-896d-854801645d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-593340c1-c3de-44f3-ad13-7a295b3d1296,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-1985be69-8421-44a2-9eaf-ca2d70b868f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-3b1a7d07-593a-4941-bd60-601a755efbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-944fa47c-6686-466c-afcb-52baa148b4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-75adc564-a083-4eaf-99c8-dca49a602942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219178358-172.17.0.3-1597379504146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33413,DS-6ecc42e3-9774-42f0-86eb-d0a790f24ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-9ef9806f-f4aa-4d53-9920-58eb01287ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-b759e6c7-4b7f-4efd-b068-03e5a6b7f68a,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-4c3dddb9-79e3-4fc8-b9ba-5d6df465bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-9ceb5acd-4fa9-4283-bd2a-3c7cb5715545,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-467785bd-952a-4add-a96d-e8c1ce582f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-bd15bbc8-853b-4a7a-9fad-c0bc590f15d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-1fd5c69b-ec70-4a7d-afc9-57484ca344d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219178358-172.17.0.3-1597379504146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33413,DS-6ecc42e3-9774-42f0-86eb-d0a790f24ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-9ef9806f-f4aa-4d53-9920-58eb01287ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-b759e6c7-4b7f-4efd-b068-03e5a6b7f68a,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-4c3dddb9-79e3-4fc8-b9ba-5d6df465bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-9ceb5acd-4fa9-4283-bd2a-3c7cb5715545,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-467785bd-952a-4add-a96d-e8c1ce582f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-bd15bbc8-853b-4a7a-9fad-c0bc590f15d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-1fd5c69b-ec70-4a7d-afc9-57484ca344d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838589233-172.17.0.3-1597380521259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45969,DS-74fdc2c3-a537-4a0b-92ed-bce8a6fa8c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-203863da-e451-403d-a130-b9b17401e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-535cc39b-ddab-44b9-85df-0717634a12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-59e6b3b4-e37f-4608-be11-62bbb1cc0e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-f5a50d32-7ae6-4d9c-9ce3-e5b8d7b911bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-8f2604d7-1e36-4c8a-a05a-721d9c16583a,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-904b536c-3551-4974-af07-3ffb6aae5ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-e9379764-af91-4847-a36d-3fd9734043b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838589233-172.17.0.3-1597380521259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45969,DS-74fdc2c3-a537-4a0b-92ed-bce8a6fa8c26,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-203863da-e451-403d-a130-b9b17401e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-535cc39b-ddab-44b9-85df-0717634a12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-59e6b3b4-e37f-4608-be11-62bbb1cc0e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-f5a50d32-7ae6-4d9c-9ce3-e5b8d7b911bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-8f2604d7-1e36-4c8a-a05a-721d9c16583a,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-904b536c-3551-4974-af07-3ffb6aae5ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-e9379764-af91-4847-a36d-3fd9734043b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127948740-172.17.0.3-1597381088703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32778,DS-0f6e1fab-4492-40b5-ae63-a66ada345bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-c2e95c80-c0a7-4eeb-9033-981cf8f9ea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-ee4958ce-7fb4-42b2-b07d-98acbcc7dae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-2663c437-070a-4a43-9a70-75234de89c71,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-2845c0b9-b040-4d77-913b-f2af8660467d,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-09d27d39-5b0a-4ed4-9d34-677a1a695591,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-7a26456c-8e76-4333-a262-1921c16e58d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-33c0be5c-b6c6-44f6-afa8-aae25c5bfdca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127948740-172.17.0.3-1597381088703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32778,DS-0f6e1fab-4492-40b5-ae63-a66ada345bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-c2e95c80-c0a7-4eeb-9033-981cf8f9ea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-ee4958ce-7fb4-42b2-b07d-98acbcc7dae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-2663c437-070a-4a43-9a70-75234de89c71,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-2845c0b9-b040-4d77-913b-f2af8660467d,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-09d27d39-5b0a-4ed4-9d34-677a1a695591,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-7a26456c-8e76-4333-a262-1921c16e58d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-33c0be5c-b6c6-44f6-afa8-aae25c5bfdca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716439950-172.17.0.3-1597381489480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41500,DS-7dbecce3-469d-44ff-a449-473a473ef569,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-6d3ded1f-a5b0-468c-b1d0-ff9964b01f60,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-87fbf16f-f818-483e-bf16-0aac6f50fef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-b49eade7-faa7-4cd4-be33-47e3cb165abb,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-36667456-6f83-4921-837c-77f93a1d964a,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-5212203d-0948-4d62-ae2c-b3c9287c57cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-8b0a4c00-6e2f-42d0-876d-5082da411f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-fed8dab2-823d-4854-b341-6d408c84e5cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716439950-172.17.0.3-1597381489480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41500,DS-7dbecce3-469d-44ff-a449-473a473ef569,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-6d3ded1f-a5b0-468c-b1d0-ff9964b01f60,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-87fbf16f-f818-483e-bf16-0aac6f50fef2,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-b49eade7-faa7-4cd4-be33-47e3cb165abb,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-36667456-6f83-4921-837c-77f93a1d964a,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-5212203d-0948-4d62-ae2c-b3c9287c57cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-8b0a4c00-6e2f-42d0-876d-5082da411f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-fed8dab2-823d-4854-b341-6d408c84e5cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363658037-172.17.0.3-1597381532639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34841,DS-30c1039a-eb87-4224-a402-624e6515ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-cfaee04b-c0f9-44da-b82b-37cd1510fac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-2e3f9833-8493-481a-8aaf-5c22edcbcd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-0e0f9941-409d-4614-bb8a-384d2d0de165,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-d5d9b3c2-9f4a-4fec-801a-811566733c32,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-277226fc-f508-4a0d-a617-97b95aa6c3be,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-74afb208-e8a2-4de2-9b47-1389dbc24ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-bdbfe79c-0c0b-486a-b9e1-a07cc63dfce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363658037-172.17.0.3-1597381532639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34841,DS-30c1039a-eb87-4224-a402-624e6515ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-cfaee04b-c0f9-44da-b82b-37cd1510fac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-2e3f9833-8493-481a-8aaf-5c22edcbcd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-0e0f9941-409d-4614-bb8a-384d2d0de165,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-d5d9b3c2-9f4a-4fec-801a-811566733c32,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-277226fc-f508-4a0d-a617-97b95aa6c3be,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-74afb208-e8a2-4de2-9b47-1389dbc24ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-bdbfe79c-0c0b-486a-b9e1-a07cc63dfce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971390554-172.17.0.3-1597381836295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40248,DS-fe805150-7a8f-4d40-b2cd-85e0723ada52,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-9bc382c9-8a7c-4060-9ad9-20baa6bcb57c,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-cf5e3fcb-b9d8-4d1c-ad05-f818eb1ba4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-0d6a901b-98dc-4f5e-bda6-22fbc55f298f,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-846fa094-a197-4a05-8cc1-e61c15a8ef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-ec9f7593-1129-4474-ae40-060a866e9c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-628b4150-a134-478d-a4b9-6a7e8c4f526e,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-8e4db387-3d59-46ae-90b2-29fe614d6f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971390554-172.17.0.3-1597381836295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40248,DS-fe805150-7a8f-4d40-b2cd-85e0723ada52,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-9bc382c9-8a7c-4060-9ad9-20baa6bcb57c,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-cf5e3fcb-b9d8-4d1c-ad05-f818eb1ba4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-0d6a901b-98dc-4f5e-bda6-22fbc55f298f,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-846fa094-a197-4a05-8cc1-e61c15a8ef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-ec9f7593-1129-4474-ae40-060a866e9c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-628b4150-a134-478d-a4b9-6a7e8c4f526e,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-8e4db387-3d59-46ae-90b2-29fe614d6f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927833233-172.17.0.3-1597382017054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42353,DS-f8cb6f3a-0e6b-44e5-a5ac-b0dec0667756,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-fbc61b0c-a7ee-4999-a42e-fc5c4e7a9905,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-3d1f034e-c8d7-420f-bd77-a2fbfd730b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-09d4028a-87f1-462c-9852-98ff4e809075,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-4888eaea-b147-43db-bdbc-551e7d280626,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-f072c051-8e3a-4a02-9ceb-aeba69ada1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-0f05fc4b-7ad4-43dd-b5ec-52245c4dbe4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-c5b9412e-6891-41a8-af9d-88ac5eeded8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927833233-172.17.0.3-1597382017054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42353,DS-f8cb6f3a-0e6b-44e5-a5ac-b0dec0667756,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-fbc61b0c-a7ee-4999-a42e-fc5c4e7a9905,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-3d1f034e-c8d7-420f-bd77-a2fbfd730b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-09d4028a-87f1-462c-9852-98ff4e809075,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-4888eaea-b147-43db-bdbc-551e7d280626,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-f072c051-8e3a-4a02-9ceb-aeba69ada1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-0f05fc4b-7ad4-43dd-b5ec-52245c4dbe4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-c5b9412e-6891-41a8-af9d-88ac5eeded8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396296948-172.17.0.3-1597382692505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37776,DS-71ad4bf2-d743-4fc7-9ff1-5cb9da54b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-4d2d50cd-10a2-40e9-be77-b041f222888f,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-fe5c5c4b-cf93-41b9-b75f-ba9be274a371,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-b3726f0e-9594-4091-9901-309cb59e8286,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-88c62475-3459-495a-83af-82cd01c2c40b,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-ad50c2de-9a60-42d7-ad85-7011ae2fc697,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-808f68a1-c11d-4acc-91dc-b0ad49b30e19,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-f2a45dd6-fdc4-47bc-aa9c-59f7ed58f91a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396296948-172.17.0.3-1597382692505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37776,DS-71ad4bf2-d743-4fc7-9ff1-5cb9da54b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-4d2d50cd-10a2-40e9-be77-b041f222888f,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-fe5c5c4b-cf93-41b9-b75f-ba9be274a371,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-b3726f0e-9594-4091-9901-309cb59e8286,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-88c62475-3459-495a-83af-82cd01c2c40b,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-ad50c2de-9a60-42d7-ad85-7011ae2fc697,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-808f68a1-c11d-4acc-91dc-b0ad49b30e19,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-f2a45dd6-fdc4-47bc-aa9c-59f7ed58f91a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019410841-172.17.0.3-1597383644125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46716,DS-cb288105-7a50-40f8-8d02-557f2144e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-af508caa-c2d1-44f0-bd9e-5923babd8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-770095fb-89c0-4544-85c6-dea387c5e561,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-f9721c0a-841a-43d6-a447-fc40c05b9d71,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-39672a4b-1ec0-4c47-94fc-80acc5832ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-2a8c6b1c-32a6-4345-9b64-ca73f94ef3de,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-79fd47e9-67a6-407c-ab23-d3fd4c824fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-5356ec7f-65b1-45b2-8246-437e5c4cce0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019410841-172.17.0.3-1597383644125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46716,DS-cb288105-7a50-40f8-8d02-557f2144e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-af508caa-c2d1-44f0-bd9e-5923babd8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-770095fb-89c0-4544-85c6-dea387c5e561,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-f9721c0a-841a-43d6-a447-fc40c05b9d71,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-39672a4b-1ec0-4c47-94fc-80acc5832ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-2a8c6b1c-32a6-4345-9b64-ca73f94ef3de,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-79fd47e9-67a6-407c-ab23-d3fd4c824fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-5356ec7f-65b1-45b2-8246-437e5c4cce0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505750843-172.17.0.3-1597383777202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-3a65c070-6f74-4451-98d3-c34c21841235,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-d35308d5-aeb4-47e5-84c9-6d15b8ada5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-7555431e-9c89-41dc-b526-c948c2180cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-2cf0a135-04f8-49e8-b31d-8a7a5fcf8703,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-93e634b4-9b50-413b-b7a5-80095b42ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-841b63b3-07a4-4c16-8bd2-46b0bdef4607,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-4233262c-59ec-4496-b324-d7e876c1c09e,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-d36ec480-bd96-48fe-ae32-730ff3b40367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505750843-172.17.0.3-1597383777202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-3a65c070-6f74-4451-98d3-c34c21841235,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-d35308d5-aeb4-47e5-84c9-6d15b8ada5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-7555431e-9c89-41dc-b526-c948c2180cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-2cf0a135-04f8-49e8-b31d-8a7a5fcf8703,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-93e634b4-9b50-413b-b7a5-80095b42ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-841b63b3-07a4-4c16-8bd2-46b0bdef4607,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-4233262c-59ec-4496-b324-d7e876c1c09e,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-d36ec480-bd96-48fe-ae32-730ff3b40367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716491695-172.17.0.3-1597383817072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44262,DS-3822e685-459f-4032-b50b-bbdc20ee8416,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-91a9a731-e6bf-428c-87c4-cb043e1b86a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-8b62cf84-999a-42b2-a476-736fb7723fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-8f1137ad-a15a-43a9-b24e-8dc1e48ceba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-d785684e-ccd8-4158-8795-ea39374d7de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-cae61fce-74ae-4879-a57d-15ca84dc0b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-0e9e10c2-2eda-4f0a-9908-0872ace6e306,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-f13b4d27-fd4d-4c24-a6f0-3b258d6bde9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716491695-172.17.0.3-1597383817072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44262,DS-3822e685-459f-4032-b50b-bbdc20ee8416,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-91a9a731-e6bf-428c-87c4-cb043e1b86a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-8b62cf84-999a-42b2-a476-736fb7723fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-8f1137ad-a15a-43a9-b24e-8dc1e48ceba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-d785684e-ccd8-4158-8795-ea39374d7de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-cae61fce-74ae-4879-a57d-15ca84dc0b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-0e9e10c2-2eda-4f0a-9908-0872ace6e306,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-f13b4d27-fd4d-4c24-a6f0-3b258d6bde9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328349387-172.17.0.3-1597384175569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38202,DS-617b668e-f96f-4bca-ac8e-94bd7daf1d86,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-414a863c-15e2-4d98-acc3-0f7f483a56ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-facd50eb-bbdd-48f1-ae90-c4010989dea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-53e4fdc6-789e-4184-a714-672d791ff872,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-35d4b54d-7117-41e0-b752-8f89d89a0967,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-3dcad05e-3307-4b11-b476-cc4b7b7c4795,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-118cdbaf-6546-4ce0-8650-aad9278f034d,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-3da78975-2961-4cab-a284-52d5bf121f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328349387-172.17.0.3-1597384175569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38202,DS-617b668e-f96f-4bca-ac8e-94bd7daf1d86,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-414a863c-15e2-4d98-acc3-0f7f483a56ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-facd50eb-bbdd-48f1-ae90-c4010989dea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-53e4fdc6-789e-4184-a714-672d791ff872,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-35d4b54d-7117-41e0-b752-8f89d89a0967,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-3dcad05e-3307-4b11-b476-cc4b7b7c4795,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-118cdbaf-6546-4ce0-8650-aad9278f034d,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-3da78975-2961-4cab-a284-52d5bf121f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599041799-172.17.0.3-1597384483673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38579,DS-14e3c16a-343e-470c-8f4b-2b229ccd7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-41176b1a-56fa-499d-9cd5-1dd01402f3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-99767859-a506-4d66-af26-e79b16ba49fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-13bd88a8-f83c-4072-9a44-fac0e515ffea,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-e7c50218-17d1-4b3a-9389-3054e100eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-cc5fd385-1a3d-4bdf-aac5-34f1eece2874,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-61401e11-f012-4e6f-a653-b05d1ef064d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-4a9506ac-2135-4c27-99e9-9d2df269a2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599041799-172.17.0.3-1597384483673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38579,DS-14e3c16a-343e-470c-8f4b-2b229ccd7da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-41176b1a-56fa-499d-9cd5-1dd01402f3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-99767859-a506-4d66-af26-e79b16ba49fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-13bd88a8-f83c-4072-9a44-fac0e515ffea,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-e7c50218-17d1-4b3a-9389-3054e100eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-cc5fd385-1a3d-4bdf-aac5-34f1eece2874,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-61401e11-f012-4e6f-a653-b05d1ef064d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-4a9506ac-2135-4c27-99e9-9d2df269a2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739333238-172.17.0.3-1597384762264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35564,DS-0a381390-0b5c-49ab-886c-864d3f102b51,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-c53da4fd-e360-4485-a63e-1501d5a69bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-275d9403-3c1e-451c-b554-95f9edeaf22a,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-eea2be94-d525-4f61-b718-942a67063c71,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-690a8396-9845-4908-9a6d-6fddc1faf164,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-af05d179-85f3-4548-9527-dfd9add070f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-9dd11428-b18a-4f3f-b01a-e13e6dabfa62,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-05c91483-a6af-414c-8068-d34023fb8601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739333238-172.17.0.3-1597384762264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35564,DS-0a381390-0b5c-49ab-886c-864d3f102b51,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-c53da4fd-e360-4485-a63e-1501d5a69bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-275d9403-3c1e-451c-b554-95f9edeaf22a,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-eea2be94-d525-4f61-b718-942a67063c71,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-690a8396-9845-4908-9a6d-6fddc1faf164,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-af05d179-85f3-4548-9527-dfd9add070f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-9dd11428-b18a-4f3f-b01a-e13e6dabfa62,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-05c91483-a6af-414c-8068-d34023fb8601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6819
