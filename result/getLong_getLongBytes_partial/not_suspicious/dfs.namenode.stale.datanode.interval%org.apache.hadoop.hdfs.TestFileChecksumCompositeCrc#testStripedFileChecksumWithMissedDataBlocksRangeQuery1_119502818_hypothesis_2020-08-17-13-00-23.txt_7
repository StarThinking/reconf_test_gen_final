reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124503861-172.17.0.12-1597669276840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38281,DS-1df15593-4319-4a01-9eee-ee17065b9f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-428f724d-97cb-4ebd-a562-20730a677ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-2afc2416-4d53-4088-8b73-6c26504835ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-23aa5f9a-7db3-4765-b1df-da1f9167779c,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-1da72e50-548e-4fba-8dbb-17c5fba37e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-5e2fa9d2-8645-45b8-8835-2e7b40fc354b,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-8a8b05e5-c85a-4f74-86d2-7c2d7e29c132,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-21241cb5-9a3a-4f8b-b87d-796b78b09b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124503861-172.17.0.12-1597669276840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38281,DS-1df15593-4319-4a01-9eee-ee17065b9f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-428f724d-97cb-4ebd-a562-20730a677ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-2afc2416-4d53-4088-8b73-6c26504835ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-23aa5f9a-7db3-4765-b1df-da1f9167779c,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-1da72e50-548e-4fba-8dbb-17c5fba37e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-5e2fa9d2-8645-45b8-8835-2e7b40fc354b,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-8a8b05e5-c85a-4f74-86d2-7c2d7e29c132,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-21241cb5-9a3a-4f8b-b87d-796b78b09b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390604424-172.17.0.12-1597669377479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40059,DS-8f929ac4-4028-4046-8f8d-f9fd9c38f4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-b37d5a5a-354c-4d03-b9e9-850897b625f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-623ea810-e74d-4095-b086-d7cc7e12f5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-5272bd2d-afb8-45b2-bdf7-cf59f1ef51f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-da6f1cd1-fece-4199-9d92-747aed8d77d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-eecfd7e6-b1b8-4e22-ae11-e2de680bbf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-8a676ce0-6387-4dd0-a757-90f49c56a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-aee92b15-18f5-469b-8e0f-0ae2a3424131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390604424-172.17.0.12-1597669377479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40059,DS-8f929ac4-4028-4046-8f8d-f9fd9c38f4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-b37d5a5a-354c-4d03-b9e9-850897b625f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-623ea810-e74d-4095-b086-d7cc7e12f5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-5272bd2d-afb8-45b2-bdf7-cf59f1ef51f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-da6f1cd1-fece-4199-9d92-747aed8d77d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-eecfd7e6-b1b8-4e22-ae11-e2de680bbf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-8a676ce0-6387-4dd0-a757-90f49c56a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-aee92b15-18f5-469b-8e0f-0ae2a3424131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209775007-172.17.0.12-1597669746019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-91f46fe9-764c-4d79-a08c-07232d5a1dea,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-7ce43c9c-f80e-4fae-ba4c-396ef36c7008,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-3675fbe1-9b42-4640-bf30-26b87d2ea5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-e0fc09cd-1bd8-43c7-86d4-e746604eeb03,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-9277ad46-298b-4501-850f-7c92abae1fba,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-896ac525-cd61-4f7c-977d-e1475780a23f,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-6acea653-5a93-4baa-901a-61209cc803f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-64694180-846d-4394-9872-22734e00420f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209775007-172.17.0.12-1597669746019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-91f46fe9-764c-4d79-a08c-07232d5a1dea,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-7ce43c9c-f80e-4fae-ba4c-396ef36c7008,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-3675fbe1-9b42-4640-bf30-26b87d2ea5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-e0fc09cd-1bd8-43c7-86d4-e746604eeb03,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-9277ad46-298b-4501-850f-7c92abae1fba,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-896ac525-cd61-4f7c-977d-e1475780a23f,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-6acea653-5a93-4baa-901a-61209cc803f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-64694180-846d-4394-9872-22734e00420f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780893143-172.17.0.12-1597670515375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-ac1f8d52-9ae8-45b8-a06d-c86b73d574bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-a5cc5ef2-8e34-4733-bec2-5c3ab3298aae,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-977c3548-544b-4397-9af3-b5badf6ac085,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-f9d20fee-cdb4-470d-92d9-d7472bedbaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-94ccb935-925f-4a1e-9f17-0b39b34812c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-0eb42c6e-273e-4a02-b46a-b7f59cfce4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-7826cc09-60e3-4237-9ce2-c39af7219b69,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-dabf43f8-9cbf-4b3d-b229-527d0a47faac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780893143-172.17.0.12-1597670515375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-ac1f8d52-9ae8-45b8-a06d-c86b73d574bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-a5cc5ef2-8e34-4733-bec2-5c3ab3298aae,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-977c3548-544b-4397-9af3-b5badf6ac085,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-f9d20fee-cdb4-470d-92d9-d7472bedbaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-94ccb935-925f-4a1e-9f17-0b39b34812c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-0eb42c6e-273e-4a02-b46a-b7f59cfce4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-7826cc09-60e3-4237-9ce2-c39af7219b69,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-dabf43f8-9cbf-4b3d-b229-527d0a47faac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666052860-172.17.0.12-1597671103664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45754,DS-967f71c2-03a3-4b11-822f-82a67a45eda8,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-568e17a6-d807-45fc-91a5-c7e032804386,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-1b5d5c6d-fc29-4132-9594-0eafa9f75618,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-7e2600f1-9503-46b6-8552-ee35faab84cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-04cff993-9220-455d-a09b-9b772a4d9d82,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-1a418d19-c589-439f-b686-903397948432,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-cfb72dd9-5d40-4959-8012-96dacac4fda2,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-59c25611-8604-4f23-b572-755f9d914fce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666052860-172.17.0.12-1597671103664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45754,DS-967f71c2-03a3-4b11-822f-82a67a45eda8,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-568e17a6-d807-45fc-91a5-c7e032804386,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-1b5d5c6d-fc29-4132-9594-0eafa9f75618,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-7e2600f1-9503-46b6-8552-ee35faab84cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-04cff993-9220-455d-a09b-9b772a4d9d82,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-1a418d19-c589-439f-b686-903397948432,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-cfb72dd9-5d40-4959-8012-96dacac4fda2,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-59c25611-8604-4f23-b572-755f9d914fce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269572632-172.17.0.12-1597671301378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-97f53ed4-05ca-4f5d-9410-484dc1240561,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-d0b7f0e5-41ad-401a-a7c5-c2e9b232451f,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-88c8c8d0-4532-4f35-8112-7b8825ad7fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-ca33b79d-caf2-4632-b66a-171f86456812,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-24412860-005a-4206-8870-b7613f4ea75a,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-33784e50-36dc-4c80-8333-e5dbe675115a,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-7c4d36ff-44de-40f9-a294-1152f8a895d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-c95427e0-ed07-4f45-a5e9-29364eaf08bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269572632-172.17.0.12-1597671301378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-97f53ed4-05ca-4f5d-9410-484dc1240561,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-d0b7f0e5-41ad-401a-a7c5-c2e9b232451f,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-88c8c8d0-4532-4f35-8112-7b8825ad7fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-ca33b79d-caf2-4632-b66a-171f86456812,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-24412860-005a-4206-8870-b7613f4ea75a,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-33784e50-36dc-4c80-8333-e5dbe675115a,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-7c4d36ff-44de-40f9-a294-1152f8a895d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-c95427e0-ed07-4f45-a5e9-29364eaf08bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844381862-172.17.0.12-1597671380844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39977,DS-38a2d04f-1520-4d5c-8618-b1ed267c572e,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-0f9a3bf7-f8e5-4406-8696-19e46d44e0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-89a2e682-3466-4161-98bb-8dd303bd100f,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-b8c4684b-f368-4b24-81ee-bd1ce037f947,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-78897397-7682-45a6-a731-ce111b3ac622,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-46fcbea4-c543-4daa-9a25-809f1c37efb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-2799673d-1359-4696-bee7-33189b9c5f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-60d1619a-1b67-43a3-bc83-4d358bb96f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844381862-172.17.0.12-1597671380844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39977,DS-38a2d04f-1520-4d5c-8618-b1ed267c572e,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-0f9a3bf7-f8e5-4406-8696-19e46d44e0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-89a2e682-3466-4161-98bb-8dd303bd100f,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-b8c4684b-f368-4b24-81ee-bd1ce037f947,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-78897397-7682-45a6-a731-ce111b3ac622,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-46fcbea4-c543-4daa-9a25-809f1c37efb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-2799673d-1359-4696-bee7-33189b9c5f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-60d1619a-1b67-43a3-bc83-4d358bb96f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448371817-172.17.0.12-1597671603048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-a19807c2-532c-42ad-a468-5cc5ad3ab6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-68763ca1-c4b2-49b4-8bb6-295be44ecd22,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-3befa1c7-7673-4c3e-86d0-440e8b9ff7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-b36bc4ad-84ae-4e31-8604-e7dbb106972f,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-9ca88a56-addd-4230-80c7-774d1a30603d,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-c1673c0f-713f-41ee-9210-1586effd0e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-caabc136-ecdd-483f-ab4e-e9413caab371,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-c1fbfa8f-cd04-4290-a0de-162e1cd0fcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448371817-172.17.0.12-1597671603048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-a19807c2-532c-42ad-a468-5cc5ad3ab6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-68763ca1-c4b2-49b4-8bb6-295be44ecd22,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-3befa1c7-7673-4c3e-86d0-440e8b9ff7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-b36bc4ad-84ae-4e31-8604-e7dbb106972f,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-9ca88a56-addd-4230-80c7-774d1a30603d,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-c1673c0f-713f-41ee-9210-1586effd0e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-caabc136-ecdd-483f-ab4e-e9413caab371,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-c1fbfa8f-cd04-4290-a0de-162e1cd0fcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049891843-172.17.0.12-1597671689328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34073,DS-f3c59da3-c34f-475d-a94a-e49240d12456,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-c9bd2421-1536-4bca-9e0f-7689b2d302c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-3aa01762-b667-4010-afee-28601f2cfa89,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-6251c69c-5f79-405e-80bb-604bc72b82a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-0554a019-a6a9-4bd8-b41f-51d79bbd5c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-73dbc92a-5e7f-44fe-b249-72d97c2fae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5b980979-8b8d-482e-819f-ae236155551c,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-5c7d094e-dc51-4c0d-9550-a20b9283e7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049891843-172.17.0.12-1597671689328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34073,DS-f3c59da3-c34f-475d-a94a-e49240d12456,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-c9bd2421-1536-4bca-9e0f-7689b2d302c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-3aa01762-b667-4010-afee-28601f2cfa89,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-6251c69c-5f79-405e-80bb-604bc72b82a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-0554a019-a6a9-4bd8-b41f-51d79bbd5c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-73dbc92a-5e7f-44fe-b249-72d97c2fae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5b980979-8b8d-482e-819f-ae236155551c,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-5c7d094e-dc51-4c0d-9550-a20b9283e7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651877451-172.17.0.12-1597672437993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-a9c36e8a-df1d-40d2-8b29-7bbf363ba10c,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-2d8dda45-2035-45bd-98cb-d67046c449b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-fc9720b8-1032-48e9-aee0-a43f6f30c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-86b3316a-d678-41f2-9e6c-4719d2dd4ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-3a49cfa7-2b91-4e04-9086-7a7144d9db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-ab89acca-cc8e-41d1-a6a6-97c03d449efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-406ec2e0-748c-4e93-8560-0b3a1e80cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-9d60f8e8-3786-4d79-bd76-faaefbd94af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651877451-172.17.0.12-1597672437993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-a9c36e8a-df1d-40d2-8b29-7bbf363ba10c,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-2d8dda45-2035-45bd-98cb-d67046c449b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-fc9720b8-1032-48e9-aee0-a43f6f30c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-86b3316a-d678-41f2-9e6c-4719d2dd4ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-3a49cfa7-2b91-4e04-9086-7a7144d9db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-ab89acca-cc8e-41d1-a6a6-97c03d449efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-406ec2e0-748c-4e93-8560-0b3a1e80cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-9d60f8e8-3786-4d79-bd76-faaefbd94af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880995412-172.17.0.12-1597672666978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-ebad1d3d-afb4-4289-8f22-f739e456eaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-d6d3185b-e5bf-4a1e-81b3-e7032bacb876,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-d8c1c2b7-43ec-44c2-8baa-211d5959a8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-115ea83b-9b64-49ff-aa3e-702efc1dc699,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-ec7f0631-8620-4eef-8edc-7e1d43565c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-806f2c03-a331-4588-8422-f09eee9a8e83,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-c3906625-136c-4587-adcd-8b6aac56de19,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-08280a16-e452-46dd-876c-3ef73dff7a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880995412-172.17.0.12-1597672666978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-ebad1d3d-afb4-4289-8f22-f739e456eaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-d6d3185b-e5bf-4a1e-81b3-e7032bacb876,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-d8c1c2b7-43ec-44c2-8baa-211d5959a8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-115ea83b-9b64-49ff-aa3e-702efc1dc699,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-ec7f0631-8620-4eef-8edc-7e1d43565c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-806f2c03-a331-4588-8422-f09eee9a8e83,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-c3906625-136c-4587-adcd-8b6aac56de19,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-08280a16-e452-46dd-876c-3ef73dff7a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680532489-172.17.0.12-1597672768573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-b99181e5-e7a0-479b-bd02-1b77861d114d,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-ad682369-175b-4c85-9639-b887ddae55ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-8010e841-6127-412f-9807-0bbcc36f8a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-0a4829d0-8d79-4485-bc50-c1d338fe6171,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1095b14f-524b-4cb3-a1c8-d3833a40f1af,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-908a57cc-27fd-4ace-b2a0-23c2cb89b840,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-af760409-9a06-44d7-b477-f041d65c9e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-bc1cb7f0-e283-42fb-a010-1d892082f1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680532489-172.17.0.12-1597672768573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-b99181e5-e7a0-479b-bd02-1b77861d114d,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-ad682369-175b-4c85-9639-b887ddae55ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-8010e841-6127-412f-9807-0bbcc36f8a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-0a4829d0-8d79-4485-bc50-c1d338fe6171,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1095b14f-524b-4cb3-a1c8-d3833a40f1af,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-908a57cc-27fd-4ace-b2a0-23c2cb89b840,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-af760409-9a06-44d7-b477-f041d65c9e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-bc1cb7f0-e283-42fb-a010-1d892082f1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572488249-172.17.0.12-1597673518853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46303,DS-c0e46de1-6315-4460-88b1-320602bc5027,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-a4a1ce15-400c-4811-91ad-86ad45860c11,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-6b062f7a-f97d-43b1-ac87-57300bbfd472,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-e2950818-5484-4bb2-9912-df93dc2870b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-37005611-28f7-45b2-a520-1791e276668d,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-45ad7338-affd-4d00-b6b0-cf50dc3d4825,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-fea52f13-7f25-47a9-9845-ec7a72359805,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-94353d52-7191-40bf-ac82-9d9c3b61cfe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572488249-172.17.0.12-1597673518853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46303,DS-c0e46de1-6315-4460-88b1-320602bc5027,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-a4a1ce15-400c-4811-91ad-86ad45860c11,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-6b062f7a-f97d-43b1-ac87-57300bbfd472,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-e2950818-5484-4bb2-9912-df93dc2870b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-37005611-28f7-45b2-a520-1791e276668d,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-45ad7338-affd-4d00-b6b0-cf50dc3d4825,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-fea52f13-7f25-47a9-9845-ec7a72359805,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-94353d52-7191-40bf-ac82-9d9c3b61cfe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277216183-172.17.0.12-1597673565646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39908,DS-3c998f3f-2b52-48a8-b6c9-5e400030ec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-3a87eaf0-5e9e-4c14-9ccc-38eda9d72237,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-ec85bf49-29ef-471f-9dba-d1e03af99225,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-dc9a89db-7413-4496-97b6-105c754a8f56,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-cce85dac-43e0-4b84-90f4-938fa9ab33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-63d84ded-0d33-4386-ac1e-ff0d2f4fe3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d2a552f1-590e-445b-b6db-49cb98ca7c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-eb62af12-7205-49a6-844f-5efceb987cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277216183-172.17.0.12-1597673565646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39908,DS-3c998f3f-2b52-48a8-b6c9-5e400030ec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-3a87eaf0-5e9e-4c14-9ccc-38eda9d72237,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-ec85bf49-29ef-471f-9dba-d1e03af99225,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-dc9a89db-7413-4496-97b6-105c754a8f56,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-cce85dac-43e0-4b84-90f4-938fa9ab33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-63d84ded-0d33-4386-ac1e-ff0d2f4fe3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d2a552f1-590e-445b-b6db-49cb98ca7c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-eb62af12-7205-49a6-844f-5efceb987cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057916213-172.17.0.12-1597673615599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-23aeafcd-4ad5-46b3-ac1e-edc9607fa866,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-23360c37-c32b-4333-801c-07a2ddbe526f,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-aae6fad8-36fe-4acb-b848-d766dcb92adf,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-1c7fa858-22cf-4270-a665-b15fe1df33c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-cb8b9786-4945-4adc-928b-cdb14507b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-2fcab555-05ee-47ab-8004-8d8c2a43ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-f9232b6e-72c0-4d03-955f-b80c9eecdd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-3e482699-0c52-49db-be59-164e63144a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057916213-172.17.0.12-1597673615599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-23aeafcd-4ad5-46b3-ac1e-edc9607fa866,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-23360c37-c32b-4333-801c-07a2ddbe526f,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-aae6fad8-36fe-4acb-b848-d766dcb92adf,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-1c7fa858-22cf-4270-a665-b15fe1df33c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-cb8b9786-4945-4adc-928b-cdb14507b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-2fcab555-05ee-47ab-8004-8d8c2a43ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-f9232b6e-72c0-4d03-955f-b80c9eecdd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-3e482699-0c52-49db-be59-164e63144a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019037890-172.17.0.12-1597673653286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-ad22ecd1-d741-4bfc-b2c5-6c0e435f8f41,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-38759717-6c78-4506-8196-36008500a307,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-d4ad5ebf-1a5b-42b8-bcef-4f0f6bfddd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-8a373ef8-67a6-4fd2-82bb-fefd4d267612,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-4fc34657-b2e5-4f8a-a50b-59cfb664c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-04465de8-cd7e-4a8a-b50c-debc1ca5a07d,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-9224e8fb-fc7e-4292-9c99-053449aae559,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-360562aa-dab1-45a4-b801-fb6a7e9aa9e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019037890-172.17.0.12-1597673653286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-ad22ecd1-d741-4bfc-b2c5-6c0e435f8f41,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-38759717-6c78-4506-8196-36008500a307,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-d4ad5ebf-1a5b-42b8-bcef-4f0f6bfddd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-8a373ef8-67a6-4fd2-82bb-fefd4d267612,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-4fc34657-b2e5-4f8a-a50b-59cfb664c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-04465de8-cd7e-4a8a-b50c-debc1ca5a07d,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-9224e8fb-fc7e-4292-9c99-053449aae559,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-360562aa-dab1-45a4-b801-fb6a7e9aa9e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698480748-172.17.0.12-1597674422807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40590,DS-78b138a1-36b1-4c13-9753-b8e875101b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-487df5ff-af36-4193-8af4-b1fcfbc6c598,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-f12b9acc-2bc4-4400-8995-af820369793f,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-08349b65-d3b9-46e8-aa45-9e19db93b254,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-d9e575c7-d8eb-4cb0-926d-d4e92800081a,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-04c9fb9d-3948-4953-93c4-043d77a54469,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-09e4ece0-b2eb-412e-bd43-79203b778679,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-21347552-e8e3-4d59-8078-69aee85ba8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698480748-172.17.0.12-1597674422807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40590,DS-78b138a1-36b1-4c13-9753-b8e875101b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-487df5ff-af36-4193-8af4-b1fcfbc6c598,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-f12b9acc-2bc4-4400-8995-af820369793f,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-08349b65-d3b9-46e8-aa45-9e19db93b254,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-d9e575c7-d8eb-4cb0-926d-d4e92800081a,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-04c9fb9d-3948-4953-93c4-043d77a54469,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-09e4ece0-b2eb-412e-bd43-79203b778679,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-21347552-e8e3-4d59-8078-69aee85ba8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443250292-172.17.0.12-1597674531464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-d8d68d90-5661-4637-a81c-60c270096a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-24e45bdb-5d8b-48a4-acae-8b0b39f417b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-76fe016e-991b-4210-b87d-f8f20a23c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-f907eeed-eeb1-429e-9105-4d352ec78e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-d133a047-b333-42b8-9eed-58377455baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-0fde5cbc-2c04-46a2-8839-efbc5a964498,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-07716211-3488-4a34-a676-88e8a4f1e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-d9956056-7b24-4207-aa9a-25c4a9abea95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443250292-172.17.0.12-1597674531464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-d8d68d90-5661-4637-a81c-60c270096a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-24e45bdb-5d8b-48a4-acae-8b0b39f417b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-76fe016e-991b-4210-b87d-f8f20a23c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-f907eeed-eeb1-429e-9105-4d352ec78e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-d133a047-b333-42b8-9eed-58377455baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-0fde5cbc-2c04-46a2-8839-efbc5a964498,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-07716211-3488-4a34-a676-88e8a4f1e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-d9956056-7b24-4207-aa9a-25c4a9abea95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827475515-172.17.0.12-1597674668677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-f87d1110-92da-453a-865c-d9393d0aff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-a394ddeb-961d-45cc-b9f3-111be7fa2cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-a88d206b-fcf7-4d69-abf7-71598f8a5a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-2c2dd4cb-f724-4150-ae59-b4bc90bbbe49,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-0aa2a16f-cf75-438e-8603-2ee9f79246d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-b16ce437-d29b-4de0-981d-d793aa415989,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-79e52dce-7e0c-447c-a70c-c62e73e7bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-3e6321d4-ef04-4a44-9f07-0afb08454c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827475515-172.17.0.12-1597674668677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-f87d1110-92da-453a-865c-d9393d0aff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-a394ddeb-961d-45cc-b9f3-111be7fa2cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-a88d206b-fcf7-4d69-abf7-71598f8a5a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-2c2dd4cb-f724-4150-ae59-b4bc90bbbe49,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-0aa2a16f-cf75-438e-8603-2ee9f79246d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-b16ce437-d29b-4de0-981d-d793aa415989,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-79e52dce-7e0c-447c-a70c-c62e73e7bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-3e6321d4-ef04-4a44-9f07-0afb08454c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355029170-172.17.0.12-1597674719227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-64312acf-688b-4ee0-b1f3-2bf89bbefd76,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-22efc69c-ec0e-48d4-89d2-93df21b540fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-c21448a7-7f48-4562-ac8c-82ea1bfeb2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-84821338-bd7a-4e4c-92a2-bacc87cf0542,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-eaf2a20f-1a97-4463-b9a6-9bd2f781c1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-8f54b3a8-7f85-4f66-978e-cf1b25015b73,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-4ec43986-0757-4b06-889b-027a5f627c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-4cbf01aa-0240-4427-be7b-4e07d94d991a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355029170-172.17.0.12-1597674719227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-64312acf-688b-4ee0-b1f3-2bf89bbefd76,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-22efc69c-ec0e-48d4-89d2-93df21b540fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-c21448a7-7f48-4562-ac8c-82ea1bfeb2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-84821338-bd7a-4e4c-92a2-bacc87cf0542,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-eaf2a20f-1a97-4463-b9a6-9bd2f781c1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-8f54b3a8-7f85-4f66-978e-cf1b25015b73,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-4ec43986-0757-4b06-889b-027a5f627c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-4cbf01aa-0240-4427-be7b-4e07d94d991a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511731306-172.17.0.12-1597675335751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-4a33fda9-6206-412d-9e7c-4fc93fba9ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-aea7b511-c32d-4059-a174-f4cdfbcd744a,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-2a8b4d65-3d02-4f92-9331-b41f127e70f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-1375194e-455d-42ec-816a-fc2b356b9d00,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-ec2ea4d5-9b30-43a8-bfaf-d6e11ae8732c,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-4c1bce6c-1d8d-4ae7-9e3c-1504be0e94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-1f7e06bf-3e1c-4dcb-9863-3d6bb131801b,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-4adf8a1d-7def-4585-ac52-d5f1da33f574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511731306-172.17.0.12-1597675335751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-4a33fda9-6206-412d-9e7c-4fc93fba9ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-aea7b511-c32d-4059-a174-f4cdfbcd744a,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-2a8b4d65-3d02-4f92-9331-b41f127e70f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-1375194e-455d-42ec-816a-fc2b356b9d00,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-ec2ea4d5-9b30-43a8-bfaf-d6e11ae8732c,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-4c1bce6c-1d8d-4ae7-9e3c-1504be0e94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-1f7e06bf-3e1c-4dcb-9863-3d6bb131801b,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-4adf8a1d-7def-4585-ac52-d5f1da33f574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488768470-172.17.0.12-1597675491030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35627,DS-20c88614-ea2c-41a2-bcce-fc29f62eeec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-641fc7df-737a-4dfb-af90-3e335c87c743,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-ba64d925-cb36-406c-814f-97fe0d27904f,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-49358304-8217-40d8-a1a2-61bc8ec66722,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-39a2bae6-8806-4db0-acf4-1b0a81968fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-06213f61-9501-4929-bf47-7226c36f1a24,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-b1c42bdc-d7b5-4ec4-8997-86e89d86f356,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-a4163829-d1ab-476e-a0c7-e7c65fb84242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488768470-172.17.0.12-1597675491030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35627,DS-20c88614-ea2c-41a2-bcce-fc29f62eeec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-641fc7df-737a-4dfb-af90-3e335c87c743,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-ba64d925-cb36-406c-814f-97fe0d27904f,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-49358304-8217-40d8-a1a2-61bc8ec66722,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-39a2bae6-8806-4db0-acf4-1b0a81968fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-06213f61-9501-4929-bf47-7226c36f1a24,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-b1c42bdc-d7b5-4ec4-8997-86e89d86f356,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-a4163829-d1ab-476e-a0c7-e7c65fb84242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258736707-172.17.0.12-1597675532715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44421,DS-352b6d1f-6cc9-498b-8d0b-3eb9314182be,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-9bc71289-363d-47d8-b95c-609d627b7f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-b03c59d1-2fac-4cb5-9390-e87c7cfd1137,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-dff7db19-3f98-4ced-a424-ba356971f670,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-361e24f8-4404-4f0f-8d81-3c1c5c4fbca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-fc3b81bd-0bb1-47f2-96a3-6cde549cb059,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-c502e14e-a255-448c-bdab-375bb9060eed,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-6da4ada8-8407-4d3f-b491-7a34e951f605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258736707-172.17.0.12-1597675532715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44421,DS-352b6d1f-6cc9-498b-8d0b-3eb9314182be,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-9bc71289-363d-47d8-b95c-609d627b7f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-b03c59d1-2fac-4cb5-9390-e87c7cfd1137,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-dff7db19-3f98-4ced-a424-ba356971f670,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-361e24f8-4404-4f0f-8d81-3c1c5c4fbca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-fc3b81bd-0bb1-47f2-96a3-6cde549cb059,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-c502e14e-a255-448c-bdab-375bb9060eed,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-6da4ada8-8407-4d3f-b491-7a34e951f605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 300000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228926083-172.17.0.12-1597675909642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-1b3f1195-90ea-4a51-931c-ed0a9cde2e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-9e86d73e-48d7-4707-a0f5-eece729d7502,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-77bf5af2-1c28-452e-8ea1-abc9c0c8c722,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-5fcf62b3-f61d-4829-b339-a5d5cf4b699b,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-e73f2b22-2dcf-4276-b2f7-c5488b6bb899,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-4c20d1eb-6f74-463a-89d9-e76faffddfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-74213a01-49d4-424a-bbd8-cf9dd4f3b8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-0b1f5394-f9e5-4eaa-8707-269d23f621b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228926083-172.17.0.12-1597675909642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-1b3f1195-90ea-4a51-931c-ed0a9cde2e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-9e86d73e-48d7-4707-a0f5-eece729d7502,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-77bf5af2-1c28-452e-8ea1-abc9c0c8c722,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-5fcf62b3-f61d-4829-b339-a5d5cf4b699b,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-e73f2b22-2dcf-4276-b2f7-c5488b6bb899,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-4c20d1eb-6f74-463a-89d9-e76faffddfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-74213a01-49d4-424a-bbd8-cf9dd4f3b8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-0b1f5394-f9e5-4eaa-8707-269d23f621b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6836
