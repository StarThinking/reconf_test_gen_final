reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635552777-172.17.0.3-1597712911973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-6599e4f7-f67e-44fb-8d72-47748cc6c62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-b18bf300-6705-43c3-bc5e-767526ef37c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-2ada1d52-110b-49f8-8b89-579f6ddb2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-67413faa-e11a-4764-ad08-c0d2d582784b,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-3236477c-72c9-42a5-9241-9cbd05f5b892,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-51de3e73-3f31-4ac4-a85d-2186a3fbd548,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-6ac83ef7-a464-416b-8f81-6fc38ea5aca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-4ba7159c-ff19-4922-8305-ef2994c99314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635552777-172.17.0.3-1597712911973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-6599e4f7-f67e-44fb-8d72-47748cc6c62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-b18bf300-6705-43c3-bc5e-767526ef37c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-2ada1d52-110b-49f8-8b89-579f6ddb2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-67413faa-e11a-4764-ad08-c0d2d582784b,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-3236477c-72c9-42a5-9241-9cbd05f5b892,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-51de3e73-3f31-4ac4-a85d-2186a3fbd548,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-6ac83ef7-a464-416b-8f81-6fc38ea5aca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-4ba7159c-ff19-4922-8305-ef2994c99314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889836118-172.17.0.3-1597713042462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-f95a1d6e-d492-4147-9990-c9d51ecb4bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-beacbeba-f370-4a74-9e01-cc399d8b27ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-34f9317e-8cd1-4264-a893-c8dad2b707b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-5171369c-d6bf-40a2-9204-c0ef05988f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-79210160-8d31-4dba-af7e-19ee4f6dc921,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-63a108b2-bae5-4d9b-9028-13e3a2e2de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-d2540c37-2ae3-4fd2-b1af-ce57e366f870,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-5471cff4-56f8-4816-bf50-cb7813fbda9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889836118-172.17.0.3-1597713042462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-f95a1d6e-d492-4147-9990-c9d51ecb4bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-beacbeba-f370-4a74-9e01-cc399d8b27ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-34f9317e-8cd1-4264-a893-c8dad2b707b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-5171369c-d6bf-40a2-9204-c0ef05988f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-79210160-8d31-4dba-af7e-19ee4f6dc921,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-63a108b2-bae5-4d9b-9028-13e3a2e2de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-d2540c37-2ae3-4fd2-b1af-ce57e366f870,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-5471cff4-56f8-4816-bf50-cb7813fbda9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127508280-172.17.0.3-1597713159499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-cc246018-cc09-4e9f-a119-76bcada824ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-ce67f137-a72a-44e9-9663-b620c56e152d,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-eb007045-996c-48bf-a9a7-926901f8e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-23744a46-d849-4937-a599-1ecae1b6dbde,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-0ec2bebe-fccf-40b3-bf63-054facc5ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-6eae2b16-c1b5-4fbd-930d-e55a69f86d53,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-0eec4d11-253f-4adc-bb77-4bb342edaf88,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-184c59af-1623-4078-9a75-deb0919401d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127508280-172.17.0.3-1597713159499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-cc246018-cc09-4e9f-a119-76bcada824ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-ce67f137-a72a-44e9-9663-b620c56e152d,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-eb007045-996c-48bf-a9a7-926901f8e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-23744a46-d849-4937-a599-1ecae1b6dbde,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-0ec2bebe-fccf-40b3-bf63-054facc5ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-6eae2b16-c1b5-4fbd-930d-e55a69f86d53,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-0eec4d11-253f-4adc-bb77-4bb342edaf88,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-184c59af-1623-4078-9a75-deb0919401d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858855788-172.17.0.3-1597713619731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40912,DS-514e5cc6-8492-45f2-a24f-d85c805506c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-593644cb-6258-41b5-8e37-278026a5f5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-aeb6b5d8-58df-4b5f-86a8-484e252706fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-5191fe96-2abe-405e-8952-d82b6828f419,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-ac6f4700-b327-4d0b-984a-2cef895dda4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-128b1682-0d8b-4807-82a8-5a455de5c384,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-f0baa9c3-21f7-4c17-895d-993433ca01f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-7fea93e4-145f-46ea-94d3-f1b76798c960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858855788-172.17.0.3-1597713619731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40912,DS-514e5cc6-8492-45f2-a24f-d85c805506c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-593644cb-6258-41b5-8e37-278026a5f5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-aeb6b5d8-58df-4b5f-86a8-484e252706fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-5191fe96-2abe-405e-8952-d82b6828f419,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-ac6f4700-b327-4d0b-984a-2cef895dda4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-128b1682-0d8b-4807-82a8-5a455de5c384,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-f0baa9c3-21f7-4c17-895d-993433ca01f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-7fea93e4-145f-46ea-94d3-f1b76798c960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676945753-172.17.0.3-1597713744203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-beeb150c-1136-4f66-8b09-9825c3ea6471,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-5770c07a-de64-482e-9ef5-f9cb2870e716,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-75b1234a-ea50-4d77-910e-b999e7b86de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-76a78a97-eb87-44a1-8c6a-9bedee063ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-e16c7994-40b3-4c42-88cc-3d0f6ef1cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-26071fe8-bf72-40e4-95d2-30e630665a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-4e548500-110f-4ca9-a020-f1edfb8462a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-300b9de7-dd5c-4117-a3bb-48db496de939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676945753-172.17.0.3-1597713744203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-beeb150c-1136-4f66-8b09-9825c3ea6471,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-5770c07a-de64-482e-9ef5-f9cb2870e716,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-75b1234a-ea50-4d77-910e-b999e7b86de0,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-76a78a97-eb87-44a1-8c6a-9bedee063ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-e16c7994-40b3-4c42-88cc-3d0f6ef1cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-26071fe8-bf72-40e4-95d2-30e630665a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-4e548500-110f-4ca9-a020-f1edfb8462a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-300b9de7-dd5c-4117-a3bb-48db496de939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616641054-172.17.0.3-1597713792270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-26d3e128-3c25-4db1-928e-559cd133076f,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-e207b2fd-c2f4-4315-ae08-06402cca8d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-be717296-0540-46ea-9bf8-412828d51fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-795a4185-4a74-4f31-b38c-f957c6befed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-c345ac1e-631d-4962-a699-6fc3a2ad77b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-0b8c8ecb-39f9-46b6-bcfd-9377ac0adc99,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-4a385ce3-a3c1-4ad1-a8df-b63ff6c9de6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-d620bb70-f30e-47c2-8292-4db5011e562b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616641054-172.17.0.3-1597713792270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-26d3e128-3c25-4db1-928e-559cd133076f,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-e207b2fd-c2f4-4315-ae08-06402cca8d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-be717296-0540-46ea-9bf8-412828d51fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-795a4185-4a74-4f31-b38c-f957c6befed5,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-c345ac1e-631d-4962-a699-6fc3a2ad77b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-0b8c8ecb-39f9-46b6-bcfd-9377ac0adc99,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-4a385ce3-a3c1-4ad1-a8df-b63ff6c9de6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-d620bb70-f30e-47c2-8292-4db5011e562b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943358210-172.17.0.3-1597714282591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37515,DS-2966c6f2-9ec7-41a5-b25c-d80f789d4e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-84ed5c33-cb09-4dd9-b534-90520ce0484b,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-08ecc7bb-ccae-423e-b334-eacd958924a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-6b0a6c7f-aa6c-43e7-8faa-8ad42a82a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-1dd81edd-9c36-4ff0-b058-4894480f6b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-cd70a20d-7e61-47c1-b201-4f5c665ddd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-57111280-bbc8-493b-a9e6-d83d0a8cb710,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-a4d9b149-5953-4247-a564-e46fe81173b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943358210-172.17.0.3-1597714282591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37515,DS-2966c6f2-9ec7-41a5-b25c-d80f789d4e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-84ed5c33-cb09-4dd9-b534-90520ce0484b,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-08ecc7bb-ccae-423e-b334-eacd958924a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-6b0a6c7f-aa6c-43e7-8faa-8ad42a82a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-1dd81edd-9c36-4ff0-b058-4894480f6b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-cd70a20d-7e61-47c1-b201-4f5c665ddd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-57111280-bbc8-493b-a9e6-d83d0a8cb710,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-a4d9b149-5953-4247-a564-e46fe81173b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027954777-172.17.0.3-1597714327045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33643,DS-ec1444bf-0ef4-474d-8a91-eda10a61abe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-9ff66629-1b80-4b39-9a9f-ec0dd3bcec45,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-7ee50505-31eb-4878-a683-a493cfa16a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-ba76d9d4-6642-4215-b5c1-b91e51954c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-4b567959-fdf0-4ecf-abde-e4fd6af77853,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-02ff8e39-4087-4e3d-8b6f-a9e9d136ad69,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-c12649c5-1f9e-4353-bb65-1833e1f9d863,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-4754b719-0930-4b62-9497-b33df694b4e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027954777-172.17.0.3-1597714327045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33643,DS-ec1444bf-0ef4-474d-8a91-eda10a61abe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-9ff66629-1b80-4b39-9a9f-ec0dd3bcec45,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-7ee50505-31eb-4878-a683-a493cfa16a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-ba76d9d4-6642-4215-b5c1-b91e51954c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-4b567959-fdf0-4ecf-abde-e4fd6af77853,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-02ff8e39-4087-4e3d-8b6f-a9e9d136ad69,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-c12649c5-1f9e-4353-bb65-1833e1f9d863,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-4754b719-0930-4b62-9497-b33df694b4e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100184438-172.17.0.3-1597714369678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-9fbb3b38-5225-48b8-a518-2a2b47a406e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-eb161acb-6f04-416c-8a29-31b8be323795,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-fcfdd675-7a8a-4fa5-a041-09bcc9ccc9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-5e48f5b9-b00a-401d-a11b-3bf41d0c8227,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-362c54b7-ca9e-4885-b530-3b6d52a8f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-107550e2-b376-42e2-b3e7-5decf87d53ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-1eb0dfc7-40e0-4fd4-820c-c09c9a9574de,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-fb15f9c1-dc9e-4d1b-a34e-5e6d83b6d03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100184438-172.17.0.3-1597714369678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-9fbb3b38-5225-48b8-a518-2a2b47a406e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-eb161acb-6f04-416c-8a29-31b8be323795,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-fcfdd675-7a8a-4fa5-a041-09bcc9ccc9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-5e48f5b9-b00a-401d-a11b-3bf41d0c8227,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-362c54b7-ca9e-4885-b530-3b6d52a8f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-107550e2-b376-42e2-b3e7-5decf87d53ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-1eb0dfc7-40e0-4fd4-820c-c09c9a9574de,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-fb15f9c1-dc9e-4d1b-a34e-5e6d83b6d03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600062951-172.17.0.3-1597714757189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41368,DS-62c1d3a3-4a30-47f5-93a3-22a632a5a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-bf12494e-12a5-4806-bf00-08853f14354c,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-53fccab5-73d5-4ca9-bc54-a9e43785d579,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-6e8ca72d-80ae-44f5-9112-517535b2d7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-4f70a78a-cadc-4edb-80bd-d342f4cafb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-68025a81-39d5-4c1a-8dd8-88f6b2abd2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-1da0ad94-4966-4d64-9967-be34a22e8e40,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-ce764b6a-9c2d-4560-828e-4a3010ac79ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600062951-172.17.0.3-1597714757189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41368,DS-62c1d3a3-4a30-47f5-93a3-22a632a5a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-bf12494e-12a5-4806-bf00-08853f14354c,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-53fccab5-73d5-4ca9-bc54-a9e43785d579,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-6e8ca72d-80ae-44f5-9112-517535b2d7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-4f70a78a-cadc-4edb-80bd-d342f4cafb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-68025a81-39d5-4c1a-8dd8-88f6b2abd2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-1da0ad94-4966-4d64-9967-be34a22e8e40,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-ce764b6a-9c2d-4560-828e-4a3010ac79ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289993832-172.17.0.3-1597715200780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-c265c729-c70a-438d-977e-10c36d90dfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-2d6646cf-9d72-430f-9809-e297a65d02af,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-8247a311-25e6-4597-9582-ff799d883bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-85f0cc64-2b60-4265-beca-5fad2e745e59,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-2c231040-b7df-451c-93b3-21d84bf4c228,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-02db88e1-b42a-46d1-922a-d193ff1d5f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-2687b31f-5666-4137-bdbf-e55f7a0eea5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-7e968969-51ad-4737-a945-53c2b9adc01b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289993832-172.17.0.3-1597715200780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-c265c729-c70a-438d-977e-10c36d90dfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-2d6646cf-9d72-430f-9809-e297a65d02af,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-8247a311-25e6-4597-9582-ff799d883bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-85f0cc64-2b60-4265-beca-5fad2e745e59,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-2c231040-b7df-451c-93b3-21d84bf4c228,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-02db88e1-b42a-46d1-922a-d193ff1d5f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-2687b31f-5666-4137-bdbf-e55f7a0eea5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-7e968969-51ad-4737-a945-53c2b9adc01b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386399006-172.17.0.3-1597715274864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43032,DS-fca01d8c-185b-442f-84ec-bedcfddcf33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-208e4e0d-75c2-490a-ac0d-54b950888ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-e99eda74-0696-4f92-9fbf-1bf68741a528,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-3e837383-89e4-4c20-b9e8-1743c832a217,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-49985072-2383-4366-9368-86f37f2d21ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-01749b3c-b741-420d-82ee-083eadc5df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-8c281fa1-efb0-4873-8e9b-57a29463fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-043ec2c1-1e70-4005-895c-774ac1119a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386399006-172.17.0.3-1597715274864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43032,DS-fca01d8c-185b-442f-84ec-bedcfddcf33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-208e4e0d-75c2-490a-ac0d-54b950888ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-e99eda74-0696-4f92-9fbf-1bf68741a528,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-3e837383-89e4-4c20-b9e8-1743c832a217,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-49985072-2383-4366-9368-86f37f2d21ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-01749b3c-b741-420d-82ee-083eadc5df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-8c281fa1-efb0-4873-8e9b-57a29463fe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-043ec2c1-1e70-4005-895c-774ac1119a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968055140-172.17.0.3-1597715667156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40758,DS-da15d18a-0e0a-4d92-9dcc-7bdb6309ed52,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-9e65b776-f887-44cf-be04-d04b94b7dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-15ba2102-57c8-4d25-a165-99a0f8621bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-2cac73ea-5a46-445c-8126-a1da89d5a311,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-453643c1-1759-4313-9970-6731077a488a,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-b15476c4-cfbf-4a22-9e92-5157a0ef2366,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-e306e125-3a3a-4de1-bd3a-12b88440d855,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-6a561349-4323-4c4b-afa4-e792aebb841e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968055140-172.17.0.3-1597715667156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40758,DS-da15d18a-0e0a-4d92-9dcc-7bdb6309ed52,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-9e65b776-f887-44cf-be04-d04b94b7dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-15ba2102-57c8-4d25-a165-99a0f8621bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-2cac73ea-5a46-445c-8126-a1da89d5a311,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-453643c1-1759-4313-9970-6731077a488a,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-b15476c4-cfbf-4a22-9e92-5157a0ef2366,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-e306e125-3a3a-4de1-bd3a-12b88440d855,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-6a561349-4323-4c4b-afa4-e792aebb841e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795286832-172.17.0.3-1597715897557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-b0e00449-78b4-4773-b587-9472bc698960,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-1b8c270d-7ca5-40bd-b76f-4faa2232eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-262bf928-c219-4db6-8536-c16afe21faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-d201f660-82b9-4a96-8d1b-b14f5675d881,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-3ef571ce-3c0d-440b-bf0c-919810349026,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-6ed54d29-dc83-460d-acd2-adc3773111dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-6a1943dc-73e4-41f5-9518-942c9253f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-8e31bde8-46de-4eb7-adc0-b7a80a375828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795286832-172.17.0.3-1597715897557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-b0e00449-78b4-4773-b587-9472bc698960,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-1b8c270d-7ca5-40bd-b76f-4faa2232eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-262bf928-c219-4db6-8536-c16afe21faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-d201f660-82b9-4a96-8d1b-b14f5675d881,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-3ef571ce-3c0d-440b-bf0c-919810349026,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-6ed54d29-dc83-460d-acd2-adc3773111dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-6a1943dc-73e4-41f5-9518-942c9253f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-8e31bde8-46de-4eb7-adc0-b7a80a375828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549935379-172.17.0.3-1597716963474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-c12f66a0-ae61-47be-9497-e7bb24459d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-b8f34495-c080-4e4b-a2f3-d664a5d120e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-1ef5c378-f1ce-41bc-a5b3-bcdfa39f2b81,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-9613ad24-f231-45c0-a7da-91ec8557258d,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-67fd6289-4250-46f4-9e51-61f2d82bd48b,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-5fc012e2-772a-4056-93dc-b30b1a300737,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-ba4a0ca3-c81a-4e2a-98dc-88a9aa9f1994,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-35458933-4745-4159-8994-5332a0e657a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549935379-172.17.0.3-1597716963474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-c12f66a0-ae61-47be-9497-e7bb24459d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-b8f34495-c080-4e4b-a2f3-d664a5d120e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-1ef5c378-f1ce-41bc-a5b3-bcdfa39f2b81,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-9613ad24-f231-45c0-a7da-91ec8557258d,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-67fd6289-4250-46f4-9e51-61f2d82bd48b,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-5fc012e2-772a-4056-93dc-b30b1a300737,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-ba4a0ca3-c81a-4e2a-98dc-88a9aa9f1994,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-35458933-4745-4159-8994-5332a0e657a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696705060-172.17.0.3-1597717036834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-34c02c1f-7bb3-421c-87a6-1808175e9beb,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-62aa0d9c-1dba-4d92-a6dc-79e8268c0705,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-63b449a1-d3c9-4e3f-88bd-7cdee5ceecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-e4c2d5de-6b4c-4205-a0ac-eba04699e7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-b01531fd-f097-4a86-9ed6-0ba9d703caad,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-8029ad3f-7fb8-462d-a26b-c67bb6253c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-87931c27-724b-4b7f-acbc-0625207a6808,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-ec574c6b-68b7-4e0a-b253-43609b76b2c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696705060-172.17.0.3-1597717036834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-34c02c1f-7bb3-421c-87a6-1808175e9beb,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-62aa0d9c-1dba-4d92-a6dc-79e8268c0705,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-63b449a1-d3c9-4e3f-88bd-7cdee5ceecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-e4c2d5de-6b4c-4205-a0ac-eba04699e7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-b01531fd-f097-4a86-9ed6-0ba9d703caad,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-8029ad3f-7fb8-462d-a26b-c67bb6253c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-87931c27-724b-4b7f-acbc-0625207a6808,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-ec574c6b-68b7-4e0a-b253-43609b76b2c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285953036-172.17.0.3-1597717524931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-8bcd19e9-8a0b-4070-b993-54a3612ace6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-7ab42d54-4973-4dab-b1cb-c90f89bf46b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-c89b059d-635c-4079-9999-415fc511bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-286dd162-824a-4feb-b4b6-22c837bf7d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-92515c34-520d-408d-92aa-6e36527045dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-e03a1ad4-14b4-45a5-a95d-072317582bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-234f8a12-f571-4641-acc9-9be6d985fc75,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-9a00664d-62c9-4110-9e0b-770781f213a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285953036-172.17.0.3-1597717524931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-8bcd19e9-8a0b-4070-b993-54a3612ace6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-7ab42d54-4973-4dab-b1cb-c90f89bf46b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-c89b059d-635c-4079-9999-415fc511bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-286dd162-824a-4feb-b4b6-22c837bf7d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-92515c34-520d-408d-92aa-6e36527045dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-e03a1ad4-14b4-45a5-a95d-072317582bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-234f8a12-f571-4641-acc9-9be6d985fc75,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-9a00664d-62c9-4110-9e0b-770781f213a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99809920-172.17.0.3-1597718113692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-226ea667-6099-4233-b0f4-aeeb86570dde,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-bdcdaa4d-538a-4d32-a780-89868260e295,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-93b841af-f5ac-4a84-9313-066550aa7469,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-e624a5fd-91d3-419f-93db-17ca8b375896,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-01538490-0b73-481b-a60c-44940c36f691,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-74a2b640-0ca4-47d1-9f4d-8fc5e79ed003,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-12d0572e-6323-4252-8bf0-b247cb686c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-f888a508-7c18-4cd3-baf7-0eaded9548b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99809920-172.17.0.3-1597718113692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-226ea667-6099-4233-b0f4-aeeb86570dde,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-bdcdaa4d-538a-4d32-a780-89868260e295,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-93b841af-f5ac-4a84-9313-066550aa7469,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-e624a5fd-91d3-419f-93db-17ca8b375896,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-01538490-0b73-481b-a60c-44940c36f691,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-74a2b640-0ca4-47d1-9f4d-8fc5e79ed003,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-12d0572e-6323-4252-8bf0-b247cb686c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-f888a508-7c18-4cd3-baf7-0eaded9548b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5909
