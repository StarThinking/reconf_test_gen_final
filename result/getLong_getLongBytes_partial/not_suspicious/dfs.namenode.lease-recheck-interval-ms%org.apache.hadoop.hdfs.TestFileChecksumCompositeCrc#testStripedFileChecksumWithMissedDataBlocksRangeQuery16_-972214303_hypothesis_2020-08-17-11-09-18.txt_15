reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007891296-172.17.0.3-1597662834582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43050,DS-41a73ed0-033e-4b72-ae8c-4ac0940107c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-dabda735-5298-463b-a2e3-04b4e24e95b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-6e7c9ace-4bf7-460e-a551-247a7c08d314,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-28f5a1d7-8319-4e28-8835-733d2a4d4aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-856c2f21-138c-4855-b7f0-ad092400da1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-b22fdbd9-829c-4fa4-8007-0b0f71a00d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-4a01e305-c5e1-453e-8952-6c28b43949d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-be40d50d-92c1-4d53-9118-bc88689d7b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007891296-172.17.0.3-1597662834582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43050,DS-41a73ed0-033e-4b72-ae8c-4ac0940107c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-dabda735-5298-463b-a2e3-04b4e24e95b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-6e7c9ace-4bf7-460e-a551-247a7c08d314,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-28f5a1d7-8319-4e28-8835-733d2a4d4aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-856c2f21-138c-4855-b7f0-ad092400da1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-b22fdbd9-829c-4fa4-8007-0b0f71a00d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-4a01e305-c5e1-453e-8952-6c28b43949d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-be40d50d-92c1-4d53-9118-bc88689d7b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933321954-172.17.0.3-1597662912029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36754,DS-56ad2b09-19cf-4436-a21c-2e56b81fcd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-d9c414a8-e80b-4d18-a686-6c015cd4eb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-0fb500ec-a72e-45a2-b1b8-1c2fd63f13ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-06f16e97-ebd1-44b6-aa5d-122e0836d75b,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-8ebd5ee3-496a-470c-b489-b26a6acc40fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-14469b0a-517d-4c9a-80ff-ee6c476f7727,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-3cc44411-3c5b-456a-a797-439e041c3211,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-d71497dd-def1-4e26-809a-d25260f62856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933321954-172.17.0.3-1597662912029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36754,DS-56ad2b09-19cf-4436-a21c-2e56b81fcd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-d9c414a8-e80b-4d18-a686-6c015cd4eb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-0fb500ec-a72e-45a2-b1b8-1c2fd63f13ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-06f16e97-ebd1-44b6-aa5d-122e0836d75b,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-8ebd5ee3-496a-470c-b489-b26a6acc40fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-14469b0a-517d-4c9a-80ff-ee6c476f7727,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-3cc44411-3c5b-456a-a797-439e041c3211,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-d71497dd-def1-4e26-809a-d25260f62856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676467198-172.17.0.3-1597662946154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39048,DS-74e4af3f-72fb-4022-a4c0-041c0e3fe391,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-f8bea3a6-eddd-4e07-a52f-91a57c97048c,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-3e8f3d07-b1d3-4f25-9a04-24e07e55e6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-d8376d2c-c412-46ac-815e-8d89e0fbf663,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-ab6d529a-4372-4d44-8c75-e8668ace002a,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-b6d4c971-c0a2-4a84-b159-24b597bf1295,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-dacaa532-9226-4ad6-9421-ced19cc0abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-0c57aaf6-d133-47ba-9a02-22c36527ae93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676467198-172.17.0.3-1597662946154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39048,DS-74e4af3f-72fb-4022-a4c0-041c0e3fe391,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-f8bea3a6-eddd-4e07-a52f-91a57c97048c,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-3e8f3d07-b1d3-4f25-9a04-24e07e55e6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-d8376d2c-c412-46ac-815e-8d89e0fbf663,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-ab6d529a-4372-4d44-8c75-e8668ace002a,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-b6d4c971-c0a2-4a84-b159-24b597bf1295,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-dacaa532-9226-4ad6-9421-ced19cc0abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-0c57aaf6-d133-47ba-9a02-22c36527ae93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016422117-172.17.0.3-1597663239190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40804,DS-f5ce4e2a-eee0-44ed-8538-8a8580112e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-a6973a15-f4a5-45ff-85e0-22361fe71297,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-6b2f3feb-f8b3-4521-b2a2-a19e1c8ac178,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-a94af421-998b-4ec3-aacd-401b85c0fa30,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-47a3b37f-9b95-412c-b454-6ed3289e42b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-329d97fe-6a82-4065-881e-63d2ec627e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-a282cd82-c9c9-468b-b88f-32a9ff84bd03,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-3a3820e7-b580-410b-8e4e-3825aa1c57cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016422117-172.17.0.3-1597663239190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40804,DS-f5ce4e2a-eee0-44ed-8538-8a8580112e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-a6973a15-f4a5-45ff-85e0-22361fe71297,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-6b2f3feb-f8b3-4521-b2a2-a19e1c8ac178,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-a94af421-998b-4ec3-aacd-401b85c0fa30,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-47a3b37f-9b95-412c-b454-6ed3289e42b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-329d97fe-6a82-4065-881e-63d2ec627e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-a282cd82-c9c9-468b-b88f-32a9ff84bd03,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-3a3820e7-b580-410b-8e4e-3825aa1c57cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661219050-172.17.0.3-1597663373218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41168,DS-0e6c29ec-8434-4844-b91d-d94bf92f8976,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-e0085e9a-c134-483a-8459-ec3b0de7dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-5fdfd6ef-11d6-484c-9e2f-c0d3349de7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-c1fa2e27-a402-4430-8798-0cf8aff58712,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-e4e33d95-c04f-4aab-90ae-b6ad42e26104,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-3617a6ab-1e69-48ea-b888-7b4cf533364e,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-42598210-c3d1-4359-ac97-2d70e1df1122,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-9f7983eb-6711-4f4c-8421-60c48b74d17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661219050-172.17.0.3-1597663373218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41168,DS-0e6c29ec-8434-4844-b91d-d94bf92f8976,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-e0085e9a-c134-483a-8459-ec3b0de7dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-5fdfd6ef-11d6-484c-9e2f-c0d3349de7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-c1fa2e27-a402-4430-8798-0cf8aff58712,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-e4e33d95-c04f-4aab-90ae-b6ad42e26104,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-3617a6ab-1e69-48ea-b888-7b4cf533364e,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-42598210-c3d1-4359-ac97-2d70e1df1122,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-9f7983eb-6711-4f4c-8421-60c48b74d17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601716604-172.17.0.3-1597663625622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42102,DS-1257c889-3504-466b-b418-9f06cd6747d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-8ee94c37-19ed-489f-a2bd-5bd610f42040,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-0ed37269-883e-44d3-ae5f-dd5d3cc29a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-6aca68ee-7376-4b99-93b0-4854667e4288,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-28909c7b-dc7e-423a-b490-750fc8f16fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-0a0ddb04-3496-4319-853b-0e72be0c638e,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-692dd592-b99b-4cf9-b1f1-603e876c343d,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-125f8a77-df70-455b-a5b1-c952256e7539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601716604-172.17.0.3-1597663625622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42102,DS-1257c889-3504-466b-b418-9f06cd6747d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-8ee94c37-19ed-489f-a2bd-5bd610f42040,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-0ed37269-883e-44d3-ae5f-dd5d3cc29a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-6aca68ee-7376-4b99-93b0-4854667e4288,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-28909c7b-dc7e-423a-b490-750fc8f16fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-0a0ddb04-3496-4319-853b-0e72be0c638e,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-692dd592-b99b-4cf9-b1f1-603e876c343d,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-125f8a77-df70-455b-a5b1-c952256e7539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858122618-172.17.0.3-1597664298398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-5af5ee30-248f-4d5a-b45c-73941c3a0239,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-b2e0a559-ccf3-4460-a60e-445084cf34ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-af06c05c-1704-4aeb-9465-8324b03fd780,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-61d40aba-65aa-4c1b-89b4-2d847c30265f,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-a2739aad-7bca-4999-9cbe-3899a6e9fd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-39539c06-13ae-4555-974b-35ef07585244,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-7789ada1-b96c-494a-9814-f74607192301,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-5d257e1a-afa9-49b1-b463-7ffbf9507f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858122618-172.17.0.3-1597664298398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-5af5ee30-248f-4d5a-b45c-73941c3a0239,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-b2e0a559-ccf3-4460-a60e-445084cf34ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-af06c05c-1704-4aeb-9465-8324b03fd780,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-61d40aba-65aa-4c1b-89b4-2d847c30265f,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-a2739aad-7bca-4999-9cbe-3899a6e9fd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-39539c06-13ae-4555-974b-35ef07585244,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-7789ada1-b96c-494a-9814-f74607192301,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-5d257e1a-afa9-49b1-b463-7ffbf9507f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196161559-172.17.0.3-1597664521150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32817,DS-822f0afa-7f67-4dcc-b7c3-ec24bde7c451,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-a86f87ca-3a77-4c32-a7e0-74aa8688689e,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-88a1bb5d-1124-4913-a7ed-273db17679cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-4cc001d7-9635-4912-8151-d6320ca464eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-469122bc-59f0-4583-856c-6d73bf8e12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-ea85de76-8cc9-4d52-a6c7-d68d681d21bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-bbf7ad5c-1a82-42eb-96a4-21abad312626,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-e56e8128-1a8e-472a-b139-ffc8be656e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196161559-172.17.0.3-1597664521150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32817,DS-822f0afa-7f67-4dcc-b7c3-ec24bde7c451,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-a86f87ca-3a77-4c32-a7e0-74aa8688689e,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-88a1bb5d-1124-4913-a7ed-273db17679cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-4cc001d7-9635-4912-8151-d6320ca464eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-469122bc-59f0-4583-856c-6d73bf8e12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-ea85de76-8cc9-4d52-a6c7-d68d681d21bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-bbf7ad5c-1a82-42eb-96a4-21abad312626,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-e56e8128-1a8e-472a-b139-ffc8be656e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-399032546-172.17.0.3-1597665039194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-19633a9a-4826-4bc6-bf36-2faf71a38110,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-aa5e2b66-09eb-425a-bd7a-e0eafbea4ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-083ddc0e-188b-48c3-b4d2-05bee9517ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-28c5b8b5-551f-4d51-bbec-61f4f6d6c452,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-8c5c4c54-8958-4d1a-ba2f-d129503381cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-9fcd52e1-b664-45dd-aca9-7673a593a8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-766360dd-c0f9-4752-8ebb-05946e8e0813,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-496ace5a-2413-4925-a338-b8c687a66814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-399032546-172.17.0.3-1597665039194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-19633a9a-4826-4bc6-bf36-2faf71a38110,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-aa5e2b66-09eb-425a-bd7a-e0eafbea4ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-083ddc0e-188b-48c3-b4d2-05bee9517ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-28c5b8b5-551f-4d51-bbec-61f4f6d6c452,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-8c5c4c54-8958-4d1a-ba2f-d129503381cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-9fcd52e1-b664-45dd-aca9-7673a593a8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-766360dd-c0f9-4752-8ebb-05946e8e0813,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-496ace5a-2413-4925-a338-b8c687a66814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836456766-172.17.0.3-1597665078384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42810,DS-bd4db91f-5402-4414-aebe-7ba55b7b01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-c7fced2d-7aac-495a-aef8-575dd54c3566,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-1612d134-bc58-4c61-8ee4-dfb0b7611f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-cb08cc75-bae9-46de-bf32-527205f9cd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-4c403015-c3fc-47d9-b22d-015ec0a7bc08,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-ad869d43-656a-4c8a-af6a-73b2d293b5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-b786a365-5426-45d5-b1cf-a3e3259bc245,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-6618a6e6-03da-4ae0-b045-a324c9061c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836456766-172.17.0.3-1597665078384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42810,DS-bd4db91f-5402-4414-aebe-7ba55b7b01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-c7fced2d-7aac-495a-aef8-575dd54c3566,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-1612d134-bc58-4c61-8ee4-dfb0b7611f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-cb08cc75-bae9-46de-bf32-527205f9cd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-4c403015-c3fc-47d9-b22d-015ec0a7bc08,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-ad869d43-656a-4c8a-af6a-73b2d293b5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-b786a365-5426-45d5-b1cf-a3e3259bc245,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-6618a6e6-03da-4ae0-b045-a324c9061c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532680321-172.17.0.3-1597665117674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34166,DS-d9793b9a-3bf3-4506-9eee-9110734dbe47,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-33507339-833b-462a-97e8-4f891b9fde63,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-4e509c37-dad6-4c89-80a7-ef8b579812ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-c64153a3-5f8e-49b7-8587-2363d9446e27,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-88967c97-9c70-43a7-8fb9-d5b5e9092a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-2846fb1e-a33e-48dc-baa8-54196ac807d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-8a970d9b-9d09-484f-a0e1-a0ea24df0618,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-6e7e5ecc-1279-4183-af6f-b36c024fc542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532680321-172.17.0.3-1597665117674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34166,DS-d9793b9a-3bf3-4506-9eee-9110734dbe47,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-33507339-833b-462a-97e8-4f891b9fde63,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-4e509c37-dad6-4c89-80a7-ef8b579812ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-c64153a3-5f8e-49b7-8587-2363d9446e27,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-88967c97-9c70-43a7-8fb9-d5b5e9092a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-2846fb1e-a33e-48dc-baa8-54196ac807d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-8a970d9b-9d09-484f-a0e1-a0ea24df0618,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-6e7e5ecc-1279-4183-af6f-b36c024fc542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648774273-172.17.0.3-1597665661944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38842,DS-ae0f2ee8-293d-4d35-9acb-cf27526f82b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-e4493aef-01fc-4d31-b11c-69f5fdd6f9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-773b0666-952f-421d-a232-4412bee48beb,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-ab6f1fa8-18b3-450e-a5d7-9bee9403aa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-43fb771e-7d02-4b62-824d-f117f5004e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-c5e46574-d105-41b5-8e7f-41cbd05b1c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-420a6da9-4591-4999-8e02-7307990d8920,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-f1276aa0-ad59-4a2d-9a87-664f6743a0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648774273-172.17.0.3-1597665661944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38842,DS-ae0f2ee8-293d-4d35-9acb-cf27526f82b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-e4493aef-01fc-4d31-b11c-69f5fdd6f9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-773b0666-952f-421d-a232-4412bee48beb,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-ab6f1fa8-18b3-450e-a5d7-9bee9403aa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-43fb771e-7d02-4b62-824d-f117f5004e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-c5e46574-d105-41b5-8e7f-41cbd05b1c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-420a6da9-4591-4999-8e02-7307990d8920,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-f1276aa0-ad59-4a2d-9a87-664f6743a0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965561858-172.17.0.3-1597665859513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41676,DS-5f37e396-3f36-4d56-9833-859303ac09b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-a8bd0dc6-5614-483d-a02c-0cd64e5a4ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-a1020f76-61b5-47ce-b49e-70cba5bdd000,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-fbe745f2-d513-4f9f-b37e-9dc03a0db0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-7e22088e-0d14-4f88-910d-bcc13b9f1884,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-4e73e16e-5a6f-4988-acdb-f027f0c6e513,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-228890f4-a518-4a74-9b09-b5c1eb32883b,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-ab1e50f4-8af4-4fa4-88f4-cbcb18894b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965561858-172.17.0.3-1597665859513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41676,DS-5f37e396-3f36-4d56-9833-859303ac09b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-a8bd0dc6-5614-483d-a02c-0cd64e5a4ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-a1020f76-61b5-47ce-b49e-70cba5bdd000,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-fbe745f2-d513-4f9f-b37e-9dc03a0db0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-7e22088e-0d14-4f88-910d-bcc13b9f1884,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-4e73e16e-5a6f-4988-acdb-f027f0c6e513,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-228890f4-a518-4a74-9b09-b5c1eb32883b,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-ab1e50f4-8af4-4fa4-88f4-cbcb18894b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231923000-172.17.0.3-1597666259786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-127575b9-edd8-4f0e-aef9-ef2fd7124e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-f326739a-6012-49de-9c31-461629157d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-323d5b5e-a238-437e-a4af-570bb3e5f920,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-ff795f6b-6947-4bde-b64d-0ad0ab6ef745,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-2e515442-af1f-4c32-9ddd-e3c28d4585c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-20da2d4f-2c10-40aa-ba1a-1538a7429dea,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-fca404c0-1d3a-444f-845e-cef80edc16f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-9342f83a-9728-449f-a2cb-3c3fb1ea972f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231923000-172.17.0.3-1597666259786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-127575b9-edd8-4f0e-aef9-ef2fd7124e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-f326739a-6012-49de-9c31-461629157d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-323d5b5e-a238-437e-a4af-570bb3e5f920,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-ff795f6b-6947-4bde-b64d-0ad0ab6ef745,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-2e515442-af1f-4c32-9ddd-e3c28d4585c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-20da2d4f-2c10-40aa-ba1a-1538a7429dea,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-fca404c0-1d3a-444f-845e-cef80edc16f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-9342f83a-9728-449f-a2cb-3c3fb1ea972f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166395228-172.17.0.3-1597667230250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-0fe87048-a83c-4f01-8851-ff04a066196a,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-78d5e0de-3694-431b-adbc-0cc313c1d629,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-b383910f-bd7b-4c5f-90c6-99182b1996ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-5c59430d-3c2b-42f8-ac34-e0f03ed7376f,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-41530009-ff22-47fe-9cfd-d0bca9248ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-b37d1319-9757-4d08-a6eb-031a980dce2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-23117d15-bc89-4189-87cb-f1004e7b7771,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-47ab7a07-271f-46a5-832a-8f8144983c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166395228-172.17.0.3-1597667230250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-0fe87048-a83c-4f01-8851-ff04a066196a,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-78d5e0de-3694-431b-adbc-0cc313c1d629,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-b383910f-bd7b-4c5f-90c6-99182b1996ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-5c59430d-3c2b-42f8-ac34-e0f03ed7376f,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-41530009-ff22-47fe-9cfd-d0bca9248ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-b37d1319-9757-4d08-a6eb-031a980dce2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-23117d15-bc89-4189-87cb-f1004e7b7771,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-47ab7a07-271f-46a5-832a-8f8144983c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971351611-172.17.0.3-1597667808828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33035,DS-1f379487-8a96-4638-8eba-d4020f676898,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-29f8be0d-95b7-4fcd-9854-91af6653d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-29a7c896-5ea1-4d54-b274-f09fba5a69ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-1683e490-1d1e-4f56-aca4-dbcf180bc8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-e4d54be0-16af-4b4e-9bdd-82292c668ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-2454f7ec-abab-4b2f-bebd-929a30213e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-8ddbe6be-c0c6-4068-99b7-9219aefc2e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-67b69e6c-aa92-4827-bb1f-30e380295832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971351611-172.17.0.3-1597667808828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33035,DS-1f379487-8a96-4638-8eba-d4020f676898,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-29f8be0d-95b7-4fcd-9854-91af6653d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-29a7c896-5ea1-4d54-b274-f09fba5a69ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-1683e490-1d1e-4f56-aca4-dbcf180bc8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-e4d54be0-16af-4b4e-9bdd-82292c668ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-2454f7ec-abab-4b2f-bebd-929a30213e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-8ddbe6be-c0c6-4068-99b7-9219aefc2e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-67b69e6c-aa92-4827-bb1f-30e380295832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5595
