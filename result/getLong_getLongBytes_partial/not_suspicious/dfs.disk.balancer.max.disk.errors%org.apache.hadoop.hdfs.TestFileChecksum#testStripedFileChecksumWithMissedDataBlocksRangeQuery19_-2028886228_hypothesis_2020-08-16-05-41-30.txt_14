reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404098830-172.17.0.20-1597556618167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-984243d7-990e-467b-807b-b9b7959629de,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-e5e0863a-76cd-4115-b8e8-f3efa7176273,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-2db95e5c-a4ae-44bb-9249-4d97eb1c9271,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-4ce94d42-753a-49e1-9a49-f077dd5b17c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-e7e3e868-a9ea-4907-86a9-a19a430a6de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-1cd92956-9ee2-40a7-b6fc-f4776efbc2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-ee7d39db-e383-4f52-9391-e27c7b8fd8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-cc568648-8cbe-47e7-ba1b-42a42e89e172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404098830-172.17.0.20-1597556618167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-984243d7-990e-467b-807b-b9b7959629de,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-e5e0863a-76cd-4115-b8e8-f3efa7176273,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-2db95e5c-a4ae-44bb-9249-4d97eb1c9271,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-4ce94d42-753a-49e1-9a49-f077dd5b17c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-e7e3e868-a9ea-4907-86a9-a19a430a6de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-1cd92956-9ee2-40a7-b6fc-f4776efbc2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-ee7d39db-e383-4f52-9391-e27c7b8fd8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-cc568648-8cbe-47e7-ba1b-42a42e89e172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632626899-172.17.0.20-1597556651659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-a90cf4a0-245a-483e-8399-ba7e3e9438d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-1f59fd52-4b94-4630-9437-18ee81e25ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-98106384-cfb4-4c31-9c7f-d5376c831456,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-68f1a508-4b72-4ffd-8f4c-f4bb42e73e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-c3e92f70-e3d9-4b0e-a0b6-0a05544363b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-faff6bd6-eac7-4515-93c5-cc30f025dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-6cf989b5-2f14-4076-b611-7b87e1d23607,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-d21ac55f-11e3-4971-a92e-dcd97fb743ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632626899-172.17.0.20-1597556651659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-a90cf4a0-245a-483e-8399-ba7e3e9438d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-1f59fd52-4b94-4630-9437-18ee81e25ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-98106384-cfb4-4c31-9c7f-d5376c831456,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-68f1a508-4b72-4ffd-8f4c-f4bb42e73e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-c3e92f70-e3d9-4b0e-a0b6-0a05544363b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-faff6bd6-eac7-4515-93c5-cc30f025dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-6cf989b5-2f14-4076-b611-7b87e1d23607,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-d21ac55f-11e3-4971-a92e-dcd97fb743ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880153314-172.17.0.20-1597557146754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-1b51605f-e113-4109-81fc-e88392eb2055,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-e161ebbc-ab8c-4115-af4f-2373727ed068,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-0df23cba-df07-4afc-ab20-2b527160453b,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-2d06cf22-290d-4456-a441-ca579be4428c,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-3b4ea203-30f2-4623-acd8-d0a7c62fa32d,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-5e7a0521-3cef-4f05-9eed-4b1999ef88e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-20b3bbff-a325-44f8-a74b-b6182269a016,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-f54fac6e-07ed-47d8-9153-c23adda2c509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880153314-172.17.0.20-1597557146754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-1b51605f-e113-4109-81fc-e88392eb2055,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-e161ebbc-ab8c-4115-af4f-2373727ed068,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-0df23cba-df07-4afc-ab20-2b527160453b,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-2d06cf22-290d-4456-a441-ca579be4428c,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-3b4ea203-30f2-4623-acd8-d0a7c62fa32d,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-5e7a0521-3cef-4f05-9eed-4b1999ef88e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-20b3bbff-a325-44f8-a74b-b6182269a016,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-f54fac6e-07ed-47d8-9153-c23adda2c509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799623803-172.17.0.20-1597557879611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-5515fbfb-5396-4735-b2fc-7e073b2d3376,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-b44134e1-1914-493e-a528-9faf903287f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-5e30f56b-f2e4-42b6-8d3d-077e60c60a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-8336b309-7d7a-45ef-967f-7e09811287e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-eb696297-5e1f-4ee3-83d1-168ced30fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-59f7ac03-e01e-4f91-9754-2632687952d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-87d9ad9e-0cfb-4d6c-a6b8-1a6b2b5a0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-4b7e1a31-bfba-4f9b-8c4c-d82e2d218b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799623803-172.17.0.20-1597557879611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-5515fbfb-5396-4735-b2fc-7e073b2d3376,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-b44134e1-1914-493e-a528-9faf903287f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-5e30f56b-f2e4-42b6-8d3d-077e60c60a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-8336b309-7d7a-45ef-967f-7e09811287e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-eb696297-5e1f-4ee3-83d1-168ced30fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-59f7ac03-e01e-4f91-9754-2632687952d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-87d9ad9e-0cfb-4d6c-a6b8-1a6b2b5a0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-4b7e1a31-bfba-4f9b-8c4c-d82e2d218b24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756299236-172.17.0.20-1597557917518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-4a627d2b-f5a9-49db-8bd4-a4a5544338f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-a4ad8e84-52da-497b-a7af-ce0ce51c0cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-af60394b-0458-4edd-858d-2222e5eaaa54,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-dbf8303f-7825-43eb-82d3-0e0396e2e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-56df1a2c-2b22-4cc3-ad4d-bb47c27b63bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-89332582-b53d-4fb3-93a8-b20cf2f74aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-0023e6a9-6faa-4f50-9ff4-8384a5d612af,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-b237c5d6-e857-4255-82e2-c42a9d3c3f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756299236-172.17.0.20-1597557917518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-4a627d2b-f5a9-49db-8bd4-a4a5544338f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-a4ad8e84-52da-497b-a7af-ce0ce51c0cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-af60394b-0458-4edd-858d-2222e5eaaa54,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-dbf8303f-7825-43eb-82d3-0e0396e2e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-56df1a2c-2b22-4cc3-ad4d-bb47c27b63bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-89332582-b53d-4fb3-93a8-b20cf2f74aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-0023e6a9-6faa-4f50-9ff4-8384a5d612af,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-b237c5d6-e857-4255-82e2-c42a9d3c3f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147990186-172.17.0.20-1597558872654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-5eddfd4d-acf2-436c-b52c-d861967359ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-2158dd0d-cfa0-4fcd-906a-ca7ae21f447c,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-0a7320d2-94b5-42e8-b8ae-725a3d253897,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-7a4ee4c7-1325-431c-8494-18fc0b036b59,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-30905d49-0e79-4d74-b9bc-1c398fff0bee,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-2ed216f4-50b8-4c33-8c93-14c4eb5579e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-51921367-11b4-4d1f-9e6d-e8939ad3f88a,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-091d105e-6987-49a8-97f7-9c942485a19e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147990186-172.17.0.20-1597558872654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-5eddfd4d-acf2-436c-b52c-d861967359ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-2158dd0d-cfa0-4fcd-906a-ca7ae21f447c,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-0a7320d2-94b5-42e8-b8ae-725a3d253897,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-7a4ee4c7-1325-431c-8494-18fc0b036b59,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-30905d49-0e79-4d74-b9bc-1c398fff0bee,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-2ed216f4-50b8-4c33-8c93-14c4eb5579e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-51921367-11b4-4d1f-9e6d-e8939ad3f88a,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-091d105e-6987-49a8-97f7-9c942485a19e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128595074-172.17.0.20-1597559047663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44671,DS-1f7fe7ee-9774-4266-81e0-7a681fc3e91e,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-72884c13-bed5-4e0e-a9c0-b82f7bda2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-6f9d3b67-73c6-45d0-85e8-ba2b0d2ae04b,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-b4588554-c999-4fac-b35d-370700d05ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-34c7512e-4e24-44e0-89e7-2826b039d3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-14daeb55-4116-4f84-abf6-177a3368a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-3f7505f4-3859-4f41-990b-cba0b1a93c37,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-5f05714f-2972-4c13-ab2f-7824e4e0e38a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128595074-172.17.0.20-1597559047663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44671,DS-1f7fe7ee-9774-4266-81e0-7a681fc3e91e,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-72884c13-bed5-4e0e-a9c0-b82f7bda2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-6f9d3b67-73c6-45d0-85e8-ba2b0d2ae04b,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-b4588554-c999-4fac-b35d-370700d05ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-34c7512e-4e24-44e0-89e7-2826b039d3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-14daeb55-4116-4f84-abf6-177a3368a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-3f7505f4-3859-4f41-990b-cba0b1a93c37,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-5f05714f-2972-4c13-ab2f-7824e4e0e38a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470028996-172.17.0.20-1597559112351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44330,DS-aa61af00-9077-4a41-8a9c-53c039c74677,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-d4df32b2-c816-4fda-a84e-5a3b6e76b30d,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-2b61bb5d-489c-4c93-9d85-426a332bcad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-67f5e692-2e34-4864-b857-afd73b0340ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-ba478c54-4251-45b3-8035-c71f6facaecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-c753fbfc-08cf-4b59-9f94-3f844e128db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-bd13a813-190a-4fa3-9593-643504954877,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-1fef09a1-925f-46d1-a0b6-411341b0f629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470028996-172.17.0.20-1597559112351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44330,DS-aa61af00-9077-4a41-8a9c-53c039c74677,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-d4df32b2-c816-4fda-a84e-5a3b6e76b30d,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-2b61bb5d-489c-4c93-9d85-426a332bcad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-67f5e692-2e34-4864-b857-afd73b0340ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-ba478c54-4251-45b3-8035-c71f6facaecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-c753fbfc-08cf-4b59-9f94-3f844e128db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-bd13a813-190a-4fa3-9593-643504954877,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-1fef09a1-925f-46d1-a0b6-411341b0f629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131717058-172.17.0.20-1597559437103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-dc0da924-7645-475d-85c5-f26f6f055339,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-b0142164-e8f8-4e4b-9a45-71284850d842,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-43e3abc2-1b50-41f2-b58f-041ad0506d05,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-b1230d3a-8a02-48e2-9cab-1e0287a7345c,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-91f3125d-9a3a-491c-993c-c643e1c79200,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-751de397-fcca-4637-907c-57c675c1a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-f4c8425e-7503-468a-96e6-2e8dce137729,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-a7ef445e-6d34-4df3-815d-afb10e1b0d38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131717058-172.17.0.20-1597559437103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-dc0da924-7645-475d-85c5-f26f6f055339,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-b0142164-e8f8-4e4b-9a45-71284850d842,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-43e3abc2-1b50-41f2-b58f-041ad0506d05,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-b1230d3a-8a02-48e2-9cab-1e0287a7345c,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-91f3125d-9a3a-491c-993c-c643e1c79200,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-751de397-fcca-4637-907c-57c675c1a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-f4c8425e-7503-468a-96e6-2e8dce137729,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-a7ef445e-6d34-4df3-815d-afb10e1b0d38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514864753-172.17.0.20-1597559811468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-28f5ff32-39df-406a-96d8-78cb579011d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-e51d46e1-4ffc-42eb-8d39-722ce380bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-b66cf8c8-cdf6-4884-9f01-df6240c5a99d,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-eeb1a132-4382-429d-b22f-1463f1c0a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-99830e66-cfe6-4ff6-91ac-1164494fadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-80ffe3bc-bc1a-49ba-9d01-4f6a7446594f,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-2a43b43b-51bc-4a65-ac33-fe399c503bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-14fcd473-8ae6-4eb5-a450-cd11bbe1d30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514864753-172.17.0.20-1597559811468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-28f5ff32-39df-406a-96d8-78cb579011d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-e51d46e1-4ffc-42eb-8d39-722ce380bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-b66cf8c8-cdf6-4884-9f01-df6240c5a99d,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-eeb1a132-4382-429d-b22f-1463f1c0a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-99830e66-cfe6-4ff6-91ac-1164494fadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-80ffe3bc-bc1a-49ba-9d01-4f6a7446594f,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-2a43b43b-51bc-4a65-ac33-fe399c503bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-14fcd473-8ae6-4eb5-a450-cd11bbe1d30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002604411-172.17.0.20-1597559880387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-85c9cd32-25f7-436a-ac22-0214068d92c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-1ef800fe-800a-4e37-a644-fd925f3e665c,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-6f3e6ca0-a6b8-4dff-a468-80a9b43eb239,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-f91e6804-c8a0-4763-977b-fae30da16b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-39806f7e-5275-4e26-a30d-838f6f0caa07,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-4e1b7b4e-da43-477f-aee6-0164721a5a57,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-6f55813a-3394-41c6-96f5-63282eb2bfce,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-0e0e52bc-44ad-46f4-9d2a-691a903e9798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002604411-172.17.0.20-1597559880387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-85c9cd32-25f7-436a-ac22-0214068d92c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-1ef800fe-800a-4e37-a644-fd925f3e665c,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-6f3e6ca0-a6b8-4dff-a468-80a9b43eb239,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-f91e6804-c8a0-4763-977b-fae30da16b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-39806f7e-5275-4e26-a30d-838f6f0caa07,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-4e1b7b4e-da43-477f-aee6-0164721a5a57,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-6f55813a-3394-41c6-96f5-63282eb2bfce,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-0e0e52bc-44ad-46f4-9d2a-691a903e9798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056960006-172.17.0.20-1597560352801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-cdbc3736-8215-4f66-9ca2-c69d437d6eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-a462a9bb-e8c6-4d45-87fa-f3e4c2f53026,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-4f0ce2a6-5b99-4448-b456-2580c09e95ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-33fda631-aa4f-46db-83a2-e64c76750d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-f87465bf-490e-4730-9b46-46796567f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-7c9c7c1a-ec95-49ec-98a2-ec224b49fa37,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-45a30169-5ef1-43fe-ac4f-0a00003f891b,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-5a9df77f-36c7-4350-9ef8-e7396bf15e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056960006-172.17.0.20-1597560352801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-cdbc3736-8215-4f66-9ca2-c69d437d6eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-a462a9bb-e8c6-4d45-87fa-f3e4c2f53026,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-4f0ce2a6-5b99-4448-b456-2580c09e95ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-33fda631-aa4f-46db-83a2-e64c76750d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-f87465bf-490e-4730-9b46-46796567f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-7c9c7c1a-ec95-49ec-98a2-ec224b49fa37,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-45a30169-5ef1-43fe-ac4f-0a00003f891b,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-5a9df77f-36c7-4350-9ef8-e7396bf15e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495800016-172.17.0.20-1597560390513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-a1a473bd-c626-4d15-91f5-b61a20bca322,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-28762f63-42b5-4271-9924-f4b8cd0b1972,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-c98f342e-6c95-41a7-abe5-0241061515c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-0e6099bf-ccba-4917-8923-e7f0244adda7,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-bd2790c3-0b0f-4113-b20b-2951880e7a78,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-d3d28007-d5ac-4d96-a7da-f96aa7e74471,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-028b83a9-82dd-4270-b6a6-21c18a0fa6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-7ea0e0ad-9f1d-476f-985e-bab8f450c3ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495800016-172.17.0.20-1597560390513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-a1a473bd-c626-4d15-91f5-b61a20bca322,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-28762f63-42b5-4271-9924-f4b8cd0b1972,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-c98f342e-6c95-41a7-abe5-0241061515c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-0e6099bf-ccba-4917-8923-e7f0244adda7,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-bd2790c3-0b0f-4113-b20b-2951880e7a78,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-d3d28007-d5ac-4d96-a7da-f96aa7e74471,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-028b83a9-82dd-4270-b6a6-21c18a0fa6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-7ea0e0ad-9f1d-476f-985e-bab8f450c3ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521067998-172.17.0.20-1597560873434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-183862a7-098e-4bad-a81d-63de4b19cc37,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-1050735c-510c-4812-bead-719e64fb5fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-eb3b3116-c676-4909-b3a8-863328a7bc59,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-7b289d23-1ef9-421c-9dc9-a054af161514,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-c074847d-e007-46b2-baa7-c794f51664da,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-15e1d349-e19c-45bb-a538-75f8b7b99898,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-1935a8e9-de0b-4bbe-9b3e-6c92df3f1670,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-ddc97854-6587-4f46-9551-65b3eb610f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521067998-172.17.0.20-1597560873434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-183862a7-098e-4bad-a81d-63de4b19cc37,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-1050735c-510c-4812-bead-719e64fb5fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-eb3b3116-c676-4909-b3a8-863328a7bc59,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-7b289d23-1ef9-421c-9dc9-a054af161514,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-c074847d-e007-46b2-baa7-c794f51664da,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-15e1d349-e19c-45bb-a538-75f8b7b99898,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-1935a8e9-de0b-4bbe-9b3e-6c92df3f1670,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-ddc97854-6587-4f46-9551-65b3eb610f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622616126-172.17.0.20-1597561060245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41640,DS-9c1f5e7d-340c-4376-8ca3-a7d494aa6556,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-7f771f89-a5fa-49dd-a49f-b6071f7ff3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-01982528-fda1-4b4f-a5ae-9e44f393362c,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-2defd3b0-deba-4b2c-90d5-9f3ff7fdaf91,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-1c16b514-954d-4f42-b2ed-11b65ef5ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-99f2e428-0e77-44a4-a20d-78634b62d35e,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-514063bd-a307-4bd2-92db-2f6a6159c167,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-33b5a003-20e3-4730-bbfa-77cc5ffccb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622616126-172.17.0.20-1597561060245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41640,DS-9c1f5e7d-340c-4376-8ca3-a7d494aa6556,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-7f771f89-a5fa-49dd-a49f-b6071f7ff3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-01982528-fda1-4b4f-a5ae-9e44f393362c,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-2defd3b0-deba-4b2c-90d5-9f3ff7fdaf91,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-1c16b514-954d-4f42-b2ed-11b65ef5ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-99f2e428-0e77-44a4-a20d-78634b62d35e,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-514063bd-a307-4bd2-92db-2f6a6159c167,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-33b5a003-20e3-4730-bbfa-77cc5ffccb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752859571-172.17.0.20-1597561164386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36656,DS-5091adf9-ff99-46e5-9b5c-b912f2ad457f,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-3420adb5-d6a6-4d00-b7dc-0ea0bb666c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-5d378acd-1f7a-4be6-b4b2-374a6c780efa,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-daaab180-3506-4179-9282-aad7d3413bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-dbb5c687-f02e-4488-beb7-9d1f52eca6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-fb9bde45-dc30-4820-b98a-9cb1107d6362,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-5462210d-8cf0-4652-9e57-674f17b070cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-5da9e5eb-fe83-42f7-8e7d-96f1b629c18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752859571-172.17.0.20-1597561164386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36656,DS-5091adf9-ff99-46e5-9b5c-b912f2ad457f,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-3420adb5-d6a6-4d00-b7dc-0ea0bb666c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-5d378acd-1f7a-4be6-b4b2-374a6c780efa,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-daaab180-3506-4179-9282-aad7d3413bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-dbb5c687-f02e-4488-beb7-9d1f52eca6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-fb9bde45-dc30-4820-b98a-9cb1107d6362,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-5462210d-8cf0-4652-9e57-674f17b070cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-5da9e5eb-fe83-42f7-8e7d-96f1b629c18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028892925-172.17.0.20-1597561693801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43726,DS-3f26b913-1ef5-4691-a8d5-c62ce3288bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-0630067e-b32b-484f-a2df-dcfb9f67a874,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-2b433cd7-36f4-434a-aeb1-6ecd89ddd397,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-74c5ec7a-9ff6-4689-9ec4-fd446ae105cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-3742aedc-f188-4f57-8c94-cbc14eff3925,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-5ead9ca2-bb3e-4ede-8d1d-7ac75a722158,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-ca942f56-6523-4bb0-8353-55aff64fd61b,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-bba57d66-b9af-4b51-b60b-1c5b36415165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028892925-172.17.0.20-1597561693801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43726,DS-3f26b913-1ef5-4691-a8d5-c62ce3288bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-0630067e-b32b-484f-a2df-dcfb9f67a874,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-2b433cd7-36f4-434a-aeb1-6ecd89ddd397,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-74c5ec7a-9ff6-4689-9ec4-fd446ae105cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-3742aedc-f188-4f57-8c94-cbc14eff3925,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-5ead9ca2-bb3e-4ede-8d1d-7ac75a722158,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-ca942f56-6523-4bb0-8353-55aff64fd61b,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-bba57d66-b9af-4b51-b60b-1c5b36415165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246264480-172.17.0.20-1597561730518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-10d1d7b8-d363-4cf3-bb8f-18208d5c09e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-8d290316-ff92-4527-81a3-a6adb15222be,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-fac30f3c-7c1f-404a-a05a-65df28f2c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-edf0afb6-f28d-4317-af5f-6af8861bd723,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-17e66bfb-91e1-4a50-bdbc-f098692a8dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-3991d9a3-7a95-4247-b7cd-19d12baba34e,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-6d63377d-082d-4506-8aec-a16e4ee03556,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-8293a2a5-a6fd-45f1-b570-b77de792b7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246264480-172.17.0.20-1597561730518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-10d1d7b8-d363-4cf3-bb8f-18208d5c09e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-8d290316-ff92-4527-81a3-a6adb15222be,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-fac30f3c-7c1f-404a-a05a-65df28f2c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-edf0afb6-f28d-4317-af5f-6af8861bd723,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-17e66bfb-91e1-4a50-bdbc-f098692a8dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-3991d9a3-7a95-4247-b7cd-19d12baba34e,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-6d63377d-082d-4506-8aec-a16e4ee03556,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-8293a2a5-a6fd-45f1-b570-b77de792b7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145170911-172.17.0.20-1597561893399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35916,DS-04b04498-debe-4d22-9f1b-21ab5ba10d47,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-2bb18e21-ec4e-4c16-8bac-fa33e36ef9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-b39ca816-8e46-4b09-bd8f-0f8622b204a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-0c02de13-8411-4686-ac4b-2f8bf9c5d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-e8f6301c-5b4e-4680-b4fd-9aebbc16abc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-a8df989c-528b-45bb-b20e-6b0fa7e495a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-405206ef-48bc-4add-bd57-ae58bc41bc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-f2788e98-1f94-4e9b-800d-baf8d7fe3971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145170911-172.17.0.20-1597561893399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35916,DS-04b04498-debe-4d22-9f1b-21ab5ba10d47,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-2bb18e21-ec4e-4c16-8bac-fa33e36ef9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-b39ca816-8e46-4b09-bd8f-0f8622b204a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-0c02de13-8411-4686-ac4b-2f8bf9c5d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-e8f6301c-5b4e-4680-b4fd-9aebbc16abc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-a8df989c-528b-45bb-b20e-6b0fa7e495a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-405206ef-48bc-4add-bd57-ae58bc41bc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-f2788e98-1f94-4e9b-800d-baf8d7fe3971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5421
