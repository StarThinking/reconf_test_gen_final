reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313452195-172.17.0.9-1597320235876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-f2536ce9-83ae-4a0e-99b2-9538a3471156,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-c8a1e928-805a-4779-9df4-58c5e2bbd952,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-5fb2f1c9-7fb4-4916-ad3c-8105a3f356e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-d9cd2857-6532-415e-9ffc-070a1bd4f3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-c04cde46-c917-41a3-b902-f06eef90ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-a9cee2f6-055f-4a97-8f70-945550c243ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-cf0a0a1d-fb39-4d7c-acb0-f0f3692efc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-19f08e78-35e4-4d55-9bbc-f83969cea3ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313452195-172.17.0.9-1597320235876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-f2536ce9-83ae-4a0e-99b2-9538a3471156,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-c8a1e928-805a-4779-9df4-58c5e2bbd952,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-5fb2f1c9-7fb4-4916-ad3c-8105a3f356e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-d9cd2857-6532-415e-9ffc-070a1bd4f3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-c04cde46-c917-41a3-b902-f06eef90ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-a9cee2f6-055f-4a97-8f70-945550c243ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-cf0a0a1d-fb39-4d7c-acb0-f0f3692efc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-19f08e78-35e4-4d55-9bbc-f83969cea3ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664121237-172.17.0.9-1597321522797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35525,DS-ff3c9d03-366b-4198-bfd8-20fd3c83827f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-1ec5611c-2769-44a8-a24c-b25444e42df9,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-fb782dff-1fea-4bf3-9778-c727a703ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-b622ea7c-8f26-474c-b795-88f031c92480,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-e9a431f4-0858-417e-9a70-2bc1fd3f8e56,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-ab5f408a-c842-41bc-b420-efbbf254dcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-4841cae0-1d96-448a-be2a-69666d8840a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-8cc82a36-eeec-45c6-b5e6-c2b30779add8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664121237-172.17.0.9-1597321522797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35525,DS-ff3c9d03-366b-4198-bfd8-20fd3c83827f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-1ec5611c-2769-44a8-a24c-b25444e42df9,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-fb782dff-1fea-4bf3-9778-c727a703ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-b622ea7c-8f26-474c-b795-88f031c92480,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-e9a431f4-0858-417e-9a70-2bc1fd3f8e56,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-ab5f408a-c842-41bc-b420-efbbf254dcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-4841cae0-1d96-448a-be2a-69666d8840a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-8cc82a36-eeec-45c6-b5e6-c2b30779add8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486814655-172.17.0.9-1597321974978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-cd1fd536-d3c3-4ef5-854f-b11fc34e8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-ecafc821-c951-40f1-a2bc-70e017257480,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-91b185a7-d3cb-4717-ad97-d564e4ca34d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-b278315b-4225-4545-91e4-58e9005234a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-bd4900e1-654a-4961-a809-22a7976afeab,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-75a73a7a-be45-49a7-b577-9c4ed7f2bc61,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-5590c47e-4bd2-4032-89c9-a4379a308701,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-d6559eb1-387a-4df8-a365-4b27fc3665e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486814655-172.17.0.9-1597321974978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-cd1fd536-d3c3-4ef5-854f-b11fc34e8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-ecafc821-c951-40f1-a2bc-70e017257480,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-91b185a7-d3cb-4717-ad97-d564e4ca34d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-b278315b-4225-4545-91e4-58e9005234a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-bd4900e1-654a-4961-a809-22a7976afeab,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-75a73a7a-be45-49a7-b577-9c4ed7f2bc61,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-5590c47e-4bd2-4032-89c9-a4379a308701,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-d6559eb1-387a-4df8-a365-4b27fc3665e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071982103-172.17.0.9-1597322019833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-608d7ade-4483-4349-870e-e48e30981662,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-0a912c54-ca2f-4084-acb9-e4894b734a47,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-c570c20b-ddb8-4749-b79d-d0ea6ac9d347,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-c74e5078-4100-4c0f-a8cb-6c5ef5aeee12,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-fa10940b-81cc-42f7-9f27-aacb3547854e,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-2274ffc6-2476-42b7-9de4-cc97fbce7d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-c89a4393-787d-4f9e-ac27-e2b2d9ae8293,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-d60771d9-ecb6-42f6-be5d-98ffcaa62f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071982103-172.17.0.9-1597322019833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-608d7ade-4483-4349-870e-e48e30981662,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-0a912c54-ca2f-4084-acb9-e4894b734a47,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-c570c20b-ddb8-4749-b79d-d0ea6ac9d347,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-c74e5078-4100-4c0f-a8cb-6c5ef5aeee12,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-fa10940b-81cc-42f7-9f27-aacb3547854e,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-2274ffc6-2476-42b7-9de4-cc97fbce7d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-c89a4393-787d-4f9e-ac27-e2b2d9ae8293,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-d60771d9-ecb6-42f6-be5d-98ffcaa62f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383749980-172.17.0.9-1597322078718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44398,DS-5fd3a662-1e5d-4e89-94c1-b64a50d955ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-e8c591bf-605f-483c-a57b-72d416fd9c35,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-39786a82-740c-4591-81ba-12ecc7caa386,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-372b71b2-7ae7-4ada-9150-4e92f6195200,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-5f34ef2f-307e-4cbf-a997-8d39ea71239c,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-b6b55589-7234-47cb-bb9c-5e7a7a5d2fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-b1198229-f9bb-4cbb-8557-bebf7f4b81b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-0dcf0cdc-40fc-4772-87bf-bf7b22f6c31c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383749980-172.17.0.9-1597322078718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44398,DS-5fd3a662-1e5d-4e89-94c1-b64a50d955ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-e8c591bf-605f-483c-a57b-72d416fd9c35,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-39786a82-740c-4591-81ba-12ecc7caa386,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-372b71b2-7ae7-4ada-9150-4e92f6195200,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-5f34ef2f-307e-4cbf-a997-8d39ea71239c,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-b6b55589-7234-47cb-bb9c-5e7a7a5d2fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-b1198229-f9bb-4cbb-8557-bebf7f4b81b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-0dcf0cdc-40fc-4772-87bf-bf7b22f6c31c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184476616-172.17.0.9-1597322570779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44620,DS-b38d2911-034d-4bf9-9d38-3784e7e491a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-af660b70-c1cc-4a2a-adc5-74683c2d01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-40cb6e6c-ecf5-40fb-9f27-e7e1294191ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-9bcc9cd0-2a52-4f5a-abf0-8cc240426b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-a7a1a7b8-7e21-4c28-87f9-e28c204eb921,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-674de5d0-c27b-4c53-86c7-91ae17ae34f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-2785100c-115f-46df-ae75-9817b370e26a,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-c6f39e76-26d6-4067-8a60-ae94738e2af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184476616-172.17.0.9-1597322570779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44620,DS-b38d2911-034d-4bf9-9d38-3784e7e491a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-af660b70-c1cc-4a2a-adc5-74683c2d01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-40cb6e6c-ecf5-40fb-9f27-e7e1294191ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-9bcc9cd0-2a52-4f5a-abf0-8cc240426b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-a7a1a7b8-7e21-4c28-87f9-e28c204eb921,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-674de5d0-c27b-4c53-86c7-91ae17ae34f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-2785100c-115f-46df-ae75-9817b370e26a,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-c6f39e76-26d6-4067-8a60-ae94738e2af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80467938-172.17.0.9-1597322615233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-beb8260c-b7a0-4bcd-94b4-9446eca641f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-93973546-8c61-4396-9a83-315a1f605a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-cf004d09-2d6d-437a-9322-ae99425a540a,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-9b26ec9c-9c2c-45ba-83e7-180f1f8fbf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-baf74088-1886-4880-9cbb-fbd2802e1e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-965e7658-b4f0-4cec-94a3-29d9d7e33e68,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-0753da73-5b17-414b-ad43-b58a12de3f36,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-3fee1bf9-08dd-4469-9f67-33f70359bdb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80467938-172.17.0.9-1597322615233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-beb8260c-b7a0-4bcd-94b4-9446eca641f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-93973546-8c61-4396-9a83-315a1f605a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-cf004d09-2d6d-437a-9322-ae99425a540a,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-9b26ec9c-9c2c-45ba-83e7-180f1f8fbf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-baf74088-1886-4880-9cbb-fbd2802e1e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-965e7658-b4f0-4cec-94a3-29d9d7e33e68,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-0753da73-5b17-414b-ad43-b58a12de3f36,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-3fee1bf9-08dd-4469-9f67-33f70359bdb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092230833-172.17.0.9-1597322719618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35669,DS-fad9cb7c-bc27-465d-84ee-a5ad057da861,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-1c37ec04-7a8f-49ba-b34a-8bc227e75168,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-7fbc7b50-9b7a-4f3f-b131-c5d1a3838991,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-3f7dedd3-753c-483b-93be-a841d7be9642,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-f244a098-ae8f-40bb-85a1-efcdd99995bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-881add2f-cabc-4a58-aff6-4a19cf189e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-2716bbd4-4fff-43f7-b778-549740cd2c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-4d8a1400-5967-4741-b659-ea6d0d43bb81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092230833-172.17.0.9-1597322719618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35669,DS-fad9cb7c-bc27-465d-84ee-a5ad057da861,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-1c37ec04-7a8f-49ba-b34a-8bc227e75168,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-7fbc7b50-9b7a-4f3f-b131-c5d1a3838991,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-3f7dedd3-753c-483b-93be-a841d7be9642,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-f244a098-ae8f-40bb-85a1-efcdd99995bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-881add2f-cabc-4a58-aff6-4a19cf189e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-2716bbd4-4fff-43f7-b778-549740cd2c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-4d8a1400-5967-4741-b659-ea6d0d43bb81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317456574-172.17.0.9-1597323070499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-f3c466c3-bf25-4b8d-b2c5-18f06cfc229d,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-d8e405f5-6710-4346-99ed-672ae10385f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-f1796298-b43e-4369-bb49-f8959b3f6336,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-f5f7dbd3-03a4-482c-b633-d8ac55973dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-46eda296-aa01-4b8d-ba3a-76037adf45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-d10c9ff4-b11d-4298-bae4-d8fa30e3173e,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-08fc405a-10c1-4550-a1a7-f7d70e511ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-b8487064-1159-4c6c-9f7c-f4297110fb4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317456574-172.17.0.9-1597323070499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-f3c466c3-bf25-4b8d-b2c5-18f06cfc229d,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-d8e405f5-6710-4346-99ed-672ae10385f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-f1796298-b43e-4369-bb49-f8959b3f6336,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-f5f7dbd3-03a4-482c-b633-d8ac55973dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-46eda296-aa01-4b8d-ba3a-76037adf45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-d10c9ff4-b11d-4298-bae4-d8fa30e3173e,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-08fc405a-10c1-4550-a1a7-f7d70e511ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-b8487064-1159-4c6c-9f7c-f4297110fb4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982240118-172.17.0.9-1597323912675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-b9c8af63-413f-4277-bc71-2497c966b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-6e101cbd-90bb-4089-bfa7-de558fb0c576,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-7ddde96e-0437-4557-b199-7a4cf26e4c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-09a8de09-2665-4f34-8321-1dffb7c14624,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-ea2b6a12-440a-42f9-b263-12e49f0f5b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-fcefea66-384b-4dbb-a4f7-bab03322ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-2959a2da-96cc-40ad-8c2a-c1f063ecfabb,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-551850dc-2bc4-4414-97f8-efb339c77306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982240118-172.17.0.9-1597323912675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44248,DS-b9c8af63-413f-4277-bc71-2497c966b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-6e101cbd-90bb-4089-bfa7-de558fb0c576,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-7ddde96e-0437-4557-b199-7a4cf26e4c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-09a8de09-2665-4f34-8321-1dffb7c14624,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-ea2b6a12-440a-42f9-b263-12e49f0f5b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-fcefea66-384b-4dbb-a4f7-bab03322ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-2959a2da-96cc-40ad-8c2a-c1f063ecfabb,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-551850dc-2bc4-4414-97f8-efb339c77306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962748579-172.17.0.9-1597324180560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-b92a49c8-0a67-4d59-a20c-feb0c056ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-a3b76ef9-83d5-4b7c-a06d-f06b966a74ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-2d1bff40-03df-4cb7-8d01-10a0f34ba19a,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-d05d3baa-31a2-4331-b8b9-4227ed2b7aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-55334eae-b725-41bd-8a5b-25f44784e13f,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-40f54191-798c-4c5a-8594-56b966faf98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-c019f87b-814c-45c9-ac1e-fc9b88fcf4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-e22545ca-0478-4ef2-8062-f2b0f4bdcd67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962748579-172.17.0.9-1597324180560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-b92a49c8-0a67-4d59-a20c-feb0c056ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-a3b76ef9-83d5-4b7c-a06d-f06b966a74ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-2d1bff40-03df-4cb7-8d01-10a0f34ba19a,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-d05d3baa-31a2-4331-b8b9-4227ed2b7aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-55334eae-b725-41bd-8a5b-25f44784e13f,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-40f54191-798c-4c5a-8594-56b966faf98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-c019f87b-814c-45c9-ac1e-fc9b88fcf4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-e22545ca-0478-4ef2-8062-f2b0f4bdcd67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523627973-172.17.0.9-1597324540310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-d42f6eed-89ae-41e7-a646-56b25af20ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-9a0137d8-9deb-4a54-b682-a4c430ed4f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-a4f35356-a171-4f2a-98dc-5578f5bf62aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-41626b8e-a75a-479c-8385-76072983982c,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-433ed498-a75a-4f63-a89f-a1425b23df04,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-f220d3ea-31ea-478c-b89c-70f96c12eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-cd58a074-0609-4a79-8021-022ba465323a,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-c12cca09-050a-4b40-bb3e-ba3902ae9d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523627973-172.17.0.9-1597324540310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-d42f6eed-89ae-41e7-a646-56b25af20ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-9a0137d8-9deb-4a54-b682-a4c430ed4f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-a4f35356-a171-4f2a-98dc-5578f5bf62aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-41626b8e-a75a-479c-8385-76072983982c,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-433ed498-a75a-4f63-a89f-a1425b23df04,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-f220d3ea-31ea-478c-b89c-70f96c12eafa,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-cd58a074-0609-4a79-8021-022ba465323a,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-c12cca09-050a-4b40-bb3e-ba3902ae9d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433834437-172.17.0.9-1597325033111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-03489044-94a8-4f44-987b-95178ea01373,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-01df7993-f34a-45aa-854f-63e63de785e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-58b5baa6-8c2c-4970-8915-168c775da4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-2e93eb08-5c90-4510-9a19-81f10f648e42,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-6e316d69-2ee9-41ed-8148-a45ef2cb8ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-e819ca6f-135a-47e5-b6e7-d90358a93ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-6b615d82-7a58-4294-96ff-0be90dffb8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-a82ec2f2-f455-4b78-8c3a-ff27fd4b44eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433834437-172.17.0.9-1597325033111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-03489044-94a8-4f44-987b-95178ea01373,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-01df7993-f34a-45aa-854f-63e63de785e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-58b5baa6-8c2c-4970-8915-168c775da4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-2e93eb08-5c90-4510-9a19-81f10f648e42,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-6e316d69-2ee9-41ed-8148-a45ef2cb8ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-e819ca6f-135a-47e5-b6e7-d90358a93ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-6b615d82-7a58-4294-96ff-0be90dffb8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-a82ec2f2-f455-4b78-8c3a-ff27fd4b44eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544999153-172.17.0.9-1597325383828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34007,DS-21f4035d-991b-4d38-8415-f04fc0df3563,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-2ba36cfc-c59e-4515-8888-0d209f4d68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-c2974848-5901-4952-a3e7-bbae6c63c418,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-7cd64294-888c-4741-9746-f7bb3d28ba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-6f1216e6-f704-4f5b-9127-4b59b07fd2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-b3ba2795-5ef0-4ce5-ab87-dd52a6563a92,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-1891545f-e47c-4638-a58c-53bcb8745385,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-dc5d748b-4c7a-48aa-ba77-ab2afc76c470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544999153-172.17.0.9-1597325383828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34007,DS-21f4035d-991b-4d38-8415-f04fc0df3563,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-2ba36cfc-c59e-4515-8888-0d209f4d68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-c2974848-5901-4952-a3e7-bbae6c63c418,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-7cd64294-888c-4741-9746-f7bb3d28ba2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-6f1216e6-f704-4f5b-9127-4b59b07fd2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-b3ba2795-5ef0-4ce5-ab87-dd52a6563a92,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-1891545f-e47c-4638-a58c-53bcb8745385,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-dc5d748b-4c7a-48aa-ba77-ab2afc76c470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121271567-172.17.0.9-1597325829317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36776,DS-1d78e509-0de8-428d-b0ae-5edb0131e278,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-cd8bb772-9ad2-43eb-a697-6499d263986d,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-b24a7d0d-58a2-4837-85a7-689fab26003e,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-3fa0dfd8-688c-4e99-ae01-7748c70e2ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-0852019c-1014-4f14-b70d-0052e32b5daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-de9a24b6-5629-4ac3-896b-ee2ae533a0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-7ab9f9f0-3c8f-4dca-9bee-88e725a9911c,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-c1d949c0-5fae-4c3f-95ac-5d941d280386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121271567-172.17.0.9-1597325829317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36776,DS-1d78e509-0de8-428d-b0ae-5edb0131e278,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-cd8bb772-9ad2-43eb-a697-6499d263986d,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-b24a7d0d-58a2-4837-85a7-689fab26003e,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-3fa0dfd8-688c-4e99-ae01-7748c70e2ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-0852019c-1014-4f14-b70d-0052e32b5daf,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-de9a24b6-5629-4ac3-896b-ee2ae533a0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-7ab9f9f0-3c8f-4dca-9bee-88e725a9911c,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-c1d949c0-5fae-4c3f-95ac-5d941d280386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6869
