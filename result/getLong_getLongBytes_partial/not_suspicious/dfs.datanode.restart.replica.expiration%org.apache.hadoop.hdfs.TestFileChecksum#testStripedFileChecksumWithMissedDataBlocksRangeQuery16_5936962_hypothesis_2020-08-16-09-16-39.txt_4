reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522557214-172.17.0.16-1597569769835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40491,DS-e1f75cd2-eca8-4cf9-a2ca-7158537a4534,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-ebb71531-dd44-4e29-9a75-65afb0ac8442,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-02c023db-a49a-4b9d-9cf2-b79fe616a140,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-ef79a821-aff4-4580-8f10-5311b9785fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-dcfb9461-3930-4e65-9c10-e512ddb796ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-326c7f92-c541-49ef-88b7-13ca1b7e94ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-11236c18-fcf0-484a-b5ad-dcd903366221,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-b4a08d66-7eb5-432f-88bc-c16020b7dde5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522557214-172.17.0.16-1597569769835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40491,DS-e1f75cd2-eca8-4cf9-a2ca-7158537a4534,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-ebb71531-dd44-4e29-9a75-65afb0ac8442,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-02c023db-a49a-4b9d-9cf2-b79fe616a140,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-ef79a821-aff4-4580-8f10-5311b9785fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-dcfb9461-3930-4e65-9c10-e512ddb796ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-326c7f92-c541-49ef-88b7-13ca1b7e94ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-11236c18-fcf0-484a-b5ad-dcd903366221,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-b4a08d66-7eb5-432f-88bc-c16020b7dde5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906992527-172.17.0.16-1597569913978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36240,DS-0e1c8d73-63cf-4758-aca4-ed1c6918035e,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-de193db0-3f8a-475f-926b-b6e6779e32cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-d3a584e5-a407-4049-99c0-1fa313c0b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-5776749e-da6a-4cc2-8755-e1c8fd94397d,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-c5b2574c-adb0-4beb-82d6-9107494a9419,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-6f9ed22b-4c7f-4381-864e-f8540cfa72ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-9168f2d6-0a23-4d2c-a645-c70b66ecf095,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-579e0441-afcb-4c07-8154-64fc2ce7fefe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906992527-172.17.0.16-1597569913978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36240,DS-0e1c8d73-63cf-4758-aca4-ed1c6918035e,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-de193db0-3f8a-475f-926b-b6e6779e32cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-d3a584e5-a407-4049-99c0-1fa313c0b53f,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-5776749e-da6a-4cc2-8755-e1c8fd94397d,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-c5b2574c-adb0-4beb-82d6-9107494a9419,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-6f9ed22b-4c7f-4381-864e-f8540cfa72ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-9168f2d6-0a23-4d2c-a645-c70b66ecf095,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-579e0441-afcb-4c07-8154-64fc2ce7fefe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705785047-172.17.0.16-1597570520026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41175,DS-fb05ecb7-f3b3-49a4-ae83-c8bdf3566b21,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-d222a9cd-933a-4f54-b452-7d06d2267bed,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-3b83e6a5-f4ed-4130-9e06-9b9d19fa786d,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-61b7ce55-d763-435c-955a-e280e0ab5101,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-03bc2e56-0da7-4e34-8303-2cd8be313bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-25b57e50-458f-483c-953d-60b840ce7e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-0b9c61ae-6e65-40fa-b09f-d9fbd69ca0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-6b5239f1-eb25-4804-8ee1-7f9d09b24bd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705785047-172.17.0.16-1597570520026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41175,DS-fb05ecb7-f3b3-49a4-ae83-c8bdf3566b21,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-d222a9cd-933a-4f54-b452-7d06d2267bed,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-3b83e6a5-f4ed-4130-9e06-9b9d19fa786d,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-61b7ce55-d763-435c-955a-e280e0ab5101,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-03bc2e56-0da7-4e34-8303-2cd8be313bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-25b57e50-458f-483c-953d-60b840ce7e26,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-0b9c61ae-6e65-40fa-b09f-d9fbd69ca0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-6b5239f1-eb25-4804-8ee1-7f9d09b24bd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780987089-172.17.0.16-1597570892766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35821,DS-784bb845-554b-4c6a-9984-794ab77c0443,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-a8575f49-aa13-4a3e-941a-a190993b75df,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-f5a88119-8969-4189-a850-dd3a03ad5534,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-230f7a64-0aef-41ee-bc1f-e03f39c97f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-1d2af536-c38b-4ec7-ad93-628d349dd137,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-c57cac69-c53b-44b9-91df-3dfe7d14f7af,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-61c2a1e0-1a68-4d57-8107-c80bfd0eced4,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-7de845bb-e198-4e26-8480-692978a55c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780987089-172.17.0.16-1597570892766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35821,DS-784bb845-554b-4c6a-9984-794ab77c0443,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-a8575f49-aa13-4a3e-941a-a190993b75df,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-f5a88119-8969-4189-a850-dd3a03ad5534,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-230f7a64-0aef-41ee-bc1f-e03f39c97f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-1d2af536-c38b-4ec7-ad93-628d349dd137,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-c57cac69-c53b-44b9-91df-3dfe7d14f7af,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-61c2a1e0-1a68-4d57-8107-c80bfd0eced4,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-7de845bb-e198-4e26-8480-692978a55c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434369235-172.17.0.16-1597571769724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38686,DS-0dcb7581-13f5-4905-9ff4-10636f2fd409,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-71b37c7f-fde7-4676-b4b3-516afb7d09bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-a867b6c6-c36b-4a83-ad76-5d4047bfda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-bbb27fe1-3b4f-4e34-9cda-0a2798951d31,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-4bf73f53-7f29-477a-8b2f-deca375341b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-85953b3a-fb07-4fa2-aad8-4a4edd83cd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-7a931f31-6018-4698-a7f8-7f9fd0feacf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-7bcf488c-85ec-4d7a-8bc3-94e642085f10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434369235-172.17.0.16-1597571769724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38686,DS-0dcb7581-13f5-4905-9ff4-10636f2fd409,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-71b37c7f-fde7-4676-b4b3-516afb7d09bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-a867b6c6-c36b-4a83-ad76-5d4047bfda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-bbb27fe1-3b4f-4e34-9cda-0a2798951d31,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-4bf73f53-7f29-477a-8b2f-deca375341b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-85953b3a-fb07-4fa2-aad8-4a4edd83cd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-7a931f31-6018-4698-a7f8-7f9fd0feacf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-7bcf488c-85ec-4d7a-8bc3-94e642085f10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126892004-172.17.0.16-1597572020453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39171,DS-71a65918-99cd-4c0f-9f88-7000b6e7aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-732c1927-5139-40fa-a7f5-1f40e0e26f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-64bcee72-1cae-4cb9-afd4-f5a23cc75753,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-51f6f5f4-0093-41f6-a26b-e540a9c9bee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-2d2ba7b4-adae-48ed-8f49-e31800fe6a57,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-534ddf5c-9a30-46a5-aada-00733818a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-e43eba04-cf43-4d75-b815-6ba525bf3392,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-84c8b166-c557-46e9-88c8-5d50bb554a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126892004-172.17.0.16-1597572020453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39171,DS-71a65918-99cd-4c0f-9f88-7000b6e7aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-732c1927-5139-40fa-a7f5-1f40e0e26f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-64bcee72-1cae-4cb9-afd4-f5a23cc75753,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-51f6f5f4-0093-41f6-a26b-e540a9c9bee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-2d2ba7b4-adae-48ed-8f49-e31800fe6a57,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-534ddf5c-9a30-46a5-aada-00733818a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-e43eba04-cf43-4d75-b815-6ba525bf3392,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-84c8b166-c557-46e9-88c8-5d50bb554a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972452675-172.17.0.16-1597572093522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36401,DS-887986a5-5593-455f-857f-4960e5e52872,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-df997406-b3ef-472e-8615-53d3a71a250e,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-5b4d3426-8a7b-4c63-9fce-4dde0a0952af,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-10cd5283-dae2-40e9-9ff7-850d854a5c53,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-5b8afb45-b171-455f-a516-f2e8f07a22b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-58298045-d174-4680-8b19-c7000c878348,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-b8c1819e-f4bb-4001-a7f0-f906cbd1abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-9e3b3ebf-e4af-449c-ba5b-a38869590ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972452675-172.17.0.16-1597572093522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36401,DS-887986a5-5593-455f-857f-4960e5e52872,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-df997406-b3ef-472e-8615-53d3a71a250e,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-5b4d3426-8a7b-4c63-9fce-4dde0a0952af,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-10cd5283-dae2-40e9-9ff7-850d854a5c53,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-5b8afb45-b171-455f-a516-f2e8f07a22b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-58298045-d174-4680-8b19-c7000c878348,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-b8c1819e-f4bb-4001-a7f0-f906cbd1abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-9e3b3ebf-e4af-449c-ba5b-a38869590ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060878393-172.17.0.16-1597572351405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-29cd25ed-139d-48ac-8364-2225e4a1e644,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-0839649d-b35e-4a53-8c94-5e7da8363c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-4bec0408-ffa4-405c-aceb-25da8437ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-6af9d18e-f239-4cf8-9ab5-e8b3fc4d0565,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-34a2c741-a943-4004-ae24-c019846dc119,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-ab214ebe-7944-4277-b313-1a47f5d35d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-5491593d-3093-42e3-9cdd-0ebdf966a836,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-be336ef5-09d1-451f-89b0-7f63919c938f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060878393-172.17.0.16-1597572351405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34285,DS-29cd25ed-139d-48ac-8364-2225e4a1e644,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-0839649d-b35e-4a53-8c94-5e7da8363c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-4bec0408-ffa4-405c-aceb-25da8437ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-6af9d18e-f239-4cf8-9ab5-e8b3fc4d0565,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-34a2c741-a943-4004-ae24-c019846dc119,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-ab214ebe-7944-4277-b313-1a47f5d35d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-5491593d-3093-42e3-9cdd-0ebdf966a836,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-be336ef5-09d1-451f-89b0-7f63919c938f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644981430-172.17.0.16-1597572497408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42030,DS-841b8107-e74a-48d0-ac69-07dcfa86b767,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-ec940105-ff96-4369-8739-1bf430444d02,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-8e85b640-1f2e-4ab9-9d69-428f43842aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-232e19a0-f5b3-4930-87fa-01487c695d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-94ae1273-3016-45ac-b4cc-78495a907dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-dbfedecb-d6e5-4837-ba17-d0c0bf7f610b,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-077be533-03c8-478c-95e5-92c6875168dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-22d5888e-f0b2-4d87-8251-8e46f3732294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644981430-172.17.0.16-1597572497408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42030,DS-841b8107-e74a-48d0-ac69-07dcfa86b767,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-ec940105-ff96-4369-8739-1bf430444d02,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-8e85b640-1f2e-4ab9-9d69-428f43842aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-232e19a0-f5b3-4930-87fa-01487c695d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-94ae1273-3016-45ac-b4cc-78495a907dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-dbfedecb-d6e5-4837-ba17-d0c0bf7f610b,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-077be533-03c8-478c-95e5-92c6875168dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-22d5888e-f0b2-4d87-8251-8e46f3732294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683533200-172.17.0.16-1597572569080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44907,DS-3afd0b38-8f5f-4928-a6f2-8f774e4617b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-1859c5de-cbc5-4b6d-88ef-6fd8dab23f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-3d670a20-f67b-4e8d-bbde-aa43c2e22627,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-eda456ae-1c9b-45c9-aa8a-395a80db8356,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-1eea44cf-84d4-4a8d-9d85-5b2a3e3944eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-974a287c-fd02-409c-a368-1fff03b0fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-80ecca27-3219-41c2-b556-8476e369f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-23fcb320-a16b-433a-8693-0e1a5278a78a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683533200-172.17.0.16-1597572569080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44907,DS-3afd0b38-8f5f-4928-a6f2-8f774e4617b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-1859c5de-cbc5-4b6d-88ef-6fd8dab23f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-3d670a20-f67b-4e8d-bbde-aa43c2e22627,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-eda456ae-1c9b-45c9-aa8a-395a80db8356,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-1eea44cf-84d4-4a8d-9d85-5b2a3e3944eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-974a287c-fd02-409c-a368-1fff03b0fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-80ecca27-3219-41c2-b556-8476e369f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-23fcb320-a16b-433a-8693-0e1a5278a78a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719071673-172.17.0.16-1597572605389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-8ed55663-74c6-4fbb-92ac-41436c2781e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-cdfa6ba9-4e58-41b6-ae92-49c0b0475720,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-1fd11ecb-a44a-442c-b2ee-ec13c1a9afd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-1892ae03-516e-48df-8efe-604faf49f105,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-1ab5ed65-1049-44e1-b9de-8ec52f853d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-d587c1ae-c740-4da0-afa1-99fb4839c826,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-6753f3c4-3d45-4a31-a53a-44c15eb7f732,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-5af77166-5865-498e-ba80-b20630f54a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719071673-172.17.0.16-1597572605389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-8ed55663-74c6-4fbb-92ac-41436c2781e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-cdfa6ba9-4e58-41b6-ae92-49c0b0475720,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-1fd11ecb-a44a-442c-b2ee-ec13c1a9afd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-1892ae03-516e-48df-8efe-604faf49f105,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-1ab5ed65-1049-44e1-b9de-8ec52f853d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-d587c1ae-c740-4da0-afa1-99fb4839c826,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-6753f3c4-3d45-4a31-a53a-44c15eb7f732,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-5af77166-5865-498e-ba80-b20630f54a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130096087-172.17.0.16-1597572674942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-c5925ec8-8723-4c2a-b565-e98b8b111399,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-e3e3166a-cfd2-43de-8019-e010f5920e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-69f5fc20-b638-4ee1-bcc3-bbbf1681b43d,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-35c8efba-4d4f-4106-8adc-49d2593eaa38,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-6e41c6d1-73e1-4206-9531-43c31d8056ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-75bcbafa-40ec-4173-9c02-4872972f6c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-96aeeeb8-bfbd-4384-b08c-81f99c052d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-c7de9855-54d0-4c44-80dd-5bc5c4d99529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130096087-172.17.0.16-1597572674942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-c5925ec8-8723-4c2a-b565-e98b8b111399,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-e3e3166a-cfd2-43de-8019-e010f5920e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-69f5fc20-b638-4ee1-bcc3-bbbf1681b43d,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-35c8efba-4d4f-4106-8adc-49d2593eaa38,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-6e41c6d1-73e1-4206-9531-43c31d8056ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-75bcbafa-40ec-4173-9c02-4872972f6c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-96aeeeb8-bfbd-4384-b08c-81f99c052d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-c7de9855-54d0-4c44-80dd-5bc5c4d99529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308417256-172.17.0.16-1597573131329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-63995f85-9e81-4a9e-aae4-634434384a32,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-9046d0f9-249a-4f97-ba90-03141baa425e,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-a18bab6f-99f2-4a4f-b1c6-6154b23d24df,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-aadcc22a-a4e2-416b-9b6e-69bf3a8442cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-61acb51b-75f6-41cb-8b66-1b5d76df346b,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-3ed2fb0f-22f3-4b69-84de-f81ccdebd448,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-62a36777-7ca7-441d-8962-75905b32604d,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-95d9465c-e972-41ae-98a7-43c4bfe190e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308417256-172.17.0.16-1597573131329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-63995f85-9e81-4a9e-aae4-634434384a32,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-9046d0f9-249a-4f97-ba90-03141baa425e,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-a18bab6f-99f2-4a4f-b1c6-6154b23d24df,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-aadcc22a-a4e2-416b-9b6e-69bf3a8442cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-61acb51b-75f6-41cb-8b66-1b5d76df346b,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-3ed2fb0f-22f3-4b69-84de-f81ccdebd448,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-62a36777-7ca7-441d-8962-75905b32604d,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-95d9465c-e972-41ae-98a7-43c4bfe190e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751333170-172.17.0.16-1597573508494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-7bb62e7f-9727-4bf9-b27d-79e968d019e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-0038e733-757c-40b1-b51c-87bf7acf82fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-0bb24936-a408-4ac6-8da4-56b2d753d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-4a49327d-bcfb-4d8c-96b5-8a1753c4b658,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-44b23985-a05f-44f0-9faa-6e135383306d,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-87e9e440-6d28-49a2-8fb3-fa7e5ea7af58,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-ac0dcfb0-e117-48c4-a881-de15096e561c,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-5c86e472-07db-4833-bf2c-71d6fd525a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751333170-172.17.0.16-1597573508494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-7bb62e7f-9727-4bf9-b27d-79e968d019e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-0038e733-757c-40b1-b51c-87bf7acf82fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-0bb24936-a408-4ac6-8da4-56b2d753d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-4a49327d-bcfb-4d8c-96b5-8a1753c4b658,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-44b23985-a05f-44f0-9faa-6e135383306d,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-87e9e440-6d28-49a2-8fb3-fa7e5ea7af58,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-ac0dcfb0-e117-48c4-a881-de15096e561c,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-5c86e472-07db-4833-bf2c-71d6fd525a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907887821-172.17.0.16-1597573963181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44466,DS-06fbf0e5-b99f-42ef-bfad-68a4b5985199,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-0962fb48-e20e-4150-bc5a-31dcf85efe11,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-59c30231-06c0-4bfe-bef2-ef4f7d0f74ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-7418930c-207e-4ebc-ad1d-e48164895df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-69fc4d6d-cb3f-4b29-b807-c88f50d01a15,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-7b6e9ee5-747a-402e-9ed1-9f265616e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-8a4701f3-6d1d-4e66-a111-289aa8426fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-c0bd02ea-387a-4fd1-8c82-fd04e855b6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907887821-172.17.0.16-1597573963181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44466,DS-06fbf0e5-b99f-42ef-bfad-68a4b5985199,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-0962fb48-e20e-4150-bc5a-31dcf85efe11,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-59c30231-06c0-4bfe-bef2-ef4f7d0f74ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-7418930c-207e-4ebc-ad1d-e48164895df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-69fc4d6d-cb3f-4b29-b807-c88f50d01a15,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-7b6e9ee5-747a-402e-9ed1-9f265616e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-8a4701f3-6d1d-4e66-a111-289aa8426fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-c0bd02ea-387a-4fd1-8c82-fd04e855b6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050482718-172.17.0.16-1597574068517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-d7307ead-f0f4-4d18-a744-b1a5d4c81f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-5ea5a7a8-7fb6-487f-acf1-25ab5dd91e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-6e4a4927-8750-4eb2-80ae-6ad91976dbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-e1961e00-8f3b-434b-ac81-2966369d08eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-0b0e92a3-2945-42c1-87b6-1149da4a0f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-1f7ce81f-cc41-4c6f-8578-443739fa3c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-027b979b-1987-491a-a2df-57d7e8eba886,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-2cab01f0-19f5-4cf7-8685-cb40fb3f4fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2050482718-172.17.0.16-1597574068517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-d7307ead-f0f4-4d18-a744-b1a5d4c81f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-5ea5a7a8-7fb6-487f-acf1-25ab5dd91e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-6e4a4927-8750-4eb2-80ae-6ad91976dbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-e1961e00-8f3b-434b-ac81-2966369d08eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-0b0e92a3-2945-42c1-87b6-1149da4a0f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-1f7ce81f-cc41-4c6f-8578-443739fa3c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-027b979b-1987-491a-a2df-57d7e8eba886,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-2cab01f0-19f5-4cf7-8685-cb40fb3f4fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913094803-172.17.0.16-1597574182166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-6ef73ebc-6046-4181-944f-d6c5f336e9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-1ff934e9-9d42-4341-a6a0-006c96c0c85c,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-0ef63f0b-8448-4a26-a964-6a849e483b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-e9041527-03ea-42d3-b6aa-96a63fa2ad21,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-27cb2370-62ba-4ddc-a3af-13d58c629aee,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-eed920cf-07e6-4e9f-9277-fabb2555c0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-a1e9109b-777a-4b2d-b235-2a2f211b027e,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-ae34109d-451a-4db2-9a62-8ff9827c8dd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913094803-172.17.0.16-1597574182166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-6ef73ebc-6046-4181-944f-d6c5f336e9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-1ff934e9-9d42-4341-a6a0-006c96c0c85c,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-0ef63f0b-8448-4a26-a964-6a849e483b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-e9041527-03ea-42d3-b6aa-96a63fa2ad21,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-27cb2370-62ba-4ddc-a3af-13d58c629aee,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-eed920cf-07e6-4e9f-9277-fabb2555c0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-a1e9109b-777a-4b2d-b235-2a2f211b027e,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-ae34109d-451a-4db2-9a62-8ff9827c8dd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696062268-172.17.0.16-1597574302500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-31418d66-d4bf-4ead-8e0c-c8c38c903a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-ccbd0639-938c-4cb5-b3ca-a32647099275,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-5f86efb7-6e18-47ab-8b1c-482225f1c944,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-a2ecfe98-c25b-47e6-be57-c39d70f7862f,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-d0dc9b45-84c3-421e-89d9-b7850cf8cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-091ac120-dc18-436d-91b7-4b985571a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-1617b90c-340f-427a-a432-eeea0cf07126,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-be7ed05a-5377-4196-83cf-6907034b1502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696062268-172.17.0.16-1597574302500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-31418d66-d4bf-4ead-8e0c-c8c38c903a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-ccbd0639-938c-4cb5-b3ca-a32647099275,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-5f86efb7-6e18-47ab-8b1c-482225f1c944,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-a2ecfe98-c25b-47e6-be57-c39d70f7862f,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-d0dc9b45-84c3-421e-89d9-b7850cf8cc33,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-091ac120-dc18-436d-91b7-4b985571a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-1617b90c-340f-427a-a432-eeea0cf07126,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-be7ed05a-5377-4196-83cf-6907034b1502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24484654-172.17.0.16-1597574613443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-5826a95e-8fdc-4366-b6cb-6a100705d5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-fd73e54a-08fb-4a64-bb1b-2fdb5914c018,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-2dc99016-80ce-4755-a39b-b930c088d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-e12afca5-4d1b-4270-a04d-744e4bb673a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-ab61192a-781f-49eb-bfeb-4a53a8c49e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-fc25a749-6b08-402e-8727-082a87f6eb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-464e3faa-443c-4ef6-9536-265be7716e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-04d2f8d1-3dc2-4a49-a6c1-e8c76ef954ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24484654-172.17.0.16-1597574613443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-5826a95e-8fdc-4366-b6cb-6a100705d5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-fd73e54a-08fb-4a64-bb1b-2fdb5914c018,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-2dc99016-80ce-4755-a39b-b930c088d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-e12afca5-4d1b-4270-a04d-744e4bb673a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-ab61192a-781f-49eb-bfeb-4a53a8c49e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-fc25a749-6b08-402e-8727-082a87f6eb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-464e3faa-443c-4ef6-9536-265be7716e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-04d2f8d1-3dc2-4a49-a6c1-e8c76ef954ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5485
