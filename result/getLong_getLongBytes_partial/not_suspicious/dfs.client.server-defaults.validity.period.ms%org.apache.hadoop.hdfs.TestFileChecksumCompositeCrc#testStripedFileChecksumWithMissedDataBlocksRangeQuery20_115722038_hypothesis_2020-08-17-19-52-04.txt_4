reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560067371-172.17.0.20-1597694236817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-4724ed6e-b596-4bee-a838-4ae2dc792a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-421915e6-cde8-45df-9deb-0653b9c218af,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-774899f9-ca5d-45b0-ad89-40d54cdb4528,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-8d1479a3-7ca5-4623-a4c9-d5538eac1d95,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-6541e01d-6d0d-4974-bd43-cce5cd36ab8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-cc314a3d-2379-4eb4-8e2b-2133c6728c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-8b47f1d7-d27c-481a-a209-c1d3247f8410,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-4dd5b552-006e-41ca-97ff-f8e7338532b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560067371-172.17.0.20-1597694236817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-4724ed6e-b596-4bee-a838-4ae2dc792a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-421915e6-cde8-45df-9deb-0653b9c218af,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-774899f9-ca5d-45b0-ad89-40d54cdb4528,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-8d1479a3-7ca5-4623-a4c9-d5538eac1d95,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-6541e01d-6d0d-4974-bd43-cce5cd36ab8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-cc314a3d-2379-4eb4-8e2b-2133c6728c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-8b47f1d7-d27c-481a-a209-c1d3247f8410,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-4dd5b552-006e-41ca-97ff-f8e7338532b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946892550-172.17.0.20-1597694531493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46655,DS-9f5e250f-87e5-437a-adac-0a26675746a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-6d71f0ea-549e-43b8-8af5-ed5faa046dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-b39970b3-b4d9-47c1-9144-6addb3f44180,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-d2a386d3-bc94-4c35-b2f9-0b8f7eed2fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-8cf206eb-6818-4b71-9da1-db5c1561a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-da798cfb-5b83-45ae-b59f-b07f15749cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-b46be67c-4b66-4c9b-b59a-f4df92a40fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-46fd72a0-7c1b-402f-8147-2d3a31ebe91f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946892550-172.17.0.20-1597694531493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46655,DS-9f5e250f-87e5-437a-adac-0a26675746a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-6d71f0ea-549e-43b8-8af5-ed5faa046dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-b39970b3-b4d9-47c1-9144-6addb3f44180,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-d2a386d3-bc94-4c35-b2f9-0b8f7eed2fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-8cf206eb-6818-4b71-9da1-db5c1561a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-da798cfb-5b83-45ae-b59f-b07f15749cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-b46be67c-4b66-4c9b-b59a-f4df92a40fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-46fd72a0-7c1b-402f-8147-2d3a31ebe91f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444269846-172.17.0.20-1597694647098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-c3988a1c-69ce-446a-96e3-2b43d7bace19,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-99743d62-da46-444b-971e-745588a01a49,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-0c22dae3-31d1-46bd-88b6-d16395d9bd17,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-aced8b7a-b888-4e5b-87dd-1fedb0d10290,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-84477007-5479-4658-92fe-858f3f72d9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-5beb698a-0deb-4794-a33a-3e52892e7329,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-2ef0d473-92ec-4808-99d2-62beeb8113e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-b2a9657c-d199-4dea-b959-994a5b52d40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444269846-172.17.0.20-1597694647098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-c3988a1c-69ce-446a-96e3-2b43d7bace19,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-99743d62-da46-444b-971e-745588a01a49,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-0c22dae3-31d1-46bd-88b6-d16395d9bd17,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-aced8b7a-b888-4e5b-87dd-1fedb0d10290,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-84477007-5479-4658-92fe-858f3f72d9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-5beb698a-0deb-4794-a33a-3e52892e7329,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-2ef0d473-92ec-4808-99d2-62beeb8113e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-b2a9657c-d199-4dea-b959-994a5b52d40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923296828-172.17.0.20-1597694854119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41559,DS-73ba228d-ad50-4fef-8a8c-9a9a58ff3ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-bf4980d5-9754-4db2-931d-ca12b46a4f63,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-a87ab1a4-bfd6-44a1-87f9-22d05e45e938,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-e4c2599f-d84d-400d-8563-f65093b999c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-4923edde-4979-4cb5-9e1b-407333e772d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-249abf21-0073-4bba-89ad-92746c673418,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-087a5d4a-03b7-4451-a4ed-14d93a25265a,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-1c574e2a-165a-4949-ba81-291b51f18cb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923296828-172.17.0.20-1597694854119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41559,DS-73ba228d-ad50-4fef-8a8c-9a9a58ff3ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-bf4980d5-9754-4db2-931d-ca12b46a4f63,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-a87ab1a4-bfd6-44a1-87f9-22d05e45e938,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-e4c2599f-d84d-400d-8563-f65093b999c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-4923edde-4979-4cb5-9e1b-407333e772d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-249abf21-0073-4bba-89ad-92746c673418,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-087a5d4a-03b7-4451-a4ed-14d93a25265a,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-1c574e2a-165a-4949-ba81-291b51f18cb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133598616-172.17.0.20-1597695001559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35021,DS-23c6b303-6761-4691-95a7-35f88c1ee24b,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-be2685eb-19a5-43ab-b0a7-240c3c866464,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-a304cf87-d37e-45d9-a13d-069e160074fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-79758eaf-edce-4201-b289-f077eed9c65e,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-01a2f9aa-3301-4dd6-9019-9993be7b5f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-9956def0-8f4b-4ea2-9f1c-e261278c5a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-4780e83a-fcde-4a4a-a325-ba68b58aac2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-ed21cefc-c4bb-40bd-beff-43b73637f265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133598616-172.17.0.20-1597695001559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35021,DS-23c6b303-6761-4691-95a7-35f88c1ee24b,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-be2685eb-19a5-43ab-b0a7-240c3c866464,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-a304cf87-d37e-45d9-a13d-069e160074fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-79758eaf-edce-4201-b289-f077eed9c65e,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-01a2f9aa-3301-4dd6-9019-9993be7b5f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-9956def0-8f4b-4ea2-9f1c-e261278c5a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-4780e83a-fcde-4a4a-a325-ba68b58aac2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-ed21cefc-c4bb-40bd-beff-43b73637f265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369198189-172.17.0.20-1597695654722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-03605883-6c48-40bb-9f1b-eb5865e7031f,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-e3df8526-35b5-4afb-a056-f39232e381ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-79c24b97-2de4-4de9-9f30-583528eea608,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-308e7f0b-7fa0-47dc-ba9b-65acedde31d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-d8a360c5-3c72-46a0-857c-2a0199f5b564,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-7096414c-accb-47de-8581-c81473b90994,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-fda3dd0b-53ff-48c0-a695-3727a1cb5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-7cdb0b70-3eeb-4d5d-ab06-ae4e90d51fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369198189-172.17.0.20-1597695654722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-03605883-6c48-40bb-9f1b-eb5865e7031f,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-e3df8526-35b5-4afb-a056-f39232e381ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-79c24b97-2de4-4de9-9f30-583528eea608,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-308e7f0b-7fa0-47dc-ba9b-65acedde31d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-d8a360c5-3c72-46a0-857c-2a0199f5b564,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-7096414c-accb-47de-8581-c81473b90994,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-fda3dd0b-53ff-48c0-a695-3727a1cb5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-7cdb0b70-3eeb-4d5d-ab06-ae4e90d51fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646624065-172.17.0.20-1597696440846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35839,DS-42dde460-5c9e-4e57-a05e-8e80eddcf6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-88c7d251-3aec-4bf4-80a3-59dc14d5fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-c307b428-639c-490b-8a5a-d33ba356b7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-7edb60c0-cb93-4e8d-83ae-08e5019a7c90,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-59364ecf-8513-4e98-9a34-96b372b58afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-0d635220-9c37-47d9-bfba-607a106c5223,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-a40aca5f-147b-49f1-9d36-901d7797fc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-ac87033d-141d-47e0-8890-3880990f05d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646624065-172.17.0.20-1597696440846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35839,DS-42dde460-5c9e-4e57-a05e-8e80eddcf6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-88c7d251-3aec-4bf4-80a3-59dc14d5fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-c307b428-639c-490b-8a5a-d33ba356b7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-7edb60c0-cb93-4e8d-83ae-08e5019a7c90,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-59364ecf-8513-4e98-9a34-96b372b58afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-0d635220-9c37-47d9-bfba-607a106c5223,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-a40aca5f-147b-49f1-9d36-901d7797fc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-ac87033d-141d-47e0-8890-3880990f05d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635065764-172.17.0.20-1597696721257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-ca6b4121-a22c-496c-80d9-a88c00ffee69,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-e34524f5-82da-4224-9a95-d216cf13e6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-b084dff3-9f4e-4dcc-9e2c-f0bcae31c442,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-dfc5176a-0264-4310-92f2-f07fc3139d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-221251b4-d19b-434a-8078-f45813f4eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-bc17046e-fa79-4e8e-bfd1-de7aa8790af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-4f912203-55e7-493e-89ec-26670c3b32de,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-a83fdee6-25f0-4ad0-ad67-4feba7a3515b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635065764-172.17.0.20-1597696721257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-ca6b4121-a22c-496c-80d9-a88c00ffee69,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-e34524f5-82da-4224-9a95-d216cf13e6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-b084dff3-9f4e-4dcc-9e2c-f0bcae31c442,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-dfc5176a-0264-4310-92f2-f07fc3139d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-221251b4-d19b-434a-8078-f45813f4eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-bc17046e-fa79-4e8e-bfd1-de7aa8790af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-4f912203-55e7-493e-89ec-26670c3b32de,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-a83fdee6-25f0-4ad0-ad67-4feba7a3515b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962043590-172.17.0.20-1597697076520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42413,DS-743c0a98-b7ad-482f-b5c5-1cc3ab10285e,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-a6f14bd3-2966-47f0-a714-8f1c6866bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-992527b0-5ee8-45e2-8edc-078775437cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-98c8cc96-e662-46fa-bd2b-c27c988c09ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-1e6dc62a-6d75-4281-8bd9-51f0b2f7957f,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-444600b2-8062-4425-ae24-6524e567cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-6156489a-c065-41bf-b225-862fc2c9a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-4f8fdd5a-f578-4c35-a68b-cbb970a556f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962043590-172.17.0.20-1597697076520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42413,DS-743c0a98-b7ad-482f-b5c5-1cc3ab10285e,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-a6f14bd3-2966-47f0-a714-8f1c6866bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-992527b0-5ee8-45e2-8edc-078775437cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-98c8cc96-e662-46fa-bd2b-c27c988c09ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-1e6dc62a-6d75-4281-8bd9-51f0b2f7957f,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-444600b2-8062-4425-ae24-6524e567cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-6156489a-c065-41bf-b225-862fc2c9a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-4f8fdd5a-f578-4c35-a68b-cbb970a556f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090292458-172.17.0.20-1597697194323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-48d73ab3-7a16-44e9-a970-5251beed40e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-cc2d119f-8f8e-403e-b774-b733e65cf35b,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-7ddb61a4-854b-47dd-89ed-470d2e113c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-7dc7bd4d-106e-4b9b-a5cc-88e6ebbaa562,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-f1dac770-a308-4035-a180-3a9b3e8d28d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-52a72d76-525e-4f6c-8a1d-0d370c9be223,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-ca7a9d87-4380-48b3-a322-32835dd8536f,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-b804c9bc-95f7-437b-9174-2b68de991a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090292458-172.17.0.20-1597697194323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-48d73ab3-7a16-44e9-a970-5251beed40e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-cc2d119f-8f8e-403e-b774-b733e65cf35b,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-7ddb61a4-854b-47dd-89ed-470d2e113c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-7dc7bd4d-106e-4b9b-a5cc-88e6ebbaa562,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-f1dac770-a308-4035-a180-3a9b3e8d28d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-52a72d76-525e-4f6c-8a1d-0d370c9be223,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-ca7a9d87-4380-48b3-a322-32835dd8536f,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-b804c9bc-95f7-437b-9174-2b68de991a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814343223-172.17.0.20-1597697276314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37290,DS-51693bfb-5a38-4c1e-8ca8-8c128e9d71de,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-ac4d7c6f-9587-486a-8721-7bc7aea4b695,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-676da5fb-8483-4676-b8cb-276dd952f4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-e765b181-27e1-4997-b329-e1c64791b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-b3fa89a6-7990-40ea-9ab1-716106a70777,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-34e11f2e-5740-4b7d-97c8-bd2b11e9754e,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-47ae0e58-81b0-4d78-a245-4125944453b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-dbbf1508-7e7f-4f8f-b0c6-b0714047735d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814343223-172.17.0.20-1597697276314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37290,DS-51693bfb-5a38-4c1e-8ca8-8c128e9d71de,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-ac4d7c6f-9587-486a-8721-7bc7aea4b695,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-676da5fb-8483-4676-b8cb-276dd952f4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-e765b181-27e1-4997-b329-e1c64791b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-b3fa89a6-7990-40ea-9ab1-716106a70777,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-34e11f2e-5740-4b7d-97c8-bd2b11e9754e,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-47ae0e58-81b0-4d78-a245-4125944453b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-dbbf1508-7e7f-4f8f-b0c6-b0714047735d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233159056-172.17.0.20-1597697311726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-a1e61e28-1c2f-40b7-a40f-73cf5af9255f,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-e1ff2f3c-4ee0-40d6-b0c0-13ba9701d040,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-d07f782b-3950-41c7-96d8-f881692fec69,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-80770af2-b972-4d77-a88c-7a5d60081e57,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-478be256-c294-411a-b8cf-8ed7445387d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-251fdc8f-f122-480a-be88-a7dae546be26,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-6b7e66c0-191a-445e-9278-f49657fe1f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-bea44d9e-09b0-4f40-8345-7ad2c7513cc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233159056-172.17.0.20-1597697311726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-a1e61e28-1c2f-40b7-a40f-73cf5af9255f,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-e1ff2f3c-4ee0-40d6-b0c0-13ba9701d040,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-d07f782b-3950-41c7-96d8-f881692fec69,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-80770af2-b972-4d77-a88c-7a5d60081e57,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-478be256-c294-411a-b8cf-8ed7445387d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-251fdc8f-f122-480a-be88-a7dae546be26,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-6b7e66c0-191a-445e-9278-f49657fe1f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-bea44d9e-09b0-4f40-8345-7ad2c7513cc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308961185-172.17.0.20-1597697421202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-78ce2442-b99b-4c8f-9f63-f49bce2f0e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-5f69e52e-0974-45fa-b460-e7f5ed5de510,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-9b04e4c3-3e02-4891-9575-3a6ef9a518b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-07179a04-4f68-4759-b5a8-20acaa273267,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-07f8572e-1cfe-4d10-b7da-ae128fadd673,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-c39c9316-3e9a-494f-a401-a4f77165e893,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-c7c5fdd9-863c-491f-bbc1-a28466ec37d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-22a0d137-dd37-4922-b650-979d4a0e6672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308961185-172.17.0.20-1597697421202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-78ce2442-b99b-4c8f-9f63-f49bce2f0e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-5f69e52e-0974-45fa-b460-e7f5ed5de510,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-9b04e4c3-3e02-4891-9575-3a6ef9a518b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-07179a04-4f68-4759-b5a8-20acaa273267,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-07f8572e-1cfe-4d10-b7da-ae128fadd673,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-c39c9316-3e9a-494f-a401-a4f77165e893,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-c7c5fdd9-863c-491f-bbc1-a28466ec37d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-22a0d137-dd37-4922-b650-979d4a0e6672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835171241-172.17.0.20-1597697536765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34704,DS-c0101d1e-c822-451c-98f1-5a9719cb0af9,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-c741b10c-abbe-416a-8b58-618e9fa6be14,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-5396dbe3-d873-4ad9-a996-daffaf81fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-a04d0030-eef5-45b6-9bc7-497ca2196d32,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-2662183c-d523-4cbd-aa87-0c804af9d8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-c0eda6bb-ec7f-45cf-9c75-e7417b0714a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-82469d32-b03f-4267-99b9-2610391130f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-a0edb292-8b10-4ae8-8542-46251a5c7c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835171241-172.17.0.20-1597697536765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34704,DS-c0101d1e-c822-451c-98f1-5a9719cb0af9,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-c741b10c-abbe-416a-8b58-618e9fa6be14,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-5396dbe3-d873-4ad9-a996-daffaf81fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-a04d0030-eef5-45b6-9bc7-497ca2196d32,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-2662183c-d523-4cbd-aa87-0c804af9d8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-c0eda6bb-ec7f-45cf-9c75-e7417b0714a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-82469d32-b03f-4267-99b9-2610391130f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-a0edb292-8b10-4ae8-8542-46251a5c7c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209815940-172.17.0.20-1597698170217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-3b39fd3f-88a9-4a89-84b2-f341baf6ba6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-1281ba0f-2829-4bcb-96dc-ca5eb9e93d20,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-32a69afa-cdb9-4d82-9101-fa81c8327ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-6e8760b0-f686-404c-9b0b-96d41d63bb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-d66099a9-702c-49f6-aeac-789d9d094446,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-5854a369-215c-476f-b696-5917252b2c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-3c53dd39-a3f1-4df4-8afe-1dafec3df2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-20cf6760-e865-49e5-8498-37deb302760b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209815940-172.17.0.20-1597698170217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-3b39fd3f-88a9-4a89-84b2-f341baf6ba6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-1281ba0f-2829-4bcb-96dc-ca5eb9e93d20,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-32a69afa-cdb9-4d82-9101-fa81c8327ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-6e8760b0-f686-404c-9b0b-96d41d63bb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-d66099a9-702c-49f6-aeac-789d9d094446,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-5854a369-215c-476f-b696-5917252b2c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-3c53dd39-a3f1-4df4-8afe-1dafec3df2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-20cf6760-e865-49e5-8498-37deb302760b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547741650-172.17.0.20-1597698430291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40303,DS-c992e4e9-f871-415a-a129-3018cf63a8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-1dc55c0c-acfc-4a7e-b599-156524a70e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-67ee2575-c2fa-4e16-b59e-09679c5efb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-e1a198ff-6e1b-4f42-a040-706706f0b67a,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-c512990e-a6b0-415f-af1f-fd943531f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-757f906f-2078-4404-bc6a-a037151e1224,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-53520b5c-4213-4349-965d-7d4145cb2576,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-9993424f-33b4-496e-876e-de5fba4c43a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547741650-172.17.0.20-1597698430291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40303,DS-c992e4e9-f871-415a-a129-3018cf63a8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-1dc55c0c-acfc-4a7e-b599-156524a70e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-67ee2575-c2fa-4e16-b59e-09679c5efb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-e1a198ff-6e1b-4f42-a040-706706f0b67a,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-c512990e-a6b0-415f-af1f-fd943531f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-757f906f-2078-4404-bc6a-a037151e1224,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-53520b5c-4213-4349-965d-7d4145cb2576,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-9993424f-33b4-496e-876e-de5fba4c43a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400426197-172.17.0.20-1597698772869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37398,DS-04ba3a3f-5fa0-4bc5-adda-0d6c7c17d64c,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-8a5743ee-9737-4715-ae9f-85e5dec4e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-d544daa5-5a8d-456b-a055-017d269cf32c,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-9962f9bd-51be-4491-8ac9-96c8b9a8f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-2043ef1c-753c-4f96-8484-6dfdb11dba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-e6f08024-b08e-4a7f-a172-cb371e297e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-9d8fe51a-c724-4fd4-8471-a272791ce790,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-549e0cc1-54f4-4db3-923f-0a3f1bdf304c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400426197-172.17.0.20-1597698772869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37398,DS-04ba3a3f-5fa0-4bc5-adda-0d6c7c17d64c,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-8a5743ee-9737-4715-ae9f-85e5dec4e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-d544daa5-5a8d-456b-a055-017d269cf32c,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-9962f9bd-51be-4491-8ac9-96c8b9a8f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-2043ef1c-753c-4f96-8484-6dfdb11dba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-e6f08024-b08e-4a7f-a172-cb371e297e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-9d8fe51a-c724-4fd4-8471-a272791ce790,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-549e0cc1-54f4-4db3-923f-0a3f1bdf304c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33112288-172.17.0.20-1597699317472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-165c92dd-8d0f-41ad-917b-651be00dc0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-9eca36e3-80aa-462b-86cf-f8f249252962,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-b9089753-8aff-422a-84c7-edaca80c770a,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-b5b69aba-4e9b-421e-9b87-3509b82c7116,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-a10008ca-39d4-443e-8181-f34067b8481a,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-6d500120-ef77-4016-bcb4-ff2abf9b54cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-7d5df855-c6fa-4ddc-b11d-2305f17b8274,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-d2fd00fd-59b5-4813-b6e5-f0c3e2effbe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33112288-172.17.0.20-1597699317472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-165c92dd-8d0f-41ad-917b-651be00dc0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-9eca36e3-80aa-462b-86cf-f8f249252962,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-b9089753-8aff-422a-84c7-edaca80c770a,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-b5b69aba-4e9b-421e-9b87-3509b82c7116,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-a10008ca-39d4-443e-8181-f34067b8481a,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-6d500120-ef77-4016-bcb4-ff2abf9b54cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-7d5df855-c6fa-4ddc-b11d-2305f17b8274,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-d2fd00fd-59b5-4813-b6e5-f0c3e2effbe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835817347-172.17.0.20-1597699433255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36906,DS-b3726414-4c6d-4a8b-aee5-e7f327892a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-f8b084e9-baa4-470d-9d82-e4720e432ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-aa329a19-9ae8-407a-a051-cf4513b3d388,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-31c2474f-b8a0-46c2-ade1-86b18e9a6843,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-e812b9f5-ef6b-4af8-a22b-39aaf252e993,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-cb6c44f8-86ca-4ba6-a89d-cb83c5a79a35,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-75dd5630-e15f-4463-b80b-826637ce52ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-a364fedf-e4be-419b-aef2-8670589fe646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835817347-172.17.0.20-1597699433255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36906,DS-b3726414-4c6d-4a8b-aee5-e7f327892a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-f8b084e9-baa4-470d-9d82-e4720e432ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-aa329a19-9ae8-407a-a051-cf4513b3d388,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-31c2474f-b8a0-46c2-ade1-86b18e9a6843,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-e812b9f5-ef6b-4af8-a22b-39aaf252e993,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-cb6c44f8-86ca-4ba6-a89d-cb83c5a79a35,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-75dd5630-e15f-4463-b80b-826637ce52ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-a364fedf-e4be-419b-aef2-8670589fe646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5561
