reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496116-172.17.0.4-1597641610800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-a7719292-46d8-4b4a-870e-6548e8875762,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-d932b3c6-73e9-4266-8f21-d9afb2e46ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-4088eead-da6e-4ca9-a667-0abaf9ec9320,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-e45a5c0e-a39c-45e8-8053-1ef5ce80b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-e20668d1-c797-4cc3-ba65-dac8b1f6800c,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-59809532-4d09-40a6-bc15-2e689f9331b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-7c619c3b-e956-4348-9258-ccfd0161154e,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-99f774b9-54b1-438a-8fa8-646ba689d672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496116-172.17.0.4-1597641610800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-a7719292-46d8-4b4a-870e-6548e8875762,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-d932b3c6-73e9-4266-8f21-d9afb2e46ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-4088eead-da6e-4ca9-a667-0abaf9ec9320,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-e45a5c0e-a39c-45e8-8053-1ef5ce80b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-e20668d1-c797-4cc3-ba65-dac8b1f6800c,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-59809532-4d09-40a6-bc15-2e689f9331b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-7c619c3b-e956-4348-9258-ccfd0161154e,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-99f774b9-54b1-438a-8fa8-646ba689d672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356599479-172.17.0.4-1597641928922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-9ff9d747-e0a2-48be-82e5-cb19949ff1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-a38f7cde-94a9-4196-a6d0-ef82cdf3d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-4c893f4d-cca3-4393-ab2d-81c62568e230,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-ba6e608b-6f2e-481b-993b-284e6853c292,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-76922e5b-b73f-4728-a7b2-07adc0690be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-787258c1-8cf8-4ef5-8248-5998e67a0f66,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-b28c9b71-cdb7-4b38-aa03-094ff5bb6e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-0a0c6cba-b1cf-4370-bb8a-244c6882ca2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356599479-172.17.0.4-1597641928922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-9ff9d747-e0a2-48be-82e5-cb19949ff1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-a38f7cde-94a9-4196-a6d0-ef82cdf3d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-4c893f4d-cca3-4393-ab2d-81c62568e230,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-ba6e608b-6f2e-481b-993b-284e6853c292,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-76922e5b-b73f-4728-a7b2-07adc0690be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-787258c1-8cf8-4ef5-8248-5998e67a0f66,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-b28c9b71-cdb7-4b38-aa03-094ff5bb6e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-0a0c6cba-b1cf-4370-bb8a-244c6882ca2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841595067-172.17.0.4-1597642296703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-6cebe3ef-6f85-49b4-8ecd-599c9f603c46,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-d62b1710-300a-49f7-8a4c-942e8a520c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-a33f9d9c-9efc-4b86-a419-6d578c3814fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-21343075-3a8e-41f8-abef-7cf9f8a4fbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-9b444a1c-1a8d-42fc-8c32-2f1354c76a84,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-a42f857b-7f8b-468b-a9ff-457f81acfa28,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-b918927f-3d4d-4dd2-bb66-cb9adafbff96,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-dd3f0384-1da6-48fe-99d5-1269083e57c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841595067-172.17.0.4-1597642296703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-6cebe3ef-6f85-49b4-8ecd-599c9f603c46,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-d62b1710-300a-49f7-8a4c-942e8a520c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-a33f9d9c-9efc-4b86-a419-6d578c3814fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-21343075-3a8e-41f8-abef-7cf9f8a4fbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-9b444a1c-1a8d-42fc-8c32-2f1354c76a84,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-a42f857b-7f8b-468b-a9ff-457f81acfa28,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-b918927f-3d4d-4dd2-bb66-cb9adafbff96,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-dd3f0384-1da6-48fe-99d5-1269083e57c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937033094-172.17.0.4-1597642870233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-56a69fdd-78e9-49ee-9783-d26b2b1fb59c,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-7f6875c0-1e29-46fd-9418-7fe29b3bf17d,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-4624312f-5f67-4131-9650-f6df936e0e16,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-7c047e6e-c3b6-425f-812f-0f095212169b,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-4b6397ff-d9eb-4a0b-a4f9-2655381c018c,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-ae6870ed-e5a1-435d-884d-682300d2cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-6a8b69b0-b910-4260-aaab-3d87af0a5097,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-5613ad0d-70f1-4f19-8338-c691a3075012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937033094-172.17.0.4-1597642870233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36230,DS-56a69fdd-78e9-49ee-9783-d26b2b1fb59c,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-7f6875c0-1e29-46fd-9418-7fe29b3bf17d,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-4624312f-5f67-4131-9650-f6df936e0e16,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-7c047e6e-c3b6-425f-812f-0f095212169b,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-4b6397ff-d9eb-4a0b-a4f9-2655381c018c,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-ae6870ed-e5a1-435d-884d-682300d2cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-6a8b69b0-b910-4260-aaab-3d87af0a5097,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-5613ad0d-70f1-4f19-8338-c691a3075012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456676964-172.17.0.4-1597643095823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-fee5f5fc-95c8-4861-9c59-063e362e76d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-f4ed5f08-1158-4b3b-ac98-17a49f874f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-17d767d2-64ec-4177-91c6-21cdde384507,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-67566d41-839b-46de-975b-255ad7e6222b,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-e9575ab2-0477-4b1e-9f4a-c1abad3b7715,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-75febbaa-2889-43d2-83c6-4755937edeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-17efcb24-809f-4c5d-a549-2ea336a300d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-42a38b80-e2b4-4c8f-bfdd-0f15da5da0ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456676964-172.17.0.4-1597643095823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-fee5f5fc-95c8-4861-9c59-063e362e76d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-f4ed5f08-1158-4b3b-ac98-17a49f874f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-17d767d2-64ec-4177-91c6-21cdde384507,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-67566d41-839b-46de-975b-255ad7e6222b,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-e9575ab2-0477-4b1e-9f4a-c1abad3b7715,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-75febbaa-2889-43d2-83c6-4755937edeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-17efcb24-809f-4c5d-a549-2ea336a300d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-42a38b80-e2b4-4c8f-bfdd-0f15da5da0ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747257555-172.17.0.4-1597643367202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35557,DS-fb259442-f4a6-4dcc-a138-687bb3472608,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-84d73581-dd9f-4c75-b51b-483c62c65f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-c2e2e116-a62c-43d9-94f6-f8456add7718,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-8efb26bc-d003-4d6d-b84a-afd5233cdcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-f9f2570e-d691-4bf7-b5cf-a1ec54272e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-373218ed-93e8-4ba9-8eb6-d7611b1d3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-f6ff9091-dceb-4878-8389-093ba6179d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-20d56faa-f820-467d-8233-d1293b7a1b01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747257555-172.17.0.4-1597643367202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35557,DS-fb259442-f4a6-4dcc-a138-687bb3472608,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-84d73581-dd9f-4c75-b51b-483c62c65f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-c2e2e116-a62c-43d9-94f6-f8456add7718,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-8efb26bc-d003-4d6d-b84a-afd5233cdcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-f9f2570e-d691-4bf7-b5cf-a1ec54272e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-373218ed-93e8-4ba9-8eb6-d7611b1d3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-f6ff9091-dceb-4878-8389-093ba6179d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-20d56faa-f820-467d-8233-d1293b7a1b01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136648111-172.17.0.4-1597643557514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-44f9a030-1339-43af-be2e-fedd92519add,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-166ca7e5-d5eb-4f15-8f35-bb85fbac2ced,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-63d74f03-5188-4d44-b33f-5c694a5f50ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-313e2c11-3a62-474f-b63d-e098933bb056,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-1f4f8ae2-a48c-49bc-873f-4ae07a2ed95a,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-5a026078-dc82-46b9-807e-a4af217d27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-8058f015-280e-4bbd-a231-731b32c94ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-1348b177-7251-45c5-aafa-1257efea711a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136648111-172.17.0.4-1597643557514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-44f9a030-1339-43af-be2e-fedd92519add,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-166ca7e5-d5eb-4f15-8f35-bb85fbac2ced,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-63d74f03-5188-4d44-b33f-5c694a5f50ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-313e2c11-3a62-474f-b63d-e098933bb056,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-1f4f8ae2-a48c-49bc-873f-4ae07a2ed95a,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-5a026078-dc82-46b9-807e-a4af217d27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-8058f015-280e-4bbd-a231-731b32c94ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-1348b177-7251-45c5-aafa-1257efea711a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751972378-172.17.0.4-1597644193992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-a2691921-04f9-487a-83a7-68cd73f76f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-407e27d0-3f46-4d91-891e-9476ef9ad4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-dbee8cf1-e114-42d2-bc6e-957ad9e9857c,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-98618c5d-604d-4f11-89ac-45484a73c184,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-64f31b06-7292-4d29-bc7d-4a6f40673a47,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-e5f3e650-97f0-405e-92d8-551690545752,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-8a381cec-47bc-4724-a580-262325296a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-146cf1ee-cac1-47b2-8abe-c6349f75234d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751972378-172.17.0.4-1597644193992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-a2691921-04f9-487a-83a7-68cd73f76f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-407e27d0-3f46-4d91-891e-9476ef9ad4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-dbee8cf1-e114-42d2-bc6e-957ad9e9857c,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-98618c5d-604d-4f11-89ac-45484a73c184,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-64f31b06-7292-4d29-bc7d-4a6f40673a47,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-e5f3e650-97f0-405e-92d8-551690545752,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-8a381cec-47bc-4724-a580-262325296a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-146cf1ee-cac1-47b2-8abe-c6349f75234d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-524527602-172.17.0.4-1597644464251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38190,DS-596cecdd-57be-4f44-bb32-453778b0b566,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-20efbe3e-916a-470b-a356-f36ee3819e12,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-490937cd-09cc-448e-9513-2bd343b1e297,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-997008b7-ddae-4a0c-890a-73ab4c151b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-2005327f-c512-4b35-80a9-c344c709eed3,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-87269549-eb99-4b06-a5ad-b85159aa210e,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-9926eb28-096c-4266-92c6-c8b17feb078b,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-a8b3e2bf-ab45-4806-b832-3bce0363fedb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-524527602-172.17.0.4-1597644464251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38190,DS-596cecdd-57be-4f44-bb32-453778b0b566,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-20efbe3e-916a-470b-a356-f36ee3819e12,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-490937cd-09cc-448e-9513-2bd343b1e297,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-997008b7-ddae-4a0c-890a-73ab4c151b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-2005327f-c512-4b35-80a9-c344c709eed3,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-87269549-eb99-4b06-a5ad-b85159aa210e,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-9926eb28-096c-4266-92c6-c8b17feb078b,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-a8b3e2bf-ab45-4806-b832-3bce0363fedb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212411041-172.17.0.4-1597644892669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-c2855038-0769-4bdd-bc72-f53829a81695,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-e718046a-a50d-4a8e-b183-e4caa7e7963a,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-08bee636-88d1-49be-9554-6343ebca51b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-f8951ed2-155d-41f6-83f8-1ba1da289780,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-ab3d44e7-6789-4b06-9a94-94c8c2b9af00,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-e26b1ab6-202b-417c-9931-51b2e4fed4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-ae882c1a-a020-409d-a352-c6a9bf13082f,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-bb7108fc-0889-440a-89b8-5de88bbb4985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212411041-172.17.0.4-1597644892669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36645,DS-c2855038-0769-4bdd-bc72-f53829a81695,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-e718046a-a50d-4a8e-b183-e4caa7e7963a,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-08bee636-88d1-49be-9554-6343ebca51b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-f8951ed2-155d-41f6-83f8-1ba1da289780,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-ab3d44e7-6789-4b06-9a94-94c8c2b9af00,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-e26b1ab6-202b-417c-9931-51b2e4fed4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-ae882c1a-a020-409d-a352-c6a9bf13082f,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-bb7108fc-0889-440a-89b8-5de88bbb4985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400937058-172.17.0.4-1597645896161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-4fdfbf34-72d6-49ae-bf2f-24ac5fa0952b,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-a05674f8-bdb2-4beb-ac02-a83220399aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-625daa63-c766-4f96-a01e-34ea75d0c253,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-c0fb379b-1954-497a-a2c0-a0eec4bee133,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-4cb95601-1c05-4f8d-a3e1-4febf7827960,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-af6580b5-66f2-4833-b3c4-c5ed577afa91,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-759533a7-28e4-4535-b11f-e36aeac4883c,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-4efc8d79-3aa9-472c-b788-10965d2b7638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400937058-172.17.0.4-1597645896161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-4fdfbf34-72d6-49ae-bf2f-24ac5fa0952b,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-a05674f8-bdb2-4beb-ac02-a83220399aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-625daa63-c766-4f96-a01e-34ea75d0c253,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-c0fb379b-1954-497a-a2c0-a0eec4bee133,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-4cb95601-1c05-4f8d-a3e1-4febf7827960,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-af6580b5-66f2-4833-b3c4-c5ed577afa91,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-759533a7-28e4-4535-b11f-e36aeac4883c,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-4efc8d79-3aa9-472c-b788-10965d2b7638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035812780-172.17.0.4-1597646232110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33580,DS-039a17ce-59bd-498a-afd8-3e1978ea3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-a3b2df44-6b60-453c-b6ed-a0d014dc726f,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-ba380605-baff-4fa9-aa1e-b4553f626845,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-296329de-1ecb-4d79-9e27-1943d074eebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-2dd41868-2b1f-4f14-b3a5-6eb87758bb53,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-42769fa7-d0c5-4ea4-a2a1-028a4d628b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-b7a986ba-18c9-4f57-aee5-18ebab8602df,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-79615e36-a9c5-4d9f-8df4-7c432b42a546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035812780-172.17.0.4-1597646232110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33580,DS-039a17ce-59bd-498a-afd8-3e1978ea3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-a3b2df44-6b60-453c-b6ed-a0d014dc726f,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-ba380605-baff-4fa9-aa1e-b4553f626845,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-296329de-1ecb-4d79-9e27-1943d074eebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-2dd41868-2b1f-4f14-b3a5-6eb87758bb53,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-42769fa7-d0c5-4ea4-a2a1-028a4d628b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-b7a986ba-18c9-4f57-aee5-18ebab8602df,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-79615e36-a9c5-4d9f-8df4-7c432b42a546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5668
