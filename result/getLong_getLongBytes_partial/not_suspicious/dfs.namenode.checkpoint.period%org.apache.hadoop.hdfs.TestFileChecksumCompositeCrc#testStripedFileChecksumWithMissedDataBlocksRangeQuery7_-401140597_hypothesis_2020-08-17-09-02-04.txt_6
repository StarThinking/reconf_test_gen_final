reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448442448-172.17.0.19-1597655396863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-47259bb7-089d-47e2-9f30-f9f54b7d621e,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-c5b6e517-ffb0-4d43-9394-cc32a2cc4f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-47871591-1156-476c-adf8-166a7c870ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-b2d804b4-5013-4afc-ba3b-8e1d9730007a,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-10769e62-f6d3-491a-be2d-c340f258fb67,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-f2d72484-b209-4604-970e-e0a12b0b378f,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-64080877-1fb7-465c-b0aa-05476769b2de,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-d559be24-c53d-4acd-b8ec-a1bef24b7a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448442448-172.17.0.19-1597655396863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-47259bb7-089d-47e2-9f30-f9f54b7d621e,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-c5b6e517-ffb0-4d43-9394-cc32a2cc4f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-47871591-1156-476c-adf8-166a7c870ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-b2d804b4-5013-4afc-ba3b-8e1d9730007a,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-10769e62-f6d3-491a-be2d-c340f258fb67,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-f2d72484-b209-4604-970e-e0a12b0b378f,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-64080877-1fb7-465c-b0aa-05476769b2de,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-d559be24-c53d-4acd-b8ec-a1bef24b7a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087824865-172.17.0.19-1597655542137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-5a7427d7-90db-4ad3-ad02-c1b07a2b3359,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-61f0ae86-d713-4aa2-b28e-9fdc953a3817,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-a722bb4f-c0b9-4cb4-ae7c-aa33a2006b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-9558a363-5aba-4d19-980f-8819400ce82c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-43611fb9-f256-4aa5-82d6-21f52943d827,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-911b507d-aee8-45a5-b52e-8c0bf6761053,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-d0ffc8c6-f1e1-427f-bb26-3711c388c293,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-c26418d5-74d2-4859-8fe5-dc888a26550f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087824865-172.17.0.19-1597655542137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-5a7427d7-90db-4ad3-ad02-c1b07a2b3359,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-61f0ae86-d713-4aa2-b28e-9fdc953a3817,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-a722bb4f-c0b9-4cb4-ae7c-aa33a2006b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-9558a363-5aba-4d19-980f-8819400ce82c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-43611fb9-f256-4aa5-82d6-21f52943d827,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-911b507d-aee8-45a5-b52e-8c0bf6761053,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-d0ffc8c6-f1e1-427f-bb26-3711c388c293,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-c26418d5-74d2-4859-8fe5-dc888a26550f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776056258-172.17.0.19-1597655766718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-9628eaac-98f8-4576-86b7-5eb47e23d774,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-4f03ab49-cfe2-4faf-a94d-076cbea774f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-c525692b-ad99-4bcd-a0e0-88794e2267ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-8a90754a-83b3-4bb5-86a8-e7b27637776c,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-063f731e-cedc-4494-a343-89673ea34b05,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-d657c444-3b9c-4ba6-a3ec-3fcddd75cde9,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-10cae30b-0e47-40f0-845c-a682c7b1dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-2b1e6dc1-e55a-462b-bfbf-c3bb7ad1f86c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776056258-172.17.0.19-1597655766718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-9628eaac-98f8-4576-86b7-5eb47e23d774,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-4f03ab49-cfe2-4faf-a94d-076cbea774f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-c525692b-ad99-4bcd-a0e0-88794e2267ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-8a90754a-83b3-4bb5-86a8-e7b27637776c,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-063f731e-cedc-4494-a343-89673ea34b05,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-d657c444-3b9c-4ba6-a3ec-3fcddd75cde9,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-10cae30b-0e47-40f0-845c-a682c7b1dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-2b1e6dc1-e55a-462b-bfbf-c3bb7ad1f86c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956810177-172.17.0.19-1597655806842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-d5a5c83e-aada-4719-8132-572ece6cb781,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-6c62c7df-d595-4af1-9335-a91b5e4fb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-38eb0420-98fa-49e0-9740-d2b6ebf4e64a,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-e5524922-71ba-439c-a9ae-af42726841ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-0ddc2046-3624-4b1b-830b-e19b2cfc535f,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-8f229448-3f1f-4f88-aa58-72d64cfc917d,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-3121006f-d45b-4811-939b-ceb4bca32d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-6ecccc17-ab9c-4f8f-b395-2bee49b3e788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956810177-172.17.0.19-1597655806842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-d5a5c83e-aada-4719-8132-572ece6cb781,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-6c62c7df-d595-4af1-9335-a91b5e4fb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-38eb0420-98fa-49e0-9740-d2b6ebf4e64a,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-e5524922-71ba-439c-a9ae-af42726841ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-0ddc2046-3624-4b1b-830b-e19b2cfc535f,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-8f229448-3f1f-4f88-aa58-72d64cfc917d,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-3121006f-d45b-4811-939b-ceb4bca32d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-6ecccc17-ab9c-4f8f-b395-2bee49b3e788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884311650-172.17.0.19-1597656186370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-59bc7d6f-eb06-49b3-b6e4-d7a4c3bf2586,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-eac7f6ad-72de-4f0d-b60d-4ca2dfdc93dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-8e764247-3681-4f22-a0ed-9e623aa37e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-488943c1-e203-4bca-8958-3791ff582f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-64473dc8-7bae-4fb0-8ec4-3060bb4c3d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-afd7d522-3251-4a64-92eb-5762864586a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-56f476e6-956b-400c-b996-8d5b48a2aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-38ecb285-aeff-48f6-b512-de6db9ecb456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884311650-172.17.0.19-1597656186370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-59bc7d6f-eb06-49b3-b6e4-d7a4c3bf2586,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-eac7f6ad-72de-4f0d-b60d-4ca2dfdc93dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-8e764247-3681-4f22-a0ed-9e623aa37e18,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-488943c1-e203-4bca-8958-3791ff582f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-64473dc8-7bae-4fb0-8ec4-3060bb4c3d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-afd7d522-3251-4a64-92eb-5762864586a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-56f476e6-956b-400c-b996-8d5b48a2aff6,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-38ecb285-aeff-48f6-b512-de6db9ecb456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082047973-172.17.0.19-1597656594419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44590,DS-803a3ea5-d20e-41fc-833a-e8c6bd592183,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-55bfb594-7a77-4e3e-9af0-b387d05a52c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-06a5a90b-f46f-42ea-a746-6f5dc7d4fe4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-6919251a-865e-4a83-b169-ce9875d1dff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-3a7bd78e-c382-4b25-9ea9-30fa4ecbd3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-10aaa0dc-619f-42ad-ae76-052b83ab084f,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-e02e368f-f297-47ca-874a-4abe7eeff15a,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-2fd0b269-782d-4326-9373-b6b5330a5209,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082047973-172.17.0.19-1597656594419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44590,DS-803a3ea5-d20e-41fc-833a-e8c6bd592183,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-55bfb594-7a77-4e3e-9af0-b387d05a52c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-06a5a90b-f46f-42ea-a746-6f5dc7d4fe4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-6919251a-865e-4a83-b169-ce9875d1dff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-3a7bd78e-c382-4b25-9ea9-30fa4ecbd3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-10aaa0dc-619f-42ad-ae76-052b83ab084f,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-e02e368f-f297-47ca-874a-4abe7eeff15a,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-2fd0b269-782d-4326-9373-b6b5330a5209,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442860103-172.17.0.19-1597656672493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38170,DS-144aa008-7e5f-4976-9960-6572526e2395,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-7f8be9c2-77d9-445a-b42f-ab9290210770,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-8ec524e7-4e1d-4667-a972-24b65351b827,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-127b844f-f455-441f-ac32-f55705f6f439,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-4a269d82-7875-4a2b-a997-f122f12030bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-d6ec5638-c6c7-424d-948a-4e0afaa812a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-276924d0-8af8-410b-8be9-8748d4194a22,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-f6c50479-4257-464c-ae0f-d85ecd01a136,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442860103-172.17.0.19-1597656672493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38170,DS-144aa008-7e5f-4976-9960-6572526e2395,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-7f8be9c2-77d9-445a-b42f-ab9290210770,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-8ec524e7-4e1d-4667-a972-24b65351b827,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-127b844f-f455-441f-ac32-f55705f6f439,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-4a269d82-7875-4a2b-a997-f122f12030bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-d6ec5638-c6c7-424d-948a-4e0afaa812a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-276924d0-8af8-410b-8be9-8748d4194a22,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-f6c50479-4257-464c-ae0f-d85ecd01a136,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386707276-172.17.0.19-1597656985232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39753,DS-30d47579-7efa-43a7-b566-7d86dab2304f,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-66bb0ae2-2854-48ab-a3de-ce8420a8e2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-e597a36e-1d01-4ff9-b365-7dde2d23a8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-abb689b2-a604-4587-af3d-b21ee7d5d735,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-9ec1e369-7090-4a9d-a481-b59202f7969f,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-60f546e9-d562-4b8f-8590-d8d2489abd75,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-6b367f34-c7b1-4e81-b470-2e726e6d6637,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-2ba998e5-4323-4618-826c-619bac1d2ad0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386707276-172.17.0.19-1597656985232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39753,DS-30d47579-7efa-43a7-b566-7d86dab2304f,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-66bb0ae2-2854-48ab-a3de-ce8420a8e2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-e597a36e-1d01-4ff9-b365-7dde2d23a8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-abb689b2-a604-4587-af3d-b21ee7d5d735,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-9ec1e369-7090-4a9d-a481-b59202f7969f,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-60f546e9-d562-4b8f-8590-d8d2489abd75,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-6b367f34-c7b1-4e81-b470-2e726e6d6637,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-2ba998e5-4323-4618-826c-619bac1d2ad0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758371015-172.17.0.19-1597657022815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-b0e767bc-4cb7-4251-a397-21096edf1aac,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-0bfd8a85-2d53-4124-b968-98648146b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-bc6c7d04-56d0-4906-b2e1-59d33e22e0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-4b5ef439-dd6c-416b-9722-149061bfbf55,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-cbdcdbdd-bf60-4091-aa4a-8101f920a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-80ab4fad-2366-4a2b-83dc-072dbb3d311d,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-568f8760-ef2d-49e1-ad7d-9585784da688,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-45f69d2f-bdd9-4149-91d0-d79a514f22dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758371015-172.17.0.19-1597657022815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-b0e767bc-4cb7-4251-a397-21096edf1aac,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-0bfd8a85-2d53-4124-b968-98648146b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-bc6c7d04-56d0-4906-b2e1-59d33e22e0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-4b5ef439-dd6c-416b-9722-149061bfbf55,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-cbdcdbdd-bf60-4091-aa4a-8101f920a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-80ab4fad-2366-4a2b-83dc-072dbb3d311d,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-568f8760-ef2d-49e1-ad7d-9585784da688,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-45f69d2f-bdd9-4149-91d0-d79a514f22dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96957127-172.17.0.19-1597657112975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33311,DS-91d9db58-1768-4ba0-bbc8-ef31fb4ff311,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-52119bf8-f14a-44e5-a05e-cb5953909a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-4734eb71-9244-48f3-a84e-fd83881896cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-be829879-32b7-4966-8986-c65e53a5e011,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-34a31a96-cdb1-487d-8b59-664b3ca8216b,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-c15306ff-7df1-42fb-a01a-2de1905f7506,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-0ad04afd-3d2d-4301-bb69-331800f1ab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-028886e3-8a25-46de-85d0-b557641ad82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96957127-172.17.0.19-1597657112975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33311,DS-91d9db58-1768-4ba0-bbc8-ef31fb4ff311,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-52119bf8-f14a-44e5-a05e-cb5953909a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-4734eb71-9244-48f3-a84e-fd83881896cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-be829879-32b7-4966-8986-c65e53a5e011,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-34a31a96-cdb1-487d-8b59-664b3ca8216b,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-c15306ff-7df1-42fb-a01a-2de1905f7506,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-0ad04afd-3d2d-4301-bb69-331800f1ab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-028886e3-8a25-46de-85d0-b557641ad82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415636625-172.17.0.19-1597657230515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44017,DS-2d1e5915-9ffe-4143-a846-1e2ed29eb840,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-c384b831-1e37-4789-86fd-0a2abad9e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-3778f2cc-423d-459c-9489-a0a4142140d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-dfdf6d92-1f13-4474-a17e-2a2322054e80,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-e24a0b9b-fc2c-495c-9c92-425baf9d56db,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-af5bccf4-06b2-47f1-b1f1-63fc15c9b29a,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-c6f365c4-403b-4a2e-98c0-58ad688d48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-c1a6e1d2-0671-41f1-b41b-48d052312052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415636625-172.17.0.19-1597657230515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44017,DS-2d1e5915-9ffe-4143-a846-1e2ed29eb840,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-c384b831-1e37-4789-86fd-0a2abad9e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-3778f2cc-423d-459c-9489-a0a4142140d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-dfdf6d92-1f13-4474-a17e-2a2322054e80,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-e24a0b9b-fc2c-495c-9c92-425baf9d56db,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-af5bccf4-06b2-47f1-b1f1-63fc15c9b29a,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-c6f365c4-403b-4a2e-98c0-58ad688d48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-c1a6e1d2-0671-41f1-b41b-48d052312052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534930631-172.17.0.19-1597657992244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-081511ec-26fe-4982-a916-7d72c2e852df,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-ac5ec849-556e-4a85-92ce-33b6cd4edc98,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-1960079f-a045-4582-b14e-927cd6842247,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-c857f18d-85d5-467f-af53-fa3b6c02a5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-2c8655b7-e4e9-405b-ac37-bccef3f128fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-37a8271d-a82c-44d6-bbc3-29f48020ed95,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-b9633d76-ebc5-4d92-aba0-d37398cf57aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-4e83c4f5-aabf-435c-aa91-d41c9881d874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534930631-172.17.0.19-1597657992244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-081511ec-26fe-4982-a916-7d72c2e852df,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-ac5ec849-556e-4a85-92ce-33b6cd4edc98,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-1960079f-a045-4582-b14e-927cd6842247,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-c857f18d-85d5-467f-af53-fa3b6c02a5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-2c8655b7-e4e9-405b-ac37-bccef3f128fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-37a8271d-a82c-44d6-bbc3-29f48020ed95,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-b9633d76-ebc5-4d92-aba0-d37398cf57aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-4e83c4f5-aabf-435c-aa91-d41c9881d874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939659186-172.17.0.19-1597658146086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45174,DS-237b33d7-d504-406f-a89e-ac5eee7be7de,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-b76aa626-0ef2-412d-9ffe-fe5674839fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-f6970dd1-ed65-42a6-b539-a25010ba401e,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-71d6e708-34dc-4606-aa2e-e7ceae53bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-05d1dbb9-0b41-4b31-8388-de016c0ae0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-ae107fb3-696d-48ed-8e17-99ccea91309a,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-129191b6-e949-4072-acd6-68d461584bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-f02cd9dc-68de-4cb9-81f1-c08246ddfce4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939659186-172.17.0.19-1597658146086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45174,DS-237b33d7-d504-406f-a89e-ac5eee7be7de,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-b76aa626-0ef2-412d-9ffe-fe5674839fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-f6970dd1-ed65-42a6-b539-a25010ba401e,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-71d6e708-34dc-4606-aa2e-e7ceae53bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-05d1dbb9-0b41-4b31-8388-de016c0ae0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-ae107fb3-696d-48ed-8e17-99ccea91309a,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-129191b6-e949-4072-acd6-68d461584bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-f02cd9dc-68de-4cb9-81f1-c08246ddfce4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473216671-172.17.0.19-1597658466980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-78faa18f-0702-4d01-bc11-f9f4e4388be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-4a9ef9cd-b885-4e08-aef1-155058f7a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-e11ad14f-d38d-4f9b-87a5-7127b15415d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-dce7ca89-5156-4c2e-a3f3-c2489704517c,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-3b1e0ab8-a34f-44c7-9556-23731c4e7110,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-a1eaba57-fcb7-4368-a8dc-3ed439dac9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-52b1493c-6f18-4c8a-bf27-789aea82d4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-c798b349-bf58-40ca-830a-6afff21a22c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473216671-172.17.0.19-1597658466980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-78faa18f-0702-4d01-bc11-f9f4e4388be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-4a9ef9cd-b885-4e08-aef1-155058f7a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-e11ad14f-d38d-4f9b-87a5-7127b15415d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-dce7ca89-5156-4c2e-a3f3-c2489704517c,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-3b1e0ab8-a34f-44c7-9556-23731c4e7110,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-a1eaba57-fcb7-4368-a8dc-3ed439dac9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-52b1493c-6f18-4c8a-bf27-789aea82d4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-c798b349-bf58-40ca-830a-6afff21a22c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864803584-172.17.0.19-1597658722106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33960,DS-d2182c77-f269-4867-84e8-91397551c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-5228b54f-857f-40cf-b31f-cb0597537cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-9926b863-091f-4a6e-a5e6-5227b7837133,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-babe5b83-3309-4891-bc20-912bd41cab11,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-269f4b7c-0f03-49e8-8a45-691ff6a2b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-29cf1bd0-84ef-43cc-9f54-7f67209affd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-00bc5cec-fe33-4794-b960-b47b56c39e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-cd85573e-c423-4055-9a38-0a830c7ec288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864803584-172.17.0.19-1597658722106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33960,DS-d2182c77-f269-4867-84e8-91397551c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-5228b54f-857f-40cf-b31f-cb0597537cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-9926b863-091f-4a6e-a5e6-5227b7837133,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-babe5b83-3309-4891-bc20-912bd41cab11,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-269f4b7c-0f03-49e8-8a45-691ff6a2b4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-29cf1bd0-84ef-43cc-9f54-7f67209affd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-00bc5cec-fe33-4794-b960-b47b56c39e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-cd85573e-c423-4055-9a38-0a830c7ec288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417776955-172.17.0.19-1597658788073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-97b6e1be-e3fe-478a-8067-e734f120833d,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-247df3ac-f08a-4cd3-9bca-329bb02c59ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-0ae95363-345f-4f29-b309-98a3534c934e,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-cbaa02c8-42b7-4935-bab8-59a167037520,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-87a9ed45-52dc-4a26-8c32-5e7348fd97ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-8b4f0ad9-28bf-41a7-a6e9-6b8c0cb20a36,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-753602fa-30a5-4866-a714-19caddfb467a,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-885230bc-a180-4096-a3ab-a48632406d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417776955-172.17.0.19-1597658788073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-97b6e1be-e3fe-478a-8067-e734f120833d,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-247df3ac-f08a-4cd3-9bca-329bb02c59ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-0ae95363-345f-4f29-b309-98a3534c934e,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-cbaa02c8-42b7-4935-bab8-59a167037520,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-87a9ed45-52dc-4a26-8c32-5e7348fd97ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-8b4f0ad9-28bf-41a7-a6e9-6b8c0cb20a36,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-753602fa-30a5-4866-a714-19caddfb467a,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-885230bc-a180-4096-a3ab-a48632406d20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040962835-172.17.0.19-1597658947879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-20c35d0b-ec76-4a92-bd36-32ef672fa1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-d292b708-8a52-4386-ab81-d1cff8c0dcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-83310864-c795-47de-a651-89b97aa7117e,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-e96faa07-b0b1-44f6-85ec-17e7f706a85c,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-e3a46d45-60f8-43dd-aacb-54cb6a536982,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-91bf12cd-4d06-444e-97c3-81390db6b4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-fe765d32-7e36-4e7d-999c-914035815925,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-47de854e-dfcb-46b8-8fda-350256ddb8c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040962835-172.17.0.19-1597658947879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40271,DS-20c35d0b-ec76-4a92-bd36-32ef672fa1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-d292b708-8a52-4386-ab81-d1cff8c0dcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-83310864-c795-47de-a651-89b97aa7117e,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-e96faa07-b0b1-44f6-85ec-17e7f706a85c,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-e3a46d45-60f8-43dd-aacb-54cb6a536982,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-91bf12cd-4d06-444e-97c3-81390db6b4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-fe765d32-7e36-4e7d-999c-914035815925,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-47de854e-dfcb-46b8-8fda-350256ddb8c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315498666-172.17.0.19-1597658992139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-fd0a70f7-22c2-4258-ae77-d9699b95a621,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-d94d16c8-93e8-4caf-914a-3e9f4055472d,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-e2d06dbe-e4d0-4c45-b1d2-547a0cd67014,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-21d054ca-92cb-461c-91bd-943ddadd97a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-797dd933-bdc8-4d33-9eef-11a948046ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-81c25874-0a65-4922-ba79-78bd46fff09e,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-cccfac25-5644-47fe-baa4-2c173b801653,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-390cb5d9-e7ec-47c8-92fb-739b009bc43d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315498666-172.17.0.19-1597658992139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-fd0a70f7-22c2-4258-ae77-d9699b95a621,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-d94d16c8-93e8-4caf-914a-3e9f4055472d,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-e2d06dbe-e4d0-4c45-b1d2-547a0cd67014,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-21d054ca-92cb-461c-91bd-943ddadd97a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-797dd933-bdc8-4d33-9eef-11a948046ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-81c25874-0a65-4922-ba79-78bd46fff09e,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-cccfac25-5644-47fe-baa4-2c173b801653,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-390cb5d9-e7ec-47c8-92fb-739b009bc43d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412460587-172.17.0.19-1597659037186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42493,DS-34dc8e41-7d1a-4658-81f4-adc356c5bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-500dbb0f-6229-4664-9389-7cba74f37bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-71164667-a2b3-4fac-9c4c-6f98f812ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-aba1669b-0cb2-4819-bd8a-4ad07371a16b,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-70533a66-46b1-4eb1-9319-bdb4e4502e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-bcd00ece-e7d5-45d4-8395-9436546eaeda,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-b6b7467b-f470-49ca-b612-685985fe54da,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-8afdc843-9089-46e0-b693-20e40b892623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412460587-172.17.0.19-1597659037186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42493,DS-34dc8e41-7d1a-4658-81f4-adc356c5bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-500dbb0f-6229-4664-9389-7cba74f37bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-71164667-a2b3-4fac-9c4c-6f98f812ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-aba1669b-0cb2-4819-bd8a-4ad07371a16b,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-70533a66-46b1-4eb1-9319-bdb4e4502e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-bcd00ece-e7d5-45d4-8395-9436546eaeda,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-b6b7467b-f470-49ca-b612-685985fe54da,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-8afdc843-9089-46e0-b693-20e40b892623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193453069-172.17.0.19-1597659158625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-a8cb56ec-667b-4a94-8e97-a28dcbbfbf76,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-4f0d5b78-3ffe-4a57-bf86-45e5a128694d,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-e1de669f-ef05-4e34-a9e2-752880b1365a,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-fbce653f-4589-429c-9192-cd2bff7bdd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-297838fa-d195-4af3-abde-a7cb503149d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-0147ddc6-11a5-4522-ae07-7efd98bfbb91,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-4facae8e-eaa6-485d-bde3-6ce0a7fb5fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-b503b079-bf2d-4d3a-a882-558fc07c22f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193453069-172.17.0.19-1597659158625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-a8cb56ec-667b-4a94-8e97-a28dcbbfbf76,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-4f0d5b78-3ffe-4a57-bf86-45e5a128694d,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-e1de669f-ef05-4e34-a9e2-752880b1365a,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-fbce653f-4589-429c-9192-cd2bff7bdd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-297838fa-d195-4af3-abde-a7cb503149d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-0147ddc6-11a5-4522-ae07-7efd98bfbb91,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-4facae8e-eaa6-485d-bde3-6ce0a7fb5fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-b503b079-bf2d-4d3a-a882-558fc07c22f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716077917-172.17.0.19-1597659232262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-57becfec-4446-4dd0-9796-6f3b80bbba65,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-2c195f5b-65ee-48cd-873c-c5edcad83081,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-ce00855a-cc94-48e5-9186-ddfe37fbeb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-55c0a1e1-e8cd-4ab1-9144-2f84e9002c10,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-972d835f-fb70-4b5c-bf8a-687961f47d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-32e16bbe-51a1-4b12-b3ee-8b9d7d43cc82,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-d00ad1b0-f69a-4110-8dfd-54f6208d07f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-5ad6968e-ffb6-4fb7-8a69-d5254ab051b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716077917-172.17.0.19-1597659232262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-57becfec-4446-4dd0-9796-6f3b80bbba65,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-2c195f5b-65ee-48cd-873c-c5edcad83081,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-ce00855a-cc94-48e5-9186-ddfe37fbeb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-55c0a1e1-e8cd-4ab1-9144-2f84e9002c10,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-972d835f-fb70-4b5c-bf8a-687961f47d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-32e16bbe-51a1-4b12-b3ee-8b9d7d43cc82,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-d00ad1b0-f69a-4110-8dfd-54f6208d07f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-5ad6968e-ffb6-4fb7-8a69-d5254ab051b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971820179-172.17.0.19-1597659990675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43052,DS-b90aeb88-310e-49be-8c92-7a1eb9cc23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-45571db8-4b2c-4188-837a-090d25eadedc,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-c76cefdb-e896-4db9-a857-225efa481dea,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-12a5ce98-008a-475c-818b-6f6b965a2d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-33bb1af5-7941-4e85-956d-cc7047eb8b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-fe18ce4a-c1f5-49df-9d9d-1658590b65f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-5535a68b-1ef6-4187-8c33-be3311c7724e,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-20480d30-9db9-47b9-9026-482f753dbd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971820179-172.17.0.19-1597659990675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43052,DS-b90aeb88-310e-49be-8c92-7a1eb9cc23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-45571db8-4b2c-4188-837a-090d25eadedc,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-c76cefdb-e896-4db9-a857-225efa481dea,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-12a5ce98-008a-475c-818b-6f6b965a2d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-33bb1af5-7941-4e85-956d-cc7047eb8b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-fe18ce4a-c1f5-49df-9d9d-1658590b65f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-5535a68b-1ef6-4187-8c33-be3311c7724e,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-20480d30-9db9-47b9-9026-482f753dbd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37831013-172.17.0.19-1597660151376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-6d0ed951-415f-4a06-9bbf-49b972d0b402,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-d19ce800-1232-4291-b758-c9a1f1ccf79a,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-1a0d5139-6c03-41c8-a91c-e6959b49fb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-19c9e89e-9690-4754-abee-01b261652ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-da6f0c7e-ec2c-40eb-aaf3-b3674f0639c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-518c55e3-2f76-415a-a3bc-1da179aad39a,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-00abfca5-bfea-4a59-bec8-28602337273d,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-a4c20ef7-f729-4ba5-86c3-9abe6041aa5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37831013-172.17.0.19-1597660151376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-6d0ed951-415f-4a06-9bbf-49b972d0b402,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-d19ce800-1232-4291-b758-c9a1f1ccf79a,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-1a0d5139-6c03-41c8-a91c-e6959b49fb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-19c9e89e-9690-4754-abee-01b261652ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-da6f0c7e-ec2c-40eb-aaf3-b3674f0639c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-518c55e3-2f76-415a-a3bc-1da179aad39a,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-00abfca5-bfea-4a59-bec8-28602337273d,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-a4c20ef7-f729-4ba5-86c3-9abe6041aa5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189062706-172.17.0.19-1597660276278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-72d2285e-ff84-44f1-9be8-3d4efbf2a86a,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-197cab84-4dd1-499c-ae34-91d5ac8b7cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-07907c56-d348-4585-a35c-ebd716ff6379,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-4ca60c23-066a-4ad0-80e6-8741f8cd6298,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-48214654-4759-4661-a71a-ef89be8675f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-496faf77-a222-4bd6-a64a-87f0bdba7b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-db102673-8cf7-4e8e-9026-725feb5d9647,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-b96f32c9-2c98-4da6-89b5-ae3140d73556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189062706-172.17.0.19-1597660276278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-72d2285e-ff84-44f1-9be8-3d4efbf2a86a,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-197cab84-4dd1-499c-ae34-91d5ac8b7cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-07907c56-d348-4585-a35c-ebd716ff6379,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-4ca60c23-066a-4ad0-80e6-8741f8cd6298,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-48214654-4759-4661-a71a-ef89be8675f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-496faf77-a222-4bd6-a64a-87f0bdba7b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-db102673-8cf7-4e8e-9026-725feb5d9647,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-b96f32c9-2c98-4da6-89b5-ae3140d73556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3ms
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157009186-172.17.0.19-1597660628085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-571d4807-b986-4e83-9cca-bfd8efa7ab22,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-d92427d3-cdd8-4d41-8882-8c83cc2533f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-f3d334f1-b428-4a6e-a296-63b815635f65,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-88e4787b-41ec-47ee-83bb-841744645dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1e381f8b-0dfe-4f28-82d1-cf17d46436f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-413d59d9-9fa1-49fd-9ad5-b2d754ec75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-6271aff1-a1ab-4584-ab50-807f68113d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-a3825d18-7578-4399-8ca9-f7ddd4c3a4e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157009186-172.17.0.19-1597660628085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-571d4807-b986-4e83-9cca-bfd8efa7ab22,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-d92427d3-cdd8-4d41-8882-8c83cc2533f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-f3d334f1-b428-4a6e-a296-63b815635f65,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-88e4787b-41ec-47ee-83bb-841744645dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-1e381f8b-0dfe-4f28-82d1-cf17d46436f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-413d59d9-9fa1-49fd-9ad5-b2d754ec75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-6271aff1-a1ab-4584-ab50-807f68113d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-a3825d18-7578-4399-8ca9-f7ddd4c3a4e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5847
