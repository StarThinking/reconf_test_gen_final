reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168383002-172.17.0.16-1597708677219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-e2ff458a-d75f-4034-9552-97724861f4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-cbc8886b-1127-41fd-b508-d4a050c04923,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-6b3b3202-3d43-4f43-80ac-64f0b4208ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-68fd22a4-a7be-496c-a35c-0fb7975407fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-21b9f165-6c40-46b4-a3d0-3f8290f6a259,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-9b446fa3-b662-40c4-a3b7-68ecd292b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-b084587a-1a60-438c-96ca-b7f8d4b37cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-2ba4afb0-45e4-4323-a09e-0dcde639c269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168383002-172.17.0.16-1597708677219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-e2ff458a-d75f-4034-9552-97724861f4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-cbc8886b-1127-41fd-b508-d4a050c04923,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-6b3b3202-3d43-4f43-80ac-64f0b4208ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-68fd22a4-a7be-496c-a35c-0fb7975407fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-21b9f165-6c40-46b4-a3d0-3f8290f6a259,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-9b446fa3-b662-40c4-a3b7-68ecd292b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-b084587a-1a60-438c-96ca-b7f8d4b37cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-2ba4afb0-45e4-4323-a09e-0dcde639c269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607042460-172.17.0.16-1597709232886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35532,DS-ccec5248-0532-48fa-b558-b13165b086d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-54bd2bb7-b585-4cfe-a7d4-5132998a5d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-dd809d27-ce0e-4f11-bea7-0e796f5cda33,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-79de5c05-8a34-40b3-ab56-0e1bce55af3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-0f3e9231-39f5-4d1e-8129-4df69904ccbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-b58f8981-bc37-473a-97a7-a37d6839a1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-8ebd328b-5c8e-4be7-a227-df8e9b4f69e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-db8dc9c6-8964-4bdf-bffe-9f88e3df6f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607042460-172.17.0.16-1597709232886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35532,DS-ccec5248-0532-48fa-b558-b13165b086d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-54bd2bb7-b585-4cfe-a7d4-5132998a5d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-dd809d27-ce0e-4f11-bea7-0e796f5cda33,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-79de5c05-8a34-40b3-ab56-0e1bce55af3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-0f3e9231-39f5-4d1e-8129-4df69904ccbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-b58f8981-bc37-473a-97a7-a37d6839a1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-8ebd328b-5c8e-4be7-a227-df8e9b4f69e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-db8dc9c6-8964-4bdf-bffe-9f88e3df6f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119431143-172.17.0.16-1597709870456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-8aac0c35-bbe2-4f40-8624-a531ea1abaae,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-f4f405fe-7ff7-418a-80ef-6275046245fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-d3d3b649-e977-421f-858b-7a713bcb90ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-83154304-d42b-43c2-9a41-eae6cfdc184b,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-47cf6624-cca5-439d-b179-d07c43608fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-aaf1c389-208c-4303-b7f2-0b56369ad2af,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-f57cf865-3d5b-4eea-a165-beb9c7f548a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-0ddcbf6d-7a58-4ed4-bdb3-a02a309fbbb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119431143-172.17.0.16-1597709870456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40004,DS-8aac0c35-bbe2-4f40-8624-a531ea1abaae,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-f4f405fe-7ff7-418a-80ef-6275046245fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-d3d3b649-e977-421f-858b-7a713bcb90ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-83154304-d42b-43c2-9a41-eae6cfdc184b,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-47cf6624-cca5-439d-b179-d07c43608fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-aaf1c389-208c-4303-b7f2-0b56369ad2af,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-f57cf865-3d5b-4eea-a165-beb9c7f548a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-0ddcbf6d-7a58-4ed4-bdb3-a02a309fbbb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573181249-172.17.0.16-1597709924519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40188,DS-5a69faac-416a-49a6-a3b2-d752d79c1274,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-e6f0a88d-ff30-47af-85b2-ecfca85cef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-92edfcb7-f2ed-40d6-8c1a-632b7635d420,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-0a065719-956a-48ab-b42a-3b4045782674,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-1e576679-cb19-4100-a853-cf30b381592b,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-4790882b-dade-4c86-bb56-7ff4ce1a8199,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-8762fa5e-0626-4ecc-8e01-87be0fa5bdba,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-c2466642-7b8e-4c78-b491-e8eeed62ab6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573181249-172.17.0.16-1597709924519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40188,DS-5a69faac-416a-49a6-a3b2-d752d79c1274,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-e6f0a88d-ff30-47af-85b2-ecfca85cef5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-92edfcb7-f2ed-40d6-8c1a-632b7635d420,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-0a065719-956a-48ab-b42a-3b4045782674,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-1e576679-cb19-4100-a853-cf30b381592b,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-4790882b-dade-4c86-bb56-7ff4ce1a8199,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-8762fa5e-0626-4ecc-8e01-87be0fa5bdba,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-c2466642-7b8e-4c78-b491-e8eeed62ab6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160713155-172.17.0.16-1597710675667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37898,DS-bf545e17-9347-43ae-9d1d-f6961596cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-44a711af-aed6-4c47-a022-34d38f9fa9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8ae4ca2a-d38c-4a0c-9663-e07ac7b2f309,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-49f86ec4-02e1-4405-ae04-3b71e8ce86b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-fd76508c-1468-44ff-97f2-b478308bb6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-76f6a708-f671-4649-a74d-f7ee32bba645,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-6e06e136-c66d-494d-ae12-97641b35db97,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-ef83aca3-7d0b-40f8-a0ea-baea2d8b73c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160713155-172.17.0.16-1597710675667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37898,DS-bf545e17-9347-43ae-9d1d-f6961596cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-44a711af-aed6-4c47-a022-34d38f9fa9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8ae4ca2a-d38c-4a0c-9663-e07ac7b2f309,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-49f86ec4-02e1-4405-ae04-3b71e8ce86b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-fd76508c-1468-44ff-97f2-b478308bb6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-76f6a708-f671-4649-a74d-f7ee32bba645,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-6e06e136-c66d-494d-ae12-97641b35db97,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-ef83aca3-7d0b-40f8-a0ea-baea2d8b73c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323692003-172.17.0.16-1597712519527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-972b2d03-35a3-4577-a19d-126163a8186e,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-bd862012-31a1-455b-87aa-c71672b54403,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-df64b5a7-6f21-4fbe-be6e-399f7bb8df98,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-a31325bf-6908-4698-bab0-5d2d85c88dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-5d59f99d-67e3-48da-813b-8110feef7e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-12a014aa-9de3-4e47-b15e-6004ad95e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-5dad6832-fb58-4a79-9402-fb0ddbbc6986,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-11dc3c03-964e-40e4-a8db-8a86c6bbc9cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323692003-172.17.0.16-1597712519527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-972b2d03-35a3-4577-a19d-126163a8186e,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-bd862012-31a1-455b-87aa-c71672b54403,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-df64b5a7-6f21-4fbe-be6e-399f7bb8df98,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-a31325bf-6908-4698-bab0-5d2d85c88dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-5d59f99d-67e3-48da-813b-8110feef7e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-12a014aa-9de3-4e47-b15e-6004ad95e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-5dad6832-fb58-4a79-9402-fb0ddbbc6986,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-11dc3c03-964e-40e4-a8db-8a86c6bbc9cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9482310-172.17.0.16-1597712690307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37936,DS-ab1fd539-7861-4549-a6fb-1bf509e12821,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-19fdd22f-84b5-40a5-a22a-166d2fd1b5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-fa2eba7c-fd02-4cd1-a627-f709ecbe26e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-ef34cadd-1b16-48f4-b2ad-2dfcfeaf22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-d913f11d-564d-4529-a3ac-f5603b3e343e,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-aaabf976-d299-4308-9cdb-49dd71509f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-a9927e8a-647b-40e4-be44-98c1b791407a,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-e97d8eb5-3a1f-4ed5-92ab-792d9b751f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9482310-172.17.0.16-1597712690307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37936,DS-ab1fd539-7861-4549-a6fb-1bf509e12821,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-19fdd22f-84b5-40a5-a22a-166d2fd1b5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-fa2eba7c-fd02-4cd1-a627-f709ecbe26e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-ef34cadd-1b16-48f4-b2ad-2dfcfeaf22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-d913f11d-564d-4529-a3ac-f5603b3e343e,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-aaabf976-d299-4308-9cdb-49dd71509f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-a9927e8a-647b-40e4-be44-98c1b791407a,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-e97d8eb5-3a1f-4ed5-92ab-792d9b751f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553959982-172.17.0.16-1597713017506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33322,DS-6af9aefb-c744-40be-890b-72ada93b7ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-afc28c09-96e1-41d5-ae0a-ae978b42d8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-88a183c1-5bbe-419c-a974-3267f8abf0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-3c206e50-25ce-4bc7-b954-147d02d51610,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-938e50d6-7af6-4160-ba5f-bca4fa92cc99,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-ef8b17b2-d7ed-46f0-9394-133c82838834,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-93f9fe9b-2e65-4f13-bd82-a70c59d23cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-e8e5e529-4df0-4d59-b1a3-ad35ccfe5494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553959982-172.17.0.16-1597713017506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33322,DS-6af9aefb-c744-40be-890b-72ada93b7ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-afc28c09-96e1-41d5-ae0a-ae978b42d8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-88a183c1-5bbe-419c-a974-3267f8abf0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-3c206e50-25ce-4bc7-b954-147d02d51610,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-938e50d6-7af6-4160-ba5f-bca4fa92cc99,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-ef8b17b2-d7ed-46f0-9394-133c82838834,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-93f9fe9b-2e65-4f13-bd82-a70c59d23cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-e8e5e529-4df0-4d59-b1a3-ad35ccfe5494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39773560-172.17.0.16-1597713636773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43125,DS-1a473168-e53a-40eb-8794-266010192b98,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-987c949f-84b2-4ff2-ae78-e35759d56f91,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-c2601a16-a494-4d01-83d2-4d5d94a9c26a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-4376b39b-e521-41a0-89e2-11d8473ded30,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-d4e2ad22-585c-4385-a797-f7060a75f71a,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-ecb38afc-e33a-4c38-91d5-21a3ecb10453,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-7b8a462b-8aec-4693-9f07-ccea53cea268,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-7ca2d835-724e-4f1f-ba1e-b68e9288e66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39773560-172.17.0.16-1597713636773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43125,DS-1a473168-e53a-40eb-8794-266010192b98,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-987c949f-84b2-4ff2-ae78-e35759d56f91,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-c2601a16-a494-4d01-83d2-4d5d94a9c26a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-4376b39b-e521-41a0-89e2-11d8473ded30,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-d4e2ad22-585c-4385-a797-f7060a75f71a,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-ecb38afc-e33a-4c38-91d5-21a3ecb10453,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-7b8a462b-8aec-4693-9f07-ccea53cea268,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-7ca2d835-724e-4f1f-ba1e-b68e9288e66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019446782-172.17.0.16-1597713913507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-1ea8db7e-6491-4ec0-bf3a-2ff329625cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-ca3a1654-9838-46d5-a25f-ebd2a2a2e862,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-5bbd74bd-575a-49fb-8472-f1eb63b4df9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-07fcc2f1-5442-47c0-913a-7edb57019bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-6f927e00-4261-42c3-a954-4a6761f07ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-7f3a8c87-85c7-42b0-b8e1-8147d21dc4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-e730bf06-0cff-41ba-846b-de87a1f04c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-b77f17a9-6d7a-4405-aa0b-14bc8dbb806d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019446782-172.17.0.16-1597713913507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-1ea8db7e-6491-4ec0-bf3a-2ff329625cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-ca3a1654-9838-46d5-a25f-ebd2a2a2e862,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-5bbd74bd-575a-49fb-8472-f1eb63b4df9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-07fcc2f1-5442-47c0-913a-7edb57019bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-6f927e00-4261-42c3-a954-4a6761f07ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-7f3a8c87-85c7-42b0-b8e1-8147d21dc4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-e730bf06-0cff-41ba-846b-de87a1f04c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-b77f17a9-6d7a-4405-aa0b-14bc8dbb806d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791775035-172.17.0.16-1597714588485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-25e0f91e-6b64-4a3f-b10b-41823a9598e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-61f298b8-f544-4a77-9254-0409c5911139,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-eb9d8bc3-a6ca-4ccb-b9ea-44a0619966cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-40cc10f8-3a72-4126-afc6-57eb633defe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-08411dcc-f7b9-4842-ac05-859de12a198f,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-07600a72-d4f8-4e2a-8772-9ac58c0c99a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-71117e6a-1402-4987-a59c-0bfb09d53a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-b1e57c62-a23d-48eb-bd6d-8e88e9eff99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791775035-172.17.0.16-1597714588485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-25e0f91e-6b64-4a3f-b10b-41823a9598e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-61f298b8-f544-4a77-9254-0409c5911139,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-eb9d8bc3-a6ca-4ccb-b9ea-44a0619966cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-40cc10f8-3a72-4126-afc6-57eb633defe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-08411dcc-f7b9-4842-ac05-859de12a198f,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-07600a72-d4f8-4e2a-8772-9ac58c0c99a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-71117e6a-1402-4987-a59c-0bfb09d53a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-b1e57c62-a23d-48eb-bd6d-8e88e9eff99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166371787-172.17.0.16-1597714991770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36240,DS-cb0dc652-91ec-4143-9b07-f7469c1b6731,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-05127912-d329-4b02-8f34-4d053b4d99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-769b656c-15d5-418c-8061-5e7670dbf890,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-30a606f0-38c4-403a-9d5d-e19639030443,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-df08052e-7e95-47d7-8f07-a32bdd008c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-e87b3a18-11f8-4056-a423-9c7bcae289b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-0001433d-b05b-4d42-b33e-c439cb378a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-f5d6f932-8a21-4889-85e8-6f372689e360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166371787-172.17.0.16-1597714991770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36240,DS-cb0dc652-91ec-4143-9b07-f7469c1b6731,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-05127912-d329-4b02-8f34-4d053b4d99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-769b656c-15d5-418c-8061-5e7670dbf890,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-30a606f0-38c4-403a-9d5d-e19639030443,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-df08052e-7e95-47d7-8f07-a32bdd008c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-e87b3a18-11f8-4056-a423-9c7bcae289b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-0001433d-b05b-4d42-b33e-c439cb378a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-f5d6f932-8a21-4889-85e8-6f372689e360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742110472-172.17.0.16-1597715037503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36044,DS-345ba35d-289d-4490-9658-5aaf49686b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-60e990f3-fe27-4d58-9b2a-c8f0f667c8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-f2326552-017e-4e24-bf28-337f90fca5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-38534e36-3e6c-4aa2-b03d-f8a6fc947ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-a610daec-6324-4646-aabc-81da77e55ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-e8175dc9-b181-4444-a7c8-0257f4493e44,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-f890ac87-6390-43f2-a1f1-a25b5c3527ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-4091b766-a303-4a63-a683-451949f7b390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742110472-172.17.0.16-1597715037503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36044,DS-345ba35d-289d-4490-9658-5aaf49686b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-60e990f3-fe27-4d58-9b2a-c8f0f667c8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-f2326552-017e-4e24-bf28-337f90fca5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-38534e36-3e6c-4aa2-b03d-f8a6fc947ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-a610daec-6324-4646-aabc-81da77e55ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-e8175dc9-b181-4444-a7c8-0257f4493e44,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-f890ac87-6390-43f2-a1f1-a25b5c3527ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-4091b766-a303-4a63-a683-451949f7b390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 6999
