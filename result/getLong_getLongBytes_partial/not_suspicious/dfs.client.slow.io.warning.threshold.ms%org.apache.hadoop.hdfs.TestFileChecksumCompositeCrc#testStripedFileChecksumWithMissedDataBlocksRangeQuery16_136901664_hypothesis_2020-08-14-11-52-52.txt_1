reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905810108-172.17.0.5-1597406339671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45031,DS-db3c4abb-a98e-4dab-a4c7-a8277302a660,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-ce78dba3-6f76-4a06-9cd7-fe08d2caebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-a4ca3a5f-13af-4999-bd23-d79120d0c850,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-7d6de76b-68bd-408c-a635-5c77ae7a2c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-5e9ec93c-84f2-46cd-ae88-c39e75aa81d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-72593b5c-ae30-43bd-a3b9-1f775ebbd51a,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-af757a62-8ea5-4258-9646-7ceb39cc6ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-db1399be-c405-46b9-a198-d18760f1e0b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905810108-172.17.0.5-1597406339671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45031,DS-db3c4abb-a98e-4dab-a4c7-a8277302a660,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-ce78dba3-6f76-4a06-9cd7-fe08d2caebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-a4ca3a5f-13af-4999-bd23-d79120d0c850,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-7d6de76b-68bd-408c-a635-5c77ae7a2c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-5e9ec93c-84f2-46cd-ae88-c39e75aa81d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-72593b5c-ae30-43bd-a3b9-1f775ebbd51a,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-af757a62-8ea5-4258-9646-7ceb39cc6ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-db1399be-c405-46b9-a198-d18760f1e0b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451951665-172.17.0.5-1597406413520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32794,DS-d63b5a4d-7837-4149-befb-ed990c0ee91a,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-aa255e36-54cf-493b-b0c6-3d4568b84373,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-45fd8ddc-b0f5-438f-bbde-08b6c6bb591a,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-16ccd28a-c6da-4624-9568-a56fa190d9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-4e931d20-3489-4ac6-9d66-f297c506953b,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-97970c77-7bd1-4ad5-af31-26386d758ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-f10502d2-c7b9-415d-8570-440621641d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-9e907fb8-7841-4ccb-8883-84d5f32cd46d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451951665-172.17.0.5-1597406413520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32794,DS-d63b5a4d-7837-4149-befb-ed990c0ee91a,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-aa255e36-54cf-493b-b0c6-3d4568b84373,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-45fd8ddc-b0f5-438f-bbde-08b6c6bb591a,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-16ccd28a-c6da-4624-9568-a56fa190d9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-4e931d20-3489-4ac6-9d66-f297c506953b,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-97970c77-7bd1-4ad5-af31-26386d758ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-f10502d2-c7b9-415d-8570-440621641d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-9e907fb8-7841-4ccb-8883-84d5f32cd46d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591481781-172.17.0.5-1597406539791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-45bd0471-b8b6-4a1e-9dc4-41a35f87cf45,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-ca43b652-2bb1-462d-9e36-15fad344688b,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-7f5cc687-db37-4d07-806a-8d40e93ca8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-cf9ff62b-b6fa-4053-abd4-7d18439c4059,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-3dfd563d-e222-4702-8a02-d1c1a1bd77b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-0933acdb-90cd-4e4c-9d84-2bc165ee968e,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-1a70bfc8-06ea-4762-9424-6c689ba80117,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-bccdf511-c14c-481a-a58e-01b0a8571545,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591481781-172.17.0.5-1597406539791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-45bd0471-b8b6-4a1e-9dc4-41a35f87cf45,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-ca43b652-2bb1-462d-9e36-15fad344688b,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-7f5cc687-db37-4d07-806a-8d40e93ca8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-cf9ff62b-b6fa-4053-abd4-7d18439c4059,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-3dfd563d-e222-4702-8a02-d1c1a1bd77b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-0933acdb-90cd-4e4c-9d84-2bc165ee968e,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-1a70bfc8-06ea-4762-9424-6c689ba80117,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-bccdf511-c14c-481a-a58e-01b0a8571545,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133585715-172.17.0.5-1597406688704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36996,DS-89854872-3f65-4206-a705-3013755b5835,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-4c592a96-c1b4-4a54-82a1-ebca80293d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-9b6ed3da-87db-4033-9712-f507b74c649f,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-df4ef7e5-c0b1-42e2-96e1-78c92a8c1985,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-825f495f-fe1c-416f-888f-186a8b0fd22a,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-38095a8a-86b8-4a32-9988-cc5f6d005389,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-bb1d5f06-5d00-4b9f-8753-8f79bf9e1e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-8491a5e9-7181-4c2b-828f-e9bccf49bd34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133585715-172.17.0.5-1597406688704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36996,DS-89854872-3f65-4206-a705-3013755b5835,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-4c592a96-c1b4-4a54-82a1-ebca80293d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-9b6ed3da-87db-4033-9712-f507b74c649f,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-df4ef7e5-c0b1-42e2-96e1-78c92a8c1985,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-825f495f-fe1c-416f-888f-186a8b0fd22a,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-38095a8a-86b8-4a32-9988-cc5f6d005389,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-bb1d5f06-5d00-4b9f-8753-8f79bf9e1e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-8491a5e9-7181-4c2b-828f-e9bccf49bd34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948088953-172.17.0.5-1597407033239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35053,DS-b9b65c29-ae21-4d02-8fa6-92f322225ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-a2e2eb16-8aa2-4f10-b00c-c7f71ba64b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-47cc329d-d712-40c1-934b-f0fc95cb1336,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-1e6f4aec-4f9d-4251-bda1-b85ef81266bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-ab956654-f8a2-4948-950b-ee73c714589b,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-28c61b61-820c-4b64-805f-325e45136f53,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-104ff888-8058-4aab-b62c-69cf9c15159f,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-b8dbf7f1-7b7c-4f7a-8007-e4753d334311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948088953-172.17.0.5-1597407033239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35053,DS-b9b65c29-ae21-4d02-8fa6-92f322225ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-a2e2eb16-8aa2-4f10-b00c-c7f71ba64b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-47cc329d-d712-40c1-934b-f0fc95cb1336,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-1e6f4aec-4f9d-4251-bda1-b85ef81266bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-ab956654-f8a2-4948-950b-ee73c714589b,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-28c61b61-820c-4b64-805f-325e45136f53,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-104ff888-8058-4aab-b62c-69cf9c15159f,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-b8dbf7f1-7b7c-4f7a-8007-e4753d334311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436057337-172.17.0.5-1597407439856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42284,DS-02ab8d97-f624-444f-901e-72177eb50fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-81cb91ae-8abf-4c0b-89d7-fe874020a6be,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-8001850a-f8be-487f-a9c6-811ad109490d,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-548f1deb-7939-426a-91ef-4b8845b2cc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-7ddff08c-8dc9-4d2e-bd27-78aff07774d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-39488506-015d-419e-9381-45a8bce85da0,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-d6d7ebee-4538-44fc-841f-406fd97610b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-c201c611-ec7c-4d73-8d41-80fcc931086e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436057337-172.17.0.5-1597407439856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42284,DS-02ab8d97-f624-444f-901e-72177eb50fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-81cb91ae-8abf-4c0b-89d7-fe874020a6be,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-8001850a-f8be-487f-a9c6-811ad109490d,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-548f1deb-7939-426a-91ef-4b8845b2cc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-7ddff08c-8dc9-4d2e-bd27-78aff07774d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-39488506-015d-419e-9381-45a8bce85da0,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-d6d7ebee-4538-44fc-841f-406fd97610b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-c201c611-ec7c-4d73-8d41-80fcc931086e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247690954-172.17.0.5-1597407682206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41876,DS-cc9a4c5b-cc91-45df-9114-0888ab6d7b40,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-dedd60cc-1384-41e3-b5e0-4179b8bc467f,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-31687100-62f0-4ec1-aad0-3b3f0f4920df,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-a0ab922f-38f5-4fdf-b40b-4fce994ec09c,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-57b36345-a0ec-437f-b477-441144a9d1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-263c31ac-9653-49b5-84d6-32eca9681947,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-1e6f350b-3390-4104-8f8a-8f77d102ca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-45d2b58b-e3c5-4af3-b83f-8d84e4c76964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247690954-172.17.0.5-1597407682206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41876,DS-cc9a4c5b-cc91-45df-9114-0888ab6d7b40,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-dedd60cc-1384-41e3-b5e0-4179b8bc467f,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-31687100-62f0-4ec1-aad0-3b3f0f4920df,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-a0ab922f-38f5-4fdf-b40b-4fce994ec09c,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-57b36345-a0ec-437f-b477-441144a9d1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-263c31ac-9653-49b5-84d6-32eca9681947,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-1e6f350b-3390-4104-8f8a-8f77d102ca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-45d2b58b-e3c5-4af3-b83f-8d84e4c76964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791454945-172.17.0.5-1597407879074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39591,DS-af91793b-7c15-4fcb-983e-bbabd0bb0702,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-e14ebc3e-9b88-4f07-add7-7c37f395b183,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-651968da-4c1a-411c-9ddb-6da4979c19fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-3eeb9483-70f7-4f8f-a027-6b305f11e949,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-29d67a7b-c945-4030-95e0-2d660f0b9d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-2488fedd-7be4-4f60-a424-91cd8591ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-ce0fd6ab-f183-4443-81d3-ba99b281c683,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-d0f50707-e5cd-4136-bad0-c1cd549cec22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791454945-172.17.0.5-1597407879074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39591,DS-af91793b-7c15-4fcb-983e-bbabd0bb0702,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-e14ebc3e-9b88-4f07-add7-7c37f395b183,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-651968da-4c1a-411c-9ddb-6da4979c19fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-3eeb9483-70f7-4f8f-a027-6b305f11e949,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-29d67a7b-c945-4030-95e0-2d660f0b9d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-2488fedd-7be4-4f60-a424-91cd8591ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-ce0fd6ab-f183-4443-81d3-ba99b281c683,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-d0f50707-e5cd-4136-bad0-c1cd549cec22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930594511-172.17.0.5-1597407920707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38300,DS-593a1d5a-5c87-4b9a-b100-e218b8f7bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-569a6a07-207e-4f9d-88c3-f37bc32fa1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-483d67db-fcba-4fc0-9fb8-ec2e74412e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-5651bfb6-6195-4e6e-8a5b-7f72852cca72,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-103b4506-016b-4360-90b1-9276ed2c89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-1d256be0-5d21-4c1c-a7f4-aaa05717a440,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-da0bcd5d-da3f-434c-b8c0-c8cf58571c49,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-decf4389-2cbd-4b1b-b640-560d47fd3b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930594511-172.17.0.5-1597407920707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38300,DS-593a1d5a-5c87-4b9a-b100-e218b8f7bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-569a6a07-207e-4f9d-88c3-f37bc32fa1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-483d67db-fcba-4fc0-9fb8-ec2e74412e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-5651bfb6-6195-4e6e-8a5b-7f72852cca72,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-103b4506-016b-4360-90b1-9276ed2c89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-1d256be0-5d21-4c1c-a7f4-aaa05717a440,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-da0bcd5d-da3f-434c-b8c0-c8cf58571c49,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-decf4389-2cbd-4b1b-b640-560d47fd3b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350810740-172.17.0.5-1597408187566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-7c90d61b-5509-454b-beb4-d0164d32d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-a87d0109-1edc-4df0-80b8-c7b2236ff606,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-78269582-de4f-475c-bc83-330f333542d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-06ad798b-6341-46e1-bbbc-d6221449852d,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-f670949a-5b58-4068-9c99-464ae56eb553,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-9fcc8573-0f41-4b98-a228-870930661f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-d15bb677-5e28-45a9-a477-6550ade5e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-3cecfd98-c867-4da7-bb59-02e964a00163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350810740-172.17.0.5-1597408187566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-7c90d61b-5509-454b-beb4-d0164d32d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-a87d0109-1edc-4df0-80b8-c7b2236ff606,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-78269582-de4f-475c-bc83-330f333542d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-06ad798b-6341-46e1-bbbc-d6221449852d,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-f670949a-5b58-4068-9c99-464ae56eb553,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-9fcc8573-0f41-4b98-a228-870930661f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-d15bb677-5e28-45a9-a477-6550ade5e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-3cecfd98-c867-4da7-bb59-02e964a00163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639321286-172.17.0.5-1597408615957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-9b816b7c-4352-48f3-8c26-f369bfd87991,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-059324d4-d1e7-47ae-b69c-478342068378,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-699f4bb7-a584-4bfb-a38a-89833bf762a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-adf27dc5-99ec-4c37-bff1-f397b18846d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-f1d9e7e0-f42d-41d4-8b69-3cb6056428db,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-40918650-bc5a-49c2-98cb-8d88b1aff796,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-7b5be4bb-7c1d-4b29-bf24-b5d9867e55f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-597ab37d-c0f7-44dd-a990-3ada85162b6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639321286-172.17.0.5-1597408615957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-9b816b7c-4352-48f3-8c26-f369bfd87991,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-059324d4-d1e7-47ae-b69c-478342068378,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-699f4bb7-a584-4bfb-a38a-89833bf762a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-adf27dc5-99ec-4c37-bff1-f397b18846d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-f1d9e7e0-f42d-41d4-8b69-3cb6056428db,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-40918650-bc5a-49c2-98cb-8d88b1aff796,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-7b5be4bb-7c1d-4b29-bf24-b5d9867e55f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-597ab37d-c0f7-44dd-a990-3ada85162b6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403168789-172.17.0.5-1597408868105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40628,DS-cc7fc02f-8ead-4ea7-8748-5a2729298fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-84048c2c-8ced-49d4-ab20-b82138c49b07,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-35a9cf73-c2ef-420d-a033-e95e56109012,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-0dedaf7c-04e4-47f9-8a04-68dcb450f541,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-3a552872-cd61-4f43-bc15-475118ab26dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-a1f8a3c4-a9d0-4e12-ac97-d0f750cf1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-fe660f3a-148f-4fa4-90e7-c372e20b6dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-d75c5532-db25-4059-b6b1-64d2c0a8cb82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403168789-172.17.0.5-1597408868105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40628,DS-cc7fc02f-8ead-4ea7-8748-5a2729298fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-84048c2c-8ced-49d4-ab20-b82138c49b07,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-35a9cf73-c2ef-420d-a033-e95e56109012,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-0dedaf7c-04e4-47f9-8a04-68dcb450f541,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-3a552872-cd61-4f43-bc15-475118ab26dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-a1f8a3c4-a9d0-4e12-ac97-d0f750cf1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-fe660f3a-148f-4fa4-90e7-c372e20b6dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-d75c5532-db25-4059-b6b1-64d2c0a8cb82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-698168396-172.17.0.5-1597408907218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38609,DS-d5af9868-4958-44d7-82eb-1cc8b4dc6a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-a33b6da0-33ec-425e-8c84-4e174085a66e,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-72719801-ca1c-4480-85ee-67aa3deb750c,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-ab6c8c13-ddb2-4330-bf50-875834d4b339,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-5c57a143-907a-41ed-994a-90b5153bd41d,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-265f3386-6f30-4d35-bae4-9e54ab9451bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-eccfdab2-9677-4d0a-8581-cde518495c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-e807042b-804a-4707-ab3a-a1eae9310735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-698168396-172.17.0.5-1597408907218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38609,DS-d5af9868-4958-44d7-82eb-1cc8b4dc6a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-a33b6da0-33ec-425e-8c84-4e174085a66e,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-72719801-ca1c-4480-85ee-67aa3deb750c,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-ab6c8c13-ddb2-4330-bf50-875834d4b339,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-5c57a143-907a-41ed-994a-90b5153bd41d,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-265f3386-6f30-4d35-bae4-9e54ab9451bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-eccfdab2-9677-4d0a-8581-cde518495c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-e807042b-804a-4707-ab3a-a1eae9310735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756409545-172.17.0.5-1597409250570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-a151501a-b548-4ccd-a835-91bced93b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-bfc3825d-7fc1-4962-a7fa-a782d735e793,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-257b6f3a-cbff-41fd-aa24-9affc3c298b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-08ea9405-a4c7-41ec-a624-27b82d437fad,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-c923ba36-3067-4557-ac3a-7bfbcef797fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-a4ac383e-7198-45ad-adca-697ed229442b,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-b85efac6-9d1e-47bf-bd9e-5fc20abc4656,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-085430bf-bb9e-45ef-8e30-c75f330acc42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756409545-172.17.0.5-1597409250570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-a151501a-b548-4ccd-a835-91bced93b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-bfc3825d-7fc1-4962-a7fa-a782d735e793,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-257b6f3a-cbff-41fd-aa24-9affc3c298b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-08ea9405-a4c7-41ec-a624-27b82d437fad,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-c923ba36-3067-4557-ac3a-7bfbcef797fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-a4ac383e-7198-45ad-adca-697ed229442b,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-b85efac6-9d1e-47bf-bd9e-5fc20abc4656,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-085430bf-bb9e-45ef-8e30-c75f330acc42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519069238-172.17.0.5-1597409327386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-b72b056d-1011-4ebc-85bc-f320463ed0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-6b11f47b-fe34-4eb3-b987-0f5a07f9079b,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-f5017333-ce30-4cd0-9953-e2b75c2c3889,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-cd039a7e-18b8-426b-a87e-ade2b3a3ade9,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-6c2ab60b-5881-43f3-bb5c-e0530a3afcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-84ec68f4-50c4-4e08-97ba-cd7b010b3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-86411267-d875-4954-970f-2c9dcc4efb90,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-d5088268-8fdd-4a29-9f36-d164a1e84a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519069238-172.17.0.5-1597409327386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-b72b056d-1011-4ebc-85bc-f320463ed0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-6b11f47b-fe34-4eb3-b987-0f5a07f9079b,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-f5017333-ce30-4cd0-9953-e2b75c2c3889,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-cd039a7e-18b8-426b-a87e-ade2b3a3ade9,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-6c2ab60b-5881-43f3-bb5c-e0530a3afcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-84ec68f4-50c4-4e08-97ba-cd7b010b3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-86411267-d875-4954-970f-2c9dcc4efb90,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-d5088268-8fdd-4a29-9f36-d164a1e84a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248440590-172.17.0.5-1597409787537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35534,DS-70bdc2d7-eccf-4a00-b4ce-a92ccf4b0278,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-ec0cf719-36e2-41c1-9d63-31051b86a224,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-e2dbd888-a85d-449a-8dab-09d5c75d75a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-9d924c7a-6782-45c2-a5bb-ea7a3d5655a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-79d2cfe5-47e9-431d-ac2b-ca682e36c03d,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-4f7dbb7a-689f-4ec7-96f5-f02e9c2cb1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-710fcd49-a562-469d-b0d8-c90766420cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-be07001e-4165-436f-b6d4-f1ea0a4f8dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248440590-172.17.0.5-1597409787537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35534,DS-70bdc2d7-eccf-4a00-b4ce-a92ccf4b0278,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-ec0cf719-36e2-41c1-9d63-31051b86a224,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-e2dbd888-a85d-449a-8dab-09d5c75d75a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-9d924c7a-6782-45c2-a5bb-ea7a3d5655a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-79d2cfe5-47e9-431d-ac2b-ca682e36c03d,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-4f7dbb7a-689f-4ec7-96f5-f02e9c2cb1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-710fcd49-a562-469d-b0d8-c90766420cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-be07001e-4165-436f-b6d4-f1ea0a4f8dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017967954-172.17.0.5-1597409827591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-10f34082-8bb4-455f-a7bd-2a371b5731f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-ab71cf1a-5c05-4cb1-be2e-23441a3fd657,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-91321e4c-86c2-47c6-be91-9a514daee6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-a7f23a46-3226-4ded-a675-d5aead3f73d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-8a8b80ab-716c-4bc9-9777-aeff3d115db2,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-5db54f32-89c4-4cd2-a7c0-2935893c0d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-a8d7b6da-7d44-49ce-8e2d-9564f2a38349,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-8246a287-d1e4-49c5-a5f1-d049d936e65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017967954-172.17.0.5-1597409827591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-10f34082-8bb4-455f-a7bd-2a371b5731f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-ab71cf1a-5c05-4cb1-be2e-23441a3fd657,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-91321e4c-86c2-47c6-be91-9a514daee6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-a7f23a46-3226-4ded-a675-d5aead3f73d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-8a8b80ab-716c-4bc9-9777-aeff3d115db2,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-5db54f32-89c4-4cd2-a7c0-2935893c0d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-a8d7b6da-7d44-49ce-8e2d-9564f2a38349,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-8246a287-d1e4-49c5-a5f1-d049d936e65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216301035-172.17.0.5-1597410166721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46582,DS-e54f25f7-905d-4a18-90c7-83e57e75bde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-a4086261-ca70-4b32-b927-20ba32dcbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-e96f0906-b84e-4559-b609-641431df645c,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-b6e146f8-4deb-4658-8e48-c97161be4c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-2c129ebd-5b54-4000-9086-4135ad60477a,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-3cd8bafa-e77b-4b74-85ef-3b1265ce22d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-08766bb7-c5e3-42e1-8de4-e325fb921ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-b8069821-4867-4325-a55b-33d26ac63b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216301035-172.17.0.5-1597410166721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46582,DS-e54f25f7-905d-4a18-90c7-83e57e75bde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-a4086261-ca70-4b32-b927-20ba32dcbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-e96f0906-b84e-4559-b609-641431df645c,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-b6e146f8-4deb-4658-8e48-c97161be4c22,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-2c129ebd-5b54-4000-9086-4135ad60477a,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-3cd8bafa-e77b-4b74-85ef-3b1265ce22d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-08766bb7-c5e3-42e1-8de4-e325fb921ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-b8069821-4867-4325-a55b-33d26ac63b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225619061-172.17.0.5-1597411059323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-7b7a0512-a092-4373-a5b3-0e720d7dd430,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-94d2f5b6-04fd-4355-849f-52a22a744f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-683223f4-655d-48cc-972e-0bb41244649c,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-850330ab-54cf-4954-9459-f0feb0a36baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-3daaa8ca-f40a-4ff5-9774-4ce82bd6c646,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-bddba683-5d19-4ff3-a8c5-00d9dc549330,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-868c5a13-9235-4f51-a370-5a0f486d84b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-914f0168-9d89-4515-9adc-67aac94464e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225619061-172.17.0.5-1597411059323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-7b7a0512-a092-4373-a5b3-0e720d7dd430,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-94d2f5b6-04fd-4355-849f-52a22a744f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-683223f4-655d-48cc-972e-0bb41244649c,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-850330ab-54cf-4954-9459-f0feb0a36baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-3daaa8ca-f40a-4ff5-9774-4ce82bd6c646,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-bddba683-5d19-4ff3-a8c5-00d9dc549330,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-868c5a13-9235-4f51-a370-5a0f486d84b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-914f0168-9d89-4515-9adc-67aac94464e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487958914-172.17.0.5-1597411575224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38432,DS-0fc4f718-d341-41d5-9fd4-a539359a1e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-d7215a3f-6049-4269-92f4-52f2c9859e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-9c90b05d-20c6-472b-83df-ac3bfa8105d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-9597de95-43cd-4d58-a997-5831606a50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-405d24ee-8dd1-4283-9550-7ace1f434045,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-32cdcee2-b63e-4924-bf63-9434f4bf3ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-1d0807f2-944f-427f-bc5d-19c7aa349947,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-0c068766-7d78-494e-b33e-f791862d6944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487958914-172.17.0.5-1597411575224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38432,DS-0fc4f718-d341-41d5-9fd4-a539359a1e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-d7215a3f-6049-4269-92f4-52f2c9859e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-9c90b05d-20c6-472b-83df-ac3bfa8105d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-9597de95-43cd-4d58-a997-5831606a50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-405d24ee-8dd1-4283-9550-7ace1f434045,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-32cdcee2-b63e-4924-bf63-9434f4bf3ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-1d0807f2-944f-427f-bc5d-19c7aa349947,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-0c068766-7d78-494e-b33e-f791862d6944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047498456-172.17.0.5-1597411612243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-63dd021b-d3ff-4c75-8b9b-8aa149da98b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-23bf40af-08a3-4096-b22c-5c33d3bcca18,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-7f730ec6-5b80-48ec-bff2-7b985c7355d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-d2d22147-f953-467b-bd30-8953eb144730,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-7e9e0618-c6a6-4493-96f9-14b938d64fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-1f29baf7-f08b-4321-a450-4b84b3d1ed28,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-dd6f20a5-2823-49f8-97e8-4b18b44f5c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-19e7d4b8-eec0-4cc4-b061-9c57fd399fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047498456-172.17.0.5-1597411612243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-63dd021b-d3ff-4c75-8b9b-8aa149da98b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-23bf40af-08a3-4096-b22c-5c33d3bcca18,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-7f730ec6-5b80-48ec-bff2-7b985c7355d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-d2d22147-f953-467b-bd30-8953eb144730,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-7e9e0618-c6a6-4493-96f9-14b938d64fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-1f29baf7-f08b-4321-a450-4b84b3d1ed28,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-dd6f20a5-2823-49f8-97e8-4b18b44f5c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-19e7d4b8-eec0-4cc4-b061-9c57fd399fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5698
