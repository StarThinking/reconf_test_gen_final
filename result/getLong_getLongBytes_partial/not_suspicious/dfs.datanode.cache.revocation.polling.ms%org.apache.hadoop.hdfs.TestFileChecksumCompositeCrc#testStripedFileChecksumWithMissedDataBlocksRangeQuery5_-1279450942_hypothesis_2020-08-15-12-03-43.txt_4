reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534545834-172.17.0.3-1597493036692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45229,DS-1f89ae0b-15b8-4e1a-a647-31494ce4dd02,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-9e532ec8-00a6-4a60-929d-7d595ca9d490,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-8235c2ad-77c8-4048-a5e2-90d96d3a28cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-9ecaab01-6b94-44df-910e-e903cc683756,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-15684921-b084-4444-9f97-d6c75222b1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-a49678ba-f3a2-4974-9191-5bd8ad9a07fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-b9f34dd0-da71-4e06-9f8c-a57ff1f15e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-3ec7731b-a4f7-4223-84ca-1b07b90f781a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534545834-172.17.0.3-1597493036692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45229,DS-1f89ae0b-15b8-4e1a-a647-31494ce4dd02,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-9e532ec8-00a6-4a60-929d-7d595ca9d490,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-8235c2ad-77c8-4048-a5e2-90d96d3a28cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-9ecaab01-6b94-44df-910e-e903cc683756,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-15684921-b084-4444-9f97-d6c75222b1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-a49678ba-f3a2-4974-9191-5bd8ad9a07fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-b9f34dd0-da71-4e06-9f8c-a57ff1f15e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-3ec7731b-a4f7-4223-84ca-1b07b90f781a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804186562-172.17.0.3-1597493843489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-9bfc7e31-5a85-41fd-97f8-486fd7c827f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-5a68b773-8f71-460c-822b-d07d3f47e3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-db18da51-2ac5-4d8e-8429-8b49eae34c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-d9c17980-184b-4317-953b-1fa7d7503d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-a4279be8-6a32-4716-965d-1cf27b9238b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-deb3088b-408b-4560-ba9f-ad60d52ccc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-72ac8c1c-2e1f-4701-bcc7-f3b9a21817f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-8feae4ac-3d5e-44b0-ad2c-c228fb743090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804186562-172.17.0.3-1597493843489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-9bfc7e31-5a85-41fd-97f8-486fd7c827f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-5a68b773-8f71-460c-822b-d07d3f47e3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-db18da51-2ac5-4d8e-8429-8b49eae34c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-d9c17980-184b-4317-953b-1fa7d7503d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-a4279be8-6a32-4716-965d-1cf27b9238b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-deb3088b-408b-4560-ba9f-ad60d52ccc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-72ac8c1c-2e1f-4701-bcc7-f3b9a21817f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-8feae4ac-3d5e-44b0-ad2c-c228fb743090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780688980-172.17.0.3-1597493958392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35360,DS-8ef5f2ef-c554-4eea-a0fb-96237b3921d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-a4b5c742-7ef7-4836-a7ec-d082d8b9dc25,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-b5de5230-29f2-4c8b-8618-cccebeafb36b,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-d94fc384-359e-4680-937f-f0b940b510b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-abe0476e-9290-4002-b8ff-342808eb8cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-bfd1ef16-91c6-46f1-b43c-625fc7d03325,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-3a6380b1-649a-4c9b-8dd1-eef171c84b99,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-e60d81c3-8400-4f32-97df-3975129f74e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780688980-172.17.0.3-1597493958392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35360,DS-8ef5f2ef-c554-4eea-a0fb-96237b3921d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-a4b5c742-7ef7-4836-a7ec-d082d8b9dc25,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-b5de5230-29f2-4c8b-8618-cccebeafb36b,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-d94fc384-359e-4680-937f-f0b940b510b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-abe0476e-9290-4002-b8ff-342808eb8cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-bfd1ef16-91c6-46f1-b43c-625fc7d03325,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-3a6380b1-649a-4c9b-8dd1-eef171c84b99,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-e60d81c3-8400-4f32-97df-3975129f74e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050742414-172.17.0.3-1597494067249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39465,DS-97037bde-6efe-4774-bc63-8d7d7196df06,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-0b2c5fbf-e220-4948-9f58-a565bada9049,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-240cb530-9ea4-4316-953d-b739375d4fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-c1c2081d-4c91-45fd-976d-875588ed596b,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-3793d79e-017f-49dd-a7d1-44aa32d766fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-ead52d8b-e2c4-4431-8788-00186fe42525,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-06844a9a-3c86-4be3-923c-cb8c5ae3a9de,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-97931178-7652-4c32-8447-9ff1063554c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050742414-172.17.0.3-1597494067249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39465,DS-97037bde-6efe-4774-bc63-8d7d7196df06,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-0b2c5fbf-e220-4948-9f58-a565bada9049,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-240cb530-9ea4-4316-953d-b739375d4fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-c1c2081d-4c91-45fd-976d-875588ed596b,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-3793d79e-017f-49dd-a7d1-44aa32d766fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-ead52d8b-e2c4-4431-8788-00186fe42525,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-06844a9a-3c86-4be3-923c-cb8c5ae3a9de,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-97931178-7652-4c32-8447-9ff1063554c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644173386-172.17.0.3-1597494224497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46343,DS-cc638afd-c324-4604-9797-d059c579d955,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-39faf731-f798-4b16-ade4-6178055b7983,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-d4d812b9-7264-423f-bb6c-2116018bed65,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-8e7480a3-7db1-49b8-9fc2-b005be7dc956,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-b3500f3f-543d-4eec-84dc-758eed3e28b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-217cb9d2-6d1d-48e3-b284-5c0174faf3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-a7ba8cd4-088b-4a1a-b8ca-875ea7afd998,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-210c9732-22db-4e13-9d12-a8fb0b1ea738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644173386-172.17.0.3-1597494224497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46343,DS-cc638afd-c324-4604-9797-d059c579d955,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-39faf731-f798-4b16-ade4-6178055b7983,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-d4d812b9-7264-423f-bb6c-2116018bed65,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-8e7480a3-7db1-49b8-9fc2-b005be7dc956,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-b3500f3f-543d-4eec-84dc-758eed3e28b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-217cb9d2-6d1d-48e3-b284-5c0174faf3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-a7ba8cd4-088b-4a1a-b8ca-875ea7afd998,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-210c9732-22db-4e13-9d12-a8fb0b1ea738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707631621-172.17.0.3-1597494963155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-9798cf3e-9665-41a3-97bb-c0b5fbb59d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-26e6f4fc-90e2-431e-9307-3442a804ef14,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-500de239-b185-4ce4-952e-0bfbcdbe4b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-06638c47-c437-4cef-aa8e-0499f73b8d55,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-ccdf9c3f-ca89-4cf9-8dd1-78540574996c,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-c84416c9-af69-4b51-8616-161018c22b08,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-7438a1c4-f067-468d-9443-67f143bc10d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-700d6445-60c2-4c3e-a4cc-8ab4d0a8293c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707631621-172.17.0.3-1597494963155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-9798cf3e-9665-41a3-97bb-c0b5fbb59d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-26e6f4fc-90e2-431e-9307-3442a804ef14,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-500de239-b185-4ce4-952e-0bfbcdbe4b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-06638c47-c437-4cef-aa8e-0499f73b8d55,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-ccdf9c3f-ca89-4cf9-8dd1-78540574996c,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-c84416c9-af69-4b51-8616-161018c22b08,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-7438a1c4-f067-468d-9443-67f143bc10d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-700d6445-60c2-4c3e-a4cc-8ab4d0a8293c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271182754-172.17.0.3-1597495254224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-72d1bf32-ca87-4117-afc5-a11244f628ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-c0ef5ef7-fbf3-4ce9-b821-ed07d6676785,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-3bad306b-1918-4687-a23c-2933435d5bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-40e56d3a-7290-458c-8da5-e5cadbe783b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-05274ffb-3cc3-4dea-b71b-81208a80c86f,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-acf57849-3917-4e59-97e0-7d6ab95a9baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-3941269e-ade4-4a9b-82de-71f6257b812d,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-a898f655-0b45-4a39-90cf-972e1889a160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271182754-172.17.0.3-1597495254224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-72d1bf32-ca87-4117-afc5-a11244f628ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-c0ef5ef7-fbf3-4ce9-b821-ed07d6676785,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-3bad306b-1918-4687-a23c-2933435d5bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-40e56d3a-7290-458c-8da5-e5cadbe783b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-05274ffb-3cc3-4dea-b71b-81208a80c86f,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-acf57849-3917-4e59-97e0-7d6ab95a9baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-3941269e-ade4-4a9b-82de-71f6257b812d,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-a898f655-0b45-4a39-90cf-972e1889a160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231417675-172.17.0.3-1597495443796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-e92daccd-e6c0-4a44-998b-cfdcff14d193,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-8fe44bb4-105a-49b8-b7fb-2acd67c8588b,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-68a906ed-b2c7-48ba-b901-e8806677060b,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-93e97d0f-7d72-4ce9-aafb-9ed105419535,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-e07bc115-b680-460f-8b5c-8db87f264115,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-7cdd2459-3f30-40d8-8edd-c38cb083f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-be64c7b9-75eb-4d88-af99-5994a87f5329,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-9e2e2bda-e2f1-4e68-ab20-098fd72b3045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231417675-172.17.0.3-1597495443796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-e92daccd-e6c0-4a44-998b-cfdcff14d193,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-8fe44bb4-105a-49b8-b7fb-2acd67c8588b,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-68a906ed-b2c7-48ba-b901-e8806677060b,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-93e97d0f-7d72-4ce9-aafb-9ed105419535,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-e07bc115-b680-460f-8b5c-8db87f264115,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-7cdd2459-3f30-40d8-8edd-c38cb083f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-be64c7b9-75eb-4d88-af99-5994a87f5329,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-9e2e2bda-e2f1-4e68-ab20-098fd72b3045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34171476-172.17.0.3-1597496008187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46009,DS-5f332ce5-91c4-4d95-a601-d417cb623895,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-92f723be-0df5-4021-ba25-2c41ee938f81,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-5a16cd51-6776-4663-b321-ee97cbe1ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-4e13ed4c-bf1d-43f8-abeb-36f87b6211ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-8845fa26-0f29-4d59-8c8e-e6724dc44daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-bce019cb-7c85-4ae7-9262-adbe96da8fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-d3a60050-b624-445b-8fd4-6319c3c69354,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-36535944-8b62-4fb2-8994-a419594fb78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34171476-172.17.0.3-1597496008187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46009,DS-5f332ce5-91c4-4d95-a601-d417cb623895,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-92f723be-0df5-4021-ba25-2c41ee938f81,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-5a16cd51-6776-4663-b321-ee97cbe1ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-4e13ed4c-bf1d-43f8-abeb-36f87b6211ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-8845fa26-0f29-4d59-8c8e-e6724dc44daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-bce019cb-7c85-4ae7-9262-adbe96da8fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-d3a60050-b624-445b-8fd4-6319c3c69354,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-36535944-8b62-4fb2-8994-a419594fb78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120012097-172.17.0.3-1597496395675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-77dcd169-3846-4dc5-bb33-2f6bf2788206,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-65b0661f-7b34-4d71-a2fa-972351fce3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-92cee0a7-1cc9-4638-b669-4c0ecb809c28,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-57c66bf3-3ff9-453c-a79f-ccb5f1333933,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-cf6a747a-e153-4557-b759-267a80f0cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-ebf2d77b-3aed-424d-9ad5-8e7b8921587f,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-5b3f1255-d9e5-41a1-b1f8-dd25fb96d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-a34aec2b-628c-41c2-bf5b-69024d01385b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120012097-172.17.0.3-1597496395675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-77dcd169-3846-4dc5-bb33-2f6bf2788206,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-65b0661f-7b34-4d71-a2fa-972351fce3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-92cee0a7-1cc9-4638-b669-4c0ecb809c28,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-57c66bf3-3ff9-453c-a79f-ccb5f1333933,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-cf6a747a-e153-4557-b759-267a80f0cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-ebf2d77b-3aed-424d-9ad5-8e7b8921587f,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-5b3f1255-d9e5-41a1-b1f8-dd25fb96d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-a34aec2b-628c-41c2-bf5b-69024d01385b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095256262-172.17.0.3-1597496654765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40045,DS-7f492946-cc0c-49b9-95cc-f63c78394acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-28d6936e-ec0f-4e98-ad1c-8d9d05cddfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-3d936686-93d8-40b5-83fd-610184ed6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-9a031175-49f1-4be5-ba0a-56f009f6b9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-14ed7063-571e-4268-a3c7-ede9b87f8dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-7a6919f7-1acd-4aac-b7a9-fde330a509c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-e7a590a0-760b-47bc-954c-01e486e6bce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-b42834b8-c481-4236-8274-a656696bbc9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095256262-172.17.0.3-1597496654765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40045,DS-7f492946-cc0c-49b9-95cc-f63c78394acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-28d6936e-ec0f-4e98-ad1c-8d9d05cddfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-3d936686-93d8-40b5-83fd-610184ed6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-9a031175-49f1-4be5-ba0a-56f009f6b9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-14ed7063-571e-4268-a3c7-ede9b87f8dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-7a6919f7-1acd-4aac-b7a9-fde330a509c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-e7a590a0-760b-47bc-954c-01e486e6bce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-b42834b8-c481-4236-8274-a656696bbc9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233820030-172.17.0.3-1597496809313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-7563c6dd-7767-4101-8f40-b02a0ed3122f,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-ee51eb67-4462-4aef-89fc-74c1b966275f,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-a6d3dfb0-240a-4529-9c40-f3a79840a08d,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-b2740ed3-237c-49c1-a3e2-5806e1e9f120,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-79e6900f-012e-4cab-a3aa-ec124b6a09b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-246577e3-7c72-449f-a38f-9a9050c9280d,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-d5fe05ce-7a96-4963-b07a-0b487d6f6f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-f446f291-1ae1-4eb3-9eb1-15927327288d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233820030-172.17.0.3-1597496809313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-7563c6dd-7767-4101-8f40-b02a0ed3122f,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-ee51eb67-4462-4aef-89fc-74c1b966275f,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-a6d3dfb0-240a-4529-9c40-f3a79840a08d,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-b2740ed3-237c-49c1-a3e2-5806e1e9f120,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-79e6900f-012e-4cab-a3aa-ec124b6a09b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-246577e3-7c72-449f-a38f-9a9050c9280d,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-d5fe05ce-7a96-4963-b07a-0b487d6f6f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-f446f291-1ae1-4eb3-9eb1-15927327288d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511367055-172.17.0.3-1597496987756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44672,DS-91177917-db05-480d-b0c5-5da400a07510,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-e1d540dd-eb96-4feb-bb56-bb01f8e9c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-2ef89460-679a-4ff5-b2d2-0403fb16ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-8c939717-054c-4c12-8d76-e0c6b5f0c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-08c55329-967b-45c9-b8b4-4efff80b0c33,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-5bae66f3-dacf-404b-b865-4e37abcc2807,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-49bb1df3-ad16-4cdf-ae95-bbb485e0873b,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-e7fe10cc-b7be-4b92-8a23-37c2b6168b94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511367055-172.17.0.3-1597496987756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44672,DS-91177917-db05-480d-b0c5-5da400a07510,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-e1d540dd-eb96-4feb-bb56-bb01f8e9c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-2ef89460-679a-4ff5-b2d2-0403fb16ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-8c939717-054c-4c12-8d76-e0c6b5f0c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-08c55329-967b-45c9-b8b4-4efff80b0c33,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-5bae66f3-dacf-404b-b865-4e37abcc2807,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-49bb1df3-ad16-4cdf-ae95-bbb485e0873b,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-e7fe10cc-b7be-4b92-8a23-37c2b6168b94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082901248-172.17.0.3-1597497057848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-e0a19a14-9495-493f-9d86-ab8c970df6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-8dfe8aaa-b984-4185-8065-c3e1b25aa8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-0e85af18-d19f-4bb7-9278-07d957c01c00,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-1a68123d-4aae-400a-a8de-b23f7945b30f,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-b1e49697-bd94-418f-9619-b0229b93ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-5e889640-5f11-427f-9145-6cd26a2ac9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-0c4280b3-8a15-4741-af2e-cfe8d56dd99e,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-50c345de-726b-4e05-a8b6-ce778222a339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082901248-172.17.0.3-1597497057848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-e0a19a14-9495-493f-9d86-ab8c970df6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-8dfe8aaa-b984-4185-8065-c3e1b25aa8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-0e85af18-d19f-4bb7-9278-07d957c01c00,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-1a68123d-4aae-400a-a8de-b23f7945b30f,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-b1e49697-bd94-418f-9619-b0229b93ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-5e889640-5f11-427f-9145-6cd26a2ac9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-0c4280b3-8a15-4741-af2e-cfe8d56dd99e,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-50c345de-726b-4e05-a8b6-ce778222a339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043834708-172.17.0.3-1597497099037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42489,DS-b204c91a-5bf3-4f06-8b10-7b7fcb2237ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-a49e46fb-b0ee-498b-8471-4a861b7ff875,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-7a498310-db0e-4c3b-8e9f-5d30262503e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-68a74882-4e8b-4e9d-8b86-2b3e5b82ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-5a7f73fc-593b-4eb7-8378-741927b35490,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-599820df-98a2-465d-b2c5-7393fd0cd129,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-bbcb3684-baa0-43f8-8a17-2e0e16afb692,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-43b0b704-bf0d-4ce6-8785-344fce280f2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043834708-172.17.0.3-1597497099037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42489,DS-b204c91a-5bf3-4f06-8b10-7b7fcb2237ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-a49e46fb-b0ee-498b-8471-4a861b7ff875,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-7a498310-db0e-4c3b-8e9f-5d30262503e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-68a74882-4e8b-4e9d-8b86-2b3e5b82ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-5a7f73fc-593b-4eb7-8378-741927b35490,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-599820df-98a2-465d-b2c5-7393fd0cd129,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-bbcb3684-baa0-43f8-8a17-2e0e16afb692,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-43b0b704-bf0d-4ce6-8785-344fce280f2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130756837-172.17.0.3-1597497310459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32903,DS-a0aeae5a-a219-4431-b38c-e7ee678d992c,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-95e86fef-cbe1-4054-8a5e-0f18cbe1084c,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-01f13686-3d11-495b-a51d-82053081e5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-6feecf4a-34ff-489a-8ef8-4813ff69b4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-b2cc9436-15ca-4c57-abb2-d339ebaa4034,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-4fe8584c-9045-4900-a90b-23d0d4cdb2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-f279e33e-7277-420f-a887-3d64e612432a,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-fc0a39e1-58db-4d15-97e7-5b91e2f15a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130756837-172.17.0.3-1597497310459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32903,DS-a0aeae5a-a219-4431-b38c-e7ee678d992c,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-95e86fef-cbe1-4054-8a5e-0f18cbe1084c,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-01f13686-3d11-495b-a51d-82053081e5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-6feecf4a-34ff-489a-8ef8-4813ff69b4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-b2cc9436-15ca-4c57-abb2-d339ebaa4034,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-4fe8584c-9045-4900-a90b-23d0d4cdb2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-f279e33e-7277-420f-a887-3d64e612432a,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-fc0a39e1-58db-4d15-97e7-5b91e2f15a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465876165-172.17.0.3-1597498034726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-4a8c1a6b-e69d-4437-b9d4-9eb64f9a0c21,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-873787a9-2bab-41ab-af2c-8633e5355c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-8d1111c5-c61f-442a-8214-71f525bc4300,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-ff5fdfaf-d014-49da-a685-7215ad3abecc,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-64c94362-557b-475f-9281-a87bc4aae24b,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-cf243c08-ecb9-4f71-bbd2-0bad56bcc9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-f508a808-6fac-4ddb-9faa-b540e9342d17,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-28159727-23a2-4aea-8320-2ce96b783141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465876165-172.17.0.3-1597498034726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-4a8c1a6b-e69d-4437-b9d4-9eb64f9a0c21,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-873787a9-2bab-41ab-af2c-8633e5355c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-8d1111c5-c61f-442a-8214-71f525bc4300,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-ff5fdfaf-d014-49da-a685-7215ad3abecc,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-64c94362-557b-475f-9281-a87bc4aae24b,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-cf243c08-ecb9-4f71-bbd2-0bad56bcc9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-f508a808-6fac-4ddb-9faa-b540e9342d17,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-28159727-23a2-4aea-8320-2ce96b783141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786623192-172.17.0.3-1597498106579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39215,DS-5803bcd2-0396-44ae-97e0-9b860a436ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-40ec864b-3546-456d-a27f-edb6c445ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-e34b93d0-8250-4419-8aee-9b4397429ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-7e5cfa2e-6a54-4d5b-af2e-921f80d3ae77,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-2cd16962-11e2-41c6-9602-84b367616f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-1c7d010f-52fb-4055-a872-49b108febe13,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-e129a600-6d7d-4b92-8f24-a0547eb788e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-c5cf240d-7f4e-4e15-9083-9ced644b5c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786623192-172.17.0.3-1597498106579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39215,DS-5803bcd2-0396-44ae-97e0-9b860a436ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-40ec864b-3546-456d-a27f-edb6c445ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-e34b93d0-8250-4419-8aee-9b4397429ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-7e5cfa2e-6a54-4d5b-af2e-921f80d3ae77,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-2cd16962-11e2-41c6-9602-84b367616f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-1c7d010f-52fb-4055-a872-49b108febe13,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-e129a600-6d7d-4b92-8f24-a0547eb788e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-c5cf240d-7f4e-4e15-9083-9ced644b5c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209926116-172.17.0.3-1597498311478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-4671d36f-106c-4053-a056-b765d52b5914,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-5acad50e-ef26-4040-be7a-3c737d72baad,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-53871953-87cc-4893-8a04-ea84ec766264,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-d3a38a24-8caa-4bcb-9ef1-afecdffec7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d8cbd6be-4a37-44f0-9a7c-d9bc7e04da89,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-e7279a42-1831-45be-8b69-258b09a21ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-14b03fe6-729c-42df-88ff-be050290fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d5b71c77-5e0b-4999-8120-ab1b6d67d3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209926116-172.17.0.3-1597498311478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-4671d36f-106c-4053-a056-b765d52b5914,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-5acad50e-ef26-4040-be7a-3c737d72baad,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-53871953-87cc-4893-8a04-ea84ec766264,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-d3a38a24-8caa-4bcb-9ef1-afecdffec7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d8cbd6be-4a37-44f0-9a7c-d9bc7e04da89,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-e7279a42-1831-45be-8b69-258b09a21ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-14b03fe6-729c-42df-88ff-be050290fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d5b71c77-5e0b-4999-8120-ab1b6d67d3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268754549-172.17.0.3-1597498421260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45915,DS-4b8103b5-5478-4b31-97f5-0a2ed07e900b,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-2220a3a5-2261-482d-bc31-13852a2e3bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-8c0365f0-f5ff-4e44-90ba-cfbc9948a5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-aa844813-a4e5-4b48-b8ea-150e92e39b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-a68b4f55-59ba-4024-bfaf-49c403602964,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-5cd33724-048a-4dab-b66d-ab8e6f9ddd78,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-31560af6-4562-4b18-b7a2-eb7f039c079d,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-7a0252f1-dccc-49d3-b9c4-94050a94e156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268754549-172.17.0.3-1597498421260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45915,DS-4b8103b5-5478-4b31-97f5-0a2ed07e900b,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-2220a3a5-2261-482d-bc31-13852a2e3bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-8c0365f0-f5ff-4e44-90ba-cfbc9948a5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-aa844813-a4e5-4b48-b8ea-150e92e39b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-a68b4f55-59ba-4024-bfaf-49c403602964,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-5cd33724-048a-4dab-b66d-ab8e6f9ddd78,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-31560af6-4562-4b18-b7a2-eb7f039c079d,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-7a0252f1-dccc-49d3-b9c4-94050a94e156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5490
