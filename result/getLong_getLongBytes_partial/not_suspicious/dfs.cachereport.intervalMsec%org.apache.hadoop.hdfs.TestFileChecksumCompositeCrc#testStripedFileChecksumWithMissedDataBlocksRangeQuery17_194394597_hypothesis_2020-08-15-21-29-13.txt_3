reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526238749-172.17.0.5-1597527041818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-2ea8e105-1370-4451-9514-e0307fd4b672,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-a7546ed3-72c4-4a05-835d-22c26fa5bc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-4fd2aea7-ce4e-411f-a5ef-561c29a52eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-087e223f-bcdd-42f2-aeca-45a92392bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-9b170979-1341-47de-ab23-1c5268529133,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-e5920614-4cfd-41b8-8bef-6e777d188e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-cc85f496-5fc1-472b-864f-3f177f1b20e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-5ca7405f-2ac1-4789-a6f0-cc011eb392d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526238749-172.17.0.5-1597527041818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-2ea8e105-1370-4451-9514-e0307fd4b672,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-a7546ed3-72c4-4a05-835d-22c26fa5bc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-4fd2aea7-ce4e-411f-a5ef-561c29a52eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-087e223f-bcdd-42f2-aeca-45a92392bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-9b170979-1341-47de-ab23-1c5268529133,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-e5920614-4cfd-41b8-8bef-6e777d188e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-cc85f496-5fc1-472b-864f-3f177f1b20e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-5ca7405f-2ac1-4789-a6f0-cc011eb392d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673771216-172.17.0.5-1597527711464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32819,DS-98ae27c5-3d65-40df-ab52-6d59927bff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-35cf2e6f-1e81-4e0d-9f85-acca7f45beef,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-2927c560-fcdc-46c9-8eb1-c995367607dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-ef202505-03c1-4250-9bea-3872909f94ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-38e1c442-a324-42cc-882e-e34d957e8c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-1fb62ad0-6935-4e0a-a007-ee6d237fc649,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-84640c00-6a7b-457d-b2cd-f62393bd665c,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-93d7394e-17a8-4e79-a1af-28ec0455285e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673771216-172.17.0.5-1597527711464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32819,DS-98ae27c5-3d65-40df-ab52-6d59927bff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-35cf2e6f-1e81-4e0d-9f85-acca7f45beef,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-2927c560-fcdc-46c9-8eb1-c995367607dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-ef202505-03c1-4250-9bea-3872909f94ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-38e1c442-a324-42cc-882e-e34d957e8c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-1fb62ad0-6935-4e0a-a007-ee6d237fc649,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-84640c00-6a7b-457d-b2cd-f62393bd665c,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-93d7394e-17a8-4e79-a1af-28ec0455285e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776795530-172.17.0.5-1597528193022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34351,DS-b300330f-27d9-41c4-9cc0-2900c18be6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-3850a116-0b48-41a1-8ff2-0c504bd17a35,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-145b6d9c-ec4c-4e6e-98d5-4ebb958f23e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-0f673447-23bb-4a7f-ab5a-6a4aa1dde83d,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-b006d162-678e-45d3-b082-f0dab758e429,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-23cf552a-0827-456f-a4d1-36552f084162,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-aef9def8-d07e-4c6a-b469-be44bc2d7315,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-b970d2c5-13f8-41ef-b1f8-266621a3deca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776795530-172.17.0.5-1597528193022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34351,DS-b300330f-27d9-41c4-9cc0-2900c18be6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-3850a116-0b48-41a1-8ff2-0c504bd17a35,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-145b6d9c-ec4c-4e6e-98d5-4ebb958f23e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-0f673447-23bb-4a7f-ab5a-6a4aa1dde83d,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-b006d162-678e-45d3-b082-f0dab758e429,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-23cf552a-0827-456f-a4d1-36552f084162,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-aef9def8-d07e-4c6a-b469-be44bc2d7315,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-b970d2c5-13f8-41ef-b1f8-266621a3deca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623323552-172.17.0.5-1597528460289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35012,DS-f2ddde84-c1ea-43a1-8b60-eb50b20b2601,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-f8690a25-208b-478a-a13e-b64e519177d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-7e578942-7af8-473d-b93d-ba85dea574a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-c8849626-a47c-48f1-a871-3b25f7d97068,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-8482932f-1eae-4d7d-8294-b55ee68603cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-a07b6b7a-d2ec-4781-90a3-30331c526129,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-0335eff7-a8af-4b2c-b7be-656404706446,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-35e5eac1-0546-4316-a357-17ee0499a18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623323552-172.17.0.5-1597528460289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35012,DS-f2ddde84-c1ea-43a1-8b60-eb50b20b2601,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-f8690a25-208b-478a-a13e-b64e519177d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-7e578942-7af8-473d-b93d-ba85dea574a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-c8849626-a47c-48f1-a871-3b25f7d97068,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-8482932f-1eae-4d7d-8294-b55ee68603cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-a07b6b7a-d2ec-4781-90a3-30331c526129,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-0335eff7-a8af-4b2c-b7be-656404706446,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-35e5eac1-0546-4316-a357-17ee0499a18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745420120-172.17.0.5-1597528594479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33706,DS-e11adb8f-6b5b-4548-aa80-07e64764a906,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-f635059a-cc4d-408e-953d-8f6f5c7227c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-d0b39c58-7e2e-408c-adb6-bd7d67240477,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-cf89b636-eadd-468a-a1bf-20d3530f4bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-af23dcac-f94d-4e76-ad7b-1cdd930a3fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-6cb281bc-0706-428d-8241-a5900ec06e39,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-f9721229-de21-4005-82bb-6a05b4b890ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-6e540f37-2ea9-4d61-81db-9b3545607e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745420120-172.17.0.5-1597528594479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33706,DS-e11adb8f-6b5b-4548-aa80-07e64764a906,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-f635059a-cc4d-408e-953d-8f6f5c7227c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-d0b39c58-7e2e-408c-adb6-bd7d67240477,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-cf89b636-eadd-468a-a1bf-20d3530f4bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-af23dcac-f94d-4e76-ad7b-1cdd930a3fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-6cb281bc-0706-428d-8241-a5900ec06e39,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-f9721229-de21-4005-82bb-6a05b4b890ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-6e540f37-2ea9-4d61-81db-9b3545607e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504016827-172.17.0.5-1597529093833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-d1a36f58-7623-4dcf-97bb-4a42b0f4b43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-e3b35f9b-4826-48f3-8f87-dfed4e548061,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-d8435681-e985-4142-9947-f48f3fa38383,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-cb07bfa8-d963-4505-a078-d76b696ad584,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-f5a6febb-b2d5-4b72-9b58-38de74e2df74,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-8e22cf0f-def5-44fd-868e-61a7a85fbcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-735c94d5-8f2f-4da5-a122-53fe29640f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-1050cad5-d081-4055-ae94-2bc9b61462f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504016827-172.17.0.5-1597529093833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-d1a36f58-7623-4dcf-97bb-4a42b0f4b43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-e3b35f9b-4826-48f3-8f87-dfed4e548061,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-d8435681-e985-4142-9947-f48f3fa38383,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-cb07bfa8-d963-4505-a078-d76b696ad584,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-f5a6febb-b2d5-4b72-9b58-38de74e2df74,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-8e22cf0f-def5-44fd-868e-61a7a85fbcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-735c94d5-8f2f-4da5-a122-53fe29640f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-1050cad5-d081-4055-ae94-2bc9b61462f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131521915-172.17.0.5-1597529783078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-ae7e4db7-79fc-4152-bc29-0244cee96347,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-238ec0b3-04ac-43e4-a6e6-15b827e98c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-20f89ea5-a028-48f9-a52f-d6ed8d61839f,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-2499c83d-312b-4ab5-a70a-676b6f194aae,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-9969bf58-dd57-4cfd-9450-f924461929d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-73fc509a-8662-48fe-9311-cb9da4d20367,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-1711bc27-4949-4cd7-b198-c896488bf4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-3efe2062-f42e-4763-acc2-3a7bb28f3980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131521915-172.17.0.5-1597529783078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-ae7e4db7-79fc-4152-bc29-0244cee96347,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-238ec0b3-04ac-43e4-a6e6-15b827e98c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-20f89ea5-a028-48f9-a52f-d6ed8d61839f,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-2499c83d-312b-4ab5-a70a-676b6f194aae,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-9969bf58-dd57-4cfd-9450-f924461929d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-73fc509a-8662-48fe-9311-cb9da4d20367,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-1711bc27-4949-4cd7-b198-c896488bf4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-3efe2062-f42e-4763-acc2-3a7bb28f3980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734483326-172.17.0.5-1597530117570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-125723df-499a-49ba-adc8-ebab4c44e720,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-17dfd009-93ec-4d71-b596-af70b2245f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-fcfd8574-509d-42bf-882d-bdef3ed4b3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-1fff30d1-74d2-414e-83f9-d57d2549d617,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-5f3503a0-c32c-4a60-a50e-f832282800a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-151f173c-315c-45a4-bc73-76003532f3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-5e682842-00b0-4fed-8d94-ceb0d97dc27b,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-0555be66-c7c5-48b1-a20d-cf1ea333446e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734483326-172.17.0.5-1597530117570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34490,DS-125723df-499a-49ba-adc8-ebab4c44e720,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-17dfd009-93ec-4d71-b596-af70b2245f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-fcfd8574-509d-42bf-882d-bdef3ed4b3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-1fff30d1-74d2-414e-83f9-d57d2549d617,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-5f3503a0-c32c-4a60-a50e-f832282800a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-151f173c-315c-45a4-bc73-76003532f3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-5e682842-00b0-4fed-8d94-ceb0d97dc27b,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-0555be66-c7c5-48b1-a20d-cf1ea333446e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722145825-172.17.0.5-1597530544412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33510,DS-ca128f72-fe15-4eb0-b4e3-8e5061b1ae35,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-01041fed-3ed9-480d-8147-cc86b3be2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-35365c72-97ff-4043-8b0b-a3967ab85840,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-0b51d4c4-e68d-4921-bad4-9855ccc23e25,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-c76c777c-bf9a-463a-b2ef-4fdd45ba68c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-df9abc65-aa2b-4379-8922-4510742e5890,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-7a3e4040-8d7b-420d-b9d3-4a0e31e57793,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-9ddf0140-0031-4117-a5d6-576ed6887be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722145825-172.17.0.5-1597530544412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33510,DS-ca128f72-fe15-4eb0-b4e3-8e5061b1ae35,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-01041fed-3ed9-480d-8147-cc86b3be2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-35365c72-97ff-4043-8b0b-a3967ab85840,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-0b51d4c4-e68d-4921-bad4-9855ccc23e25,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-c76c777c-bf9a-463a-b2ef-4fdd45ba68c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-df9abc65-aa2b-4379-8922-4510742e5890,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-7a3e4040-8d7b-420d-b9d3-4a0e31e57793,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-9ddf0140-0031-4117-a5d6-576ed6887be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490931449-172.17.0.5-1597530755678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38269,DS-05883765-5fc0-4476-8652-313c60c62b97,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-b17919af-55c8-47fa-b761-9d1fea1f7954,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-aaea1de7-e9fd-44c5-b51f-5b5e696ee0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-ca3145c2-91e7-4108-812f-21a0270590ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-ef066e24-22fe-421f-b768-fe654945a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-ab3eb6b9-dc1f-470e-9521-7977623ded73,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-8d029628-b548-41e9-99d9-99a4cba74cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-9ec85777-9174-4256-8254-39c64ca4bb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490931449-172.17.0.5-1597530755678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38269,DS-05883765-5fc0-4476-8652-313c60c62b97,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-b17919af-55c8-47fa-b761-9d1fea1f7954,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-aaea1de7-e9fd-44c5-b51f-5b5e696ee0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-ca3145c2-91e7-4108-812f-21a0270590ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-ef066e24-22fe-421f-b768-fe654945a11a,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-ab3eb6b9-dc1f-470e-9521-7977623ded73,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-8d029628-b548-41e9-99d9-99a4cba74cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-9ec85777-9174-4256-8254-39c64ca4bb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694711706-172.17.0.5-1597530995196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34504,DS-446116e3-fc40-4643-96a4-1acc09cd4536,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-c012ed7b-e704-4b67-8d0f-5b8ea92cba0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-bb81f5a9-8a3a-49a0-a119-0d75a5377330,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-61972462-b96f-4ef3-809a-519f81a90c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-c73e92d9-4951-4342-88de-06142012bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-be6149e6-3e44-47c7-9f2e-2edddb2addda,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-963efa5f-90a3-4813-b851-19c9a868bce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-befc36e8-9ce0-4ae4-bd60-d132bc1804cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694711706-172.17.0.5-1597530995196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34504,DS-446116e3-fc40-4643-96a4-1acc09cd4536,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-c012ed7b-e704-4b67-8d0f-5b8ea92cba0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-bb81f5a9-8a3a-49a0-a119-0d75a5377330,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-61972462-b96f-4ef3-809a-519f81a90c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-c73e92d9-4951-4342-88de-06142012bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-be6149e6-3e44-47c7-9f2e-2edddb2addda,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-963efa5f-90a3-4813-b851-19c9a868bce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-befc36e8-9ce0-4ae4-bd60-d132bc1804cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120604086-172.17.0.5-1597531197422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43945,DS-b1c2461c-90ed-4eb4-b751-1c680b827ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-0357d959-8b56-485a-8433-daa557c9aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-53b9234f-ee2e-4cb5-8b38-f95ec20629cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-d4025d77-88f3-429d-866d-2d705f72fc25,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-9b1cce9c-b200-4c81-9e27-4f94978a18d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-ec1583c1-45b3-46cf-bc0a-185b1a63b2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-dae52cca-4c6c-4110-a78e-ed4ac4dc5dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-6045aab2-7ccf-4da6-ab5f-eab127a96ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120604086-172.17.0.5-1597531197422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43945,DS-b1c2461c-90ed-4eb4-b751-1c680b827ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-0357d959-8b56-485a-8433-daa557c9aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-53b9234f-ee2e-4cb5-8b38-f95ec20629cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-d4025d77-88f3-429d-866d-2d705f72fc25,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-9b1cce9c-b200-4c81-9e27-4f94978a18d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-ec1583c1-45b3-46cf-bc0a-185b1a63b2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-dae52cca-4c6c-4110-a78e-ed4ac4dc5dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-6045aab2-7ccf-4da6-ab5f-eab127a96ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253035476-172.17.0.5-1597531257290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-148069e0-02d4-4c34-8fb7-786dae798577,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-50aa5688-9255-4ec3-8089-866161a7d2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-e8e86e5e-7406-462c-9be3-50942a3859e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-0ed3dd06-49d9-457e-bba2-989d8c5604f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-17136c8a-3a77-4b7b-82a6-e042feafb579,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-41eae9fd-cc2f-4944-b7db-6ba4d8de10f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-3d1f1069-9410-4dd0-abab-7e71f9b5f069,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-0a2c72ba-cf71-496b-8efa-ae099243aa3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253035476-172.17.0.5-1597531257290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-148069e0-02d4-4c34-8fb7-786dae798577,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-50aa5688-9255-4ec3-8089-866161a7d2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-e8e86e5e-7406-462c-9be3-50942a3859e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-0ed3dd06-49d9-457e-bba2-989d8c5604f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-17136c8a-3a77-4b7b-82a6-e042feafb579,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-41eae9fd-cc2f-4944-b7db-6ba4d8de10f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-3d1f1069-9410-4dd0-abab-7e71f9b5f069,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-0a2c72ba-cf71-496b-8efa-ae099243aa3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584547408-172.17.0.5-1597531292247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44309,DS-ec35b166-dbdd-4f82-aadf-d72dae948a24,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-186dfa3b-623b-4a6a-bb65-476869a72bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-9e604426-ff6b-4890-b6fd-85651d32eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-a915c840-afe2-4915-b7ee-b0b68edcf308,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-c15fb86e-c352-4659-ad11-e46f26551cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-425fab26-8c37-4936-957b-7c247a315e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-fe70d9d4-66dc-43ff-8bd7-e600d8fdc963,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-872738d9-e5e0-44b5-b4d8-6b9ff52a9afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584547408-172.17.0.5-1597531292247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44309,DS-ec35b166-dbdd-4f82-aadf-d72dae948a24,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-186dfa3b-623b-4a6a-bb65-476869a72bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-9e604426-ff6b-4890-b6fd-85651d32eea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-a915c840-afe2-4915-b7ee-b0b68edcf308,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-c15fb86e-c352-4659-ad11-e46f26551cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-425fab26-8c37-4936-957b-7c247a315e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-fe70d9d4-66dc-43ff-8bd7-e600d8fdc963,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-872738d9-e5e0-44b5-b4d8-6b9ff52a9afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519013878-172.17.0.5-1597531646776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-1a8b768a-352b-4569-82c8-f190a4208b41,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-b5c9ed6e-237a-475b-bf40-a7ea7ce6b075,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-a7e54c7f-bf67-430c-a070-cd8dab9063de,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-9513952d-8db4-47a4-852d-53ec68e735a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-9c0fe611-0090-47e5-9dd8-1450f6012dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-758e8887-b578-4e03-9792-eb92c56032d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-709aafcd-133c-42f3-96a1-0f401f55081c,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-ac7b839b-0c03-4d2c-b7dc-75e48624c6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519013878-172.17.0.5-1597531646776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-1a8b768a-352b-4569-82c8-f190a4208b41,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-b5c9ed6e-237a-475b-bf40-a7ea7ce6b075,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-a7e54c7f-bf67-430c-a070-cd8dab9063de,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-9513952d-8db4-47a4-852d-53ec68e735a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-9c0fe611-0090-47e5-9dd8-1450f6012dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-758e8887-b578-4e03-9792-eb92c56032d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-709aafcd-133c-42f3-96a1-0f401f55081c,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-ac7b839b-0c03-4d2c-b7dc-75e48624c6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146237739-172.17.0.5-1597531889987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-5d789f95-99cd-4c98-b272-c39c0a6f243c,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-245f2d9c-d5ac-4e8f-b43d-d3b3e4b643f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-760af9b0-547e-4c7a-86a2-66f5b3923fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-e71ed625-97c6-4355-b6a6-b314619c5154,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-dda4f099-f77e-4234-8b92-2026858fb31b,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-bbf73b2e-c726-4a22-856d-7d0600d8f890,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-b93e8d81-366f-4157-bdd1-7dab78af8106,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-f1761b57-074b-4484-930d-e15d7eabf5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146237739-172.17.0.5-1597531889987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-5d789f95-99cd-4c98-b272-c39c0a6f243c,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-245f2d9c-d5ac-4e8f-b43d-d3b3e4b643f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-760af9b0-547e-4c7a-86a2-66f5b3923fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-e71ed625-97c6-4355-b6a6-b314619c5154,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-dda4f099-f77e-4234-8b92-2026858fb31b,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-bbf73b2e-c726-4a22-856d-7d0600d8f890,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-b93e8d81-366f-4157-bdd1-7dab78af8106,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-f1761b57-074b-4484-930d-e15d7eabf5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5289
