reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468083344-172.17.0.15-1597306777012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35628,DS-446507ad-cfeb-407d-a3c9-f311a60dd2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-0e294dc6-11a5-4d94-a444-559b4efd812a,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-da67046b-42fc-4131-b3ac-e6c225c0d281,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-5dd70cd2-9c93-4204-8bdc-95ec433a06d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-0ecb2a2d-7435-4ed7-9e70-f0327eeb4437,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-0591fa42-944f-41ba-bb31-83f18e7edb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-b9f0ef86-66dd-495b-8353-27e16facc72b,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-7b4265ed-5cd7-4c2b-be72-0b6100e45fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468083344-172.17.0.15-1597306777012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35628,DS-446507ad-cfeb-407d-a3c9-f311a60dd2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-0e294dc6-11a5-4d94-a444-559b4efd812a,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-da67046b-42fc-4131-b3ac-e6c225c0d281,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-5dd70cd2-9c93-4204-8bdc-95ec433a06d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-0ecb2a2d-7435-4ed7-9e70-f0327eeb4437,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-0591fa42-944f-41ba-bb31-83f18e7edb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-b9f0ef86-66dd-495b-8353-27e16facc72b,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-7b4265ed-5cd7-4c2b-be72-0b6100e45fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525748714-172.17.0.15-1597307121948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38089,DS-f083d273-4826-40f0-b49d-8ab075e616ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-2d5fed0a-c553-4637-bf34-810de843b7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-f907781c-c65d-4728-b803-df831f8af76b,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-d4007a40-05ee-4959-b777-0faced40cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-d0dfd5ad-5135-480a-9813-f97d99b593e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-8a67a257-1926-40c7-8654-5b239917fbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-9125916c-1e66-4d8b-8e77-85c640b1e83c,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-4e896157-e5f0-414e-b75d-29289c3065de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525748714-172.17.0.15-1597307121948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38089,DS-f083d273-4826-40f0-b49d-8ab075e616ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-2d5fed0a-c553-4637-bf34-810de843b7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-f907781c-c65d-4728-b803-df831f8af76b,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-d4007a40-05ee-4959-b777-0faced40cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-d0dfd5ad-5135-480a-9813-f97d99b593e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-8a67a257-1926-40c7-8654-5b239917fbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-9125916c-1e66-4d8b-8e77-85c640b1e83c,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-4e896157-e5f0-414e-b75d-29289c3065de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345177634-172.17.0.15-1597307218724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-4ec3eac6-be4c-460d-a141-018568ceb278,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-146a15b5-b9b9-4253-a30e-3fa7ef2d6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-559c853d-69fb-4491-897c-bf5704aabfae,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-d41e6ebf-2f30-40f4-babf-880f7c3d55c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-48977eed-73e4-49b0-b392-d8b1a2d06237,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-435bba95-ca9b-4506-9834-fc562e7d13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-e36c9d28-aa3e-44f5-9c80-77b4f26d4a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-cf86cc36-29ff-4e0e-a948-439e7dc21476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345177634-172.17.0.15-1597307218724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-4ec3eac6-be4c-460d-a141-018568ceb278,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-146a15b5-b9b9-4253-a30e-3fa7ef2d6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-559c853d-69fb-4491-897c-bf5704aabfae,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-d41e6ebf-2f30-40f4-babf-880f7c3d55c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-48977eed-73e4-49b0-b392-d8b1a2d06237,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-435bba95-ca9b-4506-9834-fc562e7d13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-e36c9d28-aa3e-44f5-9c80-77b4f26d4a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-cf86cc36-29ff-4e0e-a948-439e7dc21476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807676550-172.17.0.15-1597307615149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40477,DS-368cc546-fe49-4a40-96d4-140ae6188d06,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-99bca983-5b7c-4b46-9277-0d9be5172138,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-3eb05e61-f4e1-4df5-ad87-ebe52971f35e,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-f2416348-c6c8-4dd9-918d-265514560346,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-7a736322-a0b5-4b8e-a100-70912d39ed3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-c01ff85b-7a17-45fa-b89c-bdb6a40cd696,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-ce936200-eb85-4411-b740-e52b4c628641,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-db64f14c-c439-424d-b800-178bc98f7e37,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807676550-172.17.0.15-1597307615149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40477,DS-368cc546-fe49-4a40-96d4-140ae6188d06,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-99bca983-5b7c-4b46-9277-0d9be5172138,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-3eb05e61-f4e1-4df5-ad87-ebe52971f35e,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-f2416348-c6c8-4dd9-918d-265514560346,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-7a736322-a0b5-4b8e-a100-70912d39ed3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-c01ff85b-7a17-45fa-b89c-bdb6a40cd696,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-ce936200-eb85-4411-b740-e52b4c628641,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-db64f14c-c439-424d-b800-178bc98f7e37,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026375062-172.17.0.15-1597307876308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-12138fb2-9318-41ae-9ec8-31f16d3c1cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-1fde5f03-06f4-47a9-956e-701425440198,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-102d6933-4ebb-4004-976c-4a0a1ea35d75,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-0226528a-6b90-4a09-8c03-2cb07b27cd71,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-3fff3077-8746-461e-83a8-42289ad959b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-2085a9cc-2c69-4577-bb27-3845c58ae9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-0ab30f1c-a113-404c-970c-a458753e202e,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-20c4b23b-bd81-4c08-ac84-d4d5fd3667fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026375062-172.17.0.15-1597307876308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-12138fb2-9318-41ae-9ec8-31f16d3c1cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-1fde5f03-06f4-47a9-956e-701425440198,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-102d6933-4ebb-4004-976c-4a0a1ea35d75,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-0226528a-6b90-4a09-8c03-2cb07b27cd71,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-3fff3077-8746-461e-83a8-42289ad959b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-2085a9cc-2c69-4577-bb27-3845c58ae9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-0ab30f1c-a113-404c-970c-a458753e202e,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-20c4b23b-bd81-4c08-ac84-d4d5fd3667fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516206771-172.17.0.15-1597307920044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42874,DS-3b3ec2fe-0f38-4dd4-8031-48377db529ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-5bd00112-a5d1-4ff6-8513-31118789a97e,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-a8c76697-b0a9-493b-a6f8-cee660bc0aca,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-4f58dbcf-9e29-4a11-b180-2005da65a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-6c21a561-932c-457c-963f-86965835fc28,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-43a4d187-dcce-473d-91e3-2ebd6d6f4d67,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-d3f5946c-1ddd-437b-afd5-8a9efeaa8764,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-cf5bffb4-4e7d-424f-8141-9d7a1d0178fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516206771-172.17.0.15-1597307920044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42874,DS-3b3ec2fe-0f38-4dd4-8031-48377db529ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-5bd00112-a5d1-4ff6-8513-31118789a97e,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-a8c76697-b0a9-493b-a6f8-cee660bc0aca,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-4f58dbcf-9e29-4a11-b180-2005da65a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-6c21a561-932c-457c-963f-86965835fc28,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-43a4d187-dcce-473d-91e3-2ebd6d6f4d67,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-d3f5946c-1ddd-437b-afd5-8a9efeaa8764,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-cf5bffb4-4e7d-424f-8141-9d7a1d0178fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651597886-172.17.0.15-1597308110829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-7b8a4694-f6bd-4b1d-b6b4-7d36fdd148a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-01d3cced-3895-4d47-9387-d9e09dcf1517,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-f7afbeb5-aa0e-46c2-bfb6-2a14a8fe419d,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-8691f41d-cf9b-4e0d-8467-6660ed2fdaca,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-41a9a290-a81e-4dc5-99fd-25186f67e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-dad0bf8e-f18b-4803-ad09-33653bbb3853,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-49f32bea-4407-4694-916f-1ef3b227066a,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-639329f3-31e1-48fe-99c1-1e1564a91566,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651597886-172.17.0.15-1597308110829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-7b8a4694-f6bd-4b1d-b6b4-7d36fdd148a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-01d3cced-3895-4d47-9387-d9e09dcf1517,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-f7afbeb5-aa0e-46c2-bfb6-2a14a8fe419d,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-8691f41d-cf9b-4e0d-8467-6660ed2fdaca,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-41a9a290-a81e-4dc5-99fd-25186f67e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-dad0bf8e-f18b-4803-ad09-33653bbb3853,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-49f32bea-4407-4694-916f-1ef3b227066a,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-639329f3-31e1-48fe-99c1-1e1564a91566,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568574325-172.17.0.15-1597308171309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-4cac729c-cd27-4b60-aeb1-4376c77a57f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-bdbbab9d-be65-4b09-a386-78e99962fabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-51663a46-fa5b-4cbd-bc73-01638e7a6e61,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-10bb550a-b042-4914-89b9-0a87c71195ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-73e2ecf6-ba87-4427-88e8-44ee1297ab8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-94241544-c7e6-4d9b-853f-4a6dd683b5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-729399b5-ba40-403b-b207-743ede324be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-66807a2b-3a75-419e-8421-3003e47b0764,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568574325-172.17.0.15-1597308171309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-4cac729c-cd27-4b60-aeb1-4376c77a57f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-bdbbab9d-be65-4b09-a386-78e99962fabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-51663a46-fa5b-4cbd-bc73-01638e7a6e61,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-10bb550a-b042-4914-89b9-0a87c71195ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-73e2ecf6-ba87-4427-88e8-44ee1297ab8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-94241544-c7e6-4d9b-853f-4a6dd683b5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-729399b5-ba40-403b-b207-743ede324be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-66807a2b-3a75-419e-8421-3003e47b0764,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179802659-172.17.0.15-1597308424751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-379371d2-73be-4c95-8979-b20e719a51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-76eea277-4e09-421a-81e8-cf6669d65780,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-d8fcb309-9693-4c52-bdcc-d252bc95e730,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-74a5e456-ac29-4ee3-8b3b-eb053b4cfc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-0151419f-00d1-4579-8bed-dcb28c1f4724,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-fa72e790-6f75-462a-b79e-b8b81523c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-6fed79c0-562e-4124-a080-51414c3548f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-1b692535-9ade-4130-a9a7-a833e7dc9ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179802659-172.17.0.15-1597308424751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-379371d2-73be-4c95-8979-b20e719a51b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-76eea277-4e09-421a-81e8-cf6669d65780,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-d8fcb309-9693-4c52-bdcc-d252bc95e730,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-74a5e456-ac29-4ee3-8b3b-eb053b4cfc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-0151419f-00d1-4579-8bed-dcb28c1f4724,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-fa72e790-6f75-462a-b79e-b8b81523c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-6fed79c0-562e-4124-a080-51414c3548f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-1b692535-9ade-4130-a9a7-a833e7dc9ac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849728806-172.17.0.15-1597308479609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-d0d2ad6c-1efd-46dd-90f6-314b21ba763c,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-d8accf3d-757c-4179-86fd-680bef962ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-0215b7b7-b1a5-46b5-9f09-9ac4f81d5d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-bc6f0ed8-0600-473d-8213-2b9dadf98b66,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-c45ca557-923b-45c3-a202-410393f473cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-e9ad725e-3f20-4db2-beed-6e6fcfe81710,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-54eb2df7-e251-40a0-a314-8dae5c84edd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-01346de3-df1a-4ae6-aa0e-3a008ddc5c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849728806-172.17.0.15-1597308479609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-d0d2ad6c-1efd-46dd-90f6-314b21ba763c,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-d8accf3d-757c-4179-86fd-680bef962ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-0215b7b7-b1a5-46b5-9f09-9ac4f81d5d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-bc6f0ed8-0600-473d-8213-2b9dadf98b66,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-c45ca557-923b-45c3-a202-410393f473cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-e9ad725e-3f20-4db2-beed-6e6fcfe81710,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-54eb2df7-e251-40a0-a314-8dae5c84edd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-01346de3-df1a-4ae6-aa0e-3a008ddc5c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792769701-172.17.0.15-1597309059126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37793,DS-a9ef3cfa-629b-4fc1-8d1f-d28b15a37d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-8a24b889-7730-4098-a483-793d7d7e6975,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-75320c3f-76d1-468a-a6f3-c90a7391e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-ef57861a-083c-40ef-8ff7-311f36e9a1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-eb9fc0bc-9a29-4705-a376-4185d4d3d40a,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-d96c1543-d224-4a13-a191-4b00f30d2916,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-10598d88-e550-4eed-befd-e058eaadc6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-cefe5cef-6213-4de7-bf56-0fb1f8db03e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792769701-172.17.0.15-1597309059126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37793,DS-a9ef3cfa-629b-4fc1-8d1f-d28b15a37d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-8a24b889-7730-4098-a483-793d7d7e6975,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-75320c3f-76d1-468a-a6f3-c90a7391e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-ef57861a-083c-40ef-8ff7-311f36e9a1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-eb9fc0bc-9a29-4705-a376-4185d4d3d40a,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-d96c1543-d224-4a13-a191-4b00f30d2916,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-10598d88-e550-4eed-befd-e058eaadc6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-cefe5cef-6213-4de7-bf56-0fb1f8db03e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645034549-172.17.0.15-1597309099112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-6ee371d9-565e-43aa-ac54-e3d256f1e407,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-c9e60e15-567d-4b38-a62a-0720901f17cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-7d6789cc-585f-413e-a1c2-aadd59a7a1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-30ac5fb4-151d-479e-90a6-8cd23db9a281,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-a3c52695-997f-4a5f-816e-5861581faa52,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-d5994603-60ef-478c-95db-3b89e2117e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-69d7c9db-29b9-4b04-a010-acf77338a4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-9ce6e53e-559b-450c-9365-47d4c2dcbba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645034549-172.17.0.15-1597309099112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-6ee371d9-565e-43aa-ac54-e3d256f1e407,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-c9e60e15-567d-4b38-a62a-0720901f17cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-7d6789cc-585f-413e-a1c2-aadd59a7a1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-30ac5fb4-151d-479e-90a6-8cd23db9a281,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-a3c52695-997f-4a5f-816e-5861581faa52,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-d5994603-60ef-478c-95db-3b89e2117e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-69d7c9db-29b9-4b04-a010-acf77338a4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-9ce6e53e-559b-450c-9365-47d4c2dcbba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024033968-172.17.0.15-1597309403565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-50adbee6-3b7e-496e-90b1-84ec03c337ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-e58f3bdf-93df-45b5-be7e-b5774cf16ada,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-920677e4-a390-4cb5-b98e-76bba400862b,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-50ca9166-bc10-472a-bf24-675fc2072d05,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-39159b40-88bd-4758-aa70-d8d167f2b450,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-dbbd1c71-55d7-456e-86c2-9f4a99a0b355,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-5f371ad3-cb05-4e84-96ca-3d57cf1c14f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-b5774950-68cc-40b6-b22b-2a81d868ff80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024033968-172.17.0.15-1597309403565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46560,DS-50adbee6-3b7e-496e-90b1-84ec03c337ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-e58f3bdf-93df-45b5-be7e-b5774cf16ada,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-920677e4-a390-4cb5-b98e-76bba400862b,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-50ca9166-bc10-472a-bf24-675fc2072d05,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-39159b40-88bd-4758-aa70-d8d167f2b450,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-dbbd1c71-55d7-456e-86c2-9f4a99a0b355,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-5f371ad3-cb05-4e84-96ca-3d57cf1c14f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-b5774950-68cc-40b6-b22b-2a81d868ff80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301274484-172.17.0.15-1597309505628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-2e022c22-0ca2-4d0a-b0ce-4fd7dd80eae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-b58ad06e-69c7-4b34-b31d-ac59d4d4c07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-0dbbf1aa-9950-4ec7-8187-34b926bb645c,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-d127a104-ceae-4846-8340-23104e95e83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-426b5c84-03e7-4730-8b77-bb154ae81e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-e19ff1ac-893e-42bd-93d0-d329de5ad2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-cdf44e5e-b540-420f-b5f3-947629069d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-4899e629-65a4-4b77-ac21-687fb7c410a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301274484-172.17.0.15-1597309505628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-2e022c22-0ca2-4d0a-b0ce-4fd7dd80eae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-b58ad06e-69c7-4b34-b31d-ac59d4d4c07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-0dbbf1aa-9950-4ec7-8187-34b926bb645c,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-d127a104-ceae-4846-8340-23104e95e83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-426b5c84-03e7-4730-8b77-bb154ae81e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-e19ff1ac-893e-42bd-93d0-d329de5ad2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-cdf44e5e-b540-420f-b5f3-947629069d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-4899e629-65a4-4b77-ac21-687fb7c410a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25728270-172.17.0.15-1597309553227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43397,DS-a1fef318-c9d5-4833-ae98-c1908e68647e,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-d06abee3-ed11-4480-b900-1be4068b205c,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-ee102461-25be-455e-8057-fa6068952d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-14cc41f8-bad3-4b2c-a6c7-ab5d415d47f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-930c5bab-4f2d-49e1-86b5-c9569bcec745,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-99d224cc-2fe3-45c8-847c-dc18cf2709e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-9897aefb-06a4-4619-a41e-21638951f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-421912db-5367-4467-9bd7-138aebf27b93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25728270-172.17.0.15-1597309553227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43397,DS-a1fef318-c9d5-4833-ae98-c1908e68647e,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-d06abee3-ed11-4480-b900-1be4068b205c,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-ee102461-25be-455e-8057-fa6068952d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-14cc41f8-bad3-4b2c-a6c7-ab5d415d47f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-930c5bab-4f2d-49e1-86b5-c9569bcec745,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-99d224cc-2fe3-45c8-847c-dc18cf2709e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-9897aefb-06a4-4619-a41e-21638951f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-421912db-5367-4467-9bd7-138aebf27b93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618071982-172.17.0.15-1597309686466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37807,DS-8b58059c-5857-4fae-bfc2-de297007455b,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-5c8f68a3-0d49-426b-9250-1583097bda70,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-b7a0b07c-2264-4fd8-83c4-6f54a8194234,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-12bec128-6937-4022-bda9-9260edfac681,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d2535ab8-3da8-4714-ab47-bf3428fe4144,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-ff99cf7a-e8b0-4c30-9ce1-97fd0a41b099,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-15e7fdb8-c1bc-420a-ad85-5be475a0ef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-ed58afb8-9e28-4ca5-8e28-0c5784d15170,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618071982-172.17.0.15-1597309686466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37807,DS-8b58059c-5857-4fae-bfc2-de297007455b,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-5c8f68a3-0d49-426b-9250-1583097bda70,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-b7a0b07c-2264-4fd8-83c4-6f54a8194234,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-12bec128-6937-4022-bda9-9260edfac681,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d2535ab8-3da8-4714-ab47-bf3428fe4144,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-ff99cf7a-e8b0-4c30-9ce1-97fd0a41b099,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-15e7fdb8-c1bc-420a-ad85-5be475a0ef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-ed58afb8-9e28-4ca5-8e28-0c5784d15170,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412852488-172.17.0.15-1597309935353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-82d50010-b2f8-4d5f-9700-acb13619b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-a075ed57-ce2f-496c-915d-acef543d4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-696a8a33-ba95-49ee-8da3-d351dd02f974,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-bb47f9eb-58a8-4655-a95f-33ca9e9b853d,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-d6f80905-dab0-432a-92ad-11d19546fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-daaf8224-dc9e-4bce-b438-8ce80fd962a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-31729772-f927-4c4b-9f80-d3b7911204da,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-8b41aeb2-30c8-4750-9b2b-ad8444a9dfae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412852488-172.17.0.15-1597309935353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-82d50010-b2f8-4d5f-9700-acb13619b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-a075ed57-ce2f-496c-915d-acef543d4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-696a8a33-ba95-49ee-8da3-d351dd02f974,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-bb47f9eb-58a8-4655-a95f-33ca9e9b853d,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-d6f80905-dab0-432a-92ad-11d19546fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-daaf8224-dc9e-4bce-b438-8ce80fd962a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-31729772-f927-4c4b-9f80-d3b7911204da,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-8b41aeb2-30c8-4750-9b2b-ad8444a9dfae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085038531-172.17.0.15-1597309993408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35287,DS-09c7800a-7baa-4bf6-a5f0-6b91a546269a,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-2fa5cdc8-6393-4ff7-903f-5c1a558c75fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-f91bd42b-8a9b-4fb5-b7cd-3874ec58ed94,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-8a5e54d2-ca0c-4557-ba7b-446d3ac24509,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-838efd88-23e5-4eac-8ea0-a16e80ac2d46,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-a4dd72ef-fcee-4a75-92e1-a545ae97abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-aad939f9-d554-470a-bafc-856bf5cb236d,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-eb2c1afa-a95d-4623-bbcf-66113f44a0bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085038531-172.17.0.15-1597309993408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35287,DS-09c7800a-7baa-4bf6-a5f0-6b91a546269a,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-2fa5cdc8-6393-4ff7-903f-5c1a558c75fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-f91bd42b-8a9b-4fb5-b7cd-3874ec58ed94,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-8a5e54d2-ca0c-4557-ba7b-446d3ac24509,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-838efd88-23e5-4eac-8ea0-a16e80ac2d46,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-a4dd72ef-fcee-4a75-92e1-a545ae97abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-aad939f9-d554-470a-bafc-856bf5cb236d,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-eb2c1afa-a95d-4623-bbcf-66113f44a0bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924398767-172.17.0.15-1597310103783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-be71b4b2-a2f5-4022-9057-d1bf0b88b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-cfa73764-85d8-4f48-ab1a-07243f6a3e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-a7b256d2-9084-4af6-a650-7ba718fb3f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-4dd57056-366e-42e5-a801-9f865350f7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-a1f07283-ebc8-4c31-ab77-19142f9f81bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-e845a20f-183c-4300-8f6b-73cc42758c79,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-e214056d-6a6d-4e33-9155-c7b4e647d6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-dfabf1e2-13f3-4cf5-b3fe-6d95800286e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924398767-172.17.0.15-1597310103783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-be71b4b2-a2f5-4022-9057-d1bf0b88b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-cfa73764-85d8-4f48-ab1a-07243f6a3e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-a7b256d2-9084-4af6-a650-7ba718fb3f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-4dd57056-366e-42e5-a801-9f865350f7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-a1f07283-ebc8-4c31-ab77-19142f9f81bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-e845a20f-183c-4300-8f6b-73cc42758c79,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-e214056d-6a6d-4e33-9155-c7b4e647d6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-dfabf1e2-13f3-4cf5-b3fe-6d95800286e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464332330-172.17.0.15-1597310242375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39498,DS-2d455a22-d4fa-4f30-8cd8-8eb9b1f5abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-938d2640-1dcf-48cd-8310-e9025f4c0889,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-e0797513-d3b4-422e-86da-a0b67dcf55ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-c7bb3567-7b68-4959-9157-4314b6e0baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-47d38db6-ab6e-470f-acaa-0e0dc8610307,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-eee36137-e030-4051-81a6-2ad929c186aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-3f6731e3-3ecb-4543-8b07-8a6fde58ca17,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-a57debe4-56f3-4f44-b97e-4dfa9fb6c09e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464332330-172.17.0.15-1597310242375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39498,DS-2d455a22-d4fa-4f30-8cd8-8eb9b1f5abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-938d2640-1dcf-48cd-8310-e9025f4c0889,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-e0797513-d3b4-422e-86da-a0b67dcf55ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-c7bb3567-7b68-4959-9157-4314b6e0baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-47d38db6-ab6e-470f-acaa-0e0dc8610307,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-eee36137-e030-4051-81a6-2ad929c186aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-3f6731e3-3ecb-4543-8b07-8a6fde58ca17,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-a57debe4-56f3-4f44-b97e-4dfa9fb6c09e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516878539-172.17.0.15-1597310494889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33002,DS-870548db-8f1a-4a75-9463-2ba8ce54028c,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-55267a6a-2b61-4375-a519-d8ffd57e5d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-48488a1b-f8f6-45d6-8332-85ee1c8625f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-135efcbf-4303-4bca-b252-d0cbef6382c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-f2c10618-6a55-429a-aefe-387ac35c5265,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-5f0761d1-6123-48c0-ae2f-691de746092f,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-db0b441e-9065-4d94-b66e-d0965598d407,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-68babc0f-1a68-4aa4-bad6-71dd0e1c9947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1516878539-172.17.0.15-1597310494889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33002,DS-870548db-8f1a-4a75-9463-2ba8ce54028c,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-55267a6a-2b61-4375-a519-d8ffd57e5d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-48488a1b-f8f6-45d6-8332-85ee1c8625f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-135efcbf-4303-4bca-b252-d0cbef6382c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-f2c10618-6a55-429a-aefe-387ac35c5265,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-5f0761d1-6123-48c0-ae2f-691de746092f,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-db0b441e-9065-4d94-b66e-d0965598d407,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-68babc0f-1a68-4aa4-bad6-71dd0e1c9947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939970144-172.17.0.15-1597310641846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37318,DS-0074555a-f7e9-483f-88ed-ab43000eb6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-50b8513c-7557-42c7-9180-cebc765bbd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-f0c027c7-d7e3-4d50-9742-40ffd88e0a76,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-6b6b9501-46ed-40ff-8cc5-eb250c63e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-2552bae2-7afc-4807-8c1a-9b218456436c,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-c0471e9a-da66-478a-9b18-6bf4c034cc05,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-454af7e8-5682-4156-9afe-105cdcecef5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-11e29a77-2a7a-4189-994d-0eba347e5acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939970144-172.17.0.15-1597310641846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37318,DS-0074555a-f7e9-483f-88ed-ab43000eb6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-50b8513c-7557-42c7-9180-cebc765bbd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-f0c027c7-d7e3-4d50-9742-40ffd88e0a76,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-6b6b9501-46ed-40ff-8cc5-eb250c63e94d,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-2552bae2-7afc-4807-8c1a-9b218456436c,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-c0471e9a-da66-478a-9b18-6bf4c034cc05,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-454af7e8-5682-4156-9afe-105cdcecef5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-11e29a77-2a7a-4189-994d-0eba347e5acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022786255-172.17.0.15-1597310798897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-ba4a55d1-3133-4f87-ab43-17e8f16b9d66,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-a5d98ebb-ec72-41f1-9fd8-7a1befb93a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-611433a1-6236-48a8-9c2e-0198cebeb6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-3fa3d515-aa6e-4478-bc39-59e02538a55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-dfbe6f04-5bd3-4afa-b7f9-7b895c4adcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-34d10584-a31a-45f3-a438-52e04fa468f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-6a25d5be-67ef-4bf3-929f-9b5641fae924,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-1daf75e9-b0e5-4db9-a8f8-69cc918a309a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022786255-172.17.0.15-1597310798897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-ba4a55d1-3133-4f87-ab43-17e8f16b9d66,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-a5d98ebb-ec72-41f1-9fd8-7a1befb93a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-611433a1-6236-48a8-9c2e-0198cebeb6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-3fa3d515-aa6e-4478-bc39-59e02538a55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-dfbe6f04-5bd3-4afa-b7f9-7b895c4adcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-34d10584-a31a-45f3-a438-52e04fa468f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-6a25d5be-67ef-4bf3-929f-9b5641fae924,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-1daf75e9-b0e5-4db9-a8f8-69cc918a309a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681663502-172.17.0.15-1597310837516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43151,DS-719c792b-27da-4b10-8f9c-61a9233deef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-b4aa96f2-b6d5-489f-bc8f-a7ed03de2a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-b1694cc4-1a88-497e-94b6-f431c59dda77,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-9c9dcd0e-e0b0-433c-bc4b-be63ace20c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-9ab5c225-2388-4c4b-bbc5-3521074af0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-d6d1a57e-9bf0-49ee-8076-d318b0e609ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-ede16018-4ad5-49c5-b355-e00f0051f969,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-79e7efbd-b543-4bc5-aa75-16f1f00cd6a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681663502-172.17.0.15-1597310837516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43151,DS-719c792b-27da-4b10-8f9c-61a9233deef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-b4aa96f2-b6d5-489f-bc8f-a7ed03de2a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-b1694cc4-1a88-497e-94b6-f431c59dda77,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-9c9dcd0e-e0b0-433c-bc4b-be63ace20c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-9ab5c225-2388-4c4b-bbc5-3521074af0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-d6d1a57e-9bf0-49ee-8076-d318b0e609ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-ede16018-4ad5-49c5-b355-e00f0051f969,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-79e7efbd-b543-4bc5-aa75-16f1f00cd6a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992079814-172.17.0.15-1597311176666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38177,DS-222f87c2-7102-4225-8582-55f226366b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-4bf9a093-f699-4471-8609-789f4eb7238b,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-a16719b4-27f6-4a2a-8439-6428a743322e,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-b45d1f3e-c67f-4723-ba6e-cea34235f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-ec0c9a09-b7ed-460c-99bc-c0d76e8413ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-a7008d90-9a5b-4bf3-8c91-28e2258ea7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-28fb20d1-77cf-42b9-9121-d4a16065c8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-3d8fbc01-1d00-442a-9390-69517803f490,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992079814-172.17.0.15-1597311176666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38177,DS-222f87c2-7102-4225-8582-55f226366b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-4bf9a093-f699-4471-8609-789f4eb7238b,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-a16719b4-27f6-4a2a-8439-6428a743322e,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-b45d1f3e-c67f-4723-ba6e-cea34235f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-ec0c9a09-b7ed-460c-99bc-c0d76e8413ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-a7008d90-9a5b-4bf3-8c91-28e2258ea7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-28fb20d1-77cf-42b9-9121-d4a16065c8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-3d8fbc01-1d00-442a-9390-69517803f490,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560004493-172.17.0.15-1597311220412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41065,DS-5fee3f27-c658-48bc-93f3-491feff63766,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-4e62cb25-033f-4054-8597-47804e34f349,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-71a5e84c-5860-4320-a329-d50535b936a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-b626e7ca-2202-48da-9347-8306485d8643,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-92d2f7dc-345e-43b3-9581-00c21638a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-7e7be223-25f6-4f75-ac96-cea692e4e09d,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-61c84f40-a4bb-4d08-8609-381553374c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-f4b4e8e1-095d-4795-8901-4c3be9896805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560004493-172.17.0.15-1597311220412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41065,DS-5fee3f27-c658-48bc-93f3-491feff63766,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-4e62cb25-033f-4054-8597-47804e34f349,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-71a5e84c-5860-4320-a329-d50535b936a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-b626e7ca-2202-48da-9347-8306485d8643,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-92d2f7dc-345e-43b3-9581-00c21638a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-7e7be223-25f6-4f75-ac96-cea692e4e09d,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-61c84f40-a4bb-4d08-8609-381553374c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-f4b4e8e1-095d-4795-8901-4c3be9896805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772749121-172.17.0.15-1597311269156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-3748e351-5873-4cb2-b696-ba459800b727,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-782b3756-16aa-4e27-a735-2b658048d099,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-d0a1d60f-7069-429c-a2f3-b0f14e6dbe78,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-2f5bb707-737f-4249-82d5-4c0d16e431cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-3deb8cd4-761e-437c-a460-1545361da899,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-0c8c351a-4e00-4573-94f2-a0f355d20329,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-c1f35a4a-79cb-45de-a615-5ffbde587f68,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-ead5e5ef-ac67-4a77-8dc3-06c90c730ad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772749121-172.17.0.15-1597311269156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-3748e351-5873-4cb2-b696-ba459800b727,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-782b3756-16aa-4e27-a735-2b658048d099,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-d0a1d60f-7069-429c-a2f3-b0f14e6dbe78,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-2f5bb707-737f-4249-82d5-4c0d16e431cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-3deb8cd4-761e-437c-a460-1545361da899,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-0c8c351a-4e00-4573-94f2-a0f355d20329,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-c1f35a4a-79cb-45de-a615-5ffbde587f68,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-ead5e5ef-ac67-4a77-8dc3-06c90c730ad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738305178-172.17.0.15-1597311417789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45785,DS-9b1b58f6-8bb2-4286-9292-cd533de23a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-853ecaff-394e-4792-90b3-0e56235054db,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-c9cd2dba-19fa-41f7-9ecb-53c57f50544c,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-6019eb1a-ace4-4013-b9f6-43eaa5cd15b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-eadb6e28-ba73-4ddd-90cc-ac9ee54119bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-dad19856-1158-4f8e-aaab-11469fa35519,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-0c95094d-975f-4065-88ef-9a8d5aadcbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-5fa5bf2f-d1c7-4fb8-a2df-47e1cd53512d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738305178-172.17.0.15-1597311417789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45785,DS-9b1b58f6-8bb2-4286-9292-cd533de23a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-853ecaff-394e-4792-90b3-0e56235054db,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-c9cd2dba-19fa-41f7-9ecb-53c57f50544c,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-6019eb1a-ace4-4013-b9f6-43eaa5cd15b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-eadb6e28-ba73-4ddd-90cc-ac9ee54119bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-dad19856-1158-4f8e-aaab-11469fa35519,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-0c95094d-975f-4065-88ef-9a8d5aadcbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-5fa5bf2f-d1c7-4fb8-a2df-47e1cd53512d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292471272-172.17.0.15-1597311788157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34271,DS-1e4ec4ec-b9fb-40aa-b960-2da741e76aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-ac5b73c2-6584-4e69-98f5-01332b42aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-d21441bf-c8a8-4243-a58a-bac5bc94eb14,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-9f9e47fe-1006-4753-90df-cb147d59ddae,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-73daa496-95a4-4b34-8245-d812577f2e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-b7abc63b-cf92-47a8-8f05-3d6dcbf3fb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-a635f0d4-7770-4045-b680-675d3398bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-802f1c75-be58-4ca0-85e7-878484aa3a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292471272-172.17.0.15-1597311788157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34271,DS-1e4ec4ec-b9fb-40aa-b960-2da741e76aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-ac5b73c2-6584-4e69-98f5-01332b42aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-d21441bf-c8a8-4243-a58a-bac5bc94eb14,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-9f9e47fe-1006-4753-90df-cb147d59ddae,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-73daa496-95a4-4b34-8245-d812577f2e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-b7abc63b-cf92-47a8-8f05-3d6dcbf3fb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-a635f0d4-7770-4045-b680-675d3398bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-802f1c75-be58-4ca0-85e7-878484aa3a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346447287-172.17.0.15-1597311883022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-bebe0869-991c-4c99-8039-92993999aa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-277df40b-341f-441d-8ea3-7a80d2023363,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-426446e0-2810-4a2d-baca-52a880238f36,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-48e256ee-fec2-478e-850b-a42e02cdfad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-4c8c5381-aaf9-4c71-b2ee-98314e7524f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-0ec977fb-9d51-4575-bd13-1224b43fb414,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-a39d5f76-0aae-40f6-abb5-8ad3325cedc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-0102e4e1-9a22-4f67-9bb0-1b8788f9e15c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346447287-172.17.0.15-1597311883022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-bebe0869-991c-4c99-8039-92993999aa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-277df40b-341f-441d-8ea3-7a80d2023363,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-426446e0-2810-4a2d-baca-52a880238f36,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-48e256ee-fec2-478e-850b-a42e02cdfad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-4c8c5381-aaf9-4c71-b2ee-98314e7524f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-0ec977fb-9d51-4575-bd13-1224b43fb414,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-a39d5f76-0aae-40f6-abb5-8ad3325cedc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-0102e4e1-9a22-4f67-9bb0-1b8788f9e15c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336255534-172.17.0.15-1597311984900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-4e50390a-79f7-42ad-b911-37061d992cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-bc2f17d6-721c-461f-b7b8-aad28605540f,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-ce831e44-91e5-4261-8b28-14aeaa5e9dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-96a43c53-eb14-4bf2-831a-e842cc997ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-63af90e8-ca68-488b-adab-eb9b63a638b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-0148cd50-2860-4ba9-b8b1-7bfba23edeae,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-2e2daa13-30a5-4115-b96d-c14a046d60dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-20aadeac-7e0f-423a-b057-8f5a95f65b1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336255534-172.17.0.15-1597311984900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-4e50390a-79f7-42ad-b911-37061d992cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-bc2f17d6-721c-461f-b7b8-aad28605540f,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-ce831e44-91e5-4261-8b28-14aeaa5e9dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-96a43c53-eb14-4bf2-831a-e842cc997ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-63af90e8-ca68-488b-adab-eb9b63a638b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-0148cd50-2860-4ba9-b8b1-7bfba23edeae,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-2e2daa13-30a5-4115-b96d-c14a046d60dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-20aadeac-7e0f-423a-b057-8f5a95f65b1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200071828-172.17.0.15-1597312034207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38578,DS-cc7043f1-bff8-4c79-ae61-005e8a557094,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-b37f195b-ff3d-44c6-aa04-f67496a1f191,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-63fc2183-8dfb-4c2a-b3a9-3b6ccf78038b,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-9dcdb74f-22bb-46fc-ae1d-51f2ccd586d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-50f2286c-2379-4aff-af2d-a3521c71b62e,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-300e9f22-9451-4814-9372-eb33154922ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-f41355ff-d807-4e9b-a27c-8db17de8f949,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-e159e75a-f35f-43a6-a463-b33b442b4094,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200071828-172.17.0.15-1597312034207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38578,DS-cc7043f1-bff8-4c79-ae61-005e8a557094,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-b37f195b-ff3d-44c6-aa04-f67496a1f191,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-63fc2183-8dfb-4c2a-b3a9-3b6ccf78038b,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-9dcdb74f-22bb-46fc-ae1d-51f2ccd586d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-50f2286c-2379-4aff-af2d-a3521c71b62e,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-300e9f22-9451-4814-9372-eb33154922ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-f41355ff-d807-4e9b-a27c-8db17de8f949,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-e159e75a-f35f-43a6-a463-b33b442b4094,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759796650-172.17.0.15-1597312080506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36255,DS-eaacfa1f-f2f8-4753-a7fa-72686c3f0135,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-bcd943c1-e95b-49a9-82c2-8953dd95c0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-be9c50b9-3efd-4f8f-9ad8-7da0d7cf1b05,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-bf9b03d5-440b-4027-a576-687670e1b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-942b72f5-5315-48e9-85de-e12bc5fe5b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-765525e9-5215-4fc0-aa67-c35154bfa609,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-762b436c-d60b-4821-bcd3-d3f280b2802c,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-1d49bb08-fc73-4719-80f1-e81152bbf1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759796650-172.17.0.15-1597312080506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36255,DS-eaacfa1f-f2f8-4753-a7fa-72686c3f0135,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-bcd943c1-e95b-49a9-82c2-8953dd95c0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-be9c50b9-3efd-4f8f-9ad8-7da0d7cf1b05,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-bf9b03d5-440b-4027-a576-687670e1b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-942b72f5-5315-48e9-85de-e12bc5fe5b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-765525e9-5215-4fc0-aa67-c35154bfa609,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-762b436c-d60b-4821-bcd3-d3f280b2802c,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-1d49bb08-fc73-4719-80f1-e81152bbf1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042999229-172.17.0.15-1597312134190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-806924c6-2344-4d27-a85a-5519f941dd09,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-1354f62f-2cf7-4906-9268-bf1738d5e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-35b3e0db-6bac-4e24-bc12-3f0aaa52e0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-a2b1c94f-3b0a-46be-b528-2313a60a4df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-8783b009-f6bf-461c-905f-5e283a246c35,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-fdcf9b6d-88b4-489b-92d6-1ace277e7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-d0ef1b92-5195-4bf6-9a97-8ed8716c7857,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-62bace66-a6b9-41b0-ba38-7a6d7ff082a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042999229-172.17.0.15-1597312134190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43312,DS-806924c6-2344-4d27-a85a-5519f941dd09,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-1354f62f-2cf7-4906-9268-bf1738d5e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-35b3e0db-6bac-4e24-bc12-3f0aaa52e0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-a2b1c94f-3b0a-46be-b528-2313a60a4df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-8783b009-f6bf-461c-905f-5e283a246c35,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-fdcf9b6d-88b4-489b-92d6-1ace277e7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-d0ef1b92-5195-4bf6-9a97-8ed8716c7857,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-62bace66-a6b9-41b0-ba38-7a6d7ff082a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718980235-172.17.0.15-1597312188019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34812,DS-10e9501c-6d43-408a-8fb5-943d983de674,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-2146e2a0-788c-44e4-95f6-24671e0fe8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-e0cc4fdf-dd14-42af-b603-9079b5b0cfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-7295c5f4-246f-4c8b-9a4f-40a645c72a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-00c42e04-55b8-45ed-a8a5-3f391815027b,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-9619db75-3e23-4d28-9786-66791e0b0e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-029ab61c-087b-4926-bc6c-49de7230565e,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-a31531af-da02-4cb2-a9ec-0a871f8c9727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718980235-172.17.0.15-1597312188019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34812,DS-10e9501c-6d43-408a-8fb5-943d983de674,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-2146e2a0-788c-44e4-95f6-24671e0fe8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-e0cc4fdf-dd14-42af-b603-9079b5b0cfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-7295c5f4-246f-4c8b-9a4f-40a645c72a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-00c42e04-55b8-45ed-a8a5-3f391815027b,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-9619db75-3e23-4d28-9786-66791e0b0e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-029ab61c-087b-4926-bc6c-49de7230565e,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-a31531af-da02-4cb2-a9ec-0a871f8c9727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932895065-172.17.0.15-1597312325406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32960,DS-cbf4450b-29c4-4a99-a2e5-81783747b342,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-1ad92b3e-77b9-4fec-89a5-a7d34fddd87b,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-79263896-3838-48f6-bf30-c6c22e1c289a,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-5abe4701-9fc0-4b3b-9088-cb6adf818fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-ec2924dc-6c3c-4c3c-9e17-1fd48efee44e,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-dd8307c7-5300-40a6-b8ac-f9669aed90e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-64b3681c-d0fb-445a-9587-7a87efbffee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-da65f98c-2cf5-476c-b751-cc372b809147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932895065-172.17.0.15-1597312325406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32960,DS-cbf4450b-29c4-4a99-a2e5-81783747b342,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-1ad92b3e-77b9-4fec-89a5-a7d34fddd87b,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-79263896-3838-48f6-bf30-c6c22e1c289a,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-5abe4701-9fc0-4b3b-9088-cb6adf818fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-ec2924dc-6c3c-4c3c-9e17-1fd48efee44e,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-dd8307c7-5300-40a6-b8ac-f9669aed90e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-64b3681c-d0fb-445a-9587-7a87efbffee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-da65f98c-2cf5-476c-b751-cc372b809147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639133898-172.17.0.15-1597312646788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37565,DS-dd5fa30b-91b2-4d73-a22a-f9fdfde19fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-5936fd73-5230-41f4-8e65-93ee61d60b12,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-5ad9034d-09ac-45a0-bdb9-44bd17e76a11,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-7a0cd96b-ea14-4036-9092-fd743894d339,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-a3c9ba8d-d2f1-4dee-8b90-29eb86066485,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-621c345d-8ab8-4aa7-9e40-7d7ea5a0f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-f200ba59-0536-4199-8b47-f817e9c06b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-cb82e947-1720-4bf9-9c88-ec933693c3b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639133898-172.17.0.15-1597312646788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37565,DS-dd5fa30b-91b2-4d73-a22a-f9fdfde19fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-5936fd73-5230-41f4-8e65-93ee61d60b12,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-5ad9034d-09ac-45a0-bdb9-44bd17e76a11,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-7a0cd96b-ea14-4036-9092-fd743894d339,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-a3c9ba8d-d2f1-4dee-8b90-29eb86066485,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-621c345d-8ab8-4aa7-9e40-7d7ea5a0f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-f200ba59-0536-4199-8b47-f817e9c06b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-cb82e947-1720-4bf9-9c88-ec933693c3b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207169303-172.17.0.15-1597312938483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42532,DS-ec3e25b9-6c45-4ad5-a664-8f63183ff6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-6a8e8fd3-55a4-40c9-bfcd-b5640998f7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-9c560cab-97d8-43cf-b0bc-72b196857587,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-9541c0d2-d8cd-4cc8-9fe2-e02f2d325f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-179f9cc8-177e-4ae1-93fb-ad9d8eadd368,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-3b498eae-9090-4ae0-a10a-3e54363ff23e,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-661ac7c9-bece-41b4-80e6-204a87f8a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-d0e5982f-240b-476a-b3c0-45f544790d54,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207169303-172.17.0.15-1597312938483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42532,DS-ec3e25b9-6c45-4ad5-a664-8f63183ff6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-6a8e8fd3-55a4-40c9-bfcd-b5640998f7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-9c560cab-97d8-43cf-b0bc-72b196857587,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-9541c0d2-d8cd-4cc8-9fe2-e02f2d325f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-179f9cc8-177e-4ae1-93fb-ad9d8eadd368,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-3b498eae-9090-4ae0-a10a-3e54363ff23e,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-661ac7c9-bece-41b4-80e6-204a87f8a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-d0e5982f-240b-476a-b3c0-45f544790d54,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068122377-172.17.0.15-1597313697553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-50c5949f-eefa-4a5b-a1f7-c6fdff8d450e,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-352b7524-0c6a-4f3d-8f1f-d2447169e99a,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-ce04e3db-b2e4-4edc-8629-da70154db6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-3f95590f-88dc-4de6-8d13-ee9f7c226c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-b0eeeb1e-f51b-47e9-918c-d8ab2b88052d,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e8a9fe45-f01f-4df0-a2c9-e523b3098b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-292b736e-577d-45ac-83c9-78b25b901b15,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-c20d0c2f-427d-4de4-a562-c05b9a86aeed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068122377-172.17.0.15-1597313697553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37702,DS-50c5949f-eefa-4a5b-a1f7-c6fdff8d450e,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-352b7524-0c6a-4f3d-8f1f-d2447169e99a,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-ce04e3db-b2e4-4edc-8629-da70154db6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-3f95590f-88dc-4de6-8d13-ee9f7c226c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-b0eeeb1e-f51b-47e9-918c-d8ab2b88052d,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e8a9fe45-f01f-4df0-a2c9-e523b3098b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-292b736e-577d-45ac-83c9-78b25b901b15,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-c20d0c2f-427d-4de4-a562-c05b9a86aeed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513235510-172.17.0.15-1597313802363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-52c387bf-4cdc-47ae-8fa8-0dd971fcce97,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-78f088a1-f66b-42aa-91b7-5a5157da6b62,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-f567c5ac-e32d-4c7e-bc58-ebb28b02f733,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-448bf8dc-29b9-4637-b84d-26d50d5b9d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-c805d4c9-c1ca-4a7b-a7c7-3a00e18c9485,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-81cd17bc-d653-40df-bace-1bdca9d4f039,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-bc16b445-8a20-4964-98c8-62e1eed81139,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-aadf4ce9-8bf0-4822-a457-6d55491a6db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513235510-172.17.0.15-1597313802363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-52c387bf-4cdc-47ae-8fa8-0dd971fcce97,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-78f088a1-f66b-42aa-91b7-5a5157da6b62,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-f567c5ac-e32d-4c7e-bc58-ebb28b02f733,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-448bf8dc-29b9-4637-b84d-26d50d5b9d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-c805d4c9-c1ca-4a7b-a7c7-3a00e18c9485,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-81cd17bc-d653-40df-bace-1bdca9d4f039,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-bc16b445-8a20-4964-98c8-62e1eed81139,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-aadf4ce9-8bf0-4822-a457-6d55491a6db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 2160
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234854967-172.17.0.15-1597313899708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45324,DS-2ad2583e-6915-46cd-812b-c997587c8dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-c53ed2ba-94d1-4cf3-8697-863e4b95f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-7208b47a-efe4-4bf3-b43a-9de1fccdb448,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-34d4b0a5-2fab-4f29-8b31-fefd5795325a,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-bb22ebb7-9aac-4ab8-b0c0-d6e5f617b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-e025d77a-fc0b-431a-8bb5-51d0e506f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-ab07eb19-ca17-4b5e-9eb5-f497abdc3550,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-d7486a8c-cacd-4afd-a472-f4c88ebbb4d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234854967-172.17.0.15-1597313899708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45324,DS-2ad2583e-6915-46cd-812b-c997587c8dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-c53ed2ba-94d1-4cf3-8697-863e4b95f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-7208b47a-efe4-4bf3-b43a-9de1fccdb448,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-34d4b0a5-2fab-4f29-8b31-fefd5795325a,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-bb22ebb7-9aac-4ab8-b0c0-d6e5f617b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-e025d77a-fc0b-431a-8bb5-51d0e506f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-ab07eb19-ca17-4b5e-9eb5-f497abdc3550,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-d7486a8c-cacd-4afd-a472-f4c88ebbb4d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 7326
