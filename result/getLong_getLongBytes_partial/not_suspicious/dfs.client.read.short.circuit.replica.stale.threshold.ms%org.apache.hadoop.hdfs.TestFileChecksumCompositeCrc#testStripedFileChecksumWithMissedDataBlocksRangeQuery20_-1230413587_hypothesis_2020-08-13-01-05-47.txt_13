reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126350766-172.17.0.4-1597281445006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36132,DS-a18d8614-f23b-45a2-8bad-aeb7c4e6aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-70e5e94a-a9c4-4dcb-8106-5a5f843f9d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-56cffc69-cc3f-46b4-a7e5-7c64e2d8d702,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-2d90e862-0383-4b28-a47f-c43f62b79d30,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-1c7be562-5fec-4461-a1c2-26743449f75f,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-8ad8d924-0a31-4b1e-8385-01c894c42e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-fd8132f1-d567-48b6-890a-12101714b301,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-44edb4f1-aab5-4cfb-a5bf-93750072a916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126350766-172.17.0.4-1597281445006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36132,DS-a18d8614-f23b-45a2-8bad-aeb7c4e6aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-70e5e94a-a9c4-4dcb-8106-5a5f843f9d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-56cffc69-cc3f-46b4-a7e5-7c64e2d8d702,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-2d90e862-0383-4b28-a47f-c43f62b79d30,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-1c7be562-5fec-4461-a1c2-26743449f75f,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-8ad8d924-0a31-4b1e-8385-01c894c42e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-fd8132f1-d567-48b6-890a-12101714b301,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-44edb4f1-aab5-4cfb-a5bf-93750072a916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049051081-172.17.0.4-1597281557876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-c58e7e5b-fe7f-41da-a569-b51c08fba47e,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-7f2ae43d-e82b-453f-ac12-999fd8f409a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-0f09b0c9-e824-4ba7-8760-4d476f4ffae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-24fb5ae4-1906-4cf1-a0fd-cf3c86389004,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-6c129a21-9734-417b-9c4a-b4ee5523e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-53b14534-3dc4-4f6e-ae3b-078a9d9165e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-c0652ba1-6f49-44e3-a5ca-ca68d30307a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-dc555705-dd9d-4d9c-9c16-dbd789ac7095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049051081-172.17.0.4-1597281557876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-c58e7e5b-fe7f-41da-a569-b51c08fba47e,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-7f2ae43d-e82b-453f-ac12-999fd8f409a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-0f09b0c9-e824-4ba7-8760-4d476f4ffae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-24fb5ae4-1906-4cf1-a0fd-cf3c86389004,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-6c129a21-9734-417b-9c4a-b4ee5523e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-53b14534-3dc4-4f6e-ae3b-078a9d9165e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-c0652ba1-6f49-44e3-a5ca-ca68d30307a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-dc555705-dd9d-4d9c-9c16-dbd789ac7095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123963013-172.17.0.4-1597281709913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32877,DS-f8cae548-562f-4ffe-9991-7ac1984657fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-4f99b767-ec43-4039-9ff4-752d468bf784,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-a2718c21-cfc1-407f-ac58-93736200183f,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-2c818dc0-2d48-45ff-a513-4cea0fc6d305,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-507422a0-996f-42d9-aa2e-c4e1c1d206e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-2e7f4b35-b1c8-4d40-8910-f2e1568fc45e,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-51d449c7-bea7-4adb-81b5-a354bfdb9016,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-d7e392b2-564a-45f9-bcb4-f1fd3efc14d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123963013-172.17.0.4-1597281709913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32877,DS-f8cae548-562f-4ffe-9991-7ac1984657fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-4f99b767-ec43-4039-9ff4-752d468bf784,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-a2718c21-cfc1-407f-ac58-93736200183f,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-2c818dc0-2d48-45ff-a513-4cea0fc6d305,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-507422a0-996f-42d9-aa2e-c4e1c1d206e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-2e7f4b35-b1c8-4d40-8910-f2e1568fc45e,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-51d449c7-bea7-4adb-81b5-a354bfdb9016,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-d7e392b2-564a-45f9-bcb4-f1fd3efc14d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550265479-172.17.0.4-1597282010586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-807bc8b3-9c27-4104-9429-04d8c43eda64,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-c9e4f9f8-5c51-4439-955c-fbb003bbd662,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-46630b49-37fd-4c6e-8ebb-b716df6a465a,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-a71d8094-a02e-41cf-a2f3-e2c2d5dbc85b,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-01252540-6d35-4622-a99e-50d49edca68c,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-92f4f31e-fd8b-4598-93f4-6f6695679258,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-f719df6a-a008-4d7a-b7d1-e840b8fa15d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d4309963-ad93-4c9d-81e9-1cd1f5160705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550265479-172.17.0.4-1597282010586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-807bc8b3-9c27-4104-9429-04d8c43eda64,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-c9e4f9f8-5c51-4439-955c-fbb003bbd662,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-46630b49-37fd-4c6e-8ebb-b716df6a465a,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-a71d8094-a02e-41cf-a2f3-e2c2d5dbc85b,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-01252540-6d35-4622-a99e-50d49edca68c,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-92f4f31e-fd8b-4598-93f4-6f6695679258,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-f719df6a-a008-4d7a-b7d1-e840b8fa15d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d4309963-ad93-4c9d-81e9-1cd1f5160705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642589654-172.17.0.4-1597282363932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33161,DS-ed2d05cd-bf2e-4740-8b6b-5210525f7aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-49bf7eb4-ee05-4d00-a07d-0bb78e8b66c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-e8f3fe8f-f859-4623-a342-9cf17c430352,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-f8142a99-ecfc-43c4-b03c-fe122f67d20a,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e3a748eb-432e-4027-9d91-684029f9e70a,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-7862cbaa-ba77-442c-a1e8-174dbced7aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-478e956e-a34c-4924-b308-24ba3a9e8a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-1afe6d62-6d04-464c-8327-a6671276a7ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642589654-172.17.0.4-1597282363932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33161,DS-ed2d05cd-bf2e-4740-8b6b-5210525f7aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-49bf7eb4-ee05-4d00-a07d-0bb78e8b66c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-e8f3fe8f-f859-4623-a342-9cf17c430352,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-f8142a99-ecfc-43c4-b03c-fe122f67d20a,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e3a748eb-432e-4027-9d91-684029f9e70a,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-7862cbaa-ba77-442c-a1e8-174dbced7aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-478e956e-a34c-4924-b308-24ba3a9e8a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-1afe6d62-6d04-464c-8327-a6671276a7ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558612335-172.17.0.4-1597282686285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-73ee5ae3-9012-4b27-ba77-b20cffe4bb38,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-3faf3cd7-17a7-40e1-90c1-46117f952e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-ffa59741-6b53-4a31-aa53-0bc64c79f35e,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-3bf7e63f-98da-45e8-b58a-02274f63022d,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-1b8077b2-8dc7-4efe-9893-fbfdb26c0a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-f6a8f9c3-b985-44d2-8e87-cbf4d3fad80a,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-bfd08ac6-2aee-480c-ba35-ca07b805ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-7f5659f2-0191-4bb8-9192-4df87472ca8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558612335-172.17.0.4-1597282686285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-73ee5ae3-9012-4b27-ba77-b20cffe4bb38,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-3faf3cd7-17a7-40e1-90c1-46117f952e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-ffa59741-6b53-4a31-aa53-0bc64c79f35e,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-3bf7e63f-98da-45e8-b58a-02274f63022d,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-1b8077b2-8dc7-4efe-9893-fbfdb26c0a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-f6a8f9c3-b985-44d2-8e87-cbf4d3fad80a,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-bfd08ac6-2aee-480c-ba35-ca07b805ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-7f5659f2-0191-4bb8-9192-4df87472ca8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195297394-172.17.0.4-1597282967190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-77a7d229-03eb-4cb9-9b78-c645dc881914,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-b30a2a52-2fee-448f-a7ab-d2f696131950,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-d6b99c2f-7098-4d44-9df0-137971cee812,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-8a01ea14-ef71-4d90-9d99-355f07312da3,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-f1751cc2-40b2-4c33-b650-b513f08cd39d,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-00d28c52-1f25-4c4d-a702-7de736da9145,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a150f7b2-1596-4d98-ade1-707fc6a7766b,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-16835a57-93ab-49fa-814f-6b5c70189e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195297394-172.17.0.4-1597282967190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-77a7d229-03eb-4cb9-9b78-c645dc881914,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-b30a2a52-2fee-448f-a7ab-d2f696131950,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-d6b99c2f-7098-4d44-9df0-137971cee812,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-8a01ea14-ef71-4d90-9d99-355f07312da3,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-f1751cc2-40b2-4c33-b650-b513f08cd39d,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-00d28c52-1f25-4c4d-a702-7de736da9145,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-a150f7b2-1596-4d98-ade1-707fc6a7766b,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-16835a57-93ab-49fa-814f-6b5c70189e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511092999-172.17.0.4-1597283223049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-b9485d03-3545-4db0-ac8b-c38b67dcdd22,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-7c6375ff-520e-4e98-9ec7-afbe223e958d,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-bbf503b9-91d2-46a8-8e37-73c6ea05f273,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-340369a8-50c0-4298-8f57-44932a9c9a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-94cab5a5-5cd7-4a0e-b653-e1e5de2de8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-50650aee-a5a7-452f-942f-fc984e88730a,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-3a87f66d-3f66-4760-b8ad-3cbd8a8eafcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-3581b4d9-497e-4669-ab7b-652f524c863e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511092999-172.17.0.4-1597283223049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-b9485d03-3545-4db0-ac8b-c38b67dcdd22,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-7c6375ff-520e-4e98-9ec7-afbe223e958d,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-bbf503b9-91d2-46a8-8e37-73c6ea05f273,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-340369a8-50c0-4298-8f57-44932a9c9a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-94cab5a5-5cd7-4a0e-b653-e1e5de2de8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-50650aee-a5a7-452f-942f-fc984e88730a,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-3a87f66d-3f66-4760-b8ad-3cbd8a8eafcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-3581b4d9-497e-4669-ab7b-652f524c863e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976840819-172.17.0.4-1597283381887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34834,DS-75b366a7-498f-4d9f-b33a-77d19e31fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-b042e7bf-a9c9-42e9-9923-2cf2e1d90543,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-29bddd0d-8cb3-4744-91ac-28923d164066,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-674ceb19-2972-40c0-8177-ec66d14f4420,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-c00a11ba-335e-4c1e-8c87-d5eac61fc94a,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-9c6ce316-0259-4299-ba4b-0789fc551b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-e119097c-136a-41e4-920b-52b04dcc5cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-9366fa32-4be7-4d7c-9f29-dff9787794d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976840819-172.17.0.4-1597283381887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34834,DS-75b366a7-498f-4d9f-b33a-77d19e31fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-b042e7bf-a9c9-42e9-9923-2cf2e1d90543,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-29bddd0d-8cb3-4744-91ac-28923d164066,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-674ceb19-2972-40c0-8177-ec66d14f4420,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-c00a11ba-335e-4c1e-8c87-d5eac61fc94a,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-9c6ce316-0259-4299-ba4b-0789fc551b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-e119097c-136a-41e4-920b-52b04dcc5cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-9366fa32-4be7-4d7c-9f29-dff9787794d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229787036-172.17.0.4-1597283419121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39821,DS-4814b681-4365-46a2-97c7-075f642d0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-47c5c3d7-cff1-4bc1-8f3f-ff5cd626778e,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-2d4b6075-5fdf-421a-a876-904f6cdedf31,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-d3d8bc54-99bb-4053-98cc-ff55048ae5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-ab36373f-a120-4ad0-ae7b-233244918b77,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-a151d92a-b48d-40b5-85ae-5fb92b3b1b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-34221d67-dc09-4f50-8f08-6ca4fc754b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-50c2dda9-5ec0-44c1-aa89-a5c1135d64ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229787036-172.17.0.4-1597283419121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39821,DS-4814b681-4365-46a2-97c7-075f642d0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-47c5c3d7-cff1-4bc1-8f3f-ff5cd626778e,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-2d4b6075-5fdf-421a-a876-904f6cdedf31,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-d3d8bc54-99bb-4053-98cc-ff55048ae5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-ab36373f-a120-4ad0-ae7b-233244918b77,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-a151d92a-b48d-40b5-85ae-5fb92b3b1b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-34221d67-dc09-4f50-8f08-6ca4fc754b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-50c2dda9-5ec0-44c1-aa89-a5c1135d64ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731036267-172.17.0.4-1597283461097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38511,DS-8a0b8d77-d72f-4fb5-8f55-d5c2d3639e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-55bd52cf-8e1a-49c3-80f2-88eb8f06e1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-8825be07-7d50-410a-89bf-64bf15ca2c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-a8f630ec-5607-41b4-b050-72acf8c6f220,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-8e821eb0-cf7a-4db0-82af-1646d37a19a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-109f7f22-2756-462d-a6ee-f67dd1251b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-d1b5ab75-51fe-4b79-888b-79381f001306,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-f2cd6542-8e09-44f4-8b0c-bb37716626bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731036267-172.17.0.4-1597283461097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38511,DS-8a0b8d77-d72f-4fb5-8f55-d5c2d3639e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-55bd52cf-8e1a-49c3-80f2-88eb8f06e1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-8825be07-7d50-410a-89bf-64bf15ca2c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-a8f630ec-5607-41b4-b050-72acf8c6f220,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-8e821eb0-cf7a-4db0-82af-1646d37a19a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-109f7f22-2756-462d-a6ee-f67dd1251b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-d1b5ab75-51fe-4b79-888b-79381f001306,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-f2cd6542-8e09-44f4-8b0c-bb37716626bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621485614-172.17.0.4-1597283801332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37286,DS-3ff4db53-c1ff-4d2a-960d-3ebbf44e4901,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-6ce69ca8-48da-4c0d-9f94-2f9f065886f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-dc2ad97b-74c0-4b9a-a31d-e4fde91f888c,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-3bcf4dd2-21a4-4257-9468-8a3b5e5d97b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-9d03a004-1c0e-4c3d-a95c-7fdf31e9b0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-13201017-ae5f-406d-be26-b14cfaac72f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-7bb9d680-a378-4023-9a17-d08e809d68d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-e58a8f6a-74be-4ed9-bc8d-cc1a09550b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621485614-172.17.0.4-1597283801332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37286,DS-3ff4db53-c1ff-4d2a-960d-3ebbf44e4901,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-6ce69ca8-48da-4c0d-9f94-2f9f065886f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-dc2ad97b-74c0-4b9a-a31d-e4fde91f888c,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-3bcf4dd2-21a4-4257-9468-8a3b5e5d97b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-9d03a004-1c0e-4c3d-a95c-7fdf31e9b0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-13201017-ae5f-406d-be26-b14cfaac72f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-7bb9d680-a378-4023-9a17-d08e809d68d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-e58a8f6a-74be-4ed9-bc8d-cc1a09550b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087079946-172.17.0.4-1597284458756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35684,DS-a2e1bbd0-7270-4528-8f63-a665ccf7bd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-b1b95ce7-692f-469e-83a1-a01b0ff9d46d,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-0629b745-c2a6-4b21-85cf-0a0c985056f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-80400f28-3a93-4c81-8753-66007f7a772f,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-d7807095-9952-4d19-8c46-3fb86ecac178,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-0030b4ca-ecdc-4f4f-9912-18e10482b329,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-74136d1e-ee3a-4885-9259-0cb336ef0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-2414c10b-7389-4aa2-962b-310a1850b5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087079946-172.17.0.4-1597284458756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35684,DS-a2e1bbd0-7270-4528-8f63-a665ccf7bd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-b1b95ce7-692f-469e-83a1-a01b0ff9d46d,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-0629b745-c2a6-4b21-85cf-0a0c985056f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-80400f28-3a93-4c81-8753-66007f7a772f,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-d7807095-9952-4d19-8c46-3fb86ecac178,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-0030b4ca-ecdc-4f4f-9912-18e10482b329,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-74136d1e-ee3a-4885-9259-0cb336ef0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-2414c10b-7389-4aa2-962b-310a1850b5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874204367-172.17.0.4-1597284792077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34001,DS-f669f210-0ac8-461d-95e9-839021681017,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-2a6cfe88-8146-4ecb-91ee-8632414d61c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-2cc176fc-b069-442b-8601-556b50a6d364,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-91f4b3dd-44aa-4769-8e57-49faa8157fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-bf428d14-92da-45d0-9d7d-169294601c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-07e61093-bcfc-404f-9d5e-9d32321dd5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-79f5f5b2-ba59-4e19-95d8-317b6d54717d,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-973a4630-4776-46f3-b6dd-2285b4c05be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874204367-172.17.0.4-1597284792077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34001,DS-f669f210-0ac8-461d-95e9-839021681017,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-2a6cfe88-8146-4ecb-91ee-8632414d61c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-2cc176fc-b069-442b-8601-556b50a6d364,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-91f4b3dd-44aa-4769-8e57-49faa8157fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-bf428d14-92da-45d0-9d7d-169294601c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-07e61093-bcfc-404f-9d5e-9d32321dd5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-79f5f5b2-ba59-4e19-95d8-317b6d54717d,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-973a4630-4776-46f3-b6dd-2285b4c05be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 2000000
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105310156-172.17.0.4-1597285728570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37174,DS-93ef2d05-bb3d-4aa7-b2be-071d2fe25bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-ef9d2437-2d12-4b1c-9e50-a07b674bf035,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-f16ebd6b-8c37-4342-9fd0-239126048dad,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-66c7ecc1-f7f2-4298-8e2a-1224f8938ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-0dc50c41-8728-4fd7-9935-e78bf60578a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-5d7efa28-3428-43d5-b3d2-f0f2f343daea,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-4e1de7ae-770e-46eb-904b-95ac486844f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-5bbcf9eb-756d-4162-a323-ae39774306ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105310156-172.17.0.4-1597285728570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37174,DS-93ef2d05-bb3d-4aa7-b2be-071d2fe25bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-ef9d2437-2d12-4b1c-9e50-a07b674bf035,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-f16ebd6b-8c37-4342-9fd0-239126048dad,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-66c7ecc1-f7f2-4298-8e2a-1224f8938ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-0dc50c41-8728-4fd7-9935-e78bf60578a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-5d7efa28-3428-43d5-b3d2-f0f2f343daea,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-4e1de7ae-770e-46eb-904b-95ac486844f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-5bbcf9eb-756d-4162-a323-ae39774306ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5600
