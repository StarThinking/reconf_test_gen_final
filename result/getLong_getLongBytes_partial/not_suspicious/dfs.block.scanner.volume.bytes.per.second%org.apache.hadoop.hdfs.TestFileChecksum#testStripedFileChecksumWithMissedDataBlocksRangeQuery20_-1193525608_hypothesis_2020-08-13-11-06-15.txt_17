reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262126671-172.17.0.6-1597317100610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-349fb10b-2193-44f7-9c96-1b1bda95764f,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-43877198-cb51-496b-8711-548d332cd1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-3f72a987-06c7-4fe8-b7ab-840ca47f9791,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-823f66fe-5677-41bd-a01a-adecc1c14951,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-58ef2172-513e-449a-9fc1-3e4f7735e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-c9fa1c12-cad4-47d6-bf94-4e500c924383,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-1635b20e-1741-48ea-b907-2fd0a8e595fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-f11a638f-28eb-468b-8126-25d2ac07ede1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262126671-172.17.0.6-1597317100610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-349fb10b-2193-44f7-9c96-1b1bda95764f,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-43877198-cb51-496b-8711-548d332cd1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-3f72a987-06c7-4fe8-b7ab-840ca47f9791,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-823f66fe-5677-41bd-a01a-adecc1c14951,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-58ef2172-513e-449a-9fc1-3e4f7735e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-c9fa1c12-cad4-47d6-bf94-4e500c924383,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-1635b20e-1741-48ea-b907-2fd0a8e595fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-f11a638f-28eb-468b-8126-25d2ac07ede1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844783206-172.17.0.6-1597318121084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37431,DS-761a2c06-d05a-4e10-ac1e-45e3203472ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-c6388286-5c58-4c11-8cf1-9210327c34ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-74645a06-cf8a-4b3a-8e68-416db6eceead,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-63a696a8-963f-49bc-ad77-74637dbe747e,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-280e968a-e2d2-435a-a6e1-9690e6383518,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-c96dc473-2363-41cc-ab21-3197d3d9c1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-c15eb81b-0b98-486b-84e4-e897296eb28b,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-99db2876-cc23-4d1f-a33f-9539345d39fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844783206-172.17.0.6-1597318121084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37431,DS-761a2c06-d05a-4e10-ac1e-45e3203472ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-c6388286-5c58-4c11-8cf1-9210327c34ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-74645a06-cf8a-4b3a-8e68-416db6eceead,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-63a696a8-963f-49bc-ad77-74637dbe747e,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-280e968a-e2d2-435a-a6e1-9690e6383518,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-c96dc473-2363-41cc-ab21-3197d3d9c1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-c15eb81b-0b98-486b-84e4-e897296eb28b,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-99db2876-cc23-4d1f-a33f-9539345d39fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696120993-172.17.0.6-1597318272245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-21cc8037-f683-47c2-aec0-23323de05247,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-97f61411-9a4e-4ae3-ac23-b5f25414255d,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-2fea657c-c150-48c9-beb2-ced0bc7f4d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-580ed0df-f19c-4a0a-a1f4-c977547dc4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-c78d4ce8-5abe-4b70-94fc-71af57c6a5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-cc9e350e-ada3-4d04-9d98-c876fa2b9bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-0d768592-244a-4bb2-87ea-d8659d5c0a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-6cb4c514-ba99-4e0e-b1b0-ca36bb8400df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696120993-172.17.0.6-1597318272245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-21cc8037-f683-47c2-aec0-23323de05247,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-97f61411-9a4e-4ae3-ac23-b5f25414255d,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-2fea657c-c150-48c9-beb2-ced0bc7f4d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-580ed0df-f19c-4a0a-a1f4-c977547dc4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-c78d4ce8-5abe-4b70-94fc-71af57c6a5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-cc9e350e-ada3-4d04-9d98-c876fa2b9bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-0d768592-244a-4bb2-87ea-d8659d5c0a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-6cb4c514-ba99-4e0e-b1b0-ca36bb8400df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923165473-172.17.0.6-1597319129650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43689,DS-f136f13e-0fb9-4edb-8f5c-ac7b4cf48027,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-aa0f6369-15a0-448e-b385-1ef4834c1e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-53209323-7069-4271-b7a8-9aa18df93d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-0c31e5b7-8e9d-44ad-9edb-95b265516626,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-997352cc-6da2-424b-96b4-1681b4291fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-b2900426-c5f6-403b-addf-90167cfd5b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-db87bbb0-1252-4ba3-a23e-073cb6babfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-440db0d5-4085-4d26-a8bd-53ceed71bafa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923165473-172.17.0.6-1597319129650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43689,DS-f136f13e-0fb9-4edb-8f5c-ac7b4cf48027,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-aa0f6369-15a0-448e-b385-1ef4834c1e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-53209323-7069-4271-b7a8-9aa18df93d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-0c31e5b7-8e9d-44ad-9edb-95b265516626,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-997352cc-6da2-424b-96b4-1681b4291fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-b2900426-c5f6-403b-addf-90167cfd5b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-db87bbb0-1252-4ba3-a23e-073cb6babfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-440db0d5-4085-4d26-a8bd-53ceed71bafa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693038352-172.17.0.6-1597319481473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45439,DS-5cd8f9ae-31f8-42ec-aa97-1f5d1b836ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-2cdd0ca0-4d06-4e52-bdb5-10e0fc0d218f,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-c2fb5786-2ccf-4f98-a939-7b076d1c32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-8deceac1-9b50-45df-a694-8aca77bcab2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-9891d115-d63d-4958-90d2-003ae5bcdb86,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-656eb4e0-bf7a-455f-9e27-20977b7e1a23,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-dddc535f-5d66-48bb-896c-e88b74ae286b,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-0e722c1e-8c8a-43f9-a68b-0ab69a978de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693038352-172.17.0.6-1597319481473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45439,DS-5cd8f9ae-31f8-42ec-aa97-1f5d1b836ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-2cdd0ca0-4d06-4e52-bdb5-10e0fc0d218f,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-c2fb5786-2ccf-4f98-a939-7b076d1c32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-8deceac1-9b50-45df-a694-8aca77bcab2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-9891d115-d63d-4958-90d2-003ae5bcdb86,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-656eb4e0-bf7a-455f-9e27-20977b7e1a23,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-dddc535f-5d66-48bb-896c-e88b74ae286b,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-0e722c1e-8c8a-43f9-a68b-0ab69a978de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791594558-172.17.0.6-1597319845064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46727,DS-4b61daff-b497-4673-a001-3d31f128a78b,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-b5571891-4867-4238-9f08-171333ac8c35,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-5c7c10b8-d230-4f14-8cbc-32bfa2f161c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-bb707226-0b7e-4a2d-832c-59e57ccb46b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-48bfacff-7e7a-45eb-a1fa-903359646503,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-af7b5ac2-9f70-4615-a4a6-4557fa3c32a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-fccfda0b-eb84-4ba0-b14c-5ff928b88e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-cb504af7-46e0-40d0-9883-d7f0a5138e00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791594558-172.17.0.6-1597319845064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46727,DS-4b61daff-b497-4673-a001-3d31f128a78b,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-b5571891-4867-4238-9f08-171333ac8c35,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-5c7c10b8-d230-4f14-8cbc-32bfa2f161c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-bb707226-0b7e-4a2d-832c-59e57ccb46b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-48bfacff-7e7a-45eb-a1fa-903359646503,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-af7b5ac2-9f70-4615-a4a6-4557fa3c32a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-fccfda0b-eb84-4ba0-b14c-5ff928b88e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-cb504af7-46e0-40d0-9883-d7f0a5138e00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331558388-172.17.0.6-1597320098565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-dde0c6f8-8b9e-4d2c-a85c-7008136c9e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-92a38a08-1108-46fc-8d25-becc25d5e901,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-5cb688fd-5980-4237-a47c-7ee170554b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-f2c8cfb8-e626-4594-a8af-7b8ad170aba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-856d5b50-13ad-4128-a191-a4c11d87007d,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-39022b17-2686-4f7a-b99b-927af0e9a537,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-9e9a22a0-076d-447e-b0a6-db11dc87af38,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-77b0d339-8fe9-4f82-bca2-1975050bb4b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331558388-172.17.0.6-1597320098565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-dde0c6f8-8b9e-4d2c-a85c-7008136c9e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-92a38a08-1108-46fc-8d25-becc25d5e901,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-5cb688fd-5980-4237-a47c-7ee170554b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-f2c8cfb8-e626-4594-a8af-7b8ad170aba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-856d5b50-13ad-4128-a191-a4c11d87007d,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-39022b17-2686-4f7a-b99b-927af0e9a537,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-9e9a22a0-076d-447e-b0a6-db11dc87af38,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-77b0d339-8fe9-4f82-bca2-1975050bb4b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28981636-172.17.0.6-1597320178099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38286,DS-8146ae31-072e-439a-b348-46dbafbd68d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-da1348b2-a3f2-470e-80c4-d4216cd89a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-ad1544db-dff8-4174-9dd7-0810889ec717,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-ee9966ab-e911-4881-82d8-d87ce76cbe14,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-1bf88a41-e31f-4930-b724-a85c8b2d0532,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-7b6f96f9-1a75-4a87-9114-230f3232e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-82b8a32a-8d52-4829-8ec0-3eda3f9b8fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-1ec927f2-4639-45ca-8cf6-f63587c1e9fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28981636-172.17.0.6-1597320178099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38286,DS-8146ae31-072e-439a-b348-46dbafbd68d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-da1348b2-a3f2-470e-80c4-d4216cd89a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-ad1544db-dff8-4174-9dd7-0810889ec717,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-ee9966ab-e911-4881-82d8-d87ce76cbe14,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-1bf88a41-e31f-4930-b724-a85c8b2d0532,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-7b6f96f9-1a75-4a87-9114-230f3232e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-82b8a32a-8d52-4829-8ec0-3eda3f9b8fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-1ec927f2-4639-45ca-8cf6-f63587c1e9fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213576170-172.17.0.6-1597320866197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37033,DS-327017da-bdfa-4581-972f-a3f12b0668b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-3820eb18-bd22-41f3-9c17-7b37e55175d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-dd580d41-7891-4c51-a962-b4f01a985022,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-96a36272-125b-4205-a3e4-20a439b6a946,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-04eff2cd-524d-4128-afdf-25643c5d3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-ea27272a-4a0b-43a1-8c32-4ad526c8b960,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-6ffe295d-9139-4d34-86f3-ddcbeb6d18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-91834a65-7c18-4891-8f27-cea5d6a53a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213576170-172.17.0.6-1597320866197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37033,DS-327017da-bdfa-4581-972f-a3f12b0668b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-3820eb18-bd22-41f3-9c17-7b37e55175d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-dd580d41-7891-4c51-a962-b4f01a985022,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-96a36272-125b-4205-a3e4-20a439b6a946,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-04eff2cd-524d-4128-afdf-25643c5d3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-ea27272a-4a0b-43a1-8c32-4ad526c8b960,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-6ffe295d-9139-4d34-86f3-ddcbeb6d18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-91834a65-7c18-4891-8f27-cea5d6a53a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257900280-172.17.0.6-1597320982645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40318,DS-32545681-8597-4fad-9b95-2177b340234b,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-e59e90ab-b73b-4c0e-ac55-a4643d2067b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-5a79d155-8f4c-4c3a-aa26-1aecb2eae9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-0d32b63d-74f0-40d3-b85e-dc113ed7e157,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-c212999a-de08-4698-bb15-56e9cd81bda9,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-96bfa6c6-1f41-44b7-9c8b-7568c09d3436,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-4b89f824-0a68-4927-b984-17df924e7eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-822df3e1-e036-4852-8541-14a8a12674f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257900280-172.17.0.6-1597320982645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40318,DS-32545681-8597-4fad-9b95-2177b340234b,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-e59e90ab-b73b-4c0e-ac55-a4643d2067b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-5a79d155-8f4c-4c3a-aa26-1aecb2eae9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-0d32b63d-74f0-40d3-b85e-dc113ed7e157,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-c212999a-de08-4698-bb15-56e9cd81bda9,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-96bfa6c6-1f41-44b7-9c8b-7568c09d3436,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-4b89f824-0a68-4927-b984-17df924e7eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-822df3e1-e036-4852-8541-14a8a12674f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683534246-172.17.0.6-1597321239309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41175,DS-cab03979-f629-49ec-9a68-21c47967d792,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-40adde59-e1bf-4298-b8f9-59e5b8f71b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-2fff5ba2-7a74-4fe5-b218-439ada2c9f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-605d7668-c03f-483a-a885-298b7062c897,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-0ea651e7-f1dc-48ab-8b5d-6e4cd3926fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-27499b7c-84d4-45a2-9696-dde81acdc105,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-419dd685-e7e2-4566-b4b3-91bda3a52f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-20f7cecb-1fb5-4dbe-bab5-ec3988466bc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683534246-172.17.0.6-1597321239309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41175,DS-cab03979-f629-49ec-9a68-21c47967d792,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-40adde59-e1bf-4298-b8f9-59e5b8f71b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-2fff5ba2-7a74-4fe5-b218-439ada2c9f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-605d7668-c03f-483a-a885-298b7062c897,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-0ea651e7-f1dc-48ab-8b5d-6e4cd3926fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-27499b7c-84d4-45a2-9696-dde81acdc105,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-419dd685-e7e2-4566-b4b3-91bda3a52f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-20f7cecb-1fb5-4dbe-bab5-ec3988466bc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545447837-172.17.0.6-1597321370644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34487,DS-e3bfd270-06eb-48dc-abb8-dc5e81b460f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-2bef3006-695d-4c02-98ab-ca2a6c749015,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-65f1f890-f012-4800-b7a0-3ca9e457f958,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-4928bd8b-a3cb-468c-8610-dc63b4a9b213,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-af6708ce-c0e7-4fbb-be86-8361cf6e63c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-e174aacf-0c16-4398-a085-33a57d3fa2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-1068c552-b59d-4df3-88bb-5cb1cb28e580,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-91f11562-e123-40c5-9bd6-99a6aacc2d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545447837-172.17.0.6-1597321370644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34487,DS-e3bfd270-06eb-48dc-abb8-dc5e81b460f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-2bef3006-695d-4c02-98ab-ca2a6c749015,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-65f1f890-f012-4800-b7a0-3ca9e457f958,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-4928bd8b-a3cb-468c-8610-dc63b4a9b213,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-af6708ce-c0e7-4fbb-be86-8361cf6e63c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-e174aacf-0c16-4398-a085-33a57d3fa2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-1068c552-b59d-4df3-88bb-5cb1cb28e580,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-91f11562-e123-40c5-9bd6-99a6aacc2d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1489327437-172.17.0.6-1597321708431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33889,DS-6292839c-b7a5-4050-ac79-ef56edd4e113,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-71fa14b9-eae7-455e-87ed-7c86b8c4fd83,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-2ce18e20-31ae-44a3-b68d-30bb8dbae7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-6732abcb-6e83-4e77-9003-41371c9c7453,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-235b9eb1-00e7-49db-9c49-765b6d0f1dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-58757338-05ad-40f6-94f9-d345ebcae009,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-bea3a2e4-0f69-4310-b3b9-45ad3d3e21cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-6e8a1e4f-837e-4bfa-83da-95db50f72334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1489327437-172.17.0.6-1597321708431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33889,DS-6292839c-b7a5-4050-ac79-ef56edd4e113,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-71fa14b9-eae7-455e-87ed-7c86b8c4fd83,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-2ce18e20-31ae-44a3-b68d-30bb8dbae7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-6732abcb-6e83-4e77-9003-41371c9c7453,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-235b9eb1-00e7-49db-9c49-765b6d0f1dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-58757338-05ad-40f6-94f9-d345ebcae009,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-bea3a2e4-0f69-4310-b3b9-45ad3d3e21cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-6e8a1e4f-837e-4bfa-83da-95db50f72334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1857231826-172.17.0.6-1597321817379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36184,DS-e2b1816c-83a6-4062-bbd4-f650e9cfbb45,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-6f7f14a4-d23d-46ad-b99d-79a28c3c5db3,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-2045862e-afd7-4c27-8d6b-51efe09f715f,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-d03814bb-07e7-4880-9c85-50f6ba769e61,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-5bd2d5de-a3ac-4317-b5c2-25fa10d07dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-2be6b99a-a7a9-4fea-9741-5f13c67f87a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-9072252b-d055-4698-a9ae-c7a4e44f88f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-39e726e1-fba2-4214-aef2-2282f4c7fcd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1857231826-172.17.0.6-1597321817379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36184,DS-e2b1816c-83a6-4062-bbd4-f650e9cfbb45,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-6f7f14a4-d23d-46ad-b99d-79a28c3c5db3,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-2045862e-afd7-4c27-8d6b-51efe09f715f,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-d03814bb-07e7-4880-9c85-50f6ba769e61,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-5bd2d5de-a3ac-4317-b5c2-25fa10d07dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-2be6b99a-a7a9-4fea-9741-5f13c67f87a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-9072252b-d055-4698-a9ae-c7a4e44f88f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-39e726e1-fba2-4214-aef2-2282f4c7fcd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932240495-172.17.0.6-1597322236087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-83c86e06-bfd3-4f01-a486-a22db916720b,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-9de7a286-6d8a-4594-9547-86f51500a30b,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-52cbfafb-4cdf-4993-8f9d-0676343a023b,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-234b71af-5723-4107-a870-f234ae71d189,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-386d26db-9f61-47c9-87c0-9a38eaca04de,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-217e1d6c-c0e8-47bb-9917-64f326ba0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-2d3f91c2-b926-469a-8e45-3a007725b786,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-1e3791c6-aa15-44de-ab57-67d486d60778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932240495-172.17.0.6-1597322236087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-83c86e06-bfd3-4f01-a486-a22db916720b,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-9de7a286-6d8a-4594-9547-86f51500a30b,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-52cbfafb-4cdf-4993-8f9d-0676343a023b,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-234b71af-5723-4107-a870-f234ae71d189,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-386d26db-9f61-47c9-87c0-9a38eaca04de,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-217e1d6c-c0e8-47bb-9917-64f326ba0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-2d3f91c2-b926-469a-8e45-3a007725b786,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-1e3791c6-aa15-44de-ab57-67d486d60778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5912
