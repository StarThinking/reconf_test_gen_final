reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547306825-172.17.0.4-1597713513838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38918,DS-0eb063e1-ccb5-4c2a-9cc5-70e86c4e3744,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-efd5f03b-702b-41c6-a311-92b8a696a2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-9cf75b70-ee2f-4f6a-a23f-effc1644badb,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-dfb1de5a-0322-48f7-aba9-851d1874f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-2fe68ac9-ba8f-4ca1-b1ab-f741b5506306,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-0cd6b16b-3d5f-4fd1-b61b-b07808808c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-989c4d22-2ca5-4f15-bed2-32ab0750a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-b4a54cc0-31b6-4dcb-b8cd-98e5c8fe6724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547306825-172.17.0.4-1597713513838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38918,DS-0eb063e1-ccb5-4c2a-9cc5-70e86c4e3744,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-efd5f03b-702b-41c6-a311-92b8a696a2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-9cf75b70-ee2f-4f6a-a23f-effc1644badb,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-dfb1de5a-0322-48f7-aba9-851d1874f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-2fe68ac9-ba8f-4ca1-b1ab-f741b5506306,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-0cd6b16b-3d5f-4fd1-b61b-b07808808c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-989c4d22-2ca5-4f15-bed2-32ab0750a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-b4a54cc0-31b6-4dcb-b8cd-98e5c8fe6724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61398740-172.17.0.4-1597713671816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-20c656b6-54f1-4b95-b3fe-bb2b8237bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-7b4d01bd-ed57-4f4c-b082-116b9f20b052,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-03249450-0a0e-4320-b6a3-a9b59a1f71ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-093c089c-6b0b-4477-a7e8-6c3a4d045eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-b5ffc6da-21f2-4b67-bdd5-3df50fba59e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-a62870d7-40d6-4e70-9940-e5f13344e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-b3194c1a-9ef6-4d17-84ae-625b57c16dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-8e3130ab-24e9-42da-a9f2-494e41a4dcf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61398740-172.17.0.4-1597713671816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-20c656b6-54f1-4b95-b3fe-bb2b8237bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-7b4d01bd-ed57-4f4c-b082-116b9f20b052,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-03249450-0a0e-4320-b6a3-a9b59a1f71ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-093c089c-6b0b-4477-a7e8-6c3a4d045eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-b5ffc6da-21f2-4b67-bdd5-3df50fba59e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-a62870d7-40d6-4e70-9940-e5f13344e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-b3194c1a-9ef6-4d17-84ae-625b57c16dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-8e3130ab-24e9-42da-a9f2-494e41a4dcf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376685424-172.17.0.4-1597713713502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-c3dfd32c-631c-4f28-947f-a9b152b09ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-c1e6c271-88c8-470f-8eac-d8e57c1634aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-23245661-7c0c-454c-8711-1f50ff0a5be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-7e5cbe0c-4746-45b7-98ab-2fffd96cd640,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-31900a85-3078-46df-a557-9b93716b2eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-3a121140-2848-4612-8888-1ac4633067c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-5af61a99-e2c5-44fe-a640-997d8a437b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-a6a59273-81bc-46b3-b62e-c0cb772de56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376685424-172.17.0.4-1597713713502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-c3dfd32c-631c-4f28-947f-a9b152b09ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-c1e6c271-88c8-470f-8eac-d8e57c1634aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-23245661-7c0c-454c-8711-1f50ff0a5be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-7e5cbe0c-4746-45b7-98ab-2fffd96cd640,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-31900a85-3078-46df-a557-9b93716b2eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-3a121140-2848-4612-8888-1ac4633067c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-5af61a99-e2c5-44fe-a640-997d8a437b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-a6a59273-81bc-46b3-b62e-c0cb772de56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830881825-172.17.0.4-1597714077394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-7a4c8cdd-6979-4326-b6ed-89e583334121,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-35e9ca00-0d42-48d6-a538-70c203b194bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-610425dd-22e4-45f4-bae9-806ca5c83f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-8b682e56-adf1-4f83-aca4-1b559c642275,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-b8d1a9cc-8855-4db0-852c-dc515f1f6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-f76ba473-479e-4d4b-be0b-73b82629b30f,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-b1069118-3413-4b08-9c29-a76b6ff1c858,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-99969463-e088-46e5-b745-694b9c0b7640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830881825-172.17.0.4-1597714077394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-7a4c8cdd-6979-4326-b6ed-89e583334121,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-35e9ca00-0d42-48d6-a538-70c203b194bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-610425dd-22e4-45f4-bae9-806ca5c83f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-8b682e56-adf1-4f83-aca4-1b559c642275,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-b8d1a9cc-8855-4db0-852c-dc515f1f6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-f76ba473-479e-4d4b-be0b-73b82629b30f,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-b1069118-3413-4b08-9c29-a76b6ff1c858,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-99969463-e088-46e5-b745-694b9c0b7640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152299723-172.17.0.4-1597714114759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-64cbc047-a011-4871-a828-519b377168d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-05210646-6e07-4d11-9982-5febd3537c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-5e9a754c-3f96-41e7-bb25-91a9fd2633bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-5d0bcf5d-9f6e-40bf-b34c-55d3e80268ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-c3c0d663-d07f-4272-a642-82afe0741a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-887b020f-37bd-44c2-abb5-0ce7e7c349ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-5681bebc-e8a0-4bf5-bceb-6bac488e4dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-fb0e1d02-403d-42eb-a6f3-2b0e040d95d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152299723-172.17.0.4-1597714114759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-64cbc047-a011-4871-a828-519b377168d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-05210646-6e07-4d11-9982-5febd3537c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-5e9a754c-3f96-41e7-bb25-91a9fd2633bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-5d0bcf5d-9f6e-40bf-b34c-55d3e80268ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-c3c0d663-d07f-4272-a642-82afe0741a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-887b020f-37bd-44c2-abb5-0ce7e7c349ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-5681bebc-e8a0-4bf5-bceb-6bac488e4dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-fb0e1d02-403d-42eb-a6f3-2b0e040d95d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56640144-172.17.0.4-1597714384070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-b0576c70-a795-4fab-a9ee-8fc331f4e804,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-1845234b-530a-49d8-8ef0-3222bb78b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-aaafeeff-5c78-48d4-b518-5acff741a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-cf97cc34-2139-4b99-a07d-afc872c4f1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-c2cd0fd5-f6e9-4a9e-a1c4-4114447b0c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-ac723838-af9b-46b0-a474-54ab1b07db54,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-a885c0e9-f175-4916-8968-a0577b27b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-b2e6f1f2-35bb-48bc-b3f3-9c8e6820d417,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56640144-172.17.0.4-1597714384070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-b0576c70-a795-4fab-a9ee-8fc331f4e804,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-1845234b-530a-49d8-8ef0-3222bb78b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-aaafeeff-5c78-48d4-b518-5acff741a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-cf97cc34-2139-4b99-a07d-afc872c4f1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-c2cd0fd5-f6e9-4a9e-a1c4-4114447b0c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-ac723838-af9b-46b0-a474-54ab1b07db54,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-a885c0e9-f175-4916-8968-a0577b27b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-b2e6f1f2-35bb-48bc-b3f3-9c8e6820d417,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638245962-172.17.0.4-1597714743146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-af3a6c3c-e214-432e-9c8d-867033f64e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-26aa3110-c40e-4d92-9cbb-938580f0c7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-2c577ac9-e0fe-490f-8bc5-d03a53609b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-f504c0da-0c7e-4d69-8645-a1c52378ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-887e76b6-efb7-4e13-8baa-dd42a23fbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-8424ffc1-fdc0-4ab0-aae1-2b0429ad00b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-85025ca9-441c-44dc-8c1d-31f37311b18f,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-7ee08259-048d-4db6-b660-15189de9f2f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638245962-172.17.0.4-1597714743146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-af3a6c3c-e214-432e-9c8d-867033f64e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-26aa3110-c40e-4d92-9cbb-938580f0c7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-2c577ac9-e0fe-490f-8bc5-d03a53609b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-f504c0da-0c7e-4d69-8645-a1c52378ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-887e76b6-efb7-4e13-8baa-dd42a23fbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-8424ffc1-fdc0-4ab0-aae1-2b0429ad00b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-85025ca9-441c-44dc-8c1d-31f37311b18f,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-7ee08259-048d-4db6-b660-15189de9f2f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165107059-172.17.0.4-1597715062992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35818,DS-596f4325-60c5-422c-b200-987aa8f4b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-40380aa4-f613-48eb-9aaf-a2621e355a37,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-b16b9de7-d57b-4e0b-9e19-89da723da5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-9ddae9a6-751c-43c8-8023-e91d76cc2d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-03c8ff52-3bc7-4acd-8abf-dc3fb0a38770,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-cc847fd1-fecd-4a53-8bff-df69f1ab08d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-c5254e4f-8470-4c04-9069-64da7d37f839,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-232afe3a-54fc-4841-970b-01dd3042e4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165107059-172.17.0.4-1597715062992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35818,DS-596f4325-60c5-422c-b200-987aa8f4b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-40380aa4-f613-48eb-9aaf-a2621e355a37,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-b16b9de7-d57b-4e0b-9e19-89da723da5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-9ddae9a6-751c-43c8-8023-e91d76cc2d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-03c8ff52-3bc7-4acd-8abf-dc3fb0a38770,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-cc847fd1-fecd-4a53-8bff-df69f1ab08d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-c5254e4f-8470-4c04-9069-64da7d37f839,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-232afe3a-54fc-4841-970b-01dd3042e4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941832419-172.17.0.4-1597715102688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-c74e7e71-1f05-48cb-8061-4570ce073e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-d533c41d-ccde-40fb-9cd2-61251edd836d,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-e7288822-8f88-49f3-9eed-d286cbce8f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-9ee9fa82-3e88-44a8-a117-ee0ddc187e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-9df8595e-6217-4a31-971d-f67a837f0324,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-0aab4878-f1ca-419c-85d5-c2de0377d574,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-aeeca711-2eb7-4de8-8367-1e216c4669d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-733595da-4893-4160-8df1-3f22fd94a33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941832419-172.17.0.4-1597715102688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-c74e7e71-1f05-48cb-8061-4570ce073e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-d533c41d-ccde-40fb-9cd2-61251edd836d,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-e7288822-8f88-49f3-9eed-d286cbce8f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-9ee9fa82-3e88-44a8-a117-ee0ddc187e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-9df8595e-6217-4a31-971d-f67a837f0324,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-0aab4878-f1ca-419c-85d5-c2de0377d574,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-aeeca711-2eb7-4de8-8367-1e216c4669d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-733595da-4893-4160-8df1-3f22fd94a33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407627374-172.17.0.4-1597715260977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-7259e056-c819-4ca4-8b77-7aec6d181be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-fc4d47c3-eac5-4976-bcc1-98071fcae4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-47531638-4722-4762-a83e-258c2c906282,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-3fd8febf-6170-435c-81a5-5d827bd295db,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-d16d1126-4fce-44e4-ab2a-0158454c958a,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-10848a9e-9ddc-4f97-81fd-11fcfaf3207b,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-b94935bb-838b-4da0-8b82-14b8bca9e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-da1caf10-0420-4f0d-b304-210bd86747d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407627374-172.17.0.4-1597715260977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-7259e056-c819-4ca4-8b77-7aec6d181be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-fc4d47c3-eac5-4976-bcc1-98071fcae4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-47531638-4722-4762-a83e-258c2c906282,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-3fd8febf-6170-435c-81a5-5d827bd295db,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-d16d1126-4fce-44e4-ab2a-0158454c958a,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-10848a9e-9ddc-4f97-81fd-11fcfaf3207b,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-b94935bb-838b-4da0-8b82-14b8bca9e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-da1caf10-0420-4f0d-b304-210bd86747d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909342424-172.17.0.4-1597715294836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-26da28ea-c1a9-49bb-91b7-412d23056b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-413561ec-bdca-41fc-96f1-021b47a9eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-66776649-ac28-4359-bb5d-42e80aea44e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-11026b63-98fc-4c78-8d4d-6dac281fb68a,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-82c36d1b-47b5-4c97-a44e-f12addc97962,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-13a3fcd3-0414-4589-8d51-db4e429f368e,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-46b53fc2-ae94-43c1-8385-ad6143d91d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-9b29a195-2c68-4820-af64-cc7a714db447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909342424-172.17.0.4-1597715294836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-26da28ea-c1a9-49bb-91b7-412d23056b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-413561ec-bdca-41fc-96f1-021b47a9eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-66776649-ac28-4359-bb5d-42e80aea44e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-11026b63-98fc-4c78-8d4d-6dac281fb68a,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-82c36d1b-47b5-4c97-a44e-f12addc97962,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-13a3fcd3-0414-4589-8d51-db4e429f368e,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-46b53fc2-ae94-43c1-8385-ad6143d91d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-9b29a195-2c68-4820-af64-cc7a714db447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345261064-172.17.0.4-1597715639152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36666,DS-98eaf66a-0b0c-4ce8-afdc-cd35ac8938b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-3335b8fd-968c-4d64-b56c-d725a69af36b,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-af58a460-6ace-4df7-bd19-69b14891a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-2dbbf87c-ceca-4471-a6e4-d675c55554a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-0edccdad-9c30-4c83-b7a9-eacbe48fcf09,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-ad070d27-5526-4960-b3cb-bcf28c754164,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-442538af-743c-4102-851c-a087ecb0e372,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-abbeab5a-def7-4873-8bd4-e2b8b925d587,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345261064-172.17.0.4-1597715639152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36666,DS-98eaf66a-0b0c-4ce8-afdc-cd35ac8938b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-3335b8fd-968c-4d64-b56c-d725a69af36b,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-af58a460-6ace-4df7-bd19-69b14891a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-2dbbf87c-ceca-4471-a6e4-d675c55554a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-0edccdad-9c30-4c83-b7a9-eacbe48fcf09,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-ad070d27-5526-4960-b3cb-bcf28c754164,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-442538af-743c-4102-851c-a087ecb0e372,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-abbeab5a-def7-4873-8bd4-e2b8b925d587,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472550217-172.17.0.4-1597715674734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41728,DS-1b6e48af-3cd3-4d3b-a770-b45b2a96fbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-aaf285c0-8632-42e7-a8dc-f7cbee0ee471,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-a6435387-061c-446a-b3b9-2c0b8a96c898,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-1b15a06a-58db-48a2-8e48-38cb3dbb97eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-06ad385f-01e8-453e-97c9-215b40fc3fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-9cce65c7-6d9d-4f92-8dbf-18ff7dde3985,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-d86b77b2-021f-4984-b18b-a88443c63f23,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-bcbdc93a-0774-47e3-9fb6-b5ad7d569bdc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472550217-172.17.0.4-1597715674734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41728,DS-1b6e48af-3cd3-4d3b-a770-b45b2a96fbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-aaf285c0-8632-42e7-a8dc-f7cbee0ee471,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-a6435387-061c-446a-b3b9-2c0b8a96c898,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-1b15a06a-58db-48a2-8e48-38cb3dbb97eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-06ad385f-01e8-453e-97c9-215b40fc3fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-9cce65c7-6d9d-4f92-8dbf-18ff7dde3985,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-d86b77b2-021f-4984-b18b-a88443c63f23,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-bcbdc93a-0774-47e3-9fb6-b5ad7d569bdc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228950376-172.17.0.4-1597715900128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34834,DS-1e7c82c8-8c14-4c2e-a009-e7c537a6d2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-0d9eeca3-833c-46b0-98a5-40402b77e9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-1e898ba2-0a2e-4c7c-acba-160ca9c12ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-a17d1378-3ddb-430f-8827-1ec9638aac8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-4342ec3b-0d7d-4a90-a537-9340be3326c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-65c74046-40ba-4257-b84d-85f894501772,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-67b2330c-1077-4e27-aa98-169c61749d57,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-d5ce263a-4937-483f-89f8-bbcb6f2fd881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228950376-172.17.0.4-1597715900128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34834,DS-1e7c82c8-8c14-4c2e-a009-e7c537a6d2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-0d9eeca3-833c-46b0-98a5-40402b77e9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-1e898ba2-0a2e-4c7c-acba-160ca9c12ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-a17d1378-3ddb-430f-8827-1ec9638aac8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-4342ec3b-0d7d-4a90-a537-9340be3326c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-65c74046-40ba-4257-b84d-85f894501772,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-67b2330c-1077-4e27-aa98-169c61749d57,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-d5ce263a-4937-483f-89f8-bbcb6f2fd881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090382688-172.17.0.4-1597716176158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-ee15409a-879c-4a58-96b3-5b0af98905ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-9408c0eb-dd34-40e7-b7b1-7f7c73e0fb09,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-40e3b44c-6fc0-40e4-9daf-257a214bb70a,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-176e3553-6963-4ce1-b5e8-cbf4f24ca6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-1af4ba66-eef7-4bae-8319-5918d9e69581,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-b8d912e2-fe99-4da5-97ad-ccdc55870d31,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-b7b94caf-c714-41c9-9146-b73b75ea97dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-076f2b41-b979-4c83-be1a-f2d912cac754,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090382688-172.17.0.4-1597716176158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-ee15409a-879c-4a58-96b3-5b0af98905ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-9408c0eb-dd34-40e7-b7b1-7f7c73e0fb09,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-40e3b44c-6fc0-40e4-9daf-257a214bb70a,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-176e3553-6963-4ce1-b5e8-cbf4f24ca6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-1af4ba66-eef7-4bae-8319-5918d9e69581,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-b8d912e2-fe99-4da5-97ad-ccdc55870d31,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-b7b94caf-c714-41c9-9146-b73b75ea97dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-076f2b41-b979-4c83-be1a-f2d912cac754,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994357204-172.17.0.4-1597716708324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39438,DS-f0fa1154-7627-4f59-bd5c-a6ec1c54d45c,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-e053c420-a68f-4641-bfc7-300776f660ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-8bc50eae-3f89-4876-8aca-5b42c0033fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-51cad51e-85bc-4341-87bf-b2ebad141b49,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-fb9b659e-eeac-491c-a555-da50d798b7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-0a1a4522-d44d-4070-9a1b-32a00ec17df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-05f9d8d2-6f3c-403b-8ac0-3c54d2e3c08c,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-643763d6-2a57-4b12-8839-73e3ab96df1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994357204-172.17.0.4-1597716708324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39438,DS-f0fa1154-7627-4f59-bd5c-a6ec1c54d45c,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-e053c420-a68f-4641-bfc7-300776f660ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-8bc50eae-3f89-4876-8aca-5b42c0033fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-51cad51e-85bc-4341-87bf-b2ebad141b49,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-fb9b659e-eeac-491c-a555-da50d798b7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-0a1a4522-d44d-4070-9a1b-32a00ec17df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-05f9d8d2-6f3c-403b-8ac0-3c54d2e3c08c,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-643763d6-2a57-4b12-8839-73e3ab96df1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452898043-172.17.0.4-1597716935414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-24a79477-0344-4c90-9ac8-fa3a568e05da,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-fbdff4d3-bb05-4e96-8f9f-a738ea293ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-675d6eea-b918-41b8-90e0-e2b08a0c2c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-8af12928-a3ac-4a44-8b6b-74c589b0cce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-9cf28364-ffc6-4367-8f4e-5c85ecee1176,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-e5d11f91-555e-45a6-9bab-e64eeb7ed4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-ec361fe6-e137-4eeb-bc6a-2761d3278605,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-38947822-5c68-40fe-9a70-bde3339bba32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452898043-172.17.0.4-1597716935414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-24a79477-0344-4c90-9ac8-fa3a568e05da,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-fbdff4d3-bb05-4e96-8f9f-a738ea293ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-675d6eea-b918-41b8-90e0-e2b08a0c2c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-8af12928-a3ac-4a44-8b6b-74c589b0cce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-9cf28364-ffc6-4367-8f4e-5c85ecee1176,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-e5d11f91-555e-45a6-9bab-e64eeb7ed4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-ec361fe6-e137-4eeb-bc6a-2761d3278605,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-38947822-5c68-40fe-9a70-bde3339bba32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383881274-172.17.0.4-1597716980748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-cd985a1f-7dd7-44e7-9e38-773cd6f60e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-988db2e7-6831-458d-b959-737d0ee83052,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-8e8c5397-dc76-4f35-98b7-385f45533795,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-3c753d8c-5834-4930-a965-490f7fb67299,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-e42b2155-c7cc-4887-9144-b41c6f7fabea,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-880e3a75-7cf7-44b8-bc10-7c4ffe527f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-9f62f158-cc1e-40c3-a7c8-beb07e71bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-3bb26634-9155-47d8-9cff-cadd86d90202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383881274-172.17.0.4-1597716980748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-cd985a1f-7dd7-44e7-9e38-773cd6f60e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-988db2e7-6831-458d-b959-737d0ee83052,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-8e8c5397-dc76-4f35-98b7-385f45533795,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-3c753d8c-5834-4930-a965-490f7fb67299,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-e42b2155-c7cc-4887-9144-b41c6f7fabea,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-880e3a75-7cf7-44b8-bc10-7c4ffe527f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-9f62f158-cc1e-40c3-a7c8-beb07e71bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-3bb26634-9155-47d8-9cff-cadd86d90202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133806107-172.17.0.4-1597717220197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-e2015c67-53b7-4a72-8f51-bf6c1f36ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-c83461a3-d573-4a17-8a7c-c73d2c184816,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-0eecd79c-4298-45f4-93f9-e898134597e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-2f88a9c7-e0b1-4aeb-accb-75352e640237,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-c114e042-5267-4bb0-adc4-aae3c98ee907,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-9b4f8466-8c77-451d-8bed-a365e21015c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-c5ff0274-a588-4b94-8711-72261425dabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-cee723ae-5aff-45a0-93ba-4b4dd4cd8c92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133806107-172.17.0.4-1597717220197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-e2015c67-53b7-4a72-8f51-bf6c1f36ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-c83461a3-d573-4a17-8a7c-c73d2c184816,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-0eecd79c-4298-45f4-93f9-e898134597e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-2f88a9c7-e0b1-4aeb-accb-75352e640237,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-c114e042-5267-4bb0-adc4-aae3c98ee907,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-9b4f8466-8c77-451d-8bed-a365e21015c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-c5ff0274-a588-4b94-8711-72261425dabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-cee723ae-5aff-45a0-93ba-4b4dd4cd8c92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748677717-172.17.0.4-1597717291344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35796,DS-f4277bb7-760e-4f24-9237-0177f424b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-16ccaefe-928d-46f3-80f5-10c773ec4611,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-3193af2f-3f08-4c9c-91c1-64ca800be2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-abc224f4-d0b0-4125-90ce-dd317bc0d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-82e0febe-9e12-4846-a39a-fd7fb3afa06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-951f5e6c-e9a7-49a7-8efa-d982329ae1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-60804217-399b-46c9-bee3-ddc3f1aed77e,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-36d94c2b-fb42-4eaf-9f65-f8444d591b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748677717-172.17.0.4-1597717291344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35796,DS-f4277bb7-760e-4f24-9237-0177f424b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-16ccaefe-928d-46f3-80f5-10c773ec4611,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-3193af2f-3f08-4c9c-91c1-64ca800be2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-abc224f4-d0b0-4125-90ce-dd317bc0d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-82e0febe-9e12-4846-a39a-fd7fb3afa06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-951f5e6c-e9a7-49a7-8efa-d982329ae1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-60804217-399b-46c9-bee3-ddc3f1aed77e,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-36d94c2b-fb42-4eaf-9f65-f8444d591b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729400783-172.17.0.4-1597717458138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33802,DS-5f91b91d-6a94-4328-9498-5ef3633e3fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-f700b896-60c5-4eee-8e5d-38c2bd7998ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-fd76eb3c-7256-4da4-b27e-66af1b96cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-be3c37df-b6b0-404c-98b4-9d6b85a9207e,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-6acf73a2-211f-4456-b28a-3742366e1017,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-a8cdb4fa-adfd-453d-8eda-451ad80ac5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-04947bcc-8cac-4a7f-95a1-565e9ca0447b,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-944d9fba-37a6-4193-887b-cb2ecaf7f0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729400783-172.17.0.4-1597717458138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33802,DS-5f91b91d-6a94-4328-9498-5ef3633e3fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-f700b896-60c5-4eee-8e5d-38c2bd7998ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-fd76eb3c-7256-4da4-b27e-66af1b96cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-be3c37df-b6b0-404c-98b4-9d6b85a9207e,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-6acf73a2-211f-4456-b28a-3742366e1017,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-a8cdb4fa-adfd-453d-8eda-451ad80ac5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-04947bcc-8cac-4a7f-95a1-565e9ca0447b,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-944d9fba-37a6-4193-887b-cb2ecaf7f0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683259645-172.17.0.4-1597717576048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44761,DS-bbae4d54-053f-46aa-8290-e0f2b881b3be,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-517e9c73-6021-43f1-b85c-e095a21b8c69,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-01e0e8c9-865b-4fb6-8fd6-541a25fd5056,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-f027d421-73e5-4448-a97e-47f4533dbe28,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-c6b4645e-4bd6-48db-b94d-e4fc0a7809b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-8a007316-8eb6-4d93-9528-40baf11bdf87,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-722e4033-83bc-4d31-819f-28f5dbfabe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-6833ab5c-289f-4fff-8f1d-bfe4483fc4ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683259645-172.17.0.4-1597717576048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44761,DS-bbae4d54-053f-46aa-8290-e0f2b881b3be,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-517e9c73-6021-43f1-b85c-e095a21b8c69,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-01e0e8c9-865b-4fb6-8fd6-541a25fd5056,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-f027d421-73e5-4448-a97e-47f4533dbe28,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-c6b4645e-4bd6-48db-b94d-e4fc0a7809b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-8a007316-8eb6-4d93-9528-40baf11bdf87,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-722e4033-83bc-4d31-819f-28f5dbfabe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-6833ab5c-289f-4fff-8f1d-bfe4483fc4ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365419782-172.17.0.4-1597717622903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-e2bbba1c-1ab6-4fdd-a9ef-41e6ce28daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-033d1fb9-b081-4775-8f47-5e2a6deb7a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-f980375a-902e-4773-bbc1-651e346a684d,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-86e12c11-1f50-41a0-8585-ccfbf73de13f,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-288242db-5aca-4235-b6e6-7a979e641601,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-a0272cf1-c652-42c4-9a4f-35d81b94faca,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-e6a82a30-8ede-473a-afea-37457ef86191,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-04e60d31-c0df-447f-9df3-d8b1a1bc2416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365419782-172.17.0.4-1597717622903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-e2bbba1c-1ab6-4fdd-a9ef-41e6ce28daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-033d1fb9-b081-4775-8f47-5e2a6deb7a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-f980375a-902e-4773-bbc1-651e346a684d,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-86e12c11-1f50-41a0-8585-ccfbf73de13f,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-288242db-5aca-4235-b6e6-7a979e641601,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-a0272cf1-c652-42c4-9a4f-35d81b94faca,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-e6a82a30-8ede-473a-afea-37457ef86191,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-04e60d31-c0df-447f-9df3-d8b1a1bc2416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734416124-172.17.0.4-1597718106185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40454,DS-11d464cf-9968-446c-9629-19a5c2ecf61b,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-ae74b70b-f592-46cf-b101-a8d77e605c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-e383a229-023b-4a70-b760-1e9d35210f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-f25ac9f1-2285-4a16-b4bb-a5fba0c4d938,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-64ef94eb-2470-48d5-a11f-4fc546b3f8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-f1401009-f23f-4438-a8d9-dc8181e1ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-2fac8cda-a5af-427b-b5c7-0f2a7edfc689,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-cfc2b7b6-a521-4b9c-be48-45ab2477bd67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734416124-172.17.0.4-1597718106185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40454,DS-11d464cf-9968-446c-9629-19a5c2ecf61b,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-ae74b70b-f592-46cf-b101-a8d77e605c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-e383a229-023b-4a70-b760-1e9d35210f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-f25ac9f1-2285-4a16-b4bb-a5fba0c4d938,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-64ef94eb-2470-48d5-a11f-4fc546b3f8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-f1401009-f23f-4438-a8d9-dc8181e1ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-2fac8cda-a5af-427b-b5c7-0f2a7edfc689,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-cfc2b7b6-a521-4b9c-be48-45ab2477bd67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984997908-172.17.0.4-1597718367419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36623,DS-2dc26b50-9e91-4f38-906f-736df5630979,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-53c28284-a598-4ee3-9fb1-0e05742f0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-a06a1fb9-3404-4c16-9fbc-02e7814e88ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-78d8cf55-6aba-4368-9e9a-4ad7fff173a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-4a344182-c6ee-45a4-b1f1-eeb25a7e506e,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-df2aaab7-0521-473f-a3d5-097b32ab5bea,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-6dd02b2d-2579-4307-a468-9f1561e715bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-c4937986-eb7b-4540-a3d9-ab58c396d06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984997908-172.17.0.4-1597718367419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36623,DS-2dc26b50-9e91-4f38-906f-736df5630979,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-53c28284-a598-4ee3-9fb1-0e05742f0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-a06a1fb9-3404-4c16-9fbc-02e7814e88ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-78d8cf55-6aba-4368-9e9a-4ad7fff173a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-4a344182-c6ee-45a4-b1f1-eeb25a7e506e,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-df2aaab7-0521-473f-a3d5-097b32ab5bea,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-6dd02b2d-2579-4307-a468-9f1561e715bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-c4937986-eb7b-4540-a3d9-ab58c396d06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445437491-172.17.0.4-1597718709483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-1c37ce85-7de0-42e5-a737-02b1412e102b,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-6e4c2f7d-8acd-46b6-8b86-e0457862635f,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-8aca11b6-05d3-4523-a8e9-9454413c71b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-4c383013-0b79-4413-8c7b-68ff9ab722b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-0ce11bdf-c1af-44c0-a3e3-ec8fb18f42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-9394ff5e-1457-4b7e-a7f2-bc2380a3af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-a59b9ae6-9b0e-4202-8ef7-9c7601f3abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-97f3efd9-1f17-4722-8e18-b223520d6780,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445437491-172.17.0.4-1597718709483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-1c37ce85-7de0-42e5-a737-02b1412e102b,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-6e4c2f7d-8acd-46b6-8b86-e0457862635f,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-8aca11b6-05d3-4523-a8e9-9454413c71b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-4c383013-0b79-4413-8c7b-68ff9ab722b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-0ce11bdf-c1af-44c0-a3e3-ec8fb18f42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-9394ff5e-1457-4b7e-a7f2-bc2380a3af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-a59b9ae6-9b0e-4202-8ef7-9c7601f3abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-97f3efd9-1f17-4722-8e18-b223520d6780,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579496710-172.17.0.4-1597718823754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-996f1f9d-d34f-4a07-8ace-84e225c8c200,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-8a1561a9-67ff-4375-a2d4-46fe1508273b,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-8e7170da-91ac-4bc1-8822-d5b18ca10968,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-ce8a324d-1e14-4266-8277-2be345a22bab,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-81bafa1b-9c98-427d-89a6-a3df1a3eef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-ab6050b4-2e92-4dbf-9ded-1fe666e8b340,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-d459324a-cb3b-4ab1-9582-b14c58561216,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-f90bdbb8-008c-4942-b4f3-410fd049df61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579496710-172.17.0.4-1597718823754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-996f1f9d-d34f-4a07-8ace-84e225c8c200,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-8a1561a9-67ff-4375-a2d4-46fe1508273b,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-8e7170da-91ac-4bc1-8822-d5b18ca10968,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-ce8a324d-1e14-4266-8277-2be345a22bab,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-81bafa1b-9c98-427d-89a6-a3df1a3eef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-ab6050b4-2e92-4dbf-9ded-1fe666e8b340,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-d459324a-cb3b-4ab1-9582-b14c58561216,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-f90bdbb8-008c-4942-b4f3-410fd049df61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287043761-172.17.0.4-1597718864525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38625,DS-daaae37f-a5a9-451c-8828-99d4d323d475,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-657b71aa-7e76-4a12-bac5-9b535b3f9128,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-f62d4760-a0d5-4510-9ad8-fcd4ecda532c,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-9d26b97b-dc14-4f8d-8005-de5de71f2517,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-070118c2-eb13-4edf-ab2e-472f7f6e6f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-3e2fbe0f-4131-4393-aa01-d5ed41bcbf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-6937a818-c724-4ef2-92d3-e3255d01fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-5b2d49ee-aef9-40a4-b5df-001e39fbdab8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287043761-172.17.0.4-1597718864525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38625,DS-daaae37f-a5a9-451c-8828-99d4d323d475,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-657b71aa-7e76-4a12-bac5-9b535b3f9128,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-f62d4760-a0d5-4510-9ad8-fcd4ecda532c,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-9d26b97b-dc14-4f8d-8005-de5de71f2517,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-070118c2-eb13-4edf-ab2e-472f7f6e6f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-3e2fbe0f-4131-4393-aa01-d5ed41bcbf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-6937a818-c724-4ef2-92d3-e3255d01fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-5b2d49ee-aef9-40a4-b5df-001e39fbdab8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032174494-172.17.0.4-1597719006558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45973,DS-57a1ebda-18ad-4fd7-942e-1a5e2b78b5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-a51f8605-f37a-46d4-8a12-aa945b82a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-6c666511-92ce-43dd-97be-8d4b74671c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-8de29b2f-1f28-4d39-a3c1-5d5eca628bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-50a651e4-0d7f-4c7c-b9e8-eb0a2174b60c,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-d939e0f0-6f56-402a-9809-fa1767df7e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-83dfe898-ce02-4c48-9b80-a1bb3cedc3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-9fe90f92-b576-4f7b-b1c1-f14947b94642,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032174494-172.17.0.4-1597719006558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45973,DS-57a1ebda-18ad-4fd7-942e-1a5e2b78b5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-a51f8605-f37a-46d4-8a12-aa945b82a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-6c666511-92ce-43dd-97be-8d4b74671c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-8de29b2f-1f28-4d39-a3c1-5d5eca628bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-50a651e4-0d7f-4c7c-b9e8-eb0a2174b60c,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-d939e0f0-6f56-402a-9809-fa1767df7e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-83dfe898-ce02-4c48-9b80-a1bb3cedc3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-9fe90f92-b576-4f7b-b1c1-f14947b94642,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890604478-172.17.0.4-1597719050994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35890,DS-6bf869f5-d7ea-4d81-84d1-29f92f50979f,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-e628a20b-66e7-4145-89e6-ee74668aca52,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-79312f59-9a52-4a3f-8cf6-d82cfa94de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-acf9e524-878e-4c77-93d1-8d89f95c402c,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-507a8412-e8b7-4341-b195-907477fbeb03,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-83aeb57b-77d4-4982-a1b2-206a6d7647d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-9f47ac84-53c9-40f5-bdba-7c89f5de627e,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-0a870513-79d4-46cf-9fbe-965c7950a875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890604478-172.17.0.4-1597719050994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35890,DS-6bf869f5-d7ea-4d81-84d1-29f92f50979f,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-e628a20b-66e7-4145-89e6-ee74668aca52,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-79312f59-9a52-4a3f-8cf6-d82cfa94de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-acf9e524-878e-4c77-93d1-8d89f95c402c,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-507a8412-e8b7-4341-b195-907477fbeb03,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-83aeb57b-77d4-4982-a1b2-206a6d7647d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-9f47ac84-53c9-40f5-bdba-7c89f5de627e,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-0a870513-79d4-46cf-9fbe-965c7950a875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5729
