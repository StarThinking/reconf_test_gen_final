reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282310947-172.17.0.2-1597512623924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-efc48c9d-bda5-48e4-a256-188e8b0d9313,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-5d12d2f4-a2c2-4a41-a210-84ea86dcd7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-cfa03299-eb1d-4872-bee2-ae0874c32fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-64e7624d-4b7f-4729-a4e4-47ba0ec88300,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-efe80944-1d27-4578-a907-7a430bd9d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-5abcee90-3159-4ec8-b956-725ce5e277dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-e8ed0098-ddfe-40b0-82d9-74d7f95aeb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-cd6aaa50-88d4-46cc-9f93-a84ef0bf3242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282310947-172.17.0.2-1597512623924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-efc48c9d-bda5-48e4-a256-188e8b0d9313,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-5d12d2f4-a2c2-4a41-a210-84ea86dcd7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-cfa03299-eb1d-4872-bee2-ae0874c32fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-64e7624d-4b7f-4729-a4e4-47ba0ec88300,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-efe80944-1d27-4578-a907-7a430bd9d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-5abcee90-3159-4ec8-b956-725ce5e277dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-e8ed0098-ddfe-40b0-82d9-74d7f95aeb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-cd6aaa50-88d4-46cc-9f93-a84ef0bf3242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706846365-172.17.0.2-1597512736687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-b31d3991-c5af-4032-8a11-d0d1aff80b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-c1b45a8c-8331-4453-a78f-bb4c728ca7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-4cfed113-d14b-41eb-bdab-33e73f92d3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-67f45dba-0e02-46bc-bfa6-75957e775772,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-402bc787-7c86-418d-9f86-41ff517f16cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-6d38596b-deee-4bb0-a8df-aabbf2d09133,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-6b579073-5f80-4687-b23d-c496753a00a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-ff7b1513-f5a4-450a-8608-3a73f54cb404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706846365-172.17.0.2-1597512736687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-b31d3991-c5af-4032-8a11-d0d1aff80b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-c1b45a8c-8331-4453-a78f-bb4c728ca7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-4cfed113-d14b-41eb-bdab-33e73f92d3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-67f45dba-0e02-46bc-bfa6-75957e775772,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-402bc787-7c86-418d-9f86-41ff517f16cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-6d38596b-deee-4bb0-a8df-aabbf2d09133,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-6b579073-5f80-4687-b23d-c496753a00a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-ff7b1513-f5a4-450a-8608-3a73f54cb404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230983603-172.17.0.2-1597512932732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40298,DS-1c6af629-6134-4541-a2a0-f1e35de2ddce,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-45704ead-73a1-4c90-9bdc-535f8f6e1af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-b19f68af-86b2-4e52-ac96-39b2a9c71b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-237e3bfa-3b19-4b36-b96d-d55f3d2bb09d,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-9f553319-1896-48f6-a382-0055dbc48121,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-a4954715-4a10-442c-ace6-8f638d312a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-853cea49-a95d-406d-9b81-b9f90feb9ead,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-4863e2a5-a590-46d8-a1e1-ad717e8a523f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230983603-172.17.0.2-1597512932732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40298,DS-1c6af629-6134-4541-a2a0-f1e35de2ddce,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-45704ead-73a1-4c90-9bdc-535f8f6e1af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-b19f68af-86b2-4e52-ac96-39b2a9c71b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-237e3bfa-3b19-4b36-b96d-d55f3d2bb09d,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-9f553319-1896-48f6-a382-0055dbc48121,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-a4954715-4a10-442c-ace6-8f638d312a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-853cea49-a95d-406d-9b81-b9f90feb9ead,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-4863e2a5-a590-46d8-a1e1-ad717e8a523f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593415922-172.17.0.2-1597513270900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39003,DS-da8b8144-d544-4362-a889-378887876634,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-8922d403-93fd-43f2-829a-f0c2d56982ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-3d593a3c-f211-42c1-96ae-de986aa6b71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-78d456a7-ec39-4a64-8cf8-0c2f94bf2013,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-e7946b45-e563-4c17-9f8d-620205b46f14,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-67540c11-46b6-4b86-bf93-b43d1d19a5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-017b0ec9-48f1-43a8-81c5-ed07ec52809e,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-1b24969b-992f-41bd-bb81-0f97cac6e804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593415922-172.17.0.2-1597513270900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39003,DS-da8b8144-d544-4362-a889-378887876634,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-8922d403-93fd-43f2-829a-f0c2d56982ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-3d593a3c-f211-42c1-96ae-de986aa6b71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-78d456a7-ec39-4a64-8cf8-0c2f94bf2013,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-e7946b45-e563-4c17-9f8d-620205b46f14,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-67540c11-46b6-4b86-bf93-b43d1d19a5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-017b0ec9-48f1-43a8-81c5-ed07ec52809e,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-1b24969b-992f-41bd-bb81-0f97cac6e804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006051699-172.17.0.2-1597514408096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-f79f56dc-fa76-4c31-97f4-69669b3b41df,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-0caac047-d6c7-4c9a-997e-01e01a547247,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-100532e0-7bb3-43b7-a79c-ac7f90aa3cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-6967b838-98ee-4595-b92a-37fe2b493d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-9ad62188-fc38-425e-bdda-4195352db952,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-770b0d53-626a-4343-8cad-492d085e7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-630ec070-95f4-4303-bb4d-d64cf86426ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-853fb5c4-3248-4805-ac59-3d635e591537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006051699-172.17.0.2-1597514408096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-f79f56dc-fa76-4c31-97f4-69669b3b41df,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-0caac047-d6c7-4c9a-997e-01e01a547247,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-100532e0-7bb3-43b7-a79c-ac7f90aa3cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-6967b838-98ee-4595-b92a-37fe2b493d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-9ad62188-fc38-425e-bdda-4195352db952,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-770b0d53-626a-4343-8cad-492d085e7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-630ec070-95f4-4303-bb4d-d64cf86426ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-853fb5c4-3248-4805-ac59-3d635e591537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800646469-172.17.0.2-1597514898201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33026,DS-0b9121c3-6eea-42f6-a009-fed83b3aa309,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-9937f534-3ccc-4859-9399-51801243e446,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-cc70b097-2603-423d-9dda-84309e5295bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-4b75e10f-4916-4e5c-bb00-6f42d6943d92,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-8e722e9b-a406-4ec8-b4ab-18d2bfb7a140,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-ef067ef1-27f9-44c6-bf57-1971d9094f87,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-73570e84-6e33-494b-a37c-7a79b5a2145d,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-fe595ca1-1a64-4276-b163-4ff4b9e7802a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800646469-172.17.0.2-1597514898201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33026,DS-0b9121c3-6eea-42f6-a009-fed83b3aa309,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-9937f534-3ccc-4859-9399-51801243e446,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-cc70b097-2603-423d-9dda-84309e5295bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-4b75e10f-4916-4e5c-bb00-6f42d6943d92,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-8e722e9b-a406-4ec8-b4ab-18d2bfb7a140,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-ef067ef1-27f9-44c6-bf57-1971d9094f87,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-73570e84-6e33-494b-a37c-7a79b5a2145d,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-fe595ca1-1a64-4276-b163-4ff4b9e7802a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553267497-172.17.0.2-1597514941477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-dd5ffcfd-6df4-4c00-a799-21231b565c99,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-c1d254c5-3270-4b2c-8799-a03c6cd8e444,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-aec54dac-eadf-48fb-ad25-b7166dbd3c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-186e440a-27b1-43e1-9fd0-7621f85d8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-1e6e4004-bb73-4fe4-8da4-5bbe7257dccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-1f154354-8c4f-4998-bef0-46ca8cfaf651,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-39c98171-df7c-4f56-963c-528b769f3613,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-cf885870-df4b-4454-9aec-12108e0b4c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553267497-172.17.0.2-1597514941477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-dd5ffcfd-6df4-4c00-a799-21231b565c99,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-c1d254c5-3270-4b2c-8799-a03c6cd8e444,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-aec54dac-eadf-48fb-ad25-b7166dbd3c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-186e440a-27b1-43e1-9fd0-7621f85d8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-1e6e4004-bb73-4fe4-8da4-5bbe7257dccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-1f154354-8c4f-4998-bef0-46ca8cfaf651,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-39c98171-df7c-4f56-963c-528b769f3613,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-cf885870-df4b-4454-9aec-12108e0b4c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655672342-172.17.0.2-1597515022317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36964,DS-d5ef27c8-dd6a-4b8a-8900-654e8a36886e,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-31da6891-7520-4701-876b-fbf806e1d86e,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-f7c2f01d-c24c-4715-a0f8-f97f05281cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-6497baae-1d71-4675-a12a-8d6c90154598,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-fc3c1414-f3f7-40c9-af6f-2b71dc7421f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-0544c90e-3e2d-47a6-8b1a-289289aa4141,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-52632346-d833-43f9-8db7-6c414cc0b344,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-0c3d852b-7e2b-4b68-a2d4-6fcd03af0bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655672342-172.17.0.2-1597515022317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36964,DS-d5ef27c8-dd6a-4b8a-8900-654e8a36886e,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-31da6891-7520-4701-876b-fbf806e1d86e,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-f7c2f01d-c24c-4715-a0f8-f97f05281cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-6497baae-1d71-4675-a12a-8d6c90154598,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-fc3c1414-f3f7-40c9-af6f-2b71dc7421f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-0544c90e-3e2d-47a6-8b1a-289289aa4141,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-52632346-d833-43f9-8db7-6c414cc0b344,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-0c3d852b-7e2b-4b68-a2d4-6fcd03af0bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451824400-172.17.0.2-1597515701444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46823,DS-700655d2-7a9c-41f3-a6fb-8335db0e545a,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-704b7292-688a-4b5c-b343-8e0b69881840,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-0fd9ef4d-c4a5-4a1c-912f-3a8e6130edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-f09536a7-6e0f-4ff1-87ed-535d2f7e817e,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-290d1c54-68c1-4ab3-bc9c-5bf0cd29f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-79426cc6-7af0-4a55-93df-96addc773fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-cea725e4-66b2-43f9-8996-5111991e15b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-ec3ecf6e-fed1-4d10-b6b8-2c0e06a07d6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451824400-172.17.0.2-1597515701444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46823,DS-700655d2-7a9c-41f3-a6fb-8335db0e545a,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-704b7292-688a-4b5c-b343-8e0b69881840,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-0fd9ef4d-c4a5-4a1c-912f-3a8e6130edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-f09536a7-6e0f-4ff1-87ed-535d2f7e817e,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-290d1c54-68c1-4ab3-bc9c-5bf0cd29f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-79426cc6-7af0-4a55-93df-96addc773fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-cea725e4-66b2-43f9-8996-5111991e15b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-ec3ecf6e-fed1-4d10-b6b8-2c0e06a07d6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600098503-172.17.0.2-1597515962531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32875,DS-687ba92c-e23a-420e-9ce3-34da18b53653,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-1b5f3a14-2224-47d9-a785-4168414db527,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-5d317d1d-edc4-45e7-b0d7-c83e43f564d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-02cf262a-a3b2-4ca4-b628-165fed134b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-c555cd11-0fe4-4d61-b89c-939c581aea22,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-59810bac-daa1-4a52-8583-370e80e33243,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-87e02933-9de1-4084-8b91-84f10f5a0037,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-85d423d1-82f0-4369-acff-f7fe8da62df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600098503-172.17.0.2-1597515962531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32875,DS-687ba92c-e23a-420e-9ce3-34da18b53653,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-1b5f3a14-2224-47d9-a785-4168414db527,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-5d317d1d-edc4-45e7-b0d7-c83e43f564d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-02cf262a-a3b2-4ca4-b628-165fed134b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-c555cd11-0fe4-4d61-b89c-939c581aea22,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-59810bac-daa1-4a52-8583-370e80e33243,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-87e02933-9de1-4084-8b91-84f10f5a0037,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-85d423d1-82f0-4369-acff-f7fe8da62df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124987393-172.17.0.2-1597516253198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-94dacd2c-c7d0-4381-a4ed-8ec14b5428f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-3c5dfb85-b73e-44a4-b435-5ba1c54888af,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-1e6589ba-9112-4588-b174-5b98916c0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-454cc582-8fa7-485d-b9c6-5c5e6019e5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-287b30ac-13f8-449c-b9e0-094f93370910,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-a5611db6-105d-420d-900a-6d4a1b08ebd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-f030cd95-6d56-4ddf-995e-3613d840fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-c057fffd-7af2-4ee1-beed-47c205b15bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124987393-172.17.0.2-1597516253198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-94dacd2c-c7d0-4381-a4ed-8ec14b5428f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-3c5dfb85-b73e-44a4-b435-5ba1c54888af,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-1e6589ba-9112-4588-b174-5b98916c0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-454cc582-8fa7-485d-b9c6-5c5e6019e5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-287b30ac-13f8-449c-b9e0-094f93370910,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-a5611db6-105d-420d-900a-6d4a1b08ebd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-f030cd95-6d56-4ddf-995e-3613d840fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-c057fffd-7af2-4ee1-beed-47c205b15bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713070334-172.17.0.2-1597516908568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-a6e9d76a-aedc-4ed6-b0ab-c4cd79d53abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-7349cd9a-09ed-4782-9f1e-a36dd4e5a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-a9f3c53a-758f-4b14-8516-6c41a445c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-7c46200b-cdd8-4818-8151-659a8102dd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-40297adf-650f-43e1-922f-4716723e89bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-5d948906-ce5d-4107-bf72-7155bfea15b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-586d0ff2-7655-45fa-8252-897d85f8b321,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-cf39acac-ee73-400a-a6a7-830639a8f6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713070334-172.17.0.2-1597516908568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-a6e9d76a-aedc-4ed6-b0ab-c4cd79d53abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-7349cd9a-09ed-4782-9f1e-a36dd4e5a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-a9f3c53a-758f-4b14-8516-6c41a445c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-7c46200b-cdd8-4818-8151-659a8102dd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-40297adf-650f-43e1-922f-4716723e89bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-5d948906-ce5d-4107-bf72-7155bfea15b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-586d0ff2-7655-45fa-8252-897d85f8b321,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-cf39acac-ee73-400a-a6a7-830639a8f6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1902744815-172.17.0.2-1597516984081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-5800f69b-c045-433c-ad58-5d6c0b3a34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-eb5b1cc6-6f99-4148-8d16-274266283196,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-22f699c4-51ef-44ac-9ee3-f7880180a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-fd30286b-6c9d-45f4-aab5-da8fa1080454,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-1485a5ca-b152-4911-897c-0c2080c8779b,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-d6ded8bc-9869-41bf-b53e-48799fd8b629,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-2db093d8-1dba-49f0-884e-4103c7f54a86,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-84fad75f-e9d5-408f-986c-d6a5d3a30d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1902744815-172.17.0.2-1597516984081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-5800f69b-c045-433c-ad58-5d6c0b3a34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-eb5b1cc6-6f99-4148-8d16-274266283196,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-22f699c4-51ef-44ac-9ee3-f7880180a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-fd30286b-6c9d-45f4-aab5-da8fa1080454,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-1485a5ca-b152-4911-897c-0c2080c8779b,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-d6ded8bc-9869-41bf-b53e-48799fd8b629,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-2db093d8-1dba-49f0-884e-4103c7f54a86,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-84fad75f-e9d5-408f-986c-d6a5d3a30d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5653
