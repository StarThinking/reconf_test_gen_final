reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877554038-172.17.0.7-1597572330347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-40a0a586-0c09-4b13-9117-ec5225e5e330,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-25b45d0f-87b3-4d4e-8c30-8da9f0d33dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-f0e0d7a5-6ba0-45d7-af4e-3b5ea16fcf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-cc85b10d-77ef-411d-9873-6e97b8b68a36,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-c7e734d7-d776-46a7-b9df-ffa5a1d657e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-b16239e8-3829-4247-8a92-de8fb11657bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-d2478a3f-ee63-4b97-8627-ef8b9ca60f86,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-82e4411b-28db-4fa1-8c00-12b3ac8a82aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877554038-172.17.0.7-1597572330347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44199,DS-40a0a586-0c09-4b13-9117-ec5225e5e330,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-25b45d0f-87b3-4d4e-8c30-8da9f0d33dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-f0e0d7a5-6ba0-45d7-af4e-3b5ea16fcf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-cc85b10d-77ef-411d-9873-6e97b8b68a36,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-c7e734d7-d776-46a7-b9df-ffa5a1d657e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-b16239e8-3829-4247-8a92-de8fb11657bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-d2478a3f-ee63-4b97-8627-ef8b9ca60f86,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-82e4411b-28db-4fa1-8c00-12b3ac8a82aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858217891-172.17.0.7-1597572630291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44097,DS-ea0481c2-cf4b-45cb-bf66-f90d18defa66,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-a5319f64-f2f7-4c53-b2c1-ec139d003fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-bacdd3ba-d531-4630-8f3c-8d79a24fc535,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-feccdbdc-44b4-478e-942a-6f91506b94d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-116606e2-9de9-4d7a-8672-3fee5d183e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-1a9fb0c7-d225-4cae-ad74-a1aa3734859e,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-a2e6af85-6431-4189-bcb5-221abc362144,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-5c6761e3-d8d7-4ea9-8d8c-fad6c5688ddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1858217891-172.17.0.7-1597572630291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44097,DS-ea0481c2-cf4b-45cb-bf66-f90d18defa66,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-a5319f64-f2f7-4c53-b2c1-ec139d003fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-bacdd3ba-d531-4630-8f3c-8d79a24fc535,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-feccdbdc-44b4-478e-942a-6f91506b94d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-116606e2-9de9-4d7a-8672-3fee5d183e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-1a9fb0c7-d225-4cae-ad74-a1aa3734859e,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-a2e6af85-6431-4189-bcb5-221abc362144,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-5c6761e3-d8d7-4ea9-8d8c-fad6c5688ddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108581908-172.17.0.7-1597572970003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-18d2ddf1-4b39-4293-930f-c2943a5183e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-25cf4a87-6a63-49db-8172-dd066aa6e03b,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-aa562101-3a90-4040-bc58-7083fba37459,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-d5024834-1a16-4ba8-8310-8818ddc3129c,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-e1236787-ae3e-41c5-b73c-d4f73bb019ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-14915a3b-dd69-46dc-8cac-b33061086eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-8ecbe777-6dc0-495b-bd00-b49907e71424,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-ba940a89-6c8b-4356-94d1-e189ac03c922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108581908-172.17.0.7-1597572970003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-18d2ddf1-4b39-4293-930f-c2943a5183e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-25cf4a87-6a63-49db-8172-dd066aa6e03b,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-aa562101-3a90-4040-bc58-7083fba37459,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-d5024834-1a16-4ba8-8310-8818ddc3129c,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-e1236787-ae3e-41c5-b73c-d4f73bb019ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-14915a3b-dd69-46dc-8cac-b33061086eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-8ecbe777-6dc0-495b-bd00-b49907e71424,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-ba940a89-6c8b-4356-94d1-e189ac03c922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918766728-172.17.0.7-1597573050709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-f71150fc-fd39-48eb-8119-fa40a676465e,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-95dd1175-2b39-476c-bb17-e2e32bd2a7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-87e8fe3e-731e-4e65-b306-95b2e202770a,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-f52e91f9-761d-4413-91f3-c7b3b7d62c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-ccc8d3a5-ba25-4afc-9ef0-d4af80402deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-f5a25188-05d5-4604-9e80-028b502bb044,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-03d50d8a-ec04-4233-8851-1579931243de,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-904c468a-c4ea-4cb6-a984-284a97726e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918766728-172.17.0.7-1597573050709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-f71150fc-fd39-48eb-8119-fa40a676465e,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-95dd1175-2b39-476c-bb17-e2e32bd2a7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-87e8fe3e-731e-4e65-b306-95b2e202770a,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-f52e91f9-761d-4413-91f3-c7b3b7d62c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-ccc8d3a5-ba25-4afc-9ef0-d4af80402deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-f5a25188-05d5-4604-9e80-028b502bb044,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-03d50d8a-ec04-4233-8851-1579931243de,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-904c468a-c4ea-4cb6-a984-284a97726e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503044299-172.17.0.7-1597573416876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-c1cef694-fcee-48df-ae6b-a5cdf4ebce91,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-fc19a7f6-b74a-420b-934c-9d0e3d3452a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-08353828-55d6-4dff-a5bf-42dd9ad5b672,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-1d74e6db-dcd3-410d-8781-3ee9d1e9800b,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-c8e9fd4b-13b8-4e98-9f9f-566cf2964c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-eb5330e3-b0d4-4aef-99ef-861e92f95a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-7e063a3b-cfb2-4171-bb81-cc6bf12a7cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-7cd0c467-1371-49b4-9bcf-3ec1bfffe26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503044299-172.17.0.7-1597573416876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-c1cef694-fcee-48df-ae6b-a5cdf4ebce91,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-fc19a7f6-b74a-420b-934c-9d0e3d3452a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-08353828-55d6-4dff-a5bf-42dd9ad5b672,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-1d74e6db-dcd3-410d-8781-3ee9d1e9800b,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-c8e9fd4b-13b8-4e98-9f9f-566cf2964c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-eb5330e3-b0d4-4aef-99ef-861e92f95a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-7e063a3b-cfb2-4171-bb81-cc6bf12a7cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-7cd0c467-1371-49b4-9bcf-3ec1bfffe26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242304861-172.17.0.7-1597574330453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-548c0217-3543-490d-a271-d36a4881a38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-c69bba61-2d11-4615-9dad-38fc7ec24bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-bbea794a-dfa0-4354-94b0-caeded3693d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-34121b2a-ce30-4a3b-99c9-5b4875d73051,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-c165d19d-c144-42fe-890c-82e51f55e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-e6430c83-3c82-4eda-a1b9-05eb8bb66456,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-6f26a4e2-1ee1-4750-b82d-38714705cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-7e1dfc40-3bc5-482d-8584-227bc740793d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242304861-172.17.0.7-1597574330453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-548c0217-3543-490d-a271-d36a4881a38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-c69bba61-2d11-4615-9dad-38fc7ec24bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-bbea794a-dfa0-4354-94b0-caeded3693d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-34121b2a-ce30-4a3b-99c9-5b4875d73051,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-c165d19d-c144-42fe-890c-82e51f55e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-e6430c83-3c82-4eda-a1b9-05eb8bb66456,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-6f26a4e2-1ee1-4750-b82d-38714705cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-7e1dfc40-3bc5-482d-8584-227bc740793d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322604873-172.17.0.7-1597574745000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35519,DS-c0f8a7f5-fb3c-46db-9a70-1afa72296b51,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-ca033d92-0df5-42fc-a3bb-4db312cc196e,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-e7bba42a-a6a7-4ede-9daa-163711915c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-cd709ef0-a09c-4140-a931-a0e889e00dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-8a45cfc4-9462-4ecf-a600-0291c1a2cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-ce453054-bac6-4fe8-b513-70b231f6ecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-5c4cfa50-6d5f-4a40-8e9d-6e29f07daac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-6eba0404-2734-4c67-8cda-3d14d8535e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322604873-172.17.0.7-1597574745000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35519,DS-c0f8a7f5-fb3c-46db-9a70-1afa72296b51,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-ca033d92-0df5-42fc-a3bb-4db312cc196e,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-e7bba42a-a6a7-4ede-9daa-163711915c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-cd709ef0-a09c-4140-a931-a0e889e00dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-8a45cfc4-9462-4ecf-a600-0291c1a2cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-ce453054-bac6-4fe8-b513-70b231f6ecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-5c4cfa50-6d5f-4a40-8e9d-6e29f07daac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-6eba0404-2734-4c67-8cda-3d14d8535e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393374282-172.17.0.7-1597574860968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39913,DS-009160e1-54b4-4bf2-b2f1-f56ea24eed24,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-4e17dee1-37e7-42f7-b6a1-4042aca6084c,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-01d508bd-13b1-4cec-ad35-c35ff7a8333d,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-c75ff39c-4564-4efa-b6bf-404f33e7ae39,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-9862e931-c9d1-43aa-924e-f0c788181c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-ec36619a-a44a-44d3-9fb6-1c2f2b9f02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-e0343b6c-c6d3-4e4f-9e5e-215bac34bb00,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-8fa38d00-13fd-4229-a32e-9a815edae936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393374282-172.17.0.7-1597574860968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39913,DS-009160e1-54b4-4bf2-b2f1-f56ea24eed24,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-4e17dee1-37e7-42f7-b6a1-4042aca6084c,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-01d508bd-13b1-4cec-ad35-c35ff7a8333d,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-c75ff39c-4564-4efa-b6bf-404f33e7ae39,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-9862e931-c9d1-43aa-924e-f0c788181c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-ec36619a-a44a-44d3-9fb6-1c2f2b9f02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-e0343b6c-c6d3-4e4f-9e5e-215bac34bb00,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-8fa38d00-13fd-4229-a32e-9a815edae936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631549621-172.17.0.7-1597574937768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33300,DS-93fd99cf-ecc1-4ac5-a3fe-80a771e50037,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-22b1d453-a7bc-4b62-81a7-e69910f8cadd,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-05628ee6-e42c-43c0-a630-c5722e84755f,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-6551dd8b-67c9-48bb-9328-835ab8579cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-b55cc36b-1629-4f57-8d4d-580e827b9acb,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-fe0f505d-bd04-4120-8ac8-3f7e30a204b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-95ff2ccb-e0e7-4a4f-ad1d-3f8793e3b064,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-819cf075-c4b4-436c-b067-a4bd970b117d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631549621-172.17.0.7-1597574937768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33300,DS-93fd99cf-ecc1-4ac5-a3fe-80a771e50037,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-22b1d453-a7bc-4b62-81a7-e69910f8cadd,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-05628ee6-e42c-43c0-a630-c5722e84755f,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-6551dd8b-67c9-48bb-9328-835ab8579cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-b55cc36b-1629-4f57-8d4d-580e827b9acb,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-fe0f505d-bd04-4120-8ac8-3f7e30a204b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-95ff2ccb-e0e7-4a4f-ad1d-3f8793e3b064,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-819cf075-c4b4-436c-b067-a4bd970b117d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331276592-172.17.0.7-1597575661121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38148,DS-accc9ed8-696d-4c5c-9c26-39e6c76286be,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-e528ee4f-0c66-4bf1-a72b-421209372b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-d16d75b1-499c-4a7d-ae7a-a26b28113713,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-403a424d-0c49-4397-a43b-769ba17ddcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-8255d17f-ec79-4ccf-a4b8-dc292bac2b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-d7dcacfc-e159-4117-81c3-3a8ad7e3d400,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-35d4e849-5e06-4a79-9c73-a22282e0479f,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-0ab83925-96a9-4f3e-aed8-f3165ac8c195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331276592-172.17.0.7-1597575661121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38148,DS-accc9ed8-696d-4c5c-9c26-39e6c76286be,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-e528ee4f-0c66-4bf1-a72b-421209372b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-d16d75b1-499c-4a7d-ae7a-a26b28113713,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-403a424d-0c49-4397-a43b-769ba17ddcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-8255d17f-ec79-4ccf-a4b8-dc292bac2b02,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-d7dcacfc-e159-4117-81c3-3a8ad7e3d400,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-35d4e849-5e06-4a79-9c73-a22282e0479f,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-0ab83925-96a9-4f3e-aed8-f3165ac8c195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888935846-172.17.0.7-1597575991414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36372,DS-5654cf5e-0d2f-4af8-8a28-e5761611f42d,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-b55f168e-dcfa-4295-abab-628a79150165,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-c2edee9f-3649-4114-8249-4f725dc1029f,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-f64fd234-7345-469f-b652-158bd09bca07,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-b96174b9-05a6-40be-a566-5667602c9884,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-da26dbf8-3401-47bc-9950-376cd051dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-09a09d38-934a-4527-8120-2cc42d5d828a,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-cb369811-51ce-44bb-931f-5bfb94a72b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888935846-172.17.0.7-1597575991414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36372,DS-5654cf5e-0d2f-4af8-8a28-e5761611f42d,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-b55f168e-dcfa-4295-abab-628a79150165,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-c2edee9f-3649-4114-8249-4f725dc1029f,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-f64fd234-7345-469f-b652-158bd09bca07,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-b96174b9-05a6-40be-a566-5667602c9884,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-da26dbf8-3401-47bc-9950-376cd051dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-09a09d38-934a-4527-8120-2cc42d5d828a,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-cb369811-51ce-44bb-931f-5bfb94a72b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651664118-172.17.0.7-1597576099958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-34b45b23-4af1-4c54-869e-779bc0ac2caf,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-723855d0-3085-4847-9b8a-426e1badcdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-d5b1ac04-a23a-4e37-ba1f-b59d613dc09e,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-8336ba05-0d4a-49fe-b236-9aac36076a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-7ec3b5e2-1b63-475a-9bfb-d1131e803ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-cc5f3e0c-5029-4f4d-8bde-c0662c730331,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-4422d5a7-cd6f-4775-b06e-564adc83c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-638ee9e3-03c3-4067-a252-0f26771ed455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651664118-172.17.0.7-1597576099958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-34b45b23-4af1-4c54-869e-779bc0ac2caf,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-723855d0-3085-4847-9b8a-426e1badcdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-d5b1ac04-a23a-4e37-ba1f-b59d613dc09e,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-8336ba05-0d4a-49fe-b236-9aac36076a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-7ec3b5e2-1b63-475a-9bfb-d1131e803ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-cc5f3e0c-5029-4f4d-8bde-c0662c730331,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-4422d5a7-cd6f-4775-b06e-564adc83c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-638ee9e3-03c3-4067-a252-0f26771ed455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446542512-172.17.0.7-1597576548057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44657,DS-727a47e4-1f0c-48c3-92e2-e3fab465d5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-44c3d89e-f0de-4565-8e49-d0f46aae0438,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-c8b11343-6d9e-475a-84b4-57fa6565b8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-951c0028-12ba-48a9-a284-854d8f1d6655,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-f486d3f1-194d-4133-8e22-4b6ffaad2ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-31ca8d20-6f8c-46a0-8c80-55dc7ba416e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-9c033591-292c-4fd0-a211-eaf9feebd7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-a64aaf4b-c9c9-4a1c-a1bd-1f8294d43f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446542512-172.17.0.7-1597576548057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44657,DS-727a47e4-1f0c-48c3-92e2-e3fab465d5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-44c3d89e-f0de-4565-8e49-d0f46aae0438,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-c8b11343-6d9e-475a-84b4-57fa6565b8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-951c0028-12ba-48a9-a284-854d8f1d6655,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-f486d3f1-194d-4133-8e22-4b6ffaad2ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-31ca8d20-6f8c-46a0-8c80-55dc7ba416e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-9c033591-292c-4fd0-a211-eaf9feebd7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-a64aaf4b-c9c9-4a1c-a1bd-1f8294d43f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771309046-172.17.0.7-1597576582917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-88d7d594-9f5b-4e3f-ba68-772406dd47b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-a27d96aa-1765-41b8-af4e-3eb72968ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-5a931790-4897-457f-b519-ed5f3bb960f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-e066dcf9-edd4-4336-bf96-f56f2fab8e81,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-0e846f01-b56f-4632-a256-b9c26026fd47,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-bda4fcfc-7d25-4e96-8db0-ff996dc4dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-c17ac26d-6419-4de8-b897-c4b7fcc008d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-ace66a76-0e10-4e2d-8460-30cd4ee45a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771309046-172.17.0.7-1597576582917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-88d7d594-9f5b-4e3f-ba68-772406dd47b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-a27d96aa-1765-41b8-af4e-3eb72968ea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-5a931790-4897-457f-b519-ed5f3bb960f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-e066dcf9-edd4-4336-bf96-f56f2fab8e81,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-0e846f01-b56f-4632-a256-b9c26026fd47,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-bda4fcfc-7d25-4e96-8db0-ff996dc4dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-c17ac26d-6419-4de8-b897-c4b7fcc008d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-ace66a76-0e10-4e2d-8460-30cd4ee45a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962308153-172.17.0.7-1597576773440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36080,DS-6b69fbbe-52ff-47c5-9631-aba6e442d961,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-b89baea5-f184-4298-9804-22e84ad2118e,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-398b7bd2-b80b-4b54-9264-dc6cec4e7932,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-baf10dea-7fb7-436f-a0be-45f5f5711291,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-bca4a0b1-9b94-44bf-9a6b-cf83ac418094,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-644b1de6-c541-46d9-8142-61092db73684,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-9d04c77e-ab09-4420-a875-504ce934c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-613354d2-6f6d-4a9f-a716-ca0bf8ddc6ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962308153-172.17.0.7-1597576773440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36080,DS-6b69fbbe-52ff-47c5-9631-aba6e442d961,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-b89baea5-f184-4298-9804-22e84ad2118e,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-398b7bd2-b80b-4b54-9264-dc6cec4e7932,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-baf10dea-7fb7-436f-a0be-45f5f5711291,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-bca4a0b1-9b94-44bf-9a6b-cf83ac418094,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-644b1de6-c541-46d9-8142-61092db73684,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-9d04c77e-ab09-4420-a875-504ce934c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-613354d2-6f6d-4a9f-a716-ca0bf8ddc6ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352897250-172.17.0.7-1597577145294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-aa6bdad1-0602-49d3-8bb4-908cd70498e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-f40051a6-b429-4048-a660-a5ff761edc05,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-055e5fcb-2129-47e9-a8bd-56f927af3a08,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-08474783-3ea4-44c8-a94c-b4d6ba34ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-50a58dc5-f7ff-4388-a392-d109651cdcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-79c803bf-ef0b-470b-9f26-f2f6da95bd05,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-1720a921-598b-4b50-a02b-c9212faf6a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-4b91120a-a14c-48d1-bbd0-894a15c10bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352897250-172.17.0.7-1597577145294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-aa6bdad1-0602-49d3-8bb4-908cd70498e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-f40051a6-b429-4048-a660-a5ff761edc05,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-055e5fcb-2129-47e9-a8bd-56f927af3a08,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-08474783-3ea4-44c8-a94c-b4d6ba34ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-50a58dc5-f7ff-4388-a392-d109651cdcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-79c803bf-ef0b-470b-9f26-f2f6da95bd05,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-1720a921-598b-4b50-a02b-c9212faf6a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-4b91120a-a14c-48d1-bbd0-894a15c10bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120039991-172.17.0.7-1597577726433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36721,DS-6eb1a226-10a8-455b-9b10-f7cc3571c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-fcfcb467-dc62-4585-9ac9-ab2102640381,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-730d6119-f9c0-49f0-8381-f33843648554,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-eef8e5f8-16cf-426e-90f1-2a826cd33cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-4f97f5b7-e924-4a03-8530-e3d11ddced1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-804d2ec5-9ba1-4d62-b615-4620b26a2631,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-c2413922-e2c7-4cbc-900e-7fe1267762e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-c7caac8b-c33c-4c36-a5a5-1802f544630a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120039991-172.17.0.7-1597577726433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36721,DS-6eb1a226-10a8-455b-9b10-f7cc3571c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-fcfcb467-dc62-4585-9ac9-ab2102640381,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-730d6119-f9c0-49f0-8381-f33843648554,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-eef8e5f8-16cf-426e-90f1-2a826cd33cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-4f97f5b7-e924-4a03-8530-e3d11ddced1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-804d2ec5-9ba1-4d62-b615-4620b26a2631,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-c2413922-e2c7-4cbc-900e-7fe1267762e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-c7caac8b-c33c-4c36-a5a5-1802f544630a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5642
