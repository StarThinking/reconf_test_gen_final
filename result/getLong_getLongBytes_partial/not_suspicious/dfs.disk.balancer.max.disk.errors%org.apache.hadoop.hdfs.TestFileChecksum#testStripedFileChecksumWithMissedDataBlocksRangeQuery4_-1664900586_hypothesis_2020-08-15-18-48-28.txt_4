reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971669664-172.17.0.7-1597517440240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36063,DS-7dedfc6d-3038-4f5c-84e7-d19aa1fe524a,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-6e036e78-f908-4602-a854-828c3183ed35,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ff0928c6-ec6c-4223-8f37-02ef0b82225d,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-e86333ee-0d17-42c7-918e-c208b2b7fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-d747bf32-a512-46c5-a5bf-de10394d65f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-c64838f3-23d2-48ec-b921-968afa732368,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-2f702162-c73a-492c-9cc0-32f50d76e29d,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-72b9f91c-b451-45d9-ab78-2ebe12a55274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971669664-172.17.0.7-1597517440240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36063,DS-7dedfc6d-3038-4f5c-84e7-d19aa1fe524a,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-6e036e78-f908-4602-a854-828c3183ed35,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ff0928c6-ec6c-4223-8f37-02ef0b82225d,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-e86333ee-0d17-42c7-918e-c208b2b7fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-d747bf32-a512-46c5-a5bf-de10394d65f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-c64838f3-23d2-48ec-b921-968afa732368,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-2f702162-c73a-492c-9cc0-32f50d76e29d,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-72b9f91c-b451-45d9-ab78-2ebe12a55274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284280570-172.17.0.7-1597517513597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45551,DS-bee0c813-6f1d-4618-a332-ccabb05adefb,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-cf5d42ed-1e6e-450e-b4ee-36dc1c2b6d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-41b77360-7399-44f0-979b-eeb4808e4052,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-058e2bb1-4610-44e0-8893-4d629e7b7c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-41485b89-e31f-439f-8a73-cf7d6da0bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-30bdb7b7-1014-43b3-b631-90e683c755f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-ef45ef88-d7f3-4af8-a4bb-9d89ea781618,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-2a825988-397e-40c1-afaf-274e8f002fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284280570-172.17.0.7-1597517513597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45551,DS-bee0c813-6f1d-4618-a332-ccabb05adefb,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-cf5d42ed-1e6e-450e-b4ee-36dc1c2b6d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-41b77360-7399-44f0-979b-eeb4808e4052,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-058e2bb1-4610-44e0-8893-4d629e7b7c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-41485b89-e31f-439f-8a73-cf7d6da0bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-30bdb7b7-1014-43b3-b631-90e683c755f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-ef45ef88-d7f3-4af8-a4bb-9d89ea781618,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-2a825988-397e-40c1-afaf-274e8f002fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158173446-172.17.0.7-1597518479528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38570,DS-49a29a6c-3c58-4286-bb33-3ff4fb2ae571,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-594401ac-cf63-486d-a057-1e0dbe86600c,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-40863770-e6a1-49e7-bd39-d75644e03b09,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-1d09dd17-e03e-48ae-9a2c-3bd531e189ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-07b3a3cb-1bac-45b4-aedb-61c7af279b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-13fb3843-c94e-4749-800f-6bed478af2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-6098b911-ac8c-4a88-9919-c1242a9c86a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-76001840-2f25-4075-a0dc-b472ab388f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158173446-172.17.0.7-1597518479528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38570,DS-49a29a6c-3c58-4286-bb33-3ff4fb2ae571,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-594401ac-cf63-486d-a057-1e0dbe86600c,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-40863770-e6a1-49e7-bd39-d75644e03b09,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-1d09dd17-e03e-48ae-9a2c-3bd531e189ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-07b3a3cb-1bac-45b4-aedb-61c7af279b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-13fb3843-c94e-4749-800f-6bed478af2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-6098b911-ac8c-4a88-9919-c1242a9c86a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-76001840-2f25-4075-a0dc-b472ab388f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153628851-172.17.0.7-1597518954094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35361,DS-33d020fa-c0e8-471b-bfab-03100a3e3a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-d2f14602-fac4-42cf-8604-b45fcfeed6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-683ccd51-f891-4eb2-9123-ee2fb34ebbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-37816183-f9d7-4d01-a23f-c33b77537409,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-f6df60ff-e610-4955-ac38-0c35a9e085fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-7a427daa-39cc-450a-bca5-4b7b8e58720d,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-726d0dcd-67f0-499d-b187-006b80ce76fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-594ef6cb-1107-46f4-be6f-c715857bc8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153628851-172.17.0.7-1597518954094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35361,DS-33d020fa-c0e8-471b-bfab-03100a3e3a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-d2f14602-fac4-42cf-8604-b45fcfeed6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-683ccd51-f891-4eb2-9123-ee2fb34ebbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-37816183-f9d7-4d01-a23f-c33b77537409,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-f6df60ff-e610-4955-ac38-0c35a9e085fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-7a427daa-39cc-450a-bca5-4b7b8e58720d,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-726d0dcd-67f0-499d-b187-006b80ce76fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-594ef6cb-1107-46f4-be6f-c715857bc8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490072512-172.17.0.7-1597519488253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-c9cc2477-ed1f-4cfb-9840-cc1dfd1a3eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-74858467-6aad-48bd-a99e-2fda2de2793e,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-daa1bb89-4472-49b0-a3e4-d00d3394081d,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-764bf379-b97c-43b8-99b5-bb6a8a8ed23b,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-ec46eaab-fe35-4802-968d-c2816b5e1836,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-43b7e2dc-2aa1-4961-8424-e98f51dd60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-1d1b3150-a010-43aa-bea3-84727e524160,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-37eb7053-af11-4b70-8834-e9da5db50d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1490072512-172.17.0.7-1597519488253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-c9cc2477-ed1f-4cfb-9840-cc1dfd1a3eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-74858467-6aad-48bd-a99e-2fda2de2793e,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-daa1bb89-4472-49b0-a3e4-d00d3394081d,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-764bf379-b97c-43b8-99b5-bb6a8a8ed23b,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-ec46eaab-fe35-4802-968d-c2816b5e1836,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-43b7e2dc-2aa1-4961-8424-e98f51dd60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-1d1b3150-a010-43aa-bea3-84727e524160,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-37eb7053-af11-4b70-8834-e9da5db50d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393654289-172.17.0.7-1597519519451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-131c1c67-32ea-4761-a399-50983902272b,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-3013b8fb-45f3-4ec2-a733-ae303f966ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-36e72d53-54a7-4d9c-a7a2-db971098a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-1fc2064d-1933-4ff9-b6a5-03a5c78af619,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-5bdc6f99-da4f-4442-8153-d447dc47f28b,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-64c3678b-8a9f-48f6-8cff-67b4aa051fda,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-8be86d9b-9611-4a13-850f-d80b06f4c1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-fe5ff0a4-c0ee-4aea-accc-6de03e5d78d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393654289-172.17.0.7-1597519519451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-131c1c67-32ea-4761-a399-50983902272b,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-3013b8fb-45f3-4ec2-a733-ae303f966ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-36e72d53-54a7-4d9c-a7a2-db971098a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-1fc2064d-1933-4ff9-b6a5-03a5c78af619,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-5bdc6f99-da4f-4442-8153-d447dc47f28b,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-64c3678b-8a9f-48f6-8cff-67b4aa051fda,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-8be86d9b-9611-4a13-850f-d80b06f4c1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-fe5ff0a4-c0ee-4aea-accc-6de03e5d78d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8761476-172.17.0.7-1597520097382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42179,DS-b22cf0bf-a3b7-4738-a093-adf9064a946c,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-255b511b-2d7e-4c12-a605-7c70710511e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-bcf14053-cc40-4890-b9c3-8f871674793e,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-e7bffe5c-0df1-4c80-8d9f-ae65a0db7f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-2e95e2c6-813b-48c8-a7ed-6fd5c2ebaa93,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-73108e7a-12d0-46cc-94fe-4593898de5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-8bc7bd58-29be-4b01-a374-7d4e78b358f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-beb6ee90-8e30-4ed4-9104-697990f8a804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8761476-172.17.0.7-1597520097382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42179,DS-b22cf0bf-a3b7-4738-a093-adf9064a946c,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-255b511b-2d7e-4c12-a605-7c70710511e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-bcf14053-cc40-4890-b9c3-8f871674793e,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-e7bffe5c-0df1-4c80-8d9f-ae65a0db7f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-2e95e2c6-813b-48c8-a7ed-6fd5c2ebaa93,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-73108e7a-12d0-46cc-94fe-4593898de5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-8bc7bd58-29be-4b01-a374-7d4e78b358f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-beb6ee90-8e30-4ed4-9104-697990f8a804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837816503-172.17.0.7-1597520169437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33845,DS-feeb0c4c-1415-42d2-a7bf-fa6c5a354eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-c623f0a9-cc7e-4819-a967-f482837e65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-1af79e63-3857-464f-95a4-4182a061c07c,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-d0ed5899-92eb-484b-83c6-ad551569ca0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-3f285817-6587-4cb4-88c9-93e62ef0a24e,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-d1d15f66-69aa-48bc-a747-8b3afad665fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-e7062a4f-a6b3-48c2-b070-8ffc84b7980f,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-3c5685b9-633e-4265-accd-ee141acd131f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837816503-172.17.0.7-1597520169437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33845,DS-feeb0c4c-1415-42d2-a7bf-fa6c5a354eff,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-c623f0a9-cc7e-4819-a967-f482837e65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-1af79e63-3857-464f-95a4-4182a061c07c,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-d0ed5899-92eb-484b-83c6-ad551569ca0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-3f285817-6587-4cb4-88c9-93e62ef0a24e,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-d1d15f66-69aa-48bc-a747-8b3afad665fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-e7062a4f-a6b3-48c2-b070-8ffc84b7980f,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-3c5685b9-633e-4265-accd-ee141acd131f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770724499-172.17.0.7-1597520540209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-ce908f08-818a-4248-91ed-78d422b0f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-4b14f631-47a3-4d7f-b2d5-5ebf78fdf0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-ae1d3f41-fd12-4d45-9f76-2628e6e1f0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-a6301930-806e-4ab8-ae09-dbfe4d286c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-860d6f07-aea9-4c82-a1ff-fcea2049afcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-2ad74849-45ca-4d6a-a6b4-b60ac5894d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-a6f4af9a-1384-424f-8845-f484e81e74cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-e332e259-08e8-4c0d-810e-dfbb038c2d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770724499-172.17.0.7-1597520540209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-ce908f08-818a-4248-91ed-78d422b0f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-4b14f631-47a3-4d7f-b2d5-5ebf78fdf0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-ae1d3f41-fd12-4d45-9f76-2628e6e1f0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-a6301930-806e-4ab8-ae09-dbfe4d286c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-860d6f07-aea9-4c82-a1ff-fcea2049afcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-2ad74849-45ca-4d6a-a6b4-b60ac5894d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-a6f4af9a-1384-424f-8845-f484e81e74cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-e332e259-08e8-4c0d-810e-dfbb038c2d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188665535-172.17.0.7-1597520578391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38434,DS-276b5af6-0a94-4a90-875d-b5d8731ad472,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-f319e79c-b8cb-4b91-9bca-3b7c6153101c,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-860417a1-85b5-4b17-bff2-e546a8a83e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-df09bee3-0810-4dd6-bbec-54a7222d2a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-4f232c03-d9ed-4880-a134-0f3eba7cd394,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-0edf8f29-94a5-44f9-8367-f8886ffbadc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-d4164ae5-ac1d-4ce1-9c70-0dbc16f42979,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-e2cf25cc-ede8-4157-b3cd-9df4414b4de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188665535-172.17.0.7-1597520578391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38434,DS-276b5af6-0a94-4a90-875d-b5d8731ad472,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-f319e79c-b8cb-4b91-9bca-3b7c6153101c,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-860417a1-85b5-4b17-bff2-e546a8a83e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-df09bee3-0810-4dd6-bbec-54a7222d2a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-4f232c03-d9ed-4880-a134-0f3eba7cd394,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-0edf8f29-94a5-44f9-8367-f8886ffbadc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-d4164ae5-ac1d-4ce1-9c70-0dbc16f42979,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-e2cf25cc-ede8-4157-b3cd-9df4414b4de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578474067-172.17.0.7-1597520658318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-7effcde1-bdbc-468b-bef9-32bfeadcd212,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-af0c87ad-06e7-4dbb-b08d-4651c7484fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-3f2fdcbd-4da9-4e40-8c50-278017f20f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-7332c24f-4f92-4690-bf33-a3cf8676b903,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-499fc801-bd91-4e96-bd99-2084aa843d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-4fd7180a-04dd-4de3-85df-8bd6b1b4c350,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-5289f000-db15-43e6-b487-8543b502dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-59ee5d35-de1b-4bd9-b3a1-8b502889bbd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578474067-172.17.0.7-1597520658318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-7effcde1-bdbc-468b-bef9-32bfeadcd212,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-af0c87ad-06e7-4dbb-b08d-4651c7484fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-3f2fdcbd-4da9-4e40-8c50-278017f20f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-7332c24f-4f92-4690-bf33-a3cf8676b903,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-499fc801-bd91-4e96-bd99-2084aa843d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-4fd7180a-04dd-4de3-85df-8bd6b1b4c350,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-5289f000-db15-43e6-b487-8543b502dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-59ee5d35-de1b-4bd9-b3a1-8b502889bbd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290828035-172.17.0.7-1597520956291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46413,DS-424b2e69-812d-4cda-9064-455b8aa30c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-7bd8c4d2-056b-4a4c-826d-c908f069d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-ce7ea789-7e9c-4413-b71d-be49c66eda17,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-4f8af618-88c9-43fc-ab89-8aa7e05c541b,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-1a2c2cee-6deb-4c73-93d4-3282caf451e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-5058f78a-fcf2-41e9-a5cc-bb68142252bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-ad1f949e-a0b4-4eb5-b35b-ac1fc1202cac,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-2087d49f-c770-4d1d-907d-b576d5b6baf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290828035-172.17.0.7-1597520956291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46413,DS-424b2e69-812d-4cda-9064-455b8aa30c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-7bd8c4d2-056b-4a4c-826d-c908f069d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-ce7ea789-7e9c-4413-b71d-be49c66eda17,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-4f8af618-88c9-43fc-ab89-8aa7e05c541b,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-1a2c2cee-6deb-4c73-93d4-3282caf451e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-5058f78a-fcf2-41e9-a5cc-bb68142252bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-ad1f949e-a0b4-4eb5-b35b-ac1fc1202cac,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-2087d49f-c770-4d1d-907d-b576d5b6baf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426350679-172.17.0.7-1597521072940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42489,DS-5de0155d-728c-4fe0-a32e-0fb5f1559117,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-3b6496de-3e6a-4071-a61f-b92801f87576,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-ec7be5c8-6d23-452d-90bc-527377e92d38,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-89fa5b34-60d0-49bb-b317-caa2fae7a7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-cc3d5e48-0369-4574-9afc-a87e88dbaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-a07ba3bb-dc8e-42e4-875f-52e2590e7f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-ecf6d1cb-81d1-436a-8767-f79e38db90ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-b49cad95-460d-406a-b8a8-ad321a66a413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426350679-172.17.0.7-1597521072940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42489,DS-5de0155d-728c-4fe0-a32e-0fb5f1559117,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-3b6496de-3e6a-4071-a61f-b92801f87576,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-ec7be5c8-6d23-452d-90bc-527377e92d38,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-89fa5b34-60d0-49bb-b317-caa2fae7a7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-cc3d5e48-0369-4574-9afc-a87e88dbaecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-a07ba3bb-dc8e-42e4-875f-52e2590e7f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-ecf6d1cb-81d1-436a-8767-f79e38db90ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-b49cad95-460d-406a-b8a8-ad321a66a413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342917533-172.17.0.7-1597521157640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35991,DS-77d93d65-4c8a-4bb4-893e-9e03c5f11fca,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-e978e6bb-96f1-4ae7-9327-3247e1c10566,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-67998581-a86c-4bfd-a836-e4246765471a,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-97a77bb2-cb41-4ae2-943b-e1b1cc12f935,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-70b6c28c-39bf-4cac-a08b-21ee0763e183,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-7f90b4ba-00a3-409b-a500-92310d0bf6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-498b174e-4e19-413d-abe9-7c6f67df7770,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-fd04ea6c-e60a-45a3-9894-08452b2b0446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342917533-172.17.0.7-1597521157640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35991,DS-77d93d65-4c8a-4bb4-893e-9e03c5f11fca,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-e978e6bb-96f1-4ae7-9327-3247e1c10566,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-67998581-a86c-4bfd-a836-e4246765471a,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-97a77bb2-cb41-4ae2-943b-e1b1cc12f935,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-70b6c28c-39bf-4cac-a08b-21ee0763e183,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-7f90b4ba-00a3-409b-a500-92310d0bf6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-498b174e-4e19-413d-abe9-7c6f67df7770,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-fd04ea6c-e60a-45a3-9894-08452b2b0446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822509278-172.17.0.7-1597521833024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-4d29e9fc-857d-487d-9c83-6d2dc8c0e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-71756597-05cc-4247-9d35-108b17500b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-9cbbdb78-efc1-4cfd-9c93-a97012a95cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-9e9f7bb6-42f4-4b65-93a7-726fefe26c97,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-f2dce456-3d11-43d0-9393-fdc49446e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-5ef19ca6-7e05-42ff-a962-851d1444b3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-d615fed9-4162-4b99-a08f-790f1d0f5a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-b33853bf-28ba-4c1f-ada5-9c6597a74911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822509278-172.17.0.7-1597521833024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-4d29e9fc-857d-487d-9c83-6d2dc8c0e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-71756597-05cc-4247-9d35-108b17500b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-9cbbdb78-efc1-4cfd-9c93-a97012a95cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-9e9f7bb6-42f4-4b65-93a7-726fefe26c97,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-f2dce456-3d11-43d0-9393-fdc49446e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-5ef19ca6-7e05-42ff-a962-851d1444b3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-d615fed9-4162-4b99-a08f-790f1d0f5a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-b33853bf-28ba-4c1f-ada5-9c6597a74911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264069046-172.17.0.7-1597521908413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-8b4fa036-6d9a-4ea0-ada3-319d50d87d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-4aedfe42-5ac7-4e07-bb84-0594056ee45f,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-60004f9a-57c7-4198-80cc-6a7ebe29f434,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-224e2892-32fd-4bb6-98bd-f3248e151799,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-b12f1e6d-2cae-4591-bbb9-0412de312129,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-14c172a4-c038-423f-903a-2694a5c3021f,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-8090e990-7638-42a6-a835-f96cc7a3ebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-198600bd-b1f2-4646-bed4-0f98dbeec992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264069046-172.17.0.7-1597521908413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-8b4fa036-6d9a-4ea0-ada3-319d50d87d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-4aedfe42-5ac7-4e07-bb84-0594056ee45f,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-60004f9a-57c7-4198-80cc-6a7ebe29f434,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-224e2892-32fd-4bb6-98bd-f3248e151799,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-b12f1e6d-2cae-4591-bbb9-0412de312129,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-14c172a4-c038-423f-903a-2694a5c3021f,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-8090e990-7638-42a6-a835-f96cc7a3ebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-198600bd-b1f2-4646-bed4-0f98dbeec992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365013919-172.17.0.7-1597522058258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34182,DS-0c22701f-0313-49aa-a12e-61b486f234bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-b8440983-fdc6-4fd4-a7da-7a3a922e305e,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-9118733e-5a94-4b00-bec3-ceb3f9c331ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-089d5e1a-8b82-49ba-bf41-b71d54342a89,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-ab94e264-8b5b-4552-b081-39714327b591,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-8cfc49fb-a4be-4407-b943-d426dab80f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-cf845ffe-fa72-4504-8c21-81bc8a63ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-a465e7e8-01b0-4ebf-9fe1-a8847e990809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365013919-172.17.0.7-1597522058258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34182,DS-0c22701f-0313-49aa-a12e-61b486f234bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-b8440983-fdc6-4fd4-a7da-7a3a922e305e,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-9118733e-5a94-4b00-bec3-ceb3f9c331ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-089d5e1a-8b82-49ba-bf41-b71d54342a89,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-ab94e264-8b5b-4552-b081-39714327b591,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-8cfc49fb-a4be-4407-b943-d426dab80f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-cf845ffe-fa72-4504-8c21-81bc8a63ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-a465e7e8-01b0-4ebf-9fe1-a8847e990809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923566654-172.17.0.7-1597522094542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41625,DS-5e6d163c-c32b-4e68-a716-f3f6a30e48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-686bd7e8-5e7b-4836-8ea3-ff732e089798,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-650d5cf4-61cb-4523-b147-1abeef5f5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-5149cf6d-f3e6-45ef-a7e5-42023c087cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-d15a6e79-3cb2-4a33-b59a-6a074a1d346c,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-24abb9fe-5c15-43aa-8d4a-c6ec4c536165,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-cb65a75d-80d0-4533-8826-22b11b7b7c70,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-c05434b3-b19d-48fb-8c2e-d8792c22571d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923566654-172.17.0.7-1597522094542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41625,DS-5e6d163c-c32b-4e68-a716-f3f6a30e48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-686bd7e8-5e7b-4836-8ea3-ff732e089798,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-650d5cf4-61cb-4523-b147-1abeef5f5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-5149cf6d-f3e6-45ef-a7e5-42023c087cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-d15a6e79-3cb2-4a33-b59a-6a074a1d346c,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-24abb9fe-5c15-43aa-8d4a-c6ec4c536165,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-cb65a75d-80d0-4533-8826-22b11b7b7c70,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-c05434b3-b19d-48fb-8c2e-d8792c22571d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287060332-172.17.0.7-1597522128938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38855,DS-485eaa97-5d13-47c4-8a5d-1f2b65180134,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-fd855ade-6e1f-4677-abc9-baf77d71c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-3cfe09b1-3026-4ef7-8d2b-ef954d583cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-6cdbf2d2-82f0-47ca-b0d3-11184938c779,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-0046154a-d8ae-4385-b86e-cb3cabbda8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-b44022a2-9230-4d6e-9fad-58db73486fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-ee53c1ef-bbd2-4746-bedc-9136f7985f75,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-3d460138-f01c-41b8-9116-e7858ce53a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287060332-172.17.0.7-1597522128938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38855,DS-485eaa97-5d13-47c4-8a5d-1f2b65180134,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-fd855ade-6e1f-4677-abc9-baf77d71c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-3cfe09b1-3026-4ef7-8d2b-ef954d583cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-6cdbf2d2-82f0-47ca-b0d3-11184938c779,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-0046154a-d8ae-4385-b86e-cb3cabbda8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-b44022a2-9230-4d6e-9fad-58db73486fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-ee53c1ef-bbd2-4746-bedc-9136f7985f75,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-3d460138-f01c-41b8-9116-e7858ce53a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910498481-172.17.0.7-1597522210353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38988,DS-4ab6c74a-76db-4e76-a498-7ab3f5eeecde,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-2dc0d10d-1a20-494f-9eed-22c30707e575,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-a6f482e4-dc32-4aa6-9af3-e5d9dada53f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-4ad4f5ba-d80c-4682-829f-f9bb37835620,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-7e4d3985-d2c0-417e-a16d-f3c8278929c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-117848e2-6a7f-4c1e-b282-3c88c4cb5f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-e4c0f6a2-510d-4441-922e-b40d5ebc8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-94b4c1ff-8a8e-41d8-9177-a97acc35f103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910498481-172.17.0.7-1597522210353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38988,DS-4ab6c74a-76db-4e76-a498-7ab3f5eeecde,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-2dc0d10d-1a20-494f-9eed-22c30707e575,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-a6f482e4-dc32-4aa6-9af3-e5d9dada53f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-4ad4f5ba-d80c-4682-829f-f9bb37835620,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-7e4d3985-d2c0-417e-a16d-f3c8278929c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-117848e2-6a7f-4c1e-b282-3c88c4cb5f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-e4c0f6a2-510d-4441-922e-b40d5ebc8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-94b4c1ff-8a8e-41d8-9177-a97acc35f103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106241625-172.17.0.7-1597522549071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-ea6d1462-65e7-4e3d-985a-81aa5eed5eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-710b57b7-90d4-49fe-9dc0-7c2325aa6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-21e0aae9-8870-452a-9733-5ae4777b7448,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-86bdce35-cfbf-4262-bf75-9d70d7550b14,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-35fcfd61-d11b-4c13-b839-fb24145d123c,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2e872094-d73f-4094-ac22-ce69d09b0a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-5eab00fe-7c95-4d80-83d0-f24b7d3df58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-a61d618f-d24d-466d-b702-c7a6fe0aa757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106241625-172.17.0.7-1597522549071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-ea6d1462-65e7-4e3d-985a-81aa5eed5eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-710b57b7-90d4-49fe-9dc0-7c2325aa6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-21e0aae9-8870-452a-9733-5ae4777b7448,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-86bdce35-cfbf-4262-bf75-9d70d7550b14,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-35fcfd61-d11b-4c13-b839-fb24145d123c,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-2e872094-d73f-4094-ac22-ce69d09b0a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-5eab00fe-7c95-4d80-83d0-f24b7d3df58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-a61d618f-d24d-466d-b702-c7a6fe0aa757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5570
