reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962719147-172.17.0.10-1597637647671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38386,DS-d3c5d077-d42a-4062-8c6f-32872853ce74,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-20f91e78-bde2-42a7-a178-40a99ed9bd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-9ac26f02-9228-426c-99d6-9266effa1f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-f2fca63a-c1c6-49d3-9f67-11a54c0da787,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-8350ce2c-6423-46d4-af96-5b28349d6e95,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-eb347a1b-3bab-4485-a424-6e6ae4f4cf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-1b2313db-296c-4583-900e-b13f8834f2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-9bc605f4-ab75-4f9b-ac85-f56a77ae5a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962719147-172.17.0.10-1597637647671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38386,DS-d3c5d077-d42a-4062-8c6f-32872853ce74,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-20f91e78-bde2-42a7-a178-40a99ed9bd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-9ac26f02-9228-426c-99d6-9266effa1f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-f2fca63a-c1c6-49d3-9f67-11a54c0da787,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-8350ce2c-6423-46d4-af96-5b28349d6e95,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-eb347a1b-3bab-4485-a424-6e6ae4f4cf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-1b2313db-296c-4583-900e-b13f8834f2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-9bc605f4-ab75-4f9b-ac85-f56a77ae5a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611069437-172.17.0.10-1597637790255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33772,DS-e38d73fe-c75e-4135-9c4a-f6e7ca32f99d,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-04152531-f247-4bbc-b1b6-f2e0167f879f,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-f0eb206b-552f-4c63-b220-306f56651221,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-c0c9c7ce-34a1-4046-b0d3-19c0b831450d,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-243b1cd4-200b-49d2-942d-a2048ac49839,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-523c5e82-6c22-421f-9388-2247213c7ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-b43a2722-2e71-41a1-bab7-f7bca63b924e,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-daef5b84-2469-4992-98ad-1169939deedd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611069437-172.17.0.10-1597637790255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33772,DS-e38d73fe-c75e-4135-9c4a-f6e7ca32f99d,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-04152531-f247-4bbc-b1b6-f2e0167f879f,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-f0eb206b-552f-4c63-b220-306f56651221,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-c0c9c7ce-34a1-4046-b0d3-19c0b831450d,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-243b1cd4-200b-49d2-942d-a2048ac49839,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-523c5e82-6c22-421f-9388-2247213c7ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-b43a2722-2e71-41a1-bab7-f7bca63b924e,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-daef5b84-2469-4992-98ad-1169939deedd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758138857-172.17.0.10-1597638125768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42969,DS-6a204d19-4c14-4014-beec-4b115b2f4e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-ffa583ed-a407-453e-8ff2-1fcc2aab924d,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-27a75164-27e2-466e-86e5-705fa78852d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-d9ed0998-2deb-41c2-b3d9-32665e197767,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-aedd1211-496a-4197-8cc2-dff384d7f048,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-a973445a-75aa-4ab3-a2f0-2bce3d973224,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-d0209149-d3c9-4613-a609-54f9d18583ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-b50ff4d3-d278-4ce5-bc5b-a28837707efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758138857-172.17.0.10-1597638125768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42969,DS-6a204d19-4c14-4014-beec-4b115b2f4e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-ffa583ed-a407-453e-8ff2-1fcc2aab924d,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-27a75164-27e2-466e-86e5-705fa78852d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-d9ed0998-2deb-41c2-b3d9-32665e197767,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-aedd1211-496a-4197-8cc2-dff384d7f048,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-a973445a-75aa-4ab3-a2f0-2bce3d973224,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-d0209149-d3c9-4613-a609-54f9d18583ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-b50ff4d3-d278-4ce5-bc5b-a28837707efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332680217-172.17.0.10-1597638159287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32852,DS-f182aa10-59ad-4fbd-ad4d-b6f5b1fda99d,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-0e857993-dcf0-408d-92db-727dbda206b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-870cb771-b783-406d-8bf4-609bdba739e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-dd4847c6-994e-46b5-a3cd-cb43f28c771b,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-dea3b50e-ed24-401a-86c3-d068a4b2b4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-cf69a7ef-a61f-46e0-bdc1-43dfbd670eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-f11d2dc9-f54b-4f88-a652-45bc96ea20d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-809325c7-baa6-4558-8ff6-b0977925966b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332680217-172.17.0.10-1597638159287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32852,DS-f182aa10-59ad-4fbd-ad4d-b6f5b1fda99d,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-0e857993-dcf0-408d-92db-727dbda206b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-870cb771-b783-406d-8bf4-609bdba739e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-dd4847c6-994e-46b5-a3cd-cb43f28c771b,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-dea3b50e-ed24-401a-86c3-d068a4b2b4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-cf69a7ef-a61f-46e0-bdc1-43dfbd670eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-f11d2dc9-f54b-4f88-a652-45bc96ea20d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-809325c7-baa6-4558-8ff6-b0977925966b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556510246-172.17.0.10-1597638293775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43000,DS-66404c41-91ef-4fba-b7cd-a2b338c028c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-a0615494-1db5-4c9d-b606-0653b9e1e608,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-0b9100ab-ac6d-4a53-98d1-c0c6a81cae3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-e6009e4b-73b7-49f3-834a-d0f9b0f887ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-d59d0397-40ba-4a29-bddd-0cedfc57686c,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-d040fd71-2fdf-4cb7-8426-509c6c3677d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-fd803302-ab6e-4b84-b8b5-b355bcc0c708,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-52bf1ace-dc5a-4eb1-918a-3353f6afc5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556510246-172.17.0.10-1597638293775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43000,DS-66404c41-91ef-4fba-b7cd-a2b338c028c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-a0615494-1db5-4c9d-b606-0653b9e1e608,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-0b9100ab-ac6d-4a53-98d1-c0c6a81cae3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-e6009e4b-73b7-49f3-834a-d0f9b0f887ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-d59d0397-40ba-4a29-bddd-0cedfc57686c,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-d040fd71-2fdf-4cb7-8426-509c6c3677d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-fd803302-ab6e-4b84-b8b5-b355bcc0c708,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-52bf1ace-dc5a-4eb1-918a-3353f6afc5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971320658-172.17.0.10-1597638486702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33645,DS-cf3f507d-426b-4ff4-9679-8d1aea125934,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-3e89bb22-eaad-4a30-b954-02d7aabfeb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-ba768800-9e85-41a8-a670-6961e2ce3dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-99dd2e8e-c7a6-4ac7-911f-e439aa638c80,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-c3827c6a-9781-4431-aa58-c6e5fb42a027,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-c0af4906-8927-4057-91b0-0b53bb2bad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-e758c430-3481-4267-918b-4f06530cbaae,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-57c59309-2585-4e4c-844e-4e72d41aeab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971320658-172.17.0.10-1597638486702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33645,DS-cf3f507d-426b-4ff4-9679-8d1aea125934,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-3e89bb22-eaad-4a30-b954-02d7aabfeb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-ba768800-9e85-41a8-a670-6961e2ce3dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-99dd2e8e-c7a6-4ac7-911f-e439aa638c80,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-c3827c6a-9781-4431-aa58-c6e5fb42a027,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-c0af4906-8927-4057-91b0-0b53bb2bad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-e758c430-3481-4267-918b-4f06530cbaae,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-57c59309-2585-4e4c-844e-4e72d41aeab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336120122-172.17.0.10-1597638796331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-c22b099d-c37a-4659-826f-a2c6ac38234a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-c71a3a14-b84c-4bac-9f6f-2b85c5dca5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-c0832a77-4f24-4def-8c7c-50d7a4023bec,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-2289fe73-3879-4a87-b36f-91dd8068b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-65bb5235-497d-496e-be1b-cea668445145,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-1a16bb5a-01cd-4ca3-a9b9-d8b6ba4f2d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-2343bf2d-2999-45e0-8348-a86620c95f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-9b528e92-310c-41f8-a966-4377bfd81bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336120122-172.17.0.10-1597638796331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-c22b099d-c37a-4659-826f-a2c6ac38234a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-c71a3a14-b84c-4bac-9f6f-2b85c5dca5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-c0832a77-4f24-4def-8c7c-50d7a4023bec,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-2289fe73-3879-4a87-b36f-91dd8068b1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-65bb5235-497d-496e-be1b-cea668445145,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-1a16bb5a-01cd-4ca3-a9b9-d8b6ba4f2d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-2343bf2d-2999-45e0-8348-a86620c95f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-9b528e92-310c-41f8-a966-4377bfd81bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085691302-172.17.0.10-1597638830322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45434,DS-14be67d0-174e-4dfd-b8e8-b87e1795f374,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-88b57cbb-16a6-4e21-ab2f-a81742c2fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-a5aca27c-872b-4143-9812-263eae3d0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-dd882bd2-2e48-4ffd-8356-7ef40b7ace3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-ed3ca944-7b41-475a-9c04-6b5dade36468,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-12f629af-2b00-4bec-8839-eb800584f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-f1755909-2b9d-4344-9cc1-b01468cad030,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-f1356f72-dece-4197-9b5c-94e3683f3356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085691302-172.17.0.10-1597638830322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45434,DS-14be67d0-174e-4dfd-b8e8-b87e1795f374,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-88b57cbb-16a6-4e21-ab2f-a81742c2fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-a5aca27c-872b-4143-9812-263eae3d0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-dd882bd2-2e48-4ffd-8356-7ef40b7ace3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-ed3ca944-7b41-475a-9c04-6b5dade36468,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-12f629af-2b00-4bec-8839-eb800584f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-f1755909-2b9d-4344-9cc1-b01468cad030,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-f1356f72-dece-4197-9b5c-94e3683f3356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368934815-172.17.0.10-1597639581904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-df00db9c-0adf-4181-9a11-b10116c8b129,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-c51ab7f8-aa3b-4cab-a9a3-4cef2db2c24a,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-b6b52c2d-8bc8-4eaf-8e3b-9d9559d7b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-fd17680c-eae1-473e-8332-f5e7fad37d30,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-f18e870c-d425-4ecd-87a0-4341be658b25,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-f67d224c-3815-4584-ad42-35707b00a180,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-bf2829f2-263f-4197-be88-9d6d2e0cf9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-2c904db5-e319-4665-a779-a855177cc381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368934815-172.17.0.10-1597639581904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-df00db9c-0adf-4181-9a11-b10116c8b129,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-c51ab7f8-aa3b-4cab-a9a3-4cef2db2c24a,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-b6b52c2d-8bc8-4eaf-8e3b-9d9559d7b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-fd17680c-eae1-473e-8332-f5e7fad37d30,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-f18e870c-d425-4ecd-87a0-4341be658b25,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-f67d224c-3815-4584-ad42-35707b00a180,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-bf2829f2-263f-4197-be88-9d6d2e0cf9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-2c904db5-e319-4665-a779-a855177cc381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345558543-172.17.0.10-1597639770167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-7a3d8705-4197-4869-b39e-4526f885b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-1d0c9444-4581-4914-97fa-f656b424d799,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-de166f76-903e-4eb2-827c-46c2be2ffac5,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-4c347e3a-9c50-4ada-99eb-1bf0cdab8636,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-da7239ad-4f16-425c-8a12-5feca506b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-8e2f18cb-710d-46f0-aa81-23ecbfe55440,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-3abb264b-1741-4324-bcee-2e2b17b31f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-e2f77530-786d-4473-b0c8-c2f98f88e972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345558543-172.17.0.10-1597639770167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-7a3d8705-4197-4869-b39e-4526f885b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-1d0c9444-4581-4914-97fa-f656b424d799,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-de166f76-903e-4eb2-827c-46c2be2ffac5,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-4c347e3a-9c50-4ada-99eb-1bf0cdab8636,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-da7239ad-4f16-425c-8a12-5feca506b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-8e2f18cb-710d-46f0-aa81-23ecbfe55440,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-3abb264b-1741-4324-bcee-2e2b17b31f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-e2f77530-786d-4473-b0c8-c2f98f88e972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075081190-172.17.0.10-1597639802788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39864,DS-7c7c207f-70d8-48e2-96ac-1ecc16ead5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-992ec14c-f3bf-4bcc-974f-f2db06561ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-99ef48ec-6607-46df-b4b8-0ec2cd41605a,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-f729e60f-5b3c-4e2b-b3df-fdc9d8d9106c,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-89353ec8-74e4-40a3-8af9-f55490d02fce,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-ddd3ebd0-5b30-4048-b257-03e4517250db,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-8f1e317c-74af-41ec-850d-ea718f7db6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-265bde55-8062-4738-b93f-7830d316b189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075081190-172.17.0.10-1597639802788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39864,DS-7c7c207f-70d8-48e2-96ac-1ecc16ead5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-992ec14c-f3bf-4bcc-974f-f2db06561ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-99ef48ec-6607-46df-b4b8-0ec2cd41605a,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-f729e60f-5b3c-4e2b-b3df-fdc9d8d9106c,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-89353ec8-74e4-40a3-8af9-f55490d02fce,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-ddd3ebd0-5b30-4048-b257-03e4517250db,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-8f1e317c-74af-41ec-850d-ea718f7db6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-265bde55-8062-4738-b93f-7830d316b189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641247503-172.17.0.10-1597640428105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-8a3b68c9-5906-4ac4-b21d-112ecd981d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-f7c36d6c-d610-4b78-99f1-0dcb2a03b706,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-d28db897-5bba-4c5b-b6b8-405c222f73de,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-61d99896-c4a5-4f5b-80eb-55c30bc0ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-24e917bf-9750-4f77-8d43-dcfc9206df67,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-b0b1a773-39d5-4117-8afb-9be0249114a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-89fb694e-626e-4f81-bd45-76309118e3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-9afea937-5ce3-4958-a895-86ac23f7f1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641247503-172.17.0.10-1597640428105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-8a3b68c9-5906-4ac4-b21d-112ecd981d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-f7c36d6c-d610-4b78-99f1-0dcb2a03b706,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-d28db897-5bba-4c5b-b6b8-405c222f73de,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-61d99896-c4a5-4f5b-80eb-55c30bc0ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-24e917bf-9750-4f77-8d43-dcfc9206df67,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-b0b1a773-39d5-4117-8afb-9be0249114a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-89fb694e-626e-4f81-bd45-76309118e3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-9afea937-5ce3-4958-a895-86ac23f7f1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142347924-172.17.0.10-1597640542352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34920,DS-e622be47-d649-4572-95b7-5fd1b84fbf35,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-73bd5791-2633-4925-a4bf-4cff96a27d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-460772c7-6814-415c-ae50-5d18c826dcff,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-2eeb05e7-3a19-4c1b-a2fd-772448df727a,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-9b45f098-d8ce-4871-b2b0-90079a3644f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-f89be325-7d51-4e93-aa64-f9a80e9bad7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-3e1b4ae6-3f90-4413-b8bd-35bde5b7dad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-fae07416-a26d-428f-928f-11751b5fa9b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142347924-172.17.0.10-1597640542352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34920,DS-e622be47-d649-4572-95b7-5fd1b84fbf35,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-73bd5791-2633-4925-a4bf-4cff96a27d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-460772c7-6814-415c-ae50-5d18c826dcff,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-2eeb05e7-3a19-4c1b-a2fd-772448df727a,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-9b45f098-d8ce-4871-b2b0-90079a3644f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-f89be325-7d51-4e93-aa64-f9a80e9bad7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-3e1b4ae6-3f90-4413-b8bd-35bde5b7dad3,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-fae07416-a26d-428f-928f-11751b5fa9b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458357565-172.17.0.10-1597641205566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40822,DS-357253cf-ddfa-4fcc-bd42-754663cafdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-605f4f97-dcf1-4d25-97ae-6c7098254338,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-9ac7f6d5-291d-4f51-87ce-cb1693cc1797,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-30674180-c5f8-4a8d-b560-bf669b773034,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-20844bd6-ff30-4ff4-bfb5-42edb40d2fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-9656a67a-50e5-4872-aef5-d72204802400,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-8c37774f-c014-49eb-adcc-482ba65c2b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-af7b55e4-dee1-4676-be57-30ce744d5c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458357565-172.17.0.10-1597641205566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40822,DS-357253cf-ddfa-4fcc-bd42-754663cafdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-605f4f97-dcf1-4d25-97ae-6c7098254338,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-9ac7f6d5-291d-4f51-87ce-cb1693cc1797,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-30674180-c5f8-4a8d-b560-bf669b773034,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-20844bd6-ff30-4ff4-bfb5-42edb40d2fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-9656a67a-50e5-4872-aef5-d72204802400,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-8c37774f-c014-49eb-adcc-482ba65c2b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-af7b55e4-dee1-4676-be57-30ce744d5c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284707637-172.17.0.10-1597641352781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33910,DS-80693d41-df2c-48b8-8b03-047e1859b5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-89791ada-05b2-4754-a4b3-5774d496c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-15139ca0-c110-40b5-8b3b-ff73603c8374,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-c1682051-940d-4e6a-a851-76682df5b91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-df574b39-a537-4871-964a-c4684d18c6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-0410608c-1754-4d27-96b9-eb58247e272a,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-524787eb-a02b-4149-8ad1-7b5c29f5afa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-14d13e98-f90f-4c66-ba50-f41548dd0edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284707637-172.17.0.10-1597641352781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33910,DS-80693d41-df2c-48b8-8b03-047e1859b5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-89791ada-05b2-4754-a4b3-5774d496c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-15139ca0-c110-40b5-8b3b-ff73603c8374,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-c1682051-940d-4e6a-a851-76682df5b91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-df574b39-a537-4871-964a-c4684d18c6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-0410608c-1754-4d27-96b9-eb58247e272a,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-524787eb-a02b-4149-8ad1-7b5c29f5afa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-14d13e98-f90f-4c66-ba50-f41548dd0edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1931569726-172.17.0.10-1597641613826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33992,DS-b01fd00b-34cd-4e2d-a743-cef814dc378c,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-d64e273d-5a66-48ef-9fe4-71e7e1f0df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-8d45b27a-b4fc-4eea-9fd4-522b5c3d3242,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-eff2fcc7-fac0-4383-9cc5-d125a910dcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-e58d5010-dbbc-435f-9bef-a3edc3b6a1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-8a2230d9-ac42-4a26-88f7-36488409f599,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-7c4d1339-1b02-442d-97ad-0574cec2cc24,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-6c6fc151-7ade-45fc-a459-484aa3007df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1931569726-172.17.0.10-1597641613826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33992,DS-b01fd00b-34cd-4e2d-a743-cef814dc378c,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-d64e273d-5a66-48ef-9fe4-71e7e1f0df3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-8d45b27a-b4fc-4eea-9fd4-522b5c3d3242,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-eff2fcc7-fac0-4383-9cc5-d125a910dcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-e58d5010-dbbc-435f-9bef-a3edc3b6a1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-8a2230d9-ac42-4a26-88f7-36488409f599,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-7c4d1339-1b02-442d-97ad-0574cec2cc24,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-6c6fc151-7ade-45fc-a459-484aa3007df0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5431
