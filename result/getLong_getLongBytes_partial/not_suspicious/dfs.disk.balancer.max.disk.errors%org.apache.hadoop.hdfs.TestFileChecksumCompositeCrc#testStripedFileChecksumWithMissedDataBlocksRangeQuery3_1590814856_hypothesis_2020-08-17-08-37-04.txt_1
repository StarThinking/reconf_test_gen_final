reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952876684-172.17.0.2-1597653663360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44927,DS-62ba7742-b14f-474a-bf14-0abd5ddeb157,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-218afd77-f16f-4de4-bf1d-9f3d74c6f61e,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-e843d82f-aaff-47d2-aa36-9150a23c9b16,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-760c34e5-2425-4dc0-9fbd-12682f5e2f30,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-75538a87-d7d3-42a1-9290-182012478f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-f1c12d93-b3a9-483d-8067-18b242d059ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-cf1fad5c-09a1-44d2-9b86-23ffa42b0774,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-085a34a3-1574-4583-8a66-88a78fb1f81c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952876684-172.17.0.2-1597653663360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44927,DS-62ba7742-b14f-474a-bf14-0abd5ddeb157,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-218afd77-f16f-4de4-bf1d-9f3d74c6f61e,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-e843d82f-aaff-47d2-aa36-9150a23c9b16,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-760c34e5-2425-4dc0-9fbd-12682f5e2f30,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-75538a87-d7d3-42a1-9290-182012478f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-f1c12d93-b3a9-483d-8067-18b242d059ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-cf1fad5c-09a1-44d2-9b86-23ffa42b0774,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-085a34a3-1574-4583-8a66-88a78fb1f81c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836601871-172.17.0.2-1597653905181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-068fc263-994e-47e7-8a37-0b6831fc6f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-d1e910a7-8e54-4f10-a259-4e58eca417c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-2cfc48ea-bcfe-4e4a-afa5-9b99dc0f9a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-1ed85914-e8f0-4b58-b5c9-2b6f714757a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-51d88ded-1e70-40ea-8268-fe678662c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-69e176fd-ad16-4c2c-b781-26bd916375e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-f0d19082-f832-4454-9c7a-2488b1478d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-01c603f5-535f-48e3-9164-9fb3450aa87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836601871-172.17.0.2-1597653905181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-068fc263-994e-47e7-8a37-0b6831fc6f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-d1e910a7-8e54-4f10-a259-4e58eca417c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-2cfc48ea-bcfe-4e4a-afa5-9b99dc0f9a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-1ed85914-e8f0-4b58-b5c9-2b6f714757a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-51d88ded-1e70-40ea-8268-fe678662c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-69e176fd-ad16-4c2c-b781-26bd916375e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-f0d19082-f832-4454-9c7a-2488b1478d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-01c603f5-535f-48e3-9164-9fb3450aa87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978312725-172.17.0.2-1597653939238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41818,DS-8d1f12fc-454b-4561-85f6-100038c57d07,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-9fedfd11-3dfc-4a9a-8dc5-3b83f5a12df3,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-0192dd06-5b20-4aac-8441-2e091f1d9ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-b807441f-71e0-4a63-88c5-dfe5c0d81d16,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-afdaad5c-dd22-40fe-b7ea-f60452d5ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-26687501-5286-49ea-a1b8-70c4cb1acfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-1bc82dd7-289f-4e97-8de2-e82045c9cb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-a841baa4-b83c-46cf-892d-50f07fef71ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978312725-172.17.0.2-1597653939238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41818,DS-8d1f12fc-454b-4561-85f6-100038c57d07,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-9fedfd11-3dfc-4a9a-8dc5-3b83f5a12df3,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-0192dd06-5b20-4aac-8441-2e091f1d9ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-b807441f-71e0-4a63-88c5-dfe5c0d81d16,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-afdaad5c-dd22-40fe-b7ea-f60452d5ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-26687501-5286-49ea-a1b8-70c4cb1acfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-1bc82dd7-289f-4e97-8de2-e82045c9cb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-a841baa4-b83c-46cf-892d-50f07fef71ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332339025-172.17.0.2-1597654089860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-379321dd-b46f-4556-9b70-6ce05c2c28fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-a0b04211-073b-4896-a913-56e6ebf06904,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-87148c64-ee76-4beb-bf00-85246f9f1ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-9d4d5175-211f-4e14-ae84-0fc74a4c43ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-0d67f301-6cc6-4192-a235-107f8c3e4f41,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-0465e784-647f-4910-a687-201799c6b078,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-a017e336-7b1b-41df-acee-4220a74670e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-8e56ff0a-9191-4751-acad-273f785d8a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332339025-172.17.0.2-1597654089860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-379321dd-b46f-4556-9b70-6ce05c2c28fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-a0b04211-073b-4896-a913-56e6ebf06904,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-87148c64-ee76-4beb-bf00-85246f9f1ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-9d4d5175-211f-4e14-ae84-0fc74a4c43ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-0d67f301-6cc6-4192-a235-107f8c3e4f41,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-0465e784-647f-4910-a687-201799c6b078,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-a017e336-7b1b-41df-acee-4220a74670e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-8e56ff0a-9191-4751-acad-273f785d8a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969087850-172.17.0.2-1597654626732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-17ca9336-089b-4c6c-89c5-738dc6f2b0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-b02cc226-6a5e-4517-ae8a-34ea8106ee11,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-e15ba2a6-eb59-4aaf-8a5c-dcb4cdf4427a,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-d3194b4c-f03e-4cb3-997a-269363c46650,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-bf766822-3d67-4b24-b4d9-b6efc19bcb18,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-6054a7da-a1d1-45e4-a840-e2d64e3ce541,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-70d0a337-8ff4-4886-a4c1-4e2a72405425,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-695e2bb0-3e63-4029-af10-71ab5788535a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969087850-172.17.0.2-1597654626732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-17ca9336-089b-4c6c-89c5-738dc6f2b0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-b02cc226-6a5e-4517-ae8a-34ea8106ee11,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-e15ba2a6-eb59-4aaf-8a5c-dcb4cdf4427a,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-d3194b4c-f03e-4cb3-997a-269363c46650,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-bf766822-3d67-4b24-b4d9-b6efc19bcb18,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-6054a7da-a1d1-45e4-a840-e2d64e3ce541,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-70d0a337-8ff4-4886-a4c1-4e2a72405425,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-695e2bb0-3e63-4029-af10-71ab5788535a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957636638-172.17.0.2-1597655201423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46643,DS-f35548f9-f90e-4875-86ff-9ad66374a165,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-94c3390a-f0f6-44b6-870c-2bfa55877655,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-538baefb-7e38-4b9c-a32a-b3db9d3aa929,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-e26f5845-9199-450b-99ac-a7efe2010570,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-103b3efd-e54f-4c54-8c98-9786e2ec137d,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-61c9cf06-3829-4d47-a3f4-f3aa3e2cccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-156ef7de-496b-48fa-853e-20623a458150,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-ee409a09-c344-4e33-a802-f1b033faa588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957636638-172.17.0.2-1597655201423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46643,DS-f35548f9-f90e-4875-86ff-9ad66374a165,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-94c3390a-f0f6-44b6-870c-2bfa55877655,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-538baefb-7e38-4b9c-a32a-b3db9d3aa929,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-e26f5845-9199-450b-99ac-a7efe2010570,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-103b3efd-e54f-4c54-8c98-9786e2ec137d,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-61c9cf06-3829-4d47-a3f4-f3aa3e2cccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-156ef7de-496b-48fa-853e-20623a458150,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-ee409a09-c344-4e33-a802-f1b033faa588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360895097-172.17.0.2-1597655310413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40216,DS-7ca9cd7a-f7e5-4c02-ba67-b3d393937cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-63723e60-9b7a-476d-aaf6-c13f65fd9407,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-084cfc30-00fd-41be-aec2-5f6b56bfa819,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-6a19c09a-6e12-402a-9dc6-6f17c3ccd42e,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-c166d72d-f4e5-42a2-99b2-5e24818ef70a,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-2629b4ef-2c7d-43fd-9ffd-b37794231740,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-05820861-52b6-4c2e-9215-a647a48f53ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-6dc8c314-3719-4dca-812d-0d9d9716af7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360895097-172.17.0.2-1597655310413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40216,DS-7ca9cd7a-f7e5-4c02-ba67-b3d393937cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-63723e60-9b7a-476d-aaf6-c13f65fd9407,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-084cfc30-00fd-41be-aec2-5f6b56bfa819,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-6a19c09a-6e12-402a-9dc6-6f17c3ccd42e,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-c166d72d-f4e5-42a2-99b2-5e24818ef70a,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-2629b4ef-2c7d-43fd-9ffd-b37794231740,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-05820861-52b6-4c2e-9215-a647a48f53ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-6dc8c314-3719-4dca-812d-0d9d9716af7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159050913-172.17.0.2-1597656069287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41867,DS-0b227dc7-a29b-49a7-b2ee-39012408713c,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-a7e7d8ff-4e59-41dd-84c0-21b2cb6ed3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-05adc200-f958-4598-8a1e-d0f40f33a242,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-bdf328bb-ecac-476b-bfe6-7cb95c5046c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-1f3a2059-a1c7-4cc8-ba13-e82f4e9c13d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-5db31838-883a-45ba-9492-8e480965cbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-99665745-72db-4bdb-9a02-ea911bb4cfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-ff59d154-eeb8-474c-aa3f-d64a2ebc3bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159050913-172.17.0.2-1597656069287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41867,DS-0b227dc7-a29b-49a7-b2ee-39012408713c,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-a7e7d8ff-4e59-41dd-84c0-21b2cb6ed3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-05adc200-f958-4598-8a1e-d0f40f33a242,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-bdf328bb-ecac-476b-bfe6-7cb95c5046c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-1f3a2059-a1c7-4cc8-ba13-e82f4e9c13d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-5db31838-883a-45ba-9492-8e480965cbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-99665745-72db-4bdb-9a02-ea911bb4cfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-ff59d154-eeb8-474c-aa3f-d64a2ebc3bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808789855-172.17.0.2-1597656106672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44446,DS-db5ca48e-be7f-4189-84a7-e156c7538fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-5e4c3c5b-47d1-446f-bf92-b6bba275c821,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-1d3e1890-b33a-423e-98d3-bc1986c457eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-3f96e30c-b3ec-4113-973a-a1642ea14a34,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-96534e4c-3b07-405e-9337-036f3df83658,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-91b8fa58-6551-438b-b610-77ed09178d06,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-0523d5fe-6e23-40b2-ab3e-4ee282bb2305,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-229fa7a1-bcd3-4dd4-afcf-e681011a6869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808789855-172.17.0.2-1597656106672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44446,DS-db5ca48e-be7f-4189-84a7-e156c7538fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-5e4c3c5b-47d1-446f-bf92-b6bba275c821,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-1d3e1890-b33a-423e-98d3-bc1986c457eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-3f96e30c-b3ec-4113-973a-a1642ea14a34,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-96534e4c-3b07-405e-9337-036f3df83658,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-91b8fa58-6551-438b-b610-77ed09178d06,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-0523d5fe-6e23-40b2-ab3e-4ee282bb2305,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-229fa7a1-bcd3-4dd4-afcf-e681011a6869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263682433-172.17.0.2-1597656491666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37795,DS-cd3161ec-955e-4109-b3b2-dbddaaa150a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-3915a24a-64ae-40e3-b16d-f4e32f6a3d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-3493ccc5-9c2d-4679-b106-379a8ec39539,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-72a86298-05a5-4723-93da-5a1174dc5f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-8ef0393b-2f61-4310-ae2a-c53fc03b1a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-07f08fb8-5685-4439-9ee7-ac8924d4c879,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-636488e3-3efb-4309-9e30-76e87fef4746,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-f59df45c-ce03-471c-8fbf-344697506355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263682433-172.17.0.2-1597656491666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37795,DS-cd3161ec-955e-4109-b3b2-dbddaaa150a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-3915a24a-64ae-40e3-b16d-f4e32f6a3d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-3493ccc5-9c2d-4679-b106-379a8ec39539,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-72a86298-05a5-4723-93da-5a1174dc5f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-8ef0393b-2f61-4310-ae2a-c53fc03b1a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-07f08fb8-5685-4439-9ee7-ac8924d4c879,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-636488e3-3efb-4309-9e30-76e87fef4746,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-f59df45c-ce03-471c-8fbf-344697506355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41135918-172.17.0.2-1597656919955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45640,DS-1e18b4ea-5418-40d4-b9f5-4c907f509221,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-6e1f41d5-2ab7-4bbb-806f-d845e77407b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-4b39cecb-db86-46c4-b630-f07069527e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-48a8eab6-de65-4e25-855b-734a588cff71,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-3d121dfa-fd73-4832-b6a7-2e2ce402e097,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-e378ebab-d67a-4605-8152-8dda3f2e2e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-c68f4e28-c5fc-444e-ace7-f48c442aa66e,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-eb405128-24d0-41f8-b1d5-e32f7fadee56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41135918-172.17.0.2-1597656919955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45640,DS-1e18b4ea-5418-40d4-b9f5-4c907f509221,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-6e1f41d5-2ab7-4bbb-806f-d845e77407b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-4b39cecb-db86-46c4-b630-f07069527e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-48a8eab6-de65-4e25-855b-734a588cff71,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-3d121dfa-fd73-4832-b6a7-2e2ce402e097,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-e378ebab-d67a-4605-8152-8dda3f2e2e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-c68f4e28-c5fc-444e-ace7-f48c442aa66e,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-eb405128-24d0-41f8-b1d5-e32f7fadee56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577653661-172.17.0.2-1597656986060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-f74789f7-5c2a-4b76-ab65-3443a7d73b76,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-7fe9a64e-ff00-4314-b17c-660bafa1a587,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-5dac2eed-9e92-40e4-9d6b-b11e7c56a8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-797b39d8-3bd2-4a9c-83c0-7c6886a947c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-e026aadb-a214-438a-97c5-6895d6df497f,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-4db3d407-1e65-4c36-a2e1-6e26570a86ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-b3ee7946-5921-4366-81a1-890b71e79f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-c90ed1a8-a1ee-4103-a260-2cff2f72870f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577653661-172.17.0.2-1597656986060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-f74789f7-5c2a-4b76-ab65-3443a7d73b76,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-7fe9a64e-ff00-4314-b17c-660bafa1a587,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-5dac2eed-9e92-40e4-9d6b-b11e7c56a8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-797b39d8-3bd2-4a9c-83c0-7c6886a947c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-e026aadb-a214-438a-97c5-6895d6df497f,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-4db3d407-1e65-4c36-a2e1-6e26570a86ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-b3ee7946-5921-4366-81a1-890b71e79f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-c90ed1a8-a1ee-4103-a260-2cff2f72870f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083460547-172.17.0.2-1597657322067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35224,DS-d3adb99e-3db5-45a4-ab02-13e70324a8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-de75c798-f3ac-4f18-b42a-458293cb1eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-f0b99b93-bf64-428f-bdb5-d99de8ff35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-26f0ab17-f1b9-4c34-bd70-48575313418d,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-5bee7694-e8a3-4682-b6f8-0ce7703740b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-6f9c6b76-3cd2-47d1-9632-e30df7031720,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-fc593156-9369-4824-9cc4-f4e5ce131f78,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-e5d2dae4-4366-40ef-8cda-aad0b4441939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083460547-172.17.0.2-1597657322067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35224,DS-d3adb99e-3db5-45a4-ab02-13e70324a8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-de75c798-f3ac-4f18-b42a-458293cb1eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-f0b99b93-bf64-428f-bdb5-d99de8ff35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-26f0ab17-f1b9-4c34-bd70-48575313418d,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-5bee7694-e8a3-4682-b6f8-0ce7703740b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-6f9c6b76-3cd2-47d1-9632-e30df7031720,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-fc593156-9369-4824-9cc4-f4e5ce131f78,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-e5d2dae4-4366-40ef-8cda-aad0b4441939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664951066-172.17.0.2-1597657485789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40138,DS-c0d7b1ba-8bcd-4703-82f2-f157bd7c712a,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-f7df9f99-0a5f-4550-8e9f-125154038dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-de87a17a-df8c-4140-9565-f5d6e5ed8870,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-2ae6e8e7-2f44-48b1-8d95-b0a582bad159,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-8888eebe-5ff7-4704-a55c-cb4a6671bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-0f966734-4896-46c1-9703-11e6b20f0913,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-295f7f31-eb33-4f23-8482-6d59fcc764b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-f2beb60a-0558-4187-a4ed-d7212e3574c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664951066-172.17.0.2-1597657485789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40138,DS-c0d7b1ba-8bcd-4703-82f2-f157bd7c712a,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-f7df9f99-0a5f-4550-8e9f-125154038dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-de87a17a-df8c-4140-9565-f5d6e5ed8870,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-2ae6e8e7-2f44-48b1-8d95-b0a582bad159,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-8888eebe-5ff7-4704-a55c-cb4a6671bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-0f966734-4896-46c1-9703-11e6b20f0913,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-295f7f31-eb33-4f23-8482-6d59fcc764b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-f2beb60a-0558-4187-a4ed-d7212e3574c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811424770-172.17.0.2-1597657633109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41573,DS-fa381585-1ad9-45e2-ab93-91dfcea48fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-c9b35816-f7a1-4b96-9b45-ecfcd387c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-dbd46c78-40b1-4a91-8986-855811bae49a,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-b1bffe05-7a4a-441f-8c41-17761d770d98,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-d3154b36-a4d6-4f00-a205-66c0bc9b105f,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-5f7e28bf-4a91-4cbf-bbaa-922a9c35f0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-a3d482fe-5ac1-4d77-8a7a-197a5ba0b593,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-1598d269-ad17-42c5-9954-68ca1538da56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811424770-172.17.0.2-1597657633109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41573,DS-fa381585-1ad9-45e2-ab93-91dfcea48fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-c9b35816-f7a1-4b96-9b45-ecfcd387c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-dbd46c78-40b1-4a91-8986-855811bae49a,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-b1bffe05-7a4a-441f-8c41-17761d770d98,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-d3154b36-a4d6-4f00-a205-66c0bc9b105f,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-5f7e28bf-4a91-4cbf-bbaa-922a9c35f0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-a3d482fe-5ac1-4d77-8a7a-197a5ba0b593,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-1598d269-ad17-42c5-9954-68ca1538da56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137381714-172.17.0.2-1597658435162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-74bd75c9-d670-4c01-87eb-76a3d83313d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-b4d50965-c431-4074-a147-6478af287200,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-14c7143f-bb35-4e9f-93a4-6024ffb9bcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-d85bce03-eacd-4d72-95e4-19a3d7fffd00,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-14f99c2b-63fa-4bf1-a2cb-ff3d936766a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-8c61da48-af2f-4506-beb8-188ac920401d,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-3bfebadc-4e44-4ec5-b7df-bf29380d7e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-711f7661-c6e9-4946-93ec-a71e60ad5136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137381714-172.17.0.2-1597658435162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34370,DS-74bd75c9-d670-4c01-87eb-76a3d83313d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-b4d50965-c431-4074-a147-6478af287200,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-14c7143f-bb35-4e9f-93a4-6024ffb9bcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-d85bce03-eacd-4d72-95e4-19a3d7fffd00,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-14f99c2b-63fa-4bf1-a2cb-ff3d936766a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-8c61da48-af2f-4506-beb8-188ac920401d,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-3bfebadc-4e44-4ec5-b7df-bf29380d7e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-711f7661-c6e9-4946-93ec-a71e60ad5136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743995163-172.17.0.2-1597658639575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38721,DS-574afb53-fc74-42d9-a1d2-c959516b386c,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-5e07a3e3-1b8b-4c7d-8b21-de207452d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-92de0765-862f-495d-b811-79aa8279e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-936053e8-6408-4950-81ea-4dac859d5fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-d427e064-02c6-4c4f-b05a-e3b6ec382721,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-96cda6c2-ca01-4a29-94ce-18273efa65d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-e77fb069-b2fc-433c-ae59-6715a07b5950,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-8e7b3305-b43b-4755-a0ba-7047a7f05578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743995163-172.17.0.2-1597658639575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38721,DS-574afb53-fc74-42d9-a1d2-c959516b386c,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-5e07a3e3-1b8b-4c7d-8b21-de207452d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-92de0765-862f-495d-b811-79aa8279e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-936053e8-6408-4950-81ea-4dac859d5fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-d427e064-02c6-4c4f-b05a-e3b6ec382721,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-96cda6c2-ca01-4a29-94ce-18273efa65d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-e77fb069-b2fc-433c-ae59-6715a07b5950,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-8e7b3305-b43b-4755-a0ba-7047a7f05578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625275853-172.17.0.2-1597659056251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-d8931d72-f926-42bf-a78f-603eed8066c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-5483eabc-6618-48f9-a3cc-87c2c63bb0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-1bd96192-594a-4981-aaca-295200f6ca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-f2a89e7b-6b61-4510-b80d-c99a378350d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-263ebeb8-a562-48f4-8d4a-a34a9016868b,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-35a5fb60-20c3-4b7c-9627-a22280029a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-0fb9c936-9726-4a7e-993f-142f68caf3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-653ce505-3b1f-4dda-b18a-92bd8ee22626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625275853-172.17.0.2-1597659056251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-d8931d72-f926-42bf-a78f-603eed8066c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-5483eabc-6618-48f9-a3cc-87c2c63bb0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-1bd96192-594a-4981-aaca-295200f6ca5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-f2a89e7b-6b61-4510-b80d-c99a378350d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-263ebeb8-a562-48f4-8d4a-a34a9016868b,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-35a5fb60-20c3-4b7c-9627-a22280029a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-0fb9c936-9726-4a7e-993f-142f68caf3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-653ce505-3b1f-4dda-b18a-92bd8ee22626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5691
