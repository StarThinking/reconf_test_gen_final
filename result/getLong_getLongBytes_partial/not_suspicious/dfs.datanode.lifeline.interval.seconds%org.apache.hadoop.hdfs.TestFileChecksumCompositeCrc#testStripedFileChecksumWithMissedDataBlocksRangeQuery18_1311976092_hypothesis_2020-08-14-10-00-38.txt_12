reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488967549-172.17.0.15-1597399990118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-7bbdaec9-a039-4898-90bc-d9c4f997bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-465af838-9c23-4b5a-bd69-2c1d8c89a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-265e58e0-350e-4cc3-bd0f-c69100fcda2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-b0c567ac-46c0-4458-9228-1dc58a96e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-0b5bc9ca-186a-49d1-9960-63a5ae0a73af,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-5ab916e8-b846-4a42-a195-7324cd56b401,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-6f50f2f5-db25-4817-b967-55a154fa2618,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-35dcd56a-8756-464f-b320-64d20e695857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488967549-172.17.0.15-1597399990118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-7bbdaec9-a039-4898-90bc-d9c4f997bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-465af838-9c23-4b5a-bd69-2c1d8c89a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-265e58e0-350e-4cc3-bd0f-c69100fcda2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-b0c567ac-46c0-4458-9228-1dc58a96e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-0b5bc9ca-186a-49d1-9960-63a5ae0a73af,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-5ab916e8-b846-4a42-a195-7324cd56b401,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-6f50f2f5-db25-4817-b967-55a154fa2618,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-35dcd56a-8756-464f-b320-64d20e695857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051037971-172.17.0.15-1597400063362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-05a673b4-4322-4754-8ad9-a27b60b5546f,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-2f5b85d5-19fe-4000-8023-9827ebad8f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-cd1e6c8e-3917-49ca-b56f-0d31e25b7780,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-c8687855-a511-4f7d-8486-4e68d3be3121,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-c94f408a-67a7-4684-b4c7-dce4b9fb888d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-d7c0eea7-70b5-4b18-8df4-d912ecd82dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-bf11d259-b3a9-41ba-9c23-38c4cf3c05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-4803994f-0ceb-4c9b-9dda-bfc31d13399d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051037971-172.17.0.15-1597400063362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-05a673b4-4322-4754-8ad9-a27b60b5546f,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-2f5b85d5-19fe-4000-8023-9827ebad8f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-cd1e6c8e-3917-49ca-b56f-0d31e25b7780,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-c8687855-a511-4f7d-8486-4e68d3be3121,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-c94f408a-67a7-4684-b4c7-dce4b9fb888d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-d7c0eea7-70b5-4b18-8df4-d912ecd82dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-bf11d259-b3a9-41ba-9c23-38c4cf3c05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-4803994f-0ceb-4c9b-9dda-bfc31d13399d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642181615-172.17.0.15-1597400100361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-d8241280-e84f-4cca-a1d9-51a114bbb194,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-fb10bdd6-03ec-4836-ad60-3b149cd297f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f6ae3c46-7b8d-48ad-9eca-ea7060e9fc39,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-22533170-4484-4566-b435-1551b8aae8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-d86f7978-30cd-45b2-a323-fc04a8a9e404,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-6ee3f798-58ad-482d-8321-8a1b2f610e07,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-8c414e9c-0398-4084-91b8-2603d09b7e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-8ccefef5-64f9-4e5c-b268-1db0bf2a985b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642181615-172.17.0.15-1597400100361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-d8241280-e84f-4cca-a1d9-51a114bbb194,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-fb10bdd6-03ec-4836-ad60-3b149cd297f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f6ae3c46-7b8d-48ad-9eca-ea7060e9fc39,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-22533170-4484-4566-b435-1551b8aae8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-d86f7978-30cd-45b2-a323-fc04a8a9e404,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-6ee3f798-58ad-482d-8321-8a1b2f610e07,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-8c414e9c-0398-4084-91b8-2603d09b7e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-8ccefef5-64f9-4e5c-b268-1db0bf2a985b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119827965-172.17.0.15-1597400496658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-ab0a7cea-cdd5-466e-a3c6-75e59add94db,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-ead1bcb5-9ef0-4dc7-9cc9-ccaaf1c3ae80,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-d112e4c1-48bf-4d67-a6a7-fcb2a48aaa40,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-59bdf867-3657-4f21-8021-736f12f30612,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-5bfe2393-28e8-4e4e-a62c-89e89854a09a,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-45e53f9d-21d4-454d-9d33-b4e29469137c,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-90d7fd3c-e099-44eb-be20-7e91159259f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-9423de1c-2ba9-4865-a652-43c393ee9b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119827965-172.17.0.15-1597400496658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-ab0a7cea-cdd5-466e-a3c6-75e59add94db,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-ead1bcb5-9ef0-4dc7-9cc9-ccaaf1c3ae80,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-d112e4c1-48bf-4d67-a6a7-fcb2a48aaa40,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-59bdf867-3657-4f21-8021-736f12f30612,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-5bfe2393-28e8-4e4e-a62c-89e89854a09a,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-45e53f9d-21d4-454d-9d33-b4e29469137c,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-90d7fd3c-e099-44eb-be20-7e91159259f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-9423de1c-2ba9-4865-a652-43c393ee9b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825850876-172.17.0.15-1597401180492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-8e42716c-f7ca-415f-9946-b0db25e2fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-dc99173b-3873-4947-98f2-9be7e0755693,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-b8a3722a-091e-43e9-afb2-6146217de0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-1a0ef756-abaa-4017-939e-d938f6333c92,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-070d08b2-1ca6-4e98-890a-2ce4a7da21c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-35e51d25-2235-4bcf-bcb0-3a018b3c9c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-f5c3c07f-a2b5-4841-bf5c-8e5f85624124,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-c7e8e96a-e7f9-45d3-96e8-d3169662aeda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825850876-172.17.0.15-1597401180492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-8e42716c-f7ca-415f-9946-b0db25e2fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-dc99173b-3873-4947-98f2-9be7e0755693,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-b8a3722a-091e-43e9-afb2-6146217de0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-1a0ef756-abaa-4017-939e-d938f6333c92,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-070d08b2-1ca6-4e98-890a-2ce4a7da21c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-35e51d25-2235-4bcf-bcb0-3a018b3c9c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-f5c3c07f-a2b5-4841-bf5c-8e5f85624124,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-c7e8e96a-e7f9-45d3-96e8-d3169662aeda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210945663-172.17.0.15-1597401440311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-e0a2e02c-0388-42cf-b04e-f1b1f102166a,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-e7e8c081-2695-402d-a852-e6fae5dea2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-494afd62-cdb0-4481-8c94-6dded4c1024f,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-e3b874b3-bcce-4786-a123-7831801aecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-6398b7ed-c7eb-412f-a7c2-f0d493397e34,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-1b4eee02-bbc3-49cb-8280-3fa68472aa40,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-a4282646-b217-441a-a2b9-90d7ef1f0cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-d6d4cb92-0998-4c52-9862-387bd5feacc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210945663-172.17.0.15-1597401440311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-e0a2e02c-0388-42cf-b04e-f1b1f102166a,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-e7e8c081-2695-402d-a852-e6fae5dea2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-494afd62-cdb0-4481-8c94-6dded4c1024f,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-e3b874b3-bcce-4786-a123-7831801aecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-6398b7ed-c7eb-412f-a7c2-f0d493397e34,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-1b4eee02-bbc3-49cb-8280-3fa68472aa40,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-a4282646-b217-441a-a2b9-90d7ef1f0cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-d6d4cb92-0998-4c52-9862-387bd5feacc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430327433-172.17.0.15-1597401574554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-315e6cfb-2be4-4dbf-a447-9614c8f6ccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-a78fce44-3928-474f-a1f4-4576e75db836,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-202e88f2-bb86-4e44-98c4-9c9f82036668,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-9de5cc51-ac34-45bb-a127-b9cecb69ac30,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-22a8d586-1950-4022-920a-c94e203771ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-00123641-78b2-4d00-b9e4-4f30e4b533c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-afdada35-d614-40da-9c93-1344ef66fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-8448d5f0-9f4f-48cd-b8ff-d65d631ba81c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430327433-172.17.0.15-1597401574554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-315e6cfb-2be4-4dbf-a447-9614c8f6ccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-a78fce44-3928-474f-a1f4-4576e75db836,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-202e88f2-bb86-4e44-98c4-9c9f82036668,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-9de5cc51-ac34-45bb-a127-b9cecb69ac30,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-22a8d586-1950-4022-920a-c94e203771ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-00123641-78b2-4d00-b9e4-4f30e4b533c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-afdada35-d614-40da-9c93-1344ef66fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-8448d5f0-9f4f-48cd-b8ff-d65d631ba81c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686279976-172.17.0.15-1597401760257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41249,DS-34ecf347-b386-4677-87de-f7e9eed6144b,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-ae15ff92-15d3-4e6d-b91d-99751f4492c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-44ab76e4-dcd6-496b-bb0a-3247ff2a723d,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-c7471d0e-35e9-4e40-9046-144ec451685f,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-899e3c8d-d07a-468b-a15d-6b14747bafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-e432ff35-22ea-496a-a21b-dfab79d50052,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-5894859f-2c86-4e42-bf51-50a91255167f,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-8f9f4c07-869f-4d59-8637-af3adb3eff59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686279976-172.17.0.15-1597401760257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41249,DS-34ecf347-b386-4677-87de-f7e9eed6144b,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-ae15ff92-15d3-4e6d-b91d-99751f4492c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-44ab76e4-dcd6-496b-bb0a-3247ff2a723d,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-c7471d0e-35e9-4e40-9046-144ec451685f,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-899e3c8d-d07a-468b-a15d-6b14747bafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-e432ff35-22ea-496a-a21b-dfab79d50052,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-5894859f-2c86-4e42-bf51-50a91255167f,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-8f9f4c07-869f-4d59-8637-af3adb3eff59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310809633-172.17.0.15-1597402539063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-60211abc-de7d-46b2-b4f5-b7c3e8458232,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-4dd9f281-7290-4b7c-a204-1fe80d9e4ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-89cbb7c8-b090-48d1-b9a2-1f46ab67679d,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-28613d05-e69b-4908-9608-888b86f932da,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-b6ec8b7a-156d-4622-9ce1-c3da0be7d73e,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-42b90279-b7c2-4fb6-aeec-f62e7c2f3234,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-6acdfaaa-e6e3-41e0-b519-f51fe00cb340,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-cb1d24ad-f5ae-4a29-bc82-bfb2a6af4c57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310809633-172.17.0.15-1597402539063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-60211abc-de7d-46b2-b4f5-b7c3e8458232,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-4dd9f281-7290-4b7c-a204-1fe80d9e4ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-89cbb7c8-b090-48d1-b9a2-1f46ab67679d,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-28613d05-e69b-4908-9608-888b86f932da,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-b6ec8b7a-156d-4622-9ce1-c3da0be7d73e,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-42b90279-b7c2-4fb6-aeec-f62e7c2f3234,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-6acdfaaa-e6e3-41e0-b519-f51fe00cb340,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-cb1d24ad-f5ae-4a29-bc82-bfb2a6af4c57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998957968-172.17.0.15-1597403017803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-6cf67983-7356-445e-b572-2f34ba1cf635,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5da063bc-42ac-45fd-9180-c8078fa9c5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-b1f5fa69-333f-4737-a76d-23a51b570676,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-efb87bf0-d6ce-4c5a-8260-317d1ae743c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-f22c06fc-e609-48b0-9531-ed589b962fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-81f105af-fb69-4304-93dd-ee5071a3fbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-2b96aeaa-c0bb-4859-8386-eb038352142a,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-31c7bbaa-8d72-4229-bec9-6f02c1765a26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998957968-172.17.0.15-1597403017803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-6cf67983-7356-445e-b572-2f34ba1cf635,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5da063bc-42ac-45fd-9180-c8078fa9c5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-b1f5fa69-333f-4737-a76d-23a51b570676,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-efb87bf0-d6ce-4c5a-8260-317d1ae743c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-f22c06fc-e609-48b0-9531-ed589b962fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-81f105af-fb69-4304-93dd-ee5071a3fbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-2b96aeaa-c0bb-4859-8386-eb038352142a,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-31c7bbaa-8d72-4229-bec9-6f02c1765a26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837879416-172.17.0.15-1597403742208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42712,DS-78ac2a78-a1ae-4a87-810c-ccafd533409f,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-e131de7b-441f-4f77-989a-bdf9b85f5fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-17840457-2c6a-4890-81a1-0c76cd394b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-3cca8460-b9a2-4fbd-b0d2-7fca38564f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-4e20ea86-d19c-4b69-a351-d403c41c5510,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-55d1e3c7-8a94-43b9-88df-bb02ba86e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-5f7a65a4-2ab6-4673-b0c1-7190235709e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-44e00355-6d8a-425a-b0f2-b23841accea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837879416-172.17.0.15-1597403742208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42712,DS-78ac2a78-a1ae-4a87-810c-ccafd533409f,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-e131de7b-441f-4f77-989a-bdf9b85f5fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-17840457-2c6a-4890-81a1-0c76cd394b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-3cca8460-b9a2-4fbd-b0d2-7fca38564f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-4e20ea86-d19c-4b69-a351-d403c41c5510,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-55d1e3c7-8a94-43b9-88df-bb02ba86e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-5f7a65a4-2ab6-4673-b0c1-7190235709e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-44e00355-6d8a-425a-b0f2-b23841accea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193525744-172.17.0.15-1597403859869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-74d9c935-6759-49ed-9d2c-49a3d6a3b554,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-271452fb-3765-40f4-8ba6-e3591636fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-28d099d5-3b06-4ed2-818b-ebb8d923024d,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-918e7605-0494-4d81-9f26-19379c53bab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-71a12b80-99cf-46f2-baee-82ce8c9b3431,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-494d1f8a-3859-46df-9d89-349dcbfb368a,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-73c036cd-89c1-416f-a215-21b2798dd5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-7f41b4be-1c79-48fe-87a2-1298e600e96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193525744-172.17.0.15-1597403859869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-74d9c935-6759-49ed-9d2c-49a3d6a3b554,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-271452fb-3765-40f4-8ba6-e3591636fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-28d099d5-3b06-4ed2-818b-ebb8d923024d,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-918e7605-0494-4d81-9f26-19379c53bab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-71a12b80-99cf-46f2-baee-82ce8c9b3431,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-494d1f8a-3859-46df-9d89-349dcbfb368a,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-73c036cd-89c1-416f-a215-21b2798dd5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-7f41b4be-1c79-48fe-87a2-1298e600e96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5463
