reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000165741-172.17.0.17-1597486739176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34152,DS-cf46199d-59b3-4cb5-bf6a-16d74e20e366,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-bce7ba59-ddea-4cc2-b7ed-083e80c1d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-7fca2652-56f2-4cf1-b1f1-cd7cd12e35ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-37f55040-0727-431f-81cf-f2222105917b,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-a7b08bc7-0807-43ad-8100-7bc4b691c169,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-344372f9-c0f5-409b-8cdb-76d84cc56a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-56df2689-61e4-434a-ae0f-11192f60586f,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-d3de0010-bc73-4a41-b88e-01655d87e522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000165741-172.17.0.17-1597486739176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34152,DS-cf46199d-59b3-4cb5-bf6a-16d74e20e366,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-bce7ba59-ddea-4cc2-b7ed-083e80c1d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-7fca2652-56f2-4cf1-b1f1-cd7cd12e35ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-37f55040-0727-431f-81cf-f2222105917b,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-a7b08bc7-0807-43ad-8100-7bc4b691c169,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-344372f9-c0f5-409b-8cdb-76d84cc56a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-56df2689-61e4-434a-ae0f-11192f60586f,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-d3de0010-bc73-4a41-b88e-01655d87e522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679806245-172.17.0.17-1597487806085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-4f7e247e-8226-4e17-8195-ec4e30325d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-2dad578b-d839-48d4-bef0-95653aec285f,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-4bf1ee11-c126-4ab2-930a-e30ac49082c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-dc23c700-ddff-485b-bea4-6f830a4d3c74,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-1bb34152-39d5-4fcc-93d2-531e44e8abc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-a45b9dcb-c584-465d-bc22-a1c5c6512079,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-c9252180-c8d6-4cdf-b79d-38aac99e16be,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-63acd900-136d-4671-860a-9da42b8047f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679806245-172.17.0.17-1597487806085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-4f7e247e-8226-4e17-8195-ec4e30325d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-2dad578b-d839-48d4-bef0-95653aec285f,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-4bf1ee11-c126-4ab2-930a-e30ac49082c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-dc23c700-ddff-485b-bea4-6f830a4d3c74,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-1bb34152-39d5-4fcc-93d2-531e44e8abc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-a45b9dcb-c584-465d-bc22-a1c5c6512079,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-c9252180-c8d6-4cdf-b79d-38aac99e16be,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-63acd900-136d-4671-860a-9da42b8047f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168744231-172.17.0.17-1597487929810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40531,DS-57be36ea-7261-48bf-9dc8-7795b379920e,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-838c3260-3901-42f2-9493-efc506caed64,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-c9d8036a-0334-4989-8e94-42b21de55f69,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-37b105c6-dd76-4dc3-a291-7115a7773e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-0763e79b-37de-4b9c-8413-c23cc23c6871,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-b1607081-be18-45bb-8ba1-a4cc74ebf42d,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-0416e996-1906-4b31-b611-f7a6583926a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-bfaa8612-63f8-49c7-a73d-709ee68675ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168744231-172.17.0.17-1597487929810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40531,DS-57be36ea-7261-48bf-9dc8-7795b379920e,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-838c3260-3901-42f2-9493-efc506caed64,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-c9d8036a-0334-4989-8e94-42b21de55f69,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-37b105c6-dd76-4dc3-a291-7115a7773e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-0763e79b-37de-4b9c-8413-c23cc23c6871,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-b1607081-be18-45bb-8ba1-a4cc74ebf42d,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-0416e996-1906-4b31-b611-f7a6583926a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-bfaa8612-63f8-49c7-a73d-709ee68675ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602173286-172.17.0.17-1597488111069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-ff6b6bcc-dda0-4556-abc6-848a0e20c1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-0e122c33-cbb9-4108-826a-b04b8f787080,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-5ac7b399-0e36-47a3-9f9f-f8d39c1ef751,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-5a665552-8635-461a-b613-840263936753,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-dae7628d-3039-4ca1-922d-3286caf13759,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-fe51537e-99c4-44c7-a0aa-4c1ca96b7c70,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-7152a0e3-7270-45df-b498-0f4c360c2419,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-1301c991-3a3b-4f25-b2a8-acb859628eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602173286-172.17.0.17-1597488111069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-ff6b6bcc-dda0-4556-abc6-848a0e20c1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-0e122c33-cbb9-4108-826a-b04b8f787080,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-5ac7b399-0e36-47a3-9f9f-f8d39c1ef751,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-5a665552-8635-461a-b613-840263936753,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-dae7628d-3039-4ca1-922d-3286caf13759,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-fe51537e-99c4-44c7-a0aa-4c1ca96b7c70,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-7152a0e3-7270-45df-b498-0f4c360c2419,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-1301c991-3a3b-4f25-b2a8-acb859628eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490345341-172.17.0.17-1597488157004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-db3e1971-e347-410f-b4cd-eb3b07ce0820,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-6145c19c-be2a-4c14-9b55-e06b037af7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-6854bbd1-a190-4627-9cf4-00343846fc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-4bd067b8-f906-429f-8176-801a061356a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-8da9a549-baff-4319-8512-f6ab71738b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-9cfcce4a-b147-4475-a533-179817d4a13c,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-2012ccf3-ca18-4fab-8dcd-0ee17c178bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-f621a49b-53da-4840-adbc-b6d58abae0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490345341-172.17.0.17-1597488157004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-db3e1971-e347-410f-b4cd-eb3b07ce0820,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-6145c19c-be2a-4c14-9b55-e06b037af7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-6854bbd1-a190-4627-9cf4-00343846fc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-4bd067b8-f906-429f-8176-801a061356a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-8da9a549-baff-4319-8512-f6ab71738b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-9cfcce4a-b147-4475-a533-179817d4a13c,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-2012ccf3-ca18-4fab-8dcd-0ee17c178bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-f621a49b-53da-4840-adbc-b6d58abae0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951116501-172.17.0.17-1597488195064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-4cbd777f-b231-49b5-bb64-6c2523348ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-2ad0c017-37e6-4878-8a7f-37eea20a43bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-4cfd1937-28ed-4b45-8dc3-b1fc28d3fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-f1da3a65-8b43-4c9f-83c8-fc45ae474b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-5201b742-0720-488a-89bb-5cabddaf5a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-69421515-75e8-4aad-8eaa-e519a38eff7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-28c7603b-10de-440a-a1c5-0d135c2e03fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-ee2bb45d-2ad9-4fe9-8cb5-c46998629ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951116501-172.17.0.17-1597488195064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-4cbd777f-b231-49b5-bb64-6c2523348ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-2ad0c017-37e6-4878-8a7f-37eea20a43bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-4cfd1937-28ed-4b45-8dc3-b1fc28d3fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-f1da3a65-8b43-4c9f-83c8-fc45ae474b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-5201b742-0720-488a-89bb-5cabddaf5a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-69421515-75e8-4aad-8eaa-e519a38eff7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-28c7603b-10de-440a-a1c5-0d135c2e03fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-ee2bb45d-2ad9-4fe9-8cb5-c46998629ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313489322-172.17.0.17-1597489476960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40166,DS-0d3b64ed-768b-47bb-ac63-dc2a7ff9810e,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-0a0271bd-e2a0-486d-a781-a369af23d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-a1bf11f9-f43a-4697-8b5c-bd88cb2ddeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-aac45dba-7fd6-4cb1-b2e3-5476bfaf4026,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-c5eda8d8-cc3f-4839-85b4-259276aa22d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-397835eb-f2b2-4e6e-bda0-25029e1666da,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-07bbe073-b1fc-4942-85ca-2da7ee0ee529,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-4c418b3f-1fdb-4ed1-9031-f2c39ed965c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313489322-172.17.0.17-1597489476960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40166,DS-0d3b64ed-768b-47bb-ac63-dc2a7ff9810e,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-0a0271bd-e2a0-486d-a781-a369af23d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-a1bf11f9-f43a-4697-8b5c-bd88cb2ddeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-aac45dba-7fd6-4cb1-b2e3-5476bfaf4026,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-c5eda8d8-cc3f-4839-85b4-259276aa22d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-397835eb-f2b2-4e6e-bda0-25029e1666da,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-07bbe073-b1fc-4942-85ca-2da7ee0ee529,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-4c418b3f-1fdb-4ed1-9031-f2c39ed965c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196926738-172.17.0.17-1597489724024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-b15d0d62-c8de-40f7-a444-8cd241cf3209,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-3d8ee404-01dc-4b40-8ffd-4ed8dddafd30,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-79522b72-ac3f-45e9-9540-d5fee89329af,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-02535535-b08d-4b8f-98ca-ced359c33224,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-5d9d8e92-7609-4301-b138-4d842f4921db,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-a3e24d28-476f-41ab-85af-bf5aeb6abe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-112be9bd-db2c-4503-9ad7-53494f843daa,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-806c5166-ef38-4049-9a5e-1c0f67946448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196926738-172.17.0.17-1597489724024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-b15d0d62-c8de-40f7-a444-8cd241cf3209,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-3d8ee404-01dc-4b40-8ffd-4ed8dddafd30,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-79522b72-ac3f-45e9-9540-d5fee89329af,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-02535535-b08d-4b8f-98ca-ced359c33224,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-5d9d8e92-7609-4301-b138-4d842f4921db,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-a3e24d28-476f-41ab-85af-bf5aeb6abe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-112be9bd-db2c-4503-9ad7-53494f843daa,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-806c5166-ef38-4049-9a5e-1c0f67946448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7910565-172.17.0.17-1597490078171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43885,DS-d46ffee3-773e-4294-8410-a1196c90d8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-d8e2826a-3e03-446a-ad8f-fec761c9b5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-3c991910-2e0e-44b1-89f2-4765c8decdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-f2e4bd55-4823-47c3-bf47-45831497f4af,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-ab9744d7-6974-4be4-a4e3-be9ee769a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-5c9bbacc-d81e-49be-acb1-f3512c78a29e,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-795c4227-819c-4104-8501-289dde482ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-49e4dfb8-59f9-429d-8ed2-11cc0f7e9180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7910565-172.17.0.17-1597490078171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43885,DS-d46ffee3-773e-4294-8410-a1196c90d8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-d8e2826a-3e03-446a-ad8f-fec761c9b5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-3c991910-2e0e-44b1-89f2-4765c8decdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-f2e4bd55-4823-47c3-bf47-45831497f4af,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-ab9744d7-6974-4be4-a4e3-be9ee769a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-5c9bbacc-d81e-49be-acb1-f3512c78a29e,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-795c4227-819c-4104-8501-289dde482ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-49e4dfb8-59f9-429d-8ed2-11cc0f7e9180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466933697-172.17.0.17-1597490243594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-bb79d7bc-074b-4cff-aa10-1ba65b7ad18e,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-7fc2a4c0-113b-431e-9945-e2e03d58a871,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-849ccc46-b4c5-454d-b406-31baa0934e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-3f2c58ec-30a2-4217-a509-9e4c77d930a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-4f63b1f6-c1f0-40d6-8fed-7fa0add75015,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-03f7df48-2f3b-4308-b70d-4c9de09b8e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-8082b305-61c7-4f1c-a283-04c5e4e7464b,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-29bb4a1e-b1b5-4248-9b44-00856e263e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466933697-172.17.0.17-1597490243594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-bb79d7bc-074b-4cff-aa10-1ba65b7ad18e,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-7fc2a4c0-113b-431e-9945-e2e03d58a871,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-849ccc46-b4c5-454d-b406-31baa0934e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-3f2c58ec-30a2-4217-a509-9e4c77d930a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-4f63b1f6-c1f0-40d6-8fed-7fa0add75015,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-03f7df48-2f3b-4308-b70d-4c9de09b8e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-8082b305-61c7-4f1c-a283-04c5e4e7464b,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-29bb4a1e-b1b5-4248-9b44-00856e263e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495164-172.17.0.17-1597491280014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42000,DS-e7636836-936f-465b-8d75-e6b5e2740c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-11ccb7e1-9d08-4de4-9735-62da1f35d5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-8c9a349d-f2db-4e4c-8ac2-a40696aad1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-fdb7f060-a652-4a4a-add4-ba196cc22739,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-bf2c0c77-abca-40f7-990f-32838a9fae13,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-985dcd84-85af-4ba6-be27-ed1bbc2039bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-f5317aae-3370-4231-bd64-4a3a7b5c9600,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-299bf83f-7994-4e85-bd92-f54b19e20ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495164-172.17.0.17-1597491280014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42000,DS-e7636836-936f-465b-8d75-e6b5e2740c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-11ccb7e1-9d08-4de4-9735-62da1f35d5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-8c9a349d-f2db-4e4c-8ac2-a40696aad1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-fdb7f060-a652-4a4a-add4-ba196cc22739,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-bf2c0c77-abca-40f7-990f-32838a9fae13,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-985dcd84-85af-4ba6-be27-ed1bbc2039bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-f5317aae-3370-4231-bd64-4a3a7b5c9600,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-299bf83f-7994-4e85-bd92-f54b19e20ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221602213-172.17.0.17-1597491852825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39519,DS-559c7350-4139-4f4a-a580-20153212f524,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-e04e7af9-0ec6-4981-a8d1-94c6357db9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-0d962d5c-85f3-4d78-afc1-43521d7b27be,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-39c18c09-8c90-4998-9a06-60692799b797,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-f7198628-e8b5-45c0-b623-dfeb09e6fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-d7c7161c-8775-4d2b-bd0c-b4749352fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-92501e0d-da0a-4709-b871-6aa6bde28cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-c4f94d86-2199-46a0-a6fc-dafd27d82d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221602213-172.17.0.17-1597491852825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39519,DS-559c7350-4139-4f4a-a580-20153212f524,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-e04e7af9-0ec6-4981-a8d1-94c6357db9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-0d962d5c-85f3-4d78-afc1-43521d7b27be,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-39c18c09-8c90-4998-9a06-60692799b797,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-f7198628-e8b5-45c0-b623-dfeb09e6fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-d7c7161c-8775-4d2b-bd0c-b4749352fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-92501e0d-da0a-4709-b871-6aa6bde28cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-c4f94d86-2199-46a0-a6fc-dafd27d82d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342355106-172.17.0.17-1597492115635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-5e35a653-ca16-429c-ac80-e84e539a859d,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-40ea5149-0c44-430a-a000-94164509197a,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-e0db1380-5e02-4d9e-a103-04bf7da8e5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-a1fa4465-e09e-4f8c-9c86-c5fa70fc87e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-9ac4eaaa-bf74-4f5d-aa95-8ef7d8608c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-67b5de37-dbec-47cf-a0cc-9e362e501acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-c1e55851-6758-49fa-822d-86ba55cd749b,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-a0067fbc-2fa1-4a60-a20d-b57bc0be2bf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342355106-172.17.0.17-1597492115635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-5e35a653-ca16-429c-ac80-e84e539a859d,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-40ea5149-0c44-430a-a000-94164509197a,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-e0db1380-5e02-4d9e-a103-04bf7da8e5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-a1fa4465-e09e-4f8c-9c86-c5fa70fc87e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-9ac4eaaa-bf74-4f5d-aa95-8ef7d8608c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-67b5de37-dbec-47cf-a0cc-9e362e501acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-c1e55851-6758-49fa-822d-86ba55cd749b,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-a0067fbc-2fa1-4a60-a20d-b57bc0be2bf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125813705-172.17.0.17-1597492338402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32968,DS-ffe58035-520e-4de8-9bee-de0824bc26be,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-87f04646-ee63-4ea9-91f7-7bd3c1012da2,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-08036eb0-3a62-48e8-bbdf-fa0cbbc582fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-157335ce-e7ab-4966-8f47-ced7c4efe7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-532ad4e0-d45d-4430-8d88-2f4819f142b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-6cc37585-8f72-4fd1-9d96-a5ea94fb9d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-9c01a414-a6bf-49bb-a19a-a23413fe238c,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-9fb44ade-2e30-439f-9bfc-8c63b71613a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125813705-172.17.0.17-1597492338402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32968,DS-ffe58035-520e-4de8-9bee-de0824bc26be,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-87f04646-ee63-4ea9-91f7-7bd3c1012da2,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-08036eb0-3a62-48e8-bbdf-fa0cbbc582fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-157335ce-e7ab-4966-8f47-ced7c4efe7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-532ad4e0-d45d-4430-8d88-2f4819f142b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-6cc37585-8f72-4fd1-9d96-a5ea94fb9d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-9c01a414-a6bf-49bb-a19a-a23413fe238c,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-9fb44ade-2e30-439f-9bfc-8c63b71613a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827332617-172.17.0.17-1597492456700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38330,DS-5bbede6d-545d-44be-be80-ea8b950bdf43,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-ff9f2c3f-5e42-4472-804d-3837f9fe5041,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-73bb6add-cd97-4ba1-9fbe-ed66a770327d,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-4816e1b3-245d-4b3f-b82d-76c4333e5816,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-4c9cc0e3-f85e-4df4-8a32-e5cd6bde6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-34d99740-70c3-48a9-9dca-46ddccd6b7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-7374c115-57fe-4a95-996b-7b62f2964492,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-cba16a3e-bf61-462f-88a0-478e273fd562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827332617-172.17.0.17-1597492456700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38330,DS-5bbede6d-545d-44be-be80-ea8b950bdf43,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-ff9f2c3f-5e42-4472-804d-3837f9fe5041,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-73bb6add-cd97-4ba1-9fbe-ed66a770327d,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-4816e1b3-245d-4b3f-b82d-76c4333e5816,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-4c9cc0e3-f85e-4df4-8a32-e5cd6bde6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-34d99740-70c3-48a9-9dca-46ddccd6b7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-7374c115-57fe-4a95-996b-7b62f2964492,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-cba16a3e-bf61-462f-88a0-478e273fd562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6501
