reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594269731-172.17.0.5-1597679727614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37461,DS-15575b27-2994-496b-a353-c96d46133e33,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-65f720f9-1e55-4782-941a-1607f15336a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-eba38cf8-35f5-484e-bc69-2f82bc34fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-5da8edcb-889b-47ce-b460-061bc27e23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-c0416cda-0f3c-4d00-a164-4f41e52e076f,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-cddb05d6-29cc-40a6-8c6a-ee2ec79c001d,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-d1bad8e4-758b-441d-9355-30e6f6f50927,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-e89030b7-1194-4799-91fe-8367d57e5c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594269731-172.17.0.5-1597679727614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37461,DS-15575b27-2994-496b-a353-c96d46133e33,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-65f720f9-1e55-4782-941a-1607f15336a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-eba38cf8-35f5-484e-bc69-2f82bc34fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-5da8edcb-889b-47ce-b460-061bc27e23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-c0416cda-0f3c-4d00-a164-4f41e52e076f,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-cddb05d6-29cc-40a6-8c6a-ee2ec79c001d,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-d1bad8e4-758b-441d-9355-30e6f6f50927,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-e89030b7-1194-4799-91fe-8367d57e5c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232785918-172.17.0.5-1597679811171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-65114ded-e540-48a3-80e4-dc619c3cc4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-d78e7c58-67f2-4900-9152-0996b4d402c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-ce09d392-5f8d-49c1-b72d-64d9eac7d21a,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-6bafa1e8-8375-44cc-998c-8a3bc9e90582,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-1e738521-c840-4164-9804-5efd2ba2a744,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-fe0fc109-6c4d-4937-8865-06d39f0c854a,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-3fb3006e-c25b-4cde-8ac0-4e7a46ed17d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-7da05455-360c-4b86-84e1-c450452b8b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232785918-172.17.0.5-1597679811171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-65114ded-e540-48a3-80e4-dc619c3cc4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-d78e7c58-67f2-4900-9152-0996b4d402c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-ce09d392-5f8d-49c1-b72d-64d9eac7d21a,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-6bafa1e8-8375-44cc-998c-8a3bc9e90582,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-1e738521-c840-4164-9804-5efd2ba2a744,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-fe0fc109-6c4d-4937-8865-06d39f0c854a,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-3fb3006e-c25b-4cde-8ac0-4e7a46ed17d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-7da05455-360c-4b86-84e1-c450452b8b7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425265462-172.17.0.5-1597680858192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40894,DS-2fddc49f-4519-4e3c-ae9e-0416c19e71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-854e0581-e5d1-46aa-9f76-1e32166289a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-5ff57a58-422f-4339-84a9-d4c7e9e616b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-1ac2e03b-0ccb-4b6f-9590-e79474b2a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-09c5660d-b69f-46e7-bf27-e62d1e82ffe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-087233f9-eedb-4b81-9ec7-1f04e410e4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-69d85544-1a08-4703-b497-f21664508943,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-0389f0a2-b2b2-436c-9182-97d855400fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425265462-172.17.0.5-1597680858192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40894,DS-2fddc49f-4519-4e3c-ae9e-0416c19e71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-854e0581-e5d1-46aa-9f76-1e32166289a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-5ff57a58-422f-4339-84a9-d4c7e9e616b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-1ac2e03b-0ccb-4b6f-9590-e79474b2a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-09c5660d-b69f-46e7-bf27-e62d1e82ffe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-087233f9-eedb-4b81-9ec7-1f04e410e4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-69d85544-1a08-4703-b497-f21664508943,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-0389f0a2-b2b2-436c-9182-97d855400fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330841169-172.17.0.5-1597681053776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42709,DS-66171a2e-7383-4946-b3b1-4236d64b688c,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-f6e94d6f-c007-4738-8328-46736e51fe96,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-e1675891-e7df-440a-b6dc-e334ea3de6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-ae57be5d-aa2d-41af-a228-5af9d230b976,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-71a4cffc-adef-4437-9706-6759b8e69373,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-d300e767-aba1-4fd7-8c7a-7d92b40ed49d,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-150759c7-e144-40cc-9742-ac4ecc92c51a,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-de41e3db-8481-4c4f-aded-c98e0eb03327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330841169-172.17.0.5-1597681053776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42709,DS-66171a2e-7383-4946-b3b1-4236d64b688c,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-f6e94d6f-c007-4738-8328-46736e51fe96,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-e1675891-e7df-440a-b6dc-e334ea3de6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-ae57be5d-aa2d-41af-a228-5af9d230b976,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-71a4cffc-adef-4437-9706-6759b8e69373,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-d300e767-aba1-4fd7-8c7a-7d92b40ed49d,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-150759c7-e144-40cc-9742-ac4ecc92c51a,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-de41e3db-8481-4c4f-aded-c98e0eb03327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089296107-172.17.0.5-1597681133202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-57af7da3-f690-48bb-8e62-c13fb87ee261,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-b7103cc6-cee8-437b-9eb4-ebead6a59c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-2ce30cab-42ae-4378-ac12-51a1ab03dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-dd379db1-70dc-4ab3-b90b-b9652e496bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-73332214-87da-4f0c-be67-52569672e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-937e4cb9-6b2d-4545-89ee-8da34dcda341,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-de14c640-086c-4548-b8bc-c8899bce480c,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-eb83271c-8893-4a81-ad06-98de9ecf9f26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089296107-172.17.0.5-1597681133202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-57af7da3-f690-48bb-8e62-c13fb87ee261,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-b7103cc6-cee8-437b-9eb4-ebead6a59c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-2ce30cab-42ae-4378-ac12-51a1ab03dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-dd379db1-70dc-4ab3-b90b-b9652e496bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-73332214-87da-4f0c-be67-52569672e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-937e4cb9-6b2d-4545-89ee-8da34dcda341,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-de14c640-086c-4548-b8bc-c8899bce480c,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-eb83271c-8893-4a81-ad06-98de9ecf9f26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53859644-172.17.0.5-1597681341913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43784,DS-4971b27c-284a-46c7-86d1-cf5e70959a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-b1a3ea4d-234f-448e-b728-e7512a014f52,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-b19500d4-a0d1-4bb2-85f3-67c036b426da,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-ad64ea7f-0d18-41cb-b63d-afaa306c00a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-846ebb7a-8f2d-4a7d-bf21-7ece6c17b620,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-7f3a7207-7ae0-4cbf-b5ae-d21e75fcd2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-4e8b45e8-3f00-428f-9286-1d7371051acb,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-e833d0de-cec4-4522-8f48-89c1035c2aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53859644-172.17.0.5-1597681341913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43784,DS-4971b27c-284a-46c7-86d1-cf5e70959a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-b1a3ea4d-234f-448e-b728-e7512a014f52,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-b19500d4-a0d1-4bb2-85f3-67c036b426da,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-ad64ea7f-0d18-41cb-b63d-afaa306c00a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-846ebb7a-8f2d-4a7d-bf21-7ece6c17b620,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-7f3a7207-7ae0-4cbf-b5ae-d21e75fcd2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-4e8b45e8-3f00-428f-9286-1d7371051acb,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-e833d0de-cec4-4522-8f48-89c1035c2aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727309188-172.17.0.5-1597681420903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-6cf9fead-2cd2-4dbd-b533-c8eab941c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-f9b6e6c2-5d9d-4667-baac-7b4ecdd8929e,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-e14ced65-8436-4703-b952-36a4ea217f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-088e7469-5717-4da4-bd92-d3bd5048c130,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-d13a3a7a-bb8b-449a-b33d-c2953fd4c394,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-bd2435aa-19d3-4473-8e00-1baff0aaaa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-c480f398-3b56-4b19-8ebf-86eafdd4098a,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-3e36012a-2120-4a5c-9532-cbda53b09d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727309188-172.17.0.5-1597681420903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-6cf9fead-2cd2-4dbd-b533-c8eab941c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-f9b6e6c2-5d9d-4667-baac-7b4ecdd8929e,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-e14ced65-8436-4703-b952-36a4ea217f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-088e7469-5717-4da4-bd92-d3bd5048c130,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-d13a3a7a-bb8b-449a-b33d-c2953fd4c394,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-bd2435aa-19d3-4473-8e00-1baff0aaaa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-c480f398-3b56-4b19-8ebf-86eafdd4098a,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-3e36012a-2120-4a5c-9532-cbda53b09d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004710240-172.17.0.5-1597681568885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35389,DS-4f242967-ff18-4cd7-98fa-4cf49f2e189a,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-639e6197-4f9d-435b-af90-f2eb287a79ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-674acab2-79e3-4d3f-81d3-d77e72855a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-98ddfce7-ddda-4784-8637-d1ff17d5d507,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-70cf7004-6ad1-4148-aa17-2bb622b11937,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-247d9dcf-ab19-4d6f-9a23-f22f9aac2722,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-fcd5336b-0563-4d1a-89ca-a96f4644e0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-a49dcd05-f8fd-485f-958d-e34e9cd955f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004710240-172.17.0.5-1597681568885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35389,DS-4f242967-ff18-4cd7-98fa-4cf49f2e189a,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-639e6197-4f9d-435b-af90-f2eb287a79ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-674acab2-79e3-4d3f-81d3-d77e72855a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-98ddfce7-ddda-4784-8637-d1ff17d5d507,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-70cf7004-6ad1-4148-aa17-2bb622b11937,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-247d9dcf-ab19-4d6f-9a23-f22f9aac2722,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-fcd5336b-0563-4d1a-89ca-a96f4644e0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-a49dcd05-f8fd-485f-958d-e34e9cd955f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124768579-172.17.0.5-1597681883256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-99f3cc9d-72c5-49ad-b2d0-60ab55689eea,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-23ba741d-55f3-445c-a5ca-2f6ad2b15c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-a52337eb-ba61-4dba-bf16-a1a8455ef1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-54d194d6-1f9f-4f73-9d2a-032579fb82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-ded3f20a-9535-4a63-a40c-e9ebf5e9d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-33b02496-67d1-4b8c-b0ca-8656f7824412,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-5d7e0a94-6d08-41c2-9934-176578791792,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-3eadbd9b-4f50-40ce-979e-a6a74e91b400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124768579-172.17.0.5-1597681883256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-99f3cc9d-72c5-49ad-b2d0-60ab55689eea,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-23ba741d-55f3-445c-a5ca-2f6ad2b15c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-a52337eb-ba61-4dba-bf16-a1a8455ef1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-54d194d6-1f9f-4f73-9d2a-032579fb82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-ded3f20a-9535-4a63-a40c-e9ebf5e9d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-33b02496-67d1-4b8c-b0ca-8656f7824412,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-5d7e0a94-6d08-41c2-9934-176578791792,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-3eadbd9b-4f50-40ce-979e-a6a74e91b400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492590898-172.17.0.5-1597681959238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40200,DS-5c654f36-dc7f-41cb-a2fd-9eca02321d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-0ea8698c-d662-42ac-900b-615102fc94bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-1fdd66e4-d609-4efe-b1a5-f0e31c3bff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-c4608b57-0de1-4dcb-8cca-5132f183179f,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-675d43d1-6bfb-4356-bc81-727d28ec7571,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-c1de2b21-5090-40e2-966a-b04d8a438088,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-fa92049e-9c30-48f2-99f5-44caa4425bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-202bb8e6-1ca4-4e2d-b5a6-a38af08123d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492590898-172.17.0.5-1597681959238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40200,DS-5c654f36-dc7f-41cb-a2fd-9eca02321d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-0ea8698c-d662-42ac-900b-615102fc94bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-1fdd66e4-d609-4efe-b1a5-f0e31c3bff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-c4608b57-0de1-4dcb-8cca-5132f183179f,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-675d43d1-6bfb-4356-bc81-727d28ec7571,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-c1de2b21-5090-40e2-966a-b04d8a438088,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-fa92049e-9c30-48f2-99f5-44caa4425bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-202bb8e6-1ca4-4e2d-b5a6-a38af08123d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439793095-172.17.0.5-1597682004657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35078,DS-8528c95b-f400-4937-9890-9604df5e97bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-2ff2a95a-471d-47e7-b735-0371f266f2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-cdb1a728-1e11-4239-ac80-148f417b9b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-90707f5f-60a9-428e-a02c-6a4d252baee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-b3b6adb9-5eea-44db-a9d2-43496d4f1219,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-ac50833e-02ce-4c60-afe4-8f260c2241a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-81555cb4-8c18-4beb-8d42-f18b812e9274,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-db7fe0de-e62e-46e4-809f-8690315e3b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439793095-172.17.0.5-1597682004657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35078,DS-8528c95b-f400-4937-9890-9604df5e97bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-2ff2a95a-471d-47e7-b735-0371f266f2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-cdb1a728-1e11-4239-ac80-148f417b9b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-90707f5f-60a9-428e-a02c-6a4d252baee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-b3b6adb9-5eea-44db-a9d2-43496d4f1219,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-ac50833e-02ce-4c60-afe4-8f260c2241a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-81555cb4-8c18-4beb-8d42-f18b812e9274,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-db7fe0de-e62e-46e4-809f-8690315e3b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400783118-172.17.0.5-1597682191472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45467,DS-aa7cbbcf-5acc-4b77-905d-025989414eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-e145d520-c708-427e-bf1d-974041333b74,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-c44d7093-f9af-4548-95cb-68db3c5961a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-d7e631a7-50ab-43a2-8030-7dd69ce0de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-a1be09a7-83c8-4f82-ac07-decb3d52a5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-18d92146-89d1-458d-bf87-04b23e46c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-890642c6-4dc8-42f8-894f-0ad898091194,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-efbbaac5-490c-4d9e-949e-43078aa8959d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400783118-172.17.0.5-1597682191472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45467,DS-aa7cbbcf-5acc-4b77-905d-025989414eed,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-e145d520-c708-427e-bf1d-974041333b74,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-c44d7093-f9af-4548-95cb-68db3c5961a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-d7e631a7-50ab-43a2-8030-7dd69ce0de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-a1be09a7-83c8-4f82-ac07-decb3d52a5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-18d92146-89d1-458d-bf87-04b23e46c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-890642c6-4dc8-42f8-894f-0ad898091194,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-efbbaac5-490c-4d9e-949e-43078aa8959d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164947754-172.17.0.5-1597682656474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42921,DS-621f69d1-1c39-486e-a18b-06e17d554550,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-ec7470c6-91ee-428f-aed8-833b5a01efff,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-59fa858a-d70c-4e37-8076-9d30031a7e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-cb3b5170-85e3-4249-a887-efe8da308a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-49915c74-5e49-4d7f-8f93-e9abfecd4fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-8fd4f3cc-64a3-486a-8727-91a3582f43d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-93befa2b-e54a-4453-a483-853376d49e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-fc60b544-8090-47ad-9931-6db52cd8c679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164947754-172.17.0.5-1597682656474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42921,DS-621f69d1-1c39-486e-a18b-06e17d554550,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-ec7470c6-91ee-428f-aed8-833b5a01efff,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-59fa858a-d70c-4e37-8076-9d30031a7e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-cb3b5170-85e3-4249-a887-efe8da308a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-49915c74-5e49-4d7f-8f93-e9abfecd4fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-8fd4f3cc-64a3-486a-8727-91a3582f43d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-93befa2b-e54a-4453-a483-853376d49e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-fc60b544-8090-47ad-9931-6db52cd8c679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537705453-172.17.0.5-1597683137807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37118,DS-9d8fdf6a-ad7a-41e1-aa0c-6bcca07dba55,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-64ff616a-dcf1-482c-9457-bd95464b6066,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-05066350-a348-4f87-bdd0-b9d0648a5b15,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-7d9b3d2f-0d83-4fb2-83e6-56964bb04288,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-319b7241-ff7e-4dea-b47d-9e9a376f5254,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-82b01db3-1037-450d-8bd3-cccfb1f6d897,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-a3dd0ccd-d75a-449d-9733-8b2ba9959e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-849258ca-a7d1-47b9-8d2a-e6403f21d5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537705453-172.17.0.5-1597683137807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37118,DS-9d8fdf6a-ad7a-41e1-aa0c-6bcca07dba55,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-64ff616a-dcf1-482c-9457-bd95464b6066,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-05066350-a348-4f87-bdd0-b9d0648a5b15,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-7d9b3d2f-0d83-4fb2-83e6-56964bb04288,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-319b7241-ff7e-4dea-b47d-9e9a376f5254,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-82b01db3-1037-450d-8bd3-cccfb1f6d897,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-a3dd0ccd-d75a-449d-9733-8b2ba9959e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-849258ca-a7d1-47b9-8d2a-e6403f21d5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785544416-172.17.0.5-1597683694919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34515,DS-d4e6836a-7172-481c-8ae9-e7048a04b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-d0d06737-a089-433c-b9f3-c3dca54a21b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-0d734f2f-0927-4d6c-9c14-88e13be99a26,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-098ef398-df4c-491f-9604-7e008e6191cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-7aa609d6-d433-4029-94f1-980aa4f16152,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-2557b331-7265-4534-986b-490e837cf34e,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-68092028-f1d3-426f-a110-7f59fd5b132c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-b0e0b525-41dd-4666-bf03-387a8aacbcfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785544416-172.17.0.5-1597683694919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34515,DS-d4e6836a-7172-481c-8ae9-e7048a04b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-d0d06737-a089-433c-b9f3-c3dca54a21b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-0d734f2f-0927-4d6c-9c14-88e13be99a26,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-098ef398-df4c-491f-9604-7e008e6191cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-7aa609d6-d433-4029-94f1-980aa4f16152,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-2557b331-7265-4534-986b-490e837cf34e,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-68092028-f1d3-426f-a110-7f59fd5b132c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-b0e0b525-41dd-4666-bf03-387a8aacbcfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951086620-172.17.0.5-1597683859235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-6d873e5b-09ba-41e3-87da-1f54650c2138,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-6cebdb07-d4bb-4424-918b-de2e813ed8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-51255a39-5c7e-4b33-abe6-554d6de95104,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-32446742-2742-45e1-8bf0-a2aadc0b4abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-dfe506ec-1b6c-400c-97c5-62cd4b03b342,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-8f556e1a-25e5-428b-93d1-0014e7624973,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-ef3df0ba-deff-4acd-83f9-aad112dd6bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-6aa4d9f5-afbb-4cc3-9cc9-b35368aa1dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951086620-172.17.0.5-1597683859235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-6d873e5b-09ba-41e3-87da-1f54650c2138,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-6cebdb07-d4bb-4424-918b-de2e813ed8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-51255a39-5c7e-4b33-abe6-554d6de95104,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-32446742-2742-45e1-8bf0-a2aadc0b4abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-dfe506ec-1b6c-400c-97c5-62cd4b03b342,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-8f556e1a-25e5-428b-93d1-0014e7624973,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-ef3df0ba-deff-4acd-83f9-aad112dd6bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-6aa4d9f5-afbb-4cc3-9cc9-b35368aa1dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156275667-172.17.0.5-1597683889906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33411,DS-73ac57d3-0d47-4f27-aa89-0f9e3af586db,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-ef4b7e76-8cf8-4eda-9844-28f4f280dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-e5ac1a0f-4980-4a22-82c0-19c7d5073242,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-068c9c9c-444e-433d-b494-b4bee51dd226,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-02fa57b3-46eb-4dbe-96d9-374aaed12be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-b2d9bc40-b62e-4c54-acaa-9b291039d2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-ae0cc170-0d67-47e6-bc26-bdbe4bd9a633,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-cced5ab6-82cc-4195-91dc-e52a3661951c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156275667-172.17.0.5-1597683889906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33411,DS-73ac57d3-0d47-4f27-aa89-0f9e3af586db,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-ef4b7e76-8cf8-4eda-9844-28f4f280dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-e5ac1a0f-4980-4a22-82c0-19c7d5073242,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-068c9c9c-444e-433d-b494-b4bee51dd226,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-02fa57b3-46eb-4dbe-96d9-374aaed12be4,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-b2d9bc40-b62e-4c54-acaa-9b291039d2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-ae0cc170-0d67-47e6-bc26-bdbe4bd9a633,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-cced5ab6-82cc-4195-91dc-e52a3661951c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208618469-172.17.0.5-1597683933514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38276,DS-b811007f-e589-471e-bc29-e64d0fc0ab71,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-8eeea23b-42aa-4db6-9bcd-ed9e916c9413,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-91747cd2-7dd1-4ed5-bb72-c812c91b5df9,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-f91c1eb9-c1bb-4070-a786-2f4e24f68f21,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-ad8baf2f-1422-45da-b697-96f9d7910fae,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-a4a00cb5-f979-4ca2-a4b0-67c4d42049d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-3ab6a89e-f422-4092-8233-9c2607868c64,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-ee240b11-6db9-4435-8d29-4eba8233f115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208618469-172.17.0.5-1597683933514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38276,DS-b811007f-e589-471e-bc29-e64d0fc0ab71,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-8eeea23b-42aa-4db6-9bcd-ed9e916c9413,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-91747cd2-7dd1-4ed5-bb72-c812c91b5df9,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-f91c1eb9-c1bb-4070-a786-2f4e24f68f21,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-ad8baf2f-1422-45da-b697-96f9d7910fae,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-a4a00cb5-f979-4ca2-a4b0-67c4d42049d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-3ab6a89e-f422-4092-8233-9c2607868c64,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-ee240b11-6db9-4435-8d29-4eba8233f115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 200s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803155021-172.17.0.5-1597684092700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45680,DS-99965123-afee-492a-95cf-b906748d8c82,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-4b80bd25-01ce-4157-a42f-4f00a0a285b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-f42ff7d1-e620-40a0-b169-0902814e5b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-4c1624f9-8e9d-4e6d-a48a-b06e99c20d14,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-e4c366b7-7c03-48e3-826d-d8717473d840,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-31796a4d-a830-4a32-b222-e911e05add52,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-517bc507-d0eb-4086-8177-80b75275c260,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-0fbcb30e-e702-4da8-9293-65a38f9478d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803155021-172.17.0.5-1597684092700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45680,DS-99965123-afee-492a-95cf-b906748d8c82,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-4b80bd25-01ce-4157-a42f-4f00a0a285b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-f42ff7d1-e620-40a0-b169-0902814e5b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-4c1624f9-8e9d-4e6d-a48a-b06e99c20d14,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-e4c366b7-7c03-48e3-826d-d8717473d840,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-31796a4d-a830-4a32-b222-e911e05add52,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-517bc507-d0eb-4086-8177-80b75275c260,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-0fbcb30e-e702-4da8-9293-65a38f9478d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5774
