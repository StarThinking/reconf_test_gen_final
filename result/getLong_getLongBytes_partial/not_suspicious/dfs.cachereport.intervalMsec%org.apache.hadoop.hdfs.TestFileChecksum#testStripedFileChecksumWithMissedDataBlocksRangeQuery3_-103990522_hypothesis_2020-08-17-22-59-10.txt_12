reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562321998-172.17.0.14-1597705524112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43423,DS-5b75c081-6ebe-47a2-ab5d-1a6ca63a8334,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-fdaa9664-dd2f-4875-8529-7368c76f4932,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-4721bada-8eee-4d9a-9c0e-68c6b3f8f241,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-cd62e731-a8ee-4e1f-a91f-8298159c13ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-eb07fc7b-6e8a-4cd9-8025-ceb4f9c3c240,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-06ed0ceb-4acc-4f9d-b942-b4cc3033e855,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-6fbfd40d-f924-427a-8ff4-bcf9f5b775d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-5961ffa5-4008-4251-a250-bb797df49daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562321998-172.17.0.14-1597705524112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43423,DS-5b75c081-6ebe-47a2-ab5d-1a6ca63a8334,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-fdaa9664-dd2f-4875-8529-7368c76f4932,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-4721bada-8eee-4d9a-9c0e-68c6b3f8f241,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-cd62e731-a8ee-4e1f-a91f-8298159c13ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-eb07fc7b-6e8a-4cd9-8025-ceb4f9c3c240,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-06ed0ceb-4acc-4f9d-b942-b4cc3033e855,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-6fbfd40d-f924-427a-8ff4-bcf9f5b775d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-5961ffa5-4008-4251-a250-bb797df49daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616225034-172.17.0.14-1597706516805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46244,DS-5f50c869-d26b-47e3-818d-a1ff9a476eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-5a8f0346-dba0-41f4-aaf4-a5710a6b41b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-d9e24629-ccc9-4d10-9656-d49e952d89ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-1ed70703-63ca-4441-9b0a-374f66b85733,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-6c282d43-7cd9-4ad3-a4af-fbbfe08e50d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-7e571ddd-db7f-4368-95a1-1a9d85a6e9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-95415daf-77f6-45d3-9785-e599c3de22ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-c6438b00-080b-4b26-9572-3d259ec27f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616225034-172.17.0.14-1597706516805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46244,DS-5f50c869-d26b-47e3-818d-a1ff9a476eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-5a8f0346-dba0-41f4-aaf4-a5710a6b41b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-d9e24629-ccc9-4d10-9656-d49e952d89ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-1ed70703-63ca-4441-9b0a-374f66b85733,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-6c282d43-7cd9-4ad3-a4af-fbbfe08e50d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-7e571ddd-db7f-4368-95a1-1a9d85a6e9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-95415daf-77f6-45d3-9785-e599c3de22ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-c6438b00-080b-4b26-9572-3d259ec27f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230505377-172.17.0.14-1597706857695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-90eeafd5-66af-4af8-aea8-e32c3d38c50f,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-33849624-2e91-4643-ac75-f84ca7cd24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-e9ce1c38-df2e-41c3-950d-fb852d21ba87,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-70e4363a-2b1f-402a-90ec-e2c0ad03ed82,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-0ac2817b-b835-4825-a785-b92d5645d3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-1fbf6a74-2ce6-467b-9380-7323145afee2,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-aed36a77-e622-4bd6-b9aa-7e7b36f6ee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-a3bb759d-1389-4910-9f87-ab7401d4073e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230505377-172.17.0.14-1597706857695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-90eeafd5-66af-4af8-aea8-e32c3d38c50f,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-33849624-2e91-4643-ac75-f84ca7cd24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-e9ce1c38-df2e-41c3-950d-fb852d21ba87,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-70e4363a-2b1f-402a-90ec-e2c0ad03ed82,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-0ac2817b-b835-4825-a785-b92d5645d3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-1fbf6a74-2ce6-467b-9380-7323145afee2,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-aed36a77-e622-4bd6-b9aa-7e7b36f6ee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-a3bb759d-1389-4910-9f87-ab7401d4073e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804827890-172.17.0.14-1597706904218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36804,DS-75de08cf-0a52-4f81-a8fe-d4f561e72f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-7e678bed-824d-48d1-a65c-7709bb0ffc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-fa6b3668-8ddd-4806-9710-a5ad60242483,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-01c2b1b8-4754-40ae-b4dd-cccb1334af02,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-bd7b5c58-b1ac-41f8-b7d1-489b7bb5d466,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-6868707f-bbde-4ab3-9d3d-3257493c0e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-b312f087-f211-4eda-9bf3-d4168e5ada69,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-19afa67c-f7e4-4b9a-8f00-fa9dff6a7b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804827890-172.17.0.14-1597706904218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36804,DS-75de08cf-0a52-4f81-a8fe-d4f561e72f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-7e678bed-824d-48d1-a65c-7709bb0ffc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-fa6b3668-8ddd-4806-9710-a5ad60242483,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-01c2b1b8-4754-40ae-b4dd-cccb1334af02,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-bd7b5c58-b1ac-41f8-b7d1-489b7bb5d466,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-6868707f-bbde-4ab3-9d3d-3257493c0e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-b312f087-f211-4eda-9bf3-d4168e5ada69,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-19afa67c-f7e4-4b9a-8f00-fa9dff6a7b71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775891753-172.17.0.14-1597707743678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-edb50952-8392-492c-b800-10af04e7f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-80efbc41-3d6d-419b-8256-8d8c21c01e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-2f1f2133-06ba-451e-8689-365d0cbc61cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-811d9f1b-c4d0-460c-be37-3f18e7f9b786,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-f59e0fbe-e07a-450b-b020-8ba773e553c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-67036d73-cd38-4f6f-90cd-e944a3c7b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-599465ac-59b0-45f7-aee0-9e27f2882422,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-638a6e9a-a27f-4086-9cd5-fb907c003d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775891753-172.17.0.14-1597707743678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36381,DS-edb50952-8392-492c-b800-10af04e7f30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-80efbc41-3d6d-419b-8256-8d8c21c01e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-2f1f2133-06ba-451e-8689-365d0cbc61cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-811d9f1b-c4d0-460c-be37-3f18e7f9b786,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-f59e0fbe-e07a-450b-b020-8ba773e553c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-67036d73-cd38-4f6f-90cd-e944a3c7b9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-599465ac-59b0-45f7-aee0-9e27f2882422,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-638a6e9a-a27f-4086-9cd5-fb907c003d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3911995-172.17.0.14-1597707781296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43149,DS-48104678-bfdf-4cc2-b236-0d6cbf42771d,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-9930c3d8-e627-4510-a9ee-14dd0751aea4,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-d9c83bc9-d300-46aa-bf99-cd410d1271b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-556f7c99-cc85-47d3-bfeb-0f7362505c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-814c467b-940f-4f3a-9c12-bffbf3804fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-f691d3f4-521f-480d-a790-fa8b553f9165,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-ba0036e8-4d61-4fee-94b3-42deedb67114,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-77d6a4d6-bcd8-473c-a951-8d9fe8f2e192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3911995-172.17.0.14-1597707781296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43149,DS-48104678-bfdf-4cc2-b236-0d6cbf42771d,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-9930c3d8-e627-4510-a9ee-14dd0751aea4,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-d9c83bc9-d300-46aa-bf99-cd410d1271b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-556f7c99-cc85-47d3-bfeb-0f7362505c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-814c467b-940f-4f3a-9c12-bffbf3804fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-f691d3f4-521f-480d-a790-fa8b553f9165,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-ba0036e8-4d61-4fee-94b3-42deedb67114,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-77d6a4d6-bcd8-473c-a951-8d9fe8f2e192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297835672-172.17.0.14-1597708340911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-fa97e2be-9fcf-4dea-9e0e-c789f7024828,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-ae6cdb57-5bad-4424-9729-6f4c12b2f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-297e4a67-946c-4e1f-8aee-d63958b39eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-309411d4-d122-4231-bdb2-1affa02561dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-7e22e96b-0d57-48e6-87c1-bc7af99c7221,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-779caa0e-082c-4cd9-8b65-b6fc2b2a12f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-9a5a4ff0-5b2f-444b-8d8a-cc1c5eec57fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-224c6a38-99e6-4f5c-b15b-391fd2d10b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297835672-172.17.0.14-1597708340911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-fa97e2be-9fcf-4dea-9e0e-c789f7024828,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-ae6cdb57-5bad-4424-9729-6f4c12b2f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-297e4a67-946c-4e1f-8aee-d63958b39eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-309411d4-d122-4231-bdb2-1affa02561dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-7e22e96b-0d57-48e6-87c1-bc7af99c7221,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-779caa0e-082c-4cd9-8b65-b6fc2b2a12f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-9a5a4ff0-5b2f-444b-8d8a-cc1c5eec57fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-224c6a38-99e6-4f5c-b15b-391fd2d10b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107576876-172.17.0.14-1597708442503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40422,DS-e0d6a971-dbc3-4a83-a895-223740ea69fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-85cab4f1-ff3c-469a-bd85-52fc37b6371f,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-c9446ba1-2aa7-489c-b0c3-87cd35efc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-c455781d-8666-4e60-bef6-000ba403df81,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-045a641f-a956-4a24-bf13-a5f91d7946e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-cba51471-b2ce-4a3c-a9c7-bc31760972cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-0391590c-e68c-4b0c-aea2-7e9c5ce78328,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-85f4914d-14d0-42eb-a261-e0a56b333cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107576876-172.17.0.14-1597708442503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40422,DS-e0d6a971-dbc3-4a83-a895-223740ea69fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-85cab4f1-ff3c-469a-bd85-52fc37b6371f,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-c9446ba1-2aa7-489c-b0c3-87cd35efc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-c455781d-8666-4e60-bef6-000ba403df81,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-045a641f-a956-4a24-bf13-a5f91d7946e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-cba51471-b2ce-4a3c-a9c7-bc31760972cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-0391590c-e68c-4b0c-aea2-7e9c5ce78328,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-85f4914d-14d0-42eb-a261-e0a56b333cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596364827-172.17.0.14-1597708718160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-2d036c01-0049-42bc-8d40-4efee9dc687e,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-af642a8c-6307-46b8-8633-c10e32c4c912,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-00779a48-3f9c-4911-844b-ce9832b89012,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-eaff43e5-2596-4255-9cb2-999deb2b6e80,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-a9b5460b-1b2c-4e68-8524-ec6ce36cd7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-6c406dc3-2b17-4b99-8822-7f76ad25a509,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-0615aa51-b0e9-4da4-a85d-588e7542e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-3c422e18-d44d-4daf-b420-23631c2d52fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596364827-172.17.0.14-1597708718160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-2d036c01-0049-42bc-8d40-4efee9dc687e,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-af642a8c-6307-46b8-8633-c10e32c4c912,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-00779a48-3f9c-4911-844b-ce9832b89012,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-eaff43e5-2596-4255-9cb2-999deb2b6e80,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-a9b5460b-1b2c-4e68-8524-ec6ce36cd7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-6c406dc3-2b17-4b99-8822-7f76ad25a509,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-0615aa51-b0e9-4da4-a85d-588e7542e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-3c422e18-d44d-4daf-b420-23631c2d52fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600168334-172.17.0.14-1597709383758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46167,DS-2a245763-fa7a-474d-bf8d-1849e12da6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-54e1e14c-9163-4111-8d11-632a0c03a881,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-d256fdb7-1b83-49f7-8f94-0c7f5aa6a055,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-3f93ab69-56c2-4dd3-b521-a74adbc65090,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-d87822c7-4cbf-4c10-a73a-4dc7659a3833,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-8af45624-7b86-4885-bf33-63698888fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-c2cd9bea-2835-4b77-bb69-ab15a332b899,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-ddf1938f-61dc-4dab-848b-adcd8c69294e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600168334-172.17.0.14-1597709383758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46167,DS-2a245763-fa7a-474d-bf8d-1849e12da6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-54e1e14c-9163-4111-8d11-632a0c03a881,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-d256fdb7-1b83-49f7-8f94-0c7f5aa6a055,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-3f93ab69-56c2-4dd3-b521-a74adbc65090,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-d87822c7-4cbf-4c10-a73a-4dc7659a3833,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-8af45624-7b86-4885-bf33-63698888fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-c2cd9bea-2835-4b77-bb69-ab15a332b899,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-ddf1938f-61dc-4dab-848b-adcd8c69294e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214127933-172.17.0.14-1597709663162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-64cb3008-9816-4900-a040-e6c7d13935b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-be7117b6-8aed-41ac-aa26-8c77a78a5265,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-343b2e0b-e9fd-460a-9d27-9a326c25b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-881c6301-f0da-4f20-ac42-f5003bcded9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-230ae64f-2ad3-4bc6-96b4-4b1408025cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-4f8e82a4-c5ce-4ef0-8ef5-a044525dca97,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-bd949133-ffb0-4349-91a4-aedeac73bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-932daaac-0363-4a8d-9210-0c853b544ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214127933-172.17.0.14-1597709663162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-64cb3008-9816-4900-a040-e6c7d13935b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-be7117b6-8aed-41ac-aa26-8c77a78a5265,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-343b2e0b-e9fd-460a-9d27-9a326c25b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-881c6301-f0da-4f20-ac42-f5003bcded9d,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-230ae64f-2ad3-4bc6-96b4-4b1408025cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-4f8e82a4-c5ce-4ef0-8ef5-a044525dca97,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-bd949133-ffb0-4349-91a4-aedeac73bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-932daaac-0363-4a8d-9210-0c853b544ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717704275-172.17.0.14-1597709795254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37172,DS-4529152c-f278-4e1c-87e2-272077967813,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-c5fc3f27-d8fe-4604-bd56-640e18aa5586,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-c94254f4-8d27-4df4-80f4-6a6549310528,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-73af66b7-02a2-4a4c-9ba8-5a1d606d5a82,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-0861ec05-c3a9-4da8-857d-d464c0ee5aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-d72e08c9-fa3d-489a-a045-af91b6ddfbee,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-01b8e400-3253-46a3-834d-40f885f3e607,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-d5262dfc-8a44-4ee4-87ad-1be45b51cc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717704275-172.17.0.14-1597709795254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37172,DS-4529152c-f278-4e1c-87e2-272077967813,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-c5fc3f27-d8fe-4604-bd56-640e18aa5586,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-c94254f4-8d27-4df4-80f4-6a6549310528,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-73af66b7-02a2-4a4c-9ba8-5a1d606d5a82,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-0861ec05-c3a9-4da8-857d-d464c0ee5aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-d72e08c9-fa3d-489a-a045-af91b6ddfbee,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-01b8e400-3253-46a3-834d-40f885f3e607,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-d5262dfc-8a44-4ee4-87ad-1be45b51cc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776190471-172.17.0.14-1597709979063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-fec3c89b-0769-465e-b893-5fd6c25fc027,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-85c3cab8-291e-4951-8c8b-7f86e417fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-8e8e497d-a952-4bb0-9e5e-7b498254beec,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-f5e37669-2dba-4c2d-82a3-57314cf5df12,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-234bb7a3-5f3c-4ed1-a1e3-bcbc169956e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-7d8fcc4f-7b8a-4f0b-90db-b4225e52f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-d66b4f4b-c764-45c5-bb11-4353eb014fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-b62a57bc-3194-45fb-b30f-ca03c569e07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776190471-172.17.0.14-1597709979063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-fec3c89b-0769-465e-b893-5fd6c25fc027,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-85c3cab8-291e-4951-8c8b-7f86e417fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-8e8e497d-a952-4bb0-9e5e-7b498254beec,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-f5e37669-2dba-4c2d-82a3-57314cf5df12,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-234bb7a3-5f3c-4ed1-a1e3-bcbc169956e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-7d8fcc4f-7b8a-4f0b-90db-b4225e52f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-d66b4f4b-c764-45c5-bb11-4353eb014fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-b62a57bc-3194-45fb-b30f-ca03c569e07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022549536-172.17.0.14-1597710179409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-28598034-2b0f-4e57-ae5b-d961143fbe49,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-e91c5849-9d54-4ed1-877a-512ee3a68eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-a53df83a-dd11-4b2e-b024-6a5ef3d0cd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-88cd4efb-0be1-493e-bc6b-e509abf07396,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-ecf05d34-39de-4309-8178-4a8cca8e1fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-edc9ee41-0091-49b0-b270-90db71a06531,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-180b0f49-d0fd-445a-8a58-ca84e9dce940,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-c8d55ba6-0f17-45dc-8410-ebe8a7d580a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022549536-172.17.0.14-1597710179409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-28598034-2b0f-4e57-ae5b-d961143fbe49,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-e91c5849-9d54-4ed1-877a-512ee3a68eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-a53df83a-dd11-4b2e-b024-6a5ef3d0cd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-88cd4efb-0be1-493e-bc6b-e509abf07396,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-ecf05d34-39de-4309-8178-4a8cca8e1fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-edc9ee41-0091-49b0-b270-90db71a06531,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-180b0f49-d0fd-445a-8a58-ca84e9dce940,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-c8d55ba6-0f17-45dc-8410-ebe8a7d580a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653339781-172.17.0.14-1597710407207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-6b2c50fd-390d-45a3-b62e-f30644da9643,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-007c0ab6-c495-4281-9f12-b68df2d1f77a,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-4c8430b7-f45d-4584-934d-1847019f4ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-37ada958-515e-4f1d-8953-1a626a0df192,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-a4bdbb7a-9859-461c-9487-377432c5e39e,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-7a3e9019-7f16-4302-ae79-7a36006a484e,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-ab376117-d325-44f2-be14-b3f18198cbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-bae8e6ba-f971-423a-96eb-698befa51d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653339781-172.17.0.14-1597710407207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-6b2c50fd-390d-45a3-b62e-f30644da9643,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-007c0ab6-c495-4281-9f12-b68df2d1f77a,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-4c8430b7-f45d-4584-934d-1847019f4ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-37ada958-515e-4f1d-8953-1a626a0df192,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-a4bdbb7a-9859-461c-9487-377432c5e39e,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-7a3e9019-7f16-4302-ae79-7a36006a484e,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-ab376117-d325-44f2-be14-b3f18198cbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-bae8e6ba-f971-423a-96eb-698befa51d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681740584-172.17.0.14-1597711079625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42313,DS-7bdb314a-5d16-40cc-a300-9262e9309ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-43875757-19ea-4edd-a4b7-a98f2f1fd457,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-e220f27d-62d3-40b5-ba6e-38822a09c132,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-42881049-d032-4a91-9112-e21fc7f30ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-ada25e99-027a-4978-8adc-707cbc0f50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-1d4b9d2b-cfc4-4b19-a7cc-17408617e0df,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-77a2defb-10d7-4feb-8860-24ee44546db2,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-8604d202-db1d-46c6-8c34-8fd3320cf37c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681740584-172.17.0.14-1597711079625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42313,DS-7bdb314a-5d16-40cc-a300-9262e9309ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-43875757-19ea-4edd-a4b7-a98f2f1fd457,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-e220f27d-62d3-40b5-ba6e-38822a09c132,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-42881049-d032-4a91-9112-e21fc7f30ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-ada25e99-027a-4978-8adc-707cbc0f50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-1d4b9d2b-cfc4-4b19-a7cc-17408617e0df,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-77a2defb-10d7-4feb-8860-24ee44546db2,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-8604d202-db1d-46c6-8c34-8fd3320cf37c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951628902-172.17.0.14-1597711170682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-2e359a80-1121-483e-b21c-6208b13b5aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-cd10dd99-c67a-4f29-9db1-97b761006691,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-a3908511-62af-42c6-b791-553a5cdee12a,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-b09cb84c-3b75-4a79-9482-c7ba6d14bbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-f5c48891-84ee-4c40-8ca4-a3c2ca3786e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-4893be9f-150c-4879-b710-2ef325974d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-9eac762a-bedd-4ab4-aa69-2a5989d2190e,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-d0f5ae5d-a6c9-4b40-8336-f0de5d0af0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951628902-172.17.0.14-1597711170682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-2e359a80-1121-483e-b21c-6208b13b5aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-cd10dd99-c67a-4f29-9db1-97b761006691,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-a3908511-62af-42c6-b791-553a5cdee12a,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-b09cb84c-3b75-4a79-9482-c7ba6d14bbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-f5c48891-84ee-4c40-8ca4-a3c2ca3786e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-4893be9f-150c-4879-b710-2ef325974d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-9eac762a-bedd-4ab4-aa69-2a5989d2190e,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-d0f5ae5d-a6c9-4b40-8336-f0de5d0af0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152707319-172.17.0.14-1597711718817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-724d94e2-ed9d-4080-9db9-7263686145ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-3c9ee586-4d8b-4a1e-b6fa-940a78b6e906,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-4cf6ff2f-12b3-42fa-a527-1061f3d351f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-66ec399e-e084-4efa-a322-05ae070d6c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-6570d9f6-72a0-43b0-a4ab-1527776696b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-a9e44146-0250-43d9-8ebc-8265d16ae4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-1c752d20-bf93-46a0-930e-fb0577349a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-f90f87ed-fe79-40c0-846c-90bb48b510f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152707319-172.17.0.14-1597711718817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-724d94e2-ed9d-4080-9db9-7263686145ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-3c9ee586-4d8b-4a1e-b6fa-940a78b6e906,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-4cf6ff2f-12b3-42fa-a527-1061f3d351f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-66ec399e-e084-4efa-a322-05ae070d6c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-6570d9f6-72a0-43b0-a4ab-1527776696b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-a9e44146-0250-43d9-8ebc-8265d16ae4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-1c752d20-bf93-46a0-930e-fb0577349a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-f90f87ed-fe79-40c0-846c-90bb48b510f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6819
