reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25269155-172.17.0.18-1597372239637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-6a760f0c-7aa1-43f7-beef-2640fcb0b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-88bef077-1cb4-48c5-8501-1f397f755a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-60316ab7-53c1-4e2b-b1f1-5c12d199f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-8174390c-f4d7-4e9c-b801-5c25d3f3fcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-da16b5c8-b7b7-42b8-8b9e-cdde6a5c3cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-9790fea1-50ad-4c94-abff-e5fc51ad0859,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-156da4aa-b3ea-4584-af40-785511e7915b,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-b185f7ce-d3f2-42ae-aec8-bbf3d066d2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25269155-172.17.0.18-1597372239637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-6a760f0c-7aa1-43f7-beef-2640fcb0b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-88bef077-1cb4-48c5-8501-1f397f755a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-60316ab7-53c1-4e2b-b1f1-5c12d199f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-8174390c-f4d7-4e9c-b801-5c25d3f3fcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-da16b5c8-b7b7-42b8-8b9e-cdde6a5c3cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-9790fea1-50ad-4c94-abff-e5fc51ad0859,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-156da4aa-b3ea-4584-af40-785511e7915b,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-b185f7ce-d3f2-42ae-aec8-bbf3d066d2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120632593-172.17.0.18-1597372317704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35085,DS-e9204784-ca02-4267-8c5a-c4186b3bb8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-bb30009a-3ec7-4b72-bf34-a21972de8abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-9294b8cf-b467-4520-8dc7-5be9d2cf9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-51c8a701-2033-4371-93d4-6ed53cb39f85,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-69b52a37-bf1a-4f81-b7d5-8804c879f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-fe5c9a07-f675-4e06-a91c-777940b28b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-eefbea9a-cc1a-46aa-b19b-678c036a99b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-0ab9c240-4f5f-46fe-ba75-28daf84692e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120632593-172.17.0.18-1597372317704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35085,DS-e9204784-ca02-4267-8c5a-c4186b3bb8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-bb30009a-3ec7-4b72-bf34-a21972de8abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-9294b8cf-b467-4520-8dc7-5be9d2cf9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-51c8a701-2033-4371-93d4-6ed53cb39f85,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-69b52a37-bf1a-4f81-b7d5-8804c879f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-fe5c9a07-f675-4e06-a91c-777940b28b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-eefbea9a-cc1a-46aa-b19b-678c036a99b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-0ab9c240-4f5f-46fe-ba75-28daf84692e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940863991-172.17.0.18-1597372425672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-d8d021d6-7922-4c7c-81e4-4cbd3a993c91,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-14ba56be-39b8-421b-8ca9-3c1f80eb0331,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-430d8c62-39f9-4f46-8cc2-8966d8b81735,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-33a0d847-18e0-45a6-ad28-ebb291ff64f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-1aa698d6-2010-46a2-a4d2-d2d0ffd3ccd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-703a9d11-78fd-48d1-89a0-6ae055f77211,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-92fd77d5-f5cb-44b2-bf5c-75ec5d07b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-ea1e9627-7d0c-44c7-86c1-c11351729077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940863991-172.17.0.18-1597372425672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-d8d021d6-7922-4c7c-81e4-4cbd3a993c91,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-14ba56be-39b8-421b-8ca9-3c1f80eb0331,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-430d8c62-39f9-4f46-8cc2-8966d8b81735,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-33a0d847-18e0-45a6-ad28-ebb291ff64f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-1aa698d6-2010-46a2-a4d2-d2d0ffd3ccd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-703a9d11-78fd-48d1-89a0-6ae055f77211,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-92fd77d5-f5cb-44b2-bf5c-75ec5d07b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-ea1e9627-7d0c-44c7-86c1-c11351729077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89878711-172.17.0.18-1597372541296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35738,DS-7ef12179-2627-4568-8059-71ef798e3bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-516ff355-7857-4a80-89c4-ecda62ecc55f,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-2094b136-0f87-4ea5-bbe0-2893e466bf01,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-d501e788-9198-40ee-9087-c38525c5b9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-55a89d45-cf40-4a9d-9f42-1136089ba074,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-77366124-c5ba-49e5-af0e-f2872daabe58,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-87be111c-350e-4166-ab9a-3891b3dc327a,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-b97ae993-01da-4c1f-8b24-c35c6c600927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89878711-172.17.0.18-1597372541296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35738,DS-7ef12179-2627-4568-8059-71ef798e3bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-516ff355-7857-4a80-89c4-ecda62ecc55f,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-2094b136-0f87-4ea5-bbe0-2893e466bf01,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-d501e788-9198-40ee-9087-c38525c5b9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-55a89d45-cf40-4a9d-9f42-1136089ba074,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-77366124-c5ba-49e5-af0e-f2872daabe58,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-87be111c-350e-4166-ab9a-3891b3dc327a,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-b97ae993-01da-4c1f-8b24-c35c6c600927,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620965402-172.17.0.18-1597372690094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43338,DS-ec080a25-246c-4177-bd4d-0f39d72e3fee,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-a3ab4ee2-73e8-4123-8b7a-78324225f8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-515551c0-6151-4f28-9bf3-324ac10b1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-3b783619-4dfa-4b2a-a59b-4fb80e4ceb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-c747baa5-81e3-46c4-9e46-32bd1cbf0b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-f53850ce-4828-45d7-8261-bdc6b4c4469b,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-67d1ba37-747c-41c4-80e3-c94903337c60,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-7fe2268b-3a64-44dc-82d8-4ac2bc87d5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620965402-172.17.0.18-1597372690094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43338,DS-ec080a25-246c-4177-bd4d-0f39d72e3fee,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-a3ab4ee2-73e8-4123-8b7a-78324225f8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-515551c0-6151-4f28-9bf3-324ac10b1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-3b783619-4dfa-4b2a-a59b-4fb80e4ceb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-c747baa5-81e3-46c4-9e46-32bd1cbf0b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-f53850ce-4828-45d7-8261-bdc6b4c4469b,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-67d1ba37-747c-41c4-80e3-c94903337c60,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-7fe2268b-3a64-44dc-82d8-4ac2bc87d5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922711535-172.17.0.18-1597373375269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34653,DS-6cd9316a-be55-40fe-ac51-466f716e0037,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-ef62bed2-8ee8-4482-a080-fbcd39c4d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-d0150bb3-7d82-4e75-92b1-3010780b61f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-ac51fc6f-1cf4-4f40-b64d-5d7f57c16944,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-2245a034-bc55-4750-aa5f-4f84bedfc7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-fa77db7d-9e6f-4090-8ac9-2143866db804,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-df4ac3b9-faa1-4f12-a91d-d994b87706d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-6ec10dcf-d530-4a95-98a0-cade73ced1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922711535-172.17.0.18-1597373375269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34653,DS-6cd9316a-be55-40fe-ac51-466f716e0037,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-ef62bed2-8ee8-4482-a080-fbcd39c4d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-d0150bb3-7d82-4e75-92b1-3010780b61f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-ac51fc6f-1cf4-4f40-b64d-5d7f57c16944,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-2245a034-bc55-4750-aa5f-4f84bedfc7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-fa77db7d-9e6f-4090-8ac9-2143866db804,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-df4ac3b9-faa1-4f12-a91d-d994b87706d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-6ec10dcf-d530-4a95-98a0-cade73ced1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873231618-172.17.0.18-1597374984295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-f724a919-19ad-4252-9cba-839396e03f38,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-90b9b477-6d73-4a53-ae38-dc36673435fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-32a946ab-0129-4869-b794-6a8d99df544f,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-aef200b4-b66e-4f05-afa2-f5910b6c0c42,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-3cbbf55e-9f9b-4109-b004-10dbb0b4895a,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-d3f3e4a9-20ff-4a05-b631-3b4e96ebd5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-1410cc09-f126-42b1-92d4-0b5597aee191,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-9037fba1-c3ec-45d5-8ee0-76e054081758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873231618-172.17.0.18-1597374984295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-f724a919-19ad-4252-9cba-839396e03f38,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-90b9b477-6d73-4a53-ae38-dc36673435fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-32a946ab-0129-4869-b794-6a8d99df544f,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-aef200b4-b66e-4f05-afa2-f5910b6c0c42,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-3cbbf55e-9f9b-4109-b004-10dbb0b4895a,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-d3f3e4a9-20ff-4a05-b631-3b4e96ebd5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-1410cc09-f126-42b1-92d4-0b5597aee191,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-9037fba1-c3ec-45d5-8ee0-76e054081758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202080065-172.17.0.18-1597375170127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46198,DS-6d021527-8221-4d54-ac60-519053aad06e,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-5883f763-48bd-4303-8fb5-9003c3ef2b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-88968c1c-5c11-422f-88a0-1dd529755fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-ebbeae49-9d05-4516-8915-e261b274d46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-ee54a8a7-c593-4de7-8e9b-99ba43839016,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-7cd0795c-7561-4918-b3fa-c9be47b4162a,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-73a7b5b4-f7da-421b-af65-c3c2ba8e1058,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-c5e0574f-9ca7-4f50-bd32-de8de9c53842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202080065-172.17.0.18-1597375170127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46198,DS-6d021527-8221-4d54-ac60-519053aad06e,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-5883f763-48bd-4303-8fb5-9003c3ef2b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-88968c1c-5c11-422f-88a0-1dd529755fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-ebbeae49-9d05-4516-8915-e261b274d46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-ee54a8a7-c593-4de7-8e9b-99ba43839016,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-7cd0795c-7561-4918-b3fa-c9be47b4162a,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-73a7b5b4-f7da-421b-af65-c3c2ba8e1058,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-c5e0574f-9ca7-4f50-bd32-de8de9c53842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283867532-172.17.0.18-1597375353762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-fe90a80f-f2c0-41f0-b5ff-6961cb16c4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b1f5a690-becf-4759-a91b-dfe7b3cb3fac,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-cacbdf3b-be74-4637-a6ac-3d493eb323ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-db8dc553-68c5-432a-b03d-4e21156e2213,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-2340cea4-f06f-440f-84a6-1ef08334df12,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-b71b88d4-80b5-461d-b03b-69758bb4a716,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-c6deffa3-78fc-44e7-9c81-3dfe6a37ea28,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-59a2c7c7-3b87-46f4-ae62-44a399e0949b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283867532-172.17.0.18-1597375353762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-fe90a80f-f2c0-41f0-b5ff-6961cb16c4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b1f5a690-becf-4759-a91b-dfe7b3cb3fac,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-cacbdf3b-be74-4637-a6ac-3d493eb323ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-db8dc553-68c5-432a-b03d-4e21156e2213,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-2340cea4-f06f-440f-84a6-1ef08334df12,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-b71b88d4-80b5-461d-b03b-69758bb4a716,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-c6deffa3-78fc-44e7-9c81-3dfe6a37ea28,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-59a2c7c7-3b87-46f4-ae62-44a399e0949b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891023979-172.17.0.18-1597375683936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44215,DS-1d72de40-7837-4348-8850-89b8909b595a,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-a2e09b59-f68c-4aab-8edc-3394cd8b3514,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-ebfd3172-d5d1-4d24-ba21-87d3ebdb5213,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-2c198604-9703-4b2e-85ee-ba16d87b011a,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-d2fee9d0-7468-4122-bb7a-38e8ad6e2ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-0b2171e9-45fd-45bf-be8a-4977ab0061b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-809f39bd-ff21-4a02-8a52-64f48e8f19a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-7a836cb2-f978-4db6-a376-152630a0c963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891023979-172.17.0.18-1597375683936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44215,DS-1d72de40-7837-4348-8850-89b8909b595a,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-a2e09b59-f68c-4aab-8edc-3394cd8b3514,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-ebfd3172-d5d1-4d24-ba21-87d3ebdb5213,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-2c198604-9703-4b2e-85ee-ba16d87b011a,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-d2fee9d0-7468-4122-bb7a-38e8ad6e2ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-0b2171e9-45fd-45bf-be8a-4977ab0061b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-809f39bd-ff21-4a02-8a52-64f48e8f19a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-7a836cb2-f978-4db6-a376-152630a0c963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257615746-172.17.0.18-1597375929812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38145,DS-35d4e9a9-374b-46f1-b678-9faeab878e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-3f468068-2591-477a-8913-dacfe5c6be80,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-f78e3a95-cb0e-46e1-bc52-adc2bf90a757,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-8c79c625-c576-4814-9ff2-ef6f0896473c,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-d7a6a21f-9dee-4233-a455-39b2a0083d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-d3c97f86-38cb-49a5-a3b8-8fb38161ced4,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-523ed67b-0c42-42c1-9044-4cb36f326105,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-b4f836e3-4b83-4dbd-b8f1-6a2c04865757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257615746-172.17.0.18-1597375929812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38145,DS-35d4e9a9-374b-46f1-b678-9faeab878e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-3f468068-2591-477a-8913-dacfe5c6be80,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-f78e3a95-cb0e-46e1-bc52-adc2bf90a757,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-8c79c625-c576-4814-9ff2-ef6f0896473c,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-d7a6a21f-9dee-4233-a455-39b2a0083d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-d3c97f86-38cb-49a5-a3b8-8fb38161ced4,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-523ed67b-0c42-42c1-9044-4cb36f326105,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-b4f836e3-4b83-4dbd-b8f1-6a2c04865757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213516095-172.17.0.18-1597376365776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41481,DS-c7e0c0fa-fbfc-4acb-812b-5186eb23d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-4adbf890-2f48-42da-b384-3219cb3e278f,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-2baff58f-809c-4321-b22d-946fbcf2fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-a7a2592a-f6f8-47ef-aabb-b49825c29d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-39412afb-aba3-411a-8fd1-e7dad969cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-1997b54b-bc64-4cae-adfe-d27522eb532e,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-870924c6-84ee-4124-9962-cfe98ee6749d,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-e458662a-e14b-4932-bbde-e4c2fd87a07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213516095-172.17.0.18-1597376365776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41481,DS-c7e0c0fa-fbfc-4acb-812b-5186eb23d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-4adbf890-2f48-42da-b384-3219cb3e278f,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-2baff58f-809c-4321-b22d-946fbcf2fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-a7a2592a-f6f8-47ef-aabb-b49825c29d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-39412afb-aba3-411a-8fd1-e7dad969cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-1997b54b-bc64-4cae-adfe-d27522eb532e,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-870924c6-84ee-4124-9962-cfe98ee6749d,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-e458662a-e14b-4932-bbde-e4c2fd87a07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982040748-172.17.0.18-1597376401866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-4cc93192-b992-4b44-b6c2-c97d56c0e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-ee4c8ebf-1bcc-45a9-b757-73b2b2aa47d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-f57aa14c-25be-4ca5-ba3b-3aae62931bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-c41e4003-7630-4f7a-9bd1-1262d8f68702,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-77f77d5c-57c8-4d17-901b-6130630a5001,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-dc8a0ece-cb0b-49c6-90e2-f40faebfc63f,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-2fe4f64b-6997-4d21-a2ef-65597f2d7726,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-ba4215e8-6f64-4371-a573-2fba44fb3d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982040748-172.17.0.18-1597376401866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-4cc93192-b992-4b44-b6c2-c97d56c0e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-ee4c8ebf-1bcc-45a9-b757-73b2b2aa47d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-f57aa14c-25be-4ca5-ba3b-3aae62931bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-c41e4003-7630-4f7a-9bd1-1262d8f68702,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-77f77d5c-57c8-4d17-901b-6130630a5001,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-dc8a0ece-cb0b-49c6-90e2-f40faebfc63f,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-2fe4f64b-6997-4d21-a2ef-65597f2d7726,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-ba4215e8-6f64-4371-a573-2fba44fb3d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688315715-172.17.0.18-1597376984531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-bcf9eaba-4862-4e17-bc9c-49cc59ffacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-501f0751-9b1a-4deb-bdc9-1ea9374cfe60,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-3940f0cf-5724-4c22-9a37-902db120c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-ccd961b3-73d0-4dd3-bca1-aa206aa2ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-f000390a-74a4-4cf8-996a-ff39a912d3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-a4474bd3-5a05-4083-a682-ac05a9d554f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-b4c13185-00c1-4a88-8fb0-130da0c047b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-07425991-8b46-4c8b-8462-c532ffe8f242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688315715-172.17.0.18-1597376984531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-bcf9eaba-4862-4e17-bc9c-49cc59ffacc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-501f0751-9b1a-4deb-bdc9-1ea9374cfe60,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-3940f0cf-5724-4c22-9a37-902db120c4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-ccd961b3-73d0-4dd3-bca1-aa206aa2ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-f000390a-74a4-4cf8-996a-ff39a912d3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-a4474bd3-5a05-4083-a682-ac05a9d554f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-b4c13185-00c1-4a88-8fb0-130da0c047b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-07425991-8b46-4c8b-8462-c532ffe8f242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74425435-172.17.0.18-1597377261601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-511db0fa-937e-4991-a91c-19ab9ff961fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-cbb243ae-42b3-45f4-a80e-7d8d55309793,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-e5601dd0-be2e-49d7-bbfd-871eb999c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-6f8ba649-597a-41d9-984b-a7b673838b12,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-dce7a2c6-80d6-4bc2-a0bc-45487d7eaacc,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-a29189ec-866c-4a00-918c-e89d44474e06,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-98bd2e7b-ab89-449a-9054-0cb2a384ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-cbd419cd-1435-4cee-b288-1a19c4d6dcbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74425435-172.17.0.18-1597377261601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-511db0fa-937e-4991-a91c-19ab9ff961fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-cbb243ae-42b3-45f4-a80e-7d8d55309793,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-e5601dd0-be2e-49d7-bbfd-871eb999c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-6f8ba649-597a-41d9-984b-a7b673838b12,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-dce7a2c6-80d6-4bc2-a0bc-45487d7eaacc,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-a29189ec-866c-4a00-918c-e89d44474e06,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-98bd2e7b-ab89-449a-9054-0cb2a384ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-cbd419cd-1435-4cee-b288-1a19c4d6dcbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5516
