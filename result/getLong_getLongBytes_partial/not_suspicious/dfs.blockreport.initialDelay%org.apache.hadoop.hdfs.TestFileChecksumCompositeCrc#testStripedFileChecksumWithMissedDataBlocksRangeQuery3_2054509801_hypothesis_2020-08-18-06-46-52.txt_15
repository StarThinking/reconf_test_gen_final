reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061033769-172.17.0.18-1597733604741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40767,DS-8b541349-0aa4-4a8a-9a6f-78a776be4b89,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-684b416e-be5d-4f4f-bc7c-3d6ce419870c,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-fcd77a48-860e-4502-a60b-80fe422b1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-7f25028e-3080-4742-b584-f27c2aae7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-c0a785a9-2d53-4ea0-9854-578f3c0f981d,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-242c6f79-7f64-40ef-b404-319779f18fad,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-07321a54-32f8-48d7-b6b8-4ea287ed988f,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-2d33c2c4-dcdd-41a4-a011-c0e7e0ea9b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061033769-172.17.0.18-1597733604741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40767,DS-8b541349-0aa4-4a8a-9a6f-78a776be4b89,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-684b416e-be5d-4f4f-bc7c-3d6ce419870c,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-fcd77a48-860e-4502-a60b-80fe422b1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-7f25028e-3080-4742-b584-f27c2aae7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-c0a785a9-2d53-4ea0-9854-578f3c0f981d,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-242c6f79-7f64-40ef-b404-319779f18fad,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-07321a54-32f8-48d7-b6b8-4ea287ed988f,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-2d33c2c4-dcdd-41a4-a011-c0e7e0ea9b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090823048-172.17.0.18-1597733764444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34141,DS-2b2c2e6e-ca43-4fc8-8e29-7a91634424a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-7a93d38d-4f94-4ca0-89d5-756adb778c96,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-9453bb04-d084-4f73-86dd-4e436bbda640,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-be622360-f2c0-4982-9566-5f87d4658ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-e0114034-97ad-4629-91bb-e4fb9a204f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-3dbcb0e0-c818-47ed-b7a1-4f849cf16549,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-57f51727-602c-484e-b061-f849e806ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-bfad0baa-939b-4728-aa89-e08a5a143ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090823048-172.17.0.18-1597733764444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34141,DS-2b2c2e6e-ca43-4fc8-8e29-7a91634424a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-7a93d38d-4f94-4ca0-89d5-756adb778c96,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-9453bb04-d084-4f73-86dd-4e436bbda640,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-be622360-f2c0-4982-9566-5f87d4658ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-e0114034-97ad-4629-91bb-e4fb9a204f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-3dbcb0e0-c818-47ed-b7a1-4f849cf16549,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-57f51727-602c-484e-b061-f849e806ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-bfad0baa-939b-4728-aa89-e08a5a143ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036173097-172.17.0.18-1597734133074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-6733f544-0c86-4ae2-8cc2-157015a5f8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-ff3ea455-9082-4963-b6e2-1b74e32f4e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-88406698-2210-4aa3-beee-a45ef27dbb95,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-f864c7ce-d037-4090-be5e-80db437f307e,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-2a227eb4-5c28-4ff4-bba9-c6a314b1790f,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-324f99c6-ecd6-4f6d-bbb2-7b365b97118d,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-166e46d4-42f1-4cc8-ac8c-281354514c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-d4a54d9e-eea1-4c3f-a499-3451d7ececee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036173097-172.17.0.18-1597734133074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-6733f544-0c86-4ae2-8cc2-157015a5f8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-ff3ea455-9082-4963-b6e2-1b74e32f4e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-88406698-2210-4aa3-beee-a45ef27dbb95,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-f864c7ce-d037-4090-be5e-80db437f307e,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-2a227eb4-5c28-4ff4-bba9-c6a314b1790f,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-324f99c6-ecd6-4f6d-bbb2-7b365b97118d,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-166e46d4-42f1-4cc8-ac8c-281354514c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-d4a54d9e-eea1-4c3f-a499-3451d7ececee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616513285-172.17.0.18-1597734570174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42809,DS-5ee8bda0-cc28-44f4-8027-ff1a942ef461,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-453ae3fe-4a06-45e3-82fe-dfd3110fbdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-765c01bc-6d93-4817-801b-ad7dd5440c61,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-902ff78f-7e64-4401-a407-c286cd9ee91f,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-bcb6575d-0434-4b56-990d-23ae9dc00c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-138d6e2b-6725-4449-a757-6dd45bec5529,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-bc76b815-8523-470d-9a3c-6a74e4b1e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-faa34c80-892c-4230-a9da-b4aa8e7193ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616513285-172.17.0.18-1597734570174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42809,DS-5ee8bda0-cc28-44f4-8027-ff1a942ef461,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-453ae3fe-4a06-45e3-82fe-dfd3110fbdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-765c01bc-6d93-4817-801b-ad7dd5440c61,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-902ff78f-7e64-4401-a407-c286cd9ee91f,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-bcb6575d-0434-4b56-990d-23ae9dc00c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-138d6e2b-6725-4449-a757-6dd45bec5529,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-bc76b815-8523-470d-9a3c-6a74e4b1e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-faa34c80-892c-4230-a9da-b4aa8e7193ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575084690-172.17.0.18-1597735188360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42358,DS-08dcde79-26b1-461d-abc0-850de7638f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-2ac31010-2e14-4ff3-ba0d-5b4e25aa89b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-d36049f2-01d2-40a0-9ddf-08692aa79762,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-0c7095b0-cf56-42bb-9bc4-8f003c02a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-d6283944-e725-4ba6-8c7a-84b82baa3da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-8c3d3225-ee88-42df-a166-297af8e22072,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-9dd0555d-f601-4db5-b0fa-a12bb33c9018,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-aec7ed30-8869-48c9-befe-ad3a1b6c790e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575084690-172.17.0.18-1597735188360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42358,DS-08dcde79-26b1-461d-abc0-850de7638f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-2ac31010-2e14-4ff3-ba0d-5b4e25aa89b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-d36049f2-01d2-40a0-9ddf-08692aa79762,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-0c7095b0-cf56-42bb-9bc4-8f003c02a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-d6283944-e725-4ba6-8c7a-84b82baa3da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-8c3d3225-ee88-42df-a166-297af8e22072,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-9dd0555d-f601-4db5-b0fa-a12bb33c9018,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-aec7ed30-8869-48c9-befe-ad3a1b6c790e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393336791-172.17.0.18-1597735515938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39886,DS-a2a311aa-7982-471d-a2ac-fe4fe92b0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-032d1f42-5816-471c-9385-2393d0bafba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-6be632f8-6487-46b8-afe8-10d96a5fd784,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-db2c6b90-4e24-468c-bb1d-12c81f66aa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-45fb1de0-40b8-4cfc-ab59-201443f4ac96,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-770d36d3-43a8-4e67-827c-b76405c75a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-a10f6de9-c3d4-4fac-9c8c-a7f4f5e586a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-c2db3fa9-72de-4a70-98b2-3f6e29e96d0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393336791-172.17.0.18-1597735515938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39886,DS-a2a311aa-7982-471d-a2ac-fe4fe92b0b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-032d1f42-5816-471c-9385-2393d0bafba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-6be632f8-6487-46b8-afe8-10d96a5fd784,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-db2c6b90-4e24-468c-bb1d-12c81f66aa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-45fb1de0-40b8-4cfc-ab59-201443f4ac96,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-770d36d3-43a8-4e67-827c-b76405c75a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-a10f6de9-c3d4-4fac-9c8c-a7f4f5e586a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-c2db3fa9-72de-4a70-98b2-3f6e29e96d0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862880815-172.17.0.18-1597735705401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-f57fa263-3c08-47a3-9fbe-8d0172889626,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-d7b6e379-1ac2-426d-954a-d056c878ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-934c2e86-e611-42f3-887f-74439f7433bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-cc7666a0-da6a-46a2-9ed7-9154fa041553,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-addf2395-d96f-4602-9cad-465bcabc9b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-797af3e5-7db4-49f8-889a-6b1fe4dd78da,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-a0eee315-3234-410c-999c-458133414daf,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-b5b469a6-f274-41c0-9d0b-9eb318080d26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862880815-172.17.0.18-1597735705401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-f57fa263-3c08-47a3-9fbe-8d0172889626,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-d7b6e379-1ac2-426d-954a-d056c878ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-934c2e86-e611-42f3-887f-74439f7433bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-cc7666a0-da6a-46a2-9ed7-9154fa041553,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-addf2395-d96f-4602-9cad-465bcabc9b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-797af3e5-7db4-49f8-889a-6b1fe4dd78da,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-a0eee315-3234-410c-999c-458133414daf,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-b5b469a6-f274-41c0-9d0b-9eb318080d26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707315966-172.17.0.18-1597737767559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-4a394e20-a340-4d0a-9d65-cf210325390a,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-ac15128b-4152-4bf8-85ab-74ae936fd2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-a03f6f14-a204-4ee7-9352-ed53f12844a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-4883468b-4101-4fd6-a1e5-dad7bb28a7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-5e2069c7-f3db-47f4-9489-7f85fa6753dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-90fdee6a-e6a9-42b0-a65d-f39f5b78a4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-31cef0cd-fc93-4a07-b138-ac3aca9dd833,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-f9f661a0-15ec-4498-8e48-11365145ed64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707315966-172.17.0.18-1597737767559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36473,DS-4a394e20-a340-4d0a-9d65-cf210325390a,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-ac15128b-4152-4bf8-85ab-74ae936fd2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-a03f6f14-a204-4ee7-9352-ed53f12844a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-4883468b-4101-4fd6-a1e5-dad7bb28a7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-5e2069c7-f3db-47f4-9489-7f85fa6753dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-90fdee6a-e6a9-42b0-a65d-f39f5b78a4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-31cef0cd-fc93-4a07-b138-ac3aca9dd833,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-f9f661a0-15ec-4498-8e48-11365145ed64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853366799-172.17.0.18-1597738156747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-44dfd7aa-cea6-468e-bde8-7e09b320062d,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-492e0e59-3f5d-4610-a9fb-19ec5449f20e,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-1615b181-9e1d-42e7-afb3-ebec38de0f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-75dec58e-4a7c-4e94-8f2c-690ea2b5211f,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-bfed55c5-4398-4884-9f26-3a9889c657a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-64048b84-6e6f-48a5-9057-afb1ed8df788,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-a74654f1-12ec-4dad-bab2-ac9a03fb8e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-3c3faa00-35e9-4d03-b918-cdd284fa9f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853366799-172.17.0.18-1597738156747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-44dfd7aa-cea6-468e-bde8-7e09b320062d,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-492e0e59-3f5d-4610-a9fb-19ec5449f20e,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-1615b181-9e1d-42e7-afb3-ebec38de0f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-75dec58e-4a7c-4e94-8f2c-690ea2b5211f,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-bfed55c5-4398-4884-9f26-3a9889c657a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-64048b84-6e6f-48a5-9057-afb1ed8df788,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-a74654f1-12ec-4dad-bab2-ac9a03fb8e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-3c3faa00-35e9-4d03-b918-cdd284fa9f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318021579-172.17.0.18-1597738487580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-acc711ed-0524-4fd3-a505-07e05f71c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-0f8dd6b1-aef5-4331-aec3-37687997a91c,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-1d045c51-da15-4464-a76e-09c394ff265b,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-df9eca61-4490-406b-b68e-394ef3440f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-9238c778-c2fc-414b-876d-2ad79cef2e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-c8ad2f01-d021-4d9c-a75e-5365c31dd074,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-f6948797-3fbc-4785-b6ca-286f4b539183,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-0e2bc203-bc3a-44f9-af83-cfbbf1c0d447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318021579-172.17.0.18-1597738487580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-acc711ed-0524-4fd3-a505-07e05f71c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-0f8dd6b1-aef5-4331-aec3-37687997a91c,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-1d045c51-da15-4464-a76e-09c394ff265b,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-df9eca61-4490-406b-b68e-394ef3440f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-9238c778-c2fc-414b-876d-2ad79cef2e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-c8ad2f01-d021-4d9c-a75e-5365c31dd074,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-f6948797-3fbc-4785-b6ca-286f4b539183,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-0e2bc203-bc3a-44f9-af83-cfbbf1c0d447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314449084-172.17.0.18-1597738521266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36629,DS-237b8a87-9a82-4623-946c-5dc9a2968cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-d7de71c4-8cd6-4716-b416-b3e4c122cd52,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-a8d5d6bf-1408-4cf0-a895-a396fd3740dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-5b93c47b-19be-4093-9e11-191eddad279e,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-f6579ff9-db15-41d7-8c51-107660ce055f,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1c221e24-f4c9-45ff-bb0d-5eb0d7d639bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-4dd43f3c-325e-4135-ac66-89fd05fd7c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-b0415c2d-9013-41a9-a7cf-90bebdb9bfe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314449084-172.17.0.18-1597738521266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36629,DS-237b8a87-9a82-4623-946c-5dc9a2968cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-d7de71c4-8cd6-4716-b416-b3e4c122cd52,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-a8d5d6bf-1408-4cf0-a895-a396fd3740dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-5b93c47b-19be-4093-9e11-191eddad279e,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-f6579ff9-db15-41d7-8c51-107660ce055f,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1c221e24-f4c9-45ff-bb0d-5eb0d7d639bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-4dd43f3c-325e-4135-ac66-89fd05fd7c88,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-b0415c2d-9013-41a9-a7cf-90bebdb9bfe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394572498-172.17.0.18-1597738643036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-f8ed6467-66b2-4c09-901e-09d9f0db86d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-d9bd0321-95a6-4281-9525-9a2954c9d99e,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-e0fad172-3ceb-4e6e-b72b-b11a24cc2f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-9b524437-d0cc-43c7-bdc3-b2cd56bc1f92,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-e1b0d492-b675-4528-accc-1b4a2aa41ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-ddcc60b0-9058-4297-9dc9-0ee7f0b36d51,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-f80b1fca-d190-4262-b472-3209c164096d,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-44689add-ecd2-4872-9598-02c5a47737c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394572498-172.17.0.18-1597738643036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-f8ed6467-66b2-4c09-901e-09d9f0db86d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-d9bd0321-95a6-4281-9525-9a2954c9d99e,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-e0fad172-3ceb-4e6e-b72b-b11a24cc2f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-9b524437-d0cc-43c7-bdc3-b2cd56bc1f92,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-e1b0d492-b675-4528-accc-1b4a2aa41ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-ddcc60b0-9058-4297-9dc9-0ee7f0b36d51,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-f80b1fca-d190-4262-b472-3209c164096d,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-44689add-ecd2-4872-9598-02c5a47737c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5765
