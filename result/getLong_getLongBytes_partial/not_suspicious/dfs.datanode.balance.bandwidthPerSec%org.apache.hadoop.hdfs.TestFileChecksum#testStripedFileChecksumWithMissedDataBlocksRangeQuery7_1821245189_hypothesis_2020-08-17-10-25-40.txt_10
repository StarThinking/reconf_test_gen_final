reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994994721-172.17.0.3-1597660178376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43250,DS-73dc1aa7-8977-468f-9ad2-6eba4789b49c,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-06f67f22-028a-4025-aeaf-35f504311780,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-a2e46940-e15a-4c97-8508-6522ba79024c,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-44194e0b-3370-4a80-9082-87dd93afca62,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-b47bbc9a-c1d4-4052-beb5-33743c181f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-a28c75b3-fa32-4abf-b295-4c06d490ebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-0fb7a1ef-35ac-49a5-9d13-62a2aa7facca,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-af4c14a8-49b6-45ff-8362-1f7fefdec299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994994721-172.17.0.3-1597660178376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43250,DS-73dc1aa7-8977-468f-9ad2-6eba4789b49c,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-06f67f22-028a-4025-aeaf-35f504311780,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-a2e46940-e15a-4c97-8508-6522ba79024c,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-44194e0b-3370-4a80-9082-87dd93afca62,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-b47bbc9a-c1d4-4052-beb5-33743c181f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-a28c75b3-fa32-4abf-b295-4c06d490ebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-0fb7a1ef-35ac-49a5-9d13-62a2aa7facca,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-af4c14a8-49b6-45ff-8362-1f7fefdec299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791878114-172.17.0.3-1597660429430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-d0e2abce-d0f5-41f0-a238-0a8d0afa091b,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-4fd09316-e01a-4a74-8922-1f07e2a40d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-2eab2d5f-c22a-4c7b-8377-dbccd1214499,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-dcd3d9f2-510d-465d-a175-b9e1600c2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-f273c39f-d839-469b-b27a-86decf912dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-e078c2af-76e6-4ff8-960c-df28c2473f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-1f6ed3fc-1b4c-44a4-9ef4-9c1da8c0e36b,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-255bde49-b466-4a18-b9d4-d7d6b97b4891,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791878114-172.17.0.3-1597660429430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-d0e2abce-d0f5-41f0-a238-0a8d0afa091b,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-4fd09316-e01a-4a74-8922-1f07e2a40d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-2eab2d5f-c22a-4c7b-8377-dbccd1214499,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-dcd3d9f2-510d-465d-a175-b9e1600c2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-f273c39f-d839-469b-b27a-86decf912dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-e078c2af-76e6-4ff8-960c-df28c2473f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-1f6ed3fc-1b4c-44a4-9ef4-9c1da8c0e36b,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-255bde49-b466-4a18-b9d4-d7d6b97b4891,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653128229-172.17.0.3-1597661033821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44572,DS-6acc49e7-09f7-4be7-8925-b8c3e35333de,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-1df3a8ff-6b08-4324-a16d-33d9b3ba8050,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-d2486663-931a-441e-b00d-1de2e503671a,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-5deb02f3-0d20-420e-b140-20e0e124f83e,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-a74564ae-1651-4ee5-8f0c-2904f90bbbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-ae2d8efc-e660-4282-bf48-a810b8cb61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-179e003a-7633-448e-aa9f-897b7133c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-fe61f9db-74e9-4446-884f-11993dbfaf56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653128229-172.17.0.3-1597661033821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44572,DS-6acc49e7-09f7-4be7-8925-b8c3e35333de,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-1df3a8ff-6b08-4324-a16d-33d9b3ba8050,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-d2486663-931a-441e-b00d-1de2e503671a,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-5deb02f3-0d20-420e-b140-20e0e124f83e,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-a74564ae-1651-4ee5-8f0c-2904f90bbbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-ae2d8efc-e660-4282-bf48-a810b8cb61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-179e003a-7633-448e-aa9f-897b7133c5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-fe61f9db-74e9-4446-884f-11993dbfaf56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716067872-172.17.0.3-1597661186414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-584f0e6a-b472-4129-9b69-4e66e1f46d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-4fe1253e-c6e0-4371-868e-33a9d6b91a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-c76f6625-35a1-414b-9ac6-d9a5217a667d,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-e27246b4-3d64-47ce-8c73-3f2382675ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-52dea3b0-26fa-4c1f-8a61-bc43413b7fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-f4bc3d67-99c6-4d83-94bf-d5bcc2235f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-a90e7d4b-496e-41cc-a9b8-0833907c1a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-ed49f3d7-877c-4b42-9ec4-cafb04442cc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716067872-172.17.0.3-1597661186414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-584f0e6a-b472-4129-9b69-4e66e1f46d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-4fe1253e-c6e0-4371-868e-33a9d6b91a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-c76f6625-35a1-414b-9ac6-d9a5217a667d,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-e27246b4-3d64-47ce-8c73-3f2382675ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-52dea3b0-26fa-4c1f-8a61-bc43413b7fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-f4bc3d67-99c6-4d83-94bf-d5bcc2235f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-a90e7d4b-496e-41cc-a9b8-0833907c1a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-ed49f3d7-877c-4b42-9ec4-cafb04442cc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408751768-172.17.0.3-1597661562462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-fc4de81b-241f-4d53-b3b1-75a6a5eabc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-5f75fd4c-d039-4324-b135-e9b61f3443cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-7b326099-0a8c-4b76-b409-42b7c2b970ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-5002d4db-b074-442c-90b3-d309060ba6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-cdee082e-d75c-4cc3-a88e-75d146010989,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e4cf6599-abb1-4aee-a240-7a034459dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-099cb8de-fed7-4082-a1e7-546592f488d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-7c5128bc-7e24-462c-8052-7fe5c42a71b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408751768-172.17.0.3-1597661562462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-fc4de81b-241f-4d53-b3b1-75a6a5eabc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-5f75fd4c-d039-4324-b135-e9b61f3443cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-7b326099-0a8c-4b76-b409-42b7c2b970ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-5002d4db-b074-442c-90b3-d309060ba6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-cdee082e-d75c-4cc3-a88e-75d146010989,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e4cf6599-abb1-4aee-a240-7a034459dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-099cb8de-fed7-4082-a1e7-546592f488d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-7c5128bc-7e24-462c-8052-7fe5c42a71b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799618226-172.17.0.3-1597662016291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46354,DS-29ce5f30-d1ff-4e8c-97e8-673f5a82a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-3b02e104-9f6c-4a23-a7d9-35b5904095ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-76c5c5ea-19e7-4a2b-99b1-c24668c0f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-4b5c4388-d953-4771-a14f-601291efd406,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-8f9283c7-9dc8-4636-9943-827fab938ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-e50174e9-e45c-49db-b5f7-36beb2718f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-8e71d1f0-3712-42c1-8862-5eeccca6d071,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-3aa3badb-9876-4c67-8881-b230056fa12b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799618226-172.17.0.3-1597662016291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46354,DS-29ce5f30-d1ff-4e8c-97e8-673f5a82a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-3b02e104-9f6c-4a23-a7d9-35b5904095ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-76c5c5ea-19e7-4a2b-99b1-c24668c0f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-4b5c4388-d953-4771-a14f-601291efd406,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-8f9283c7-9dc8-4636-9943-827fab938ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-e50174e9-e45c-49db-b5f7-36beb2718f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-8e71d1f0-3712-42c1-8862-5eeccca6d071,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-3aa3badb-9876-4c67-8881-b230056fa12b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562397662-172.17.0.3-1597662143081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38038,DS-8cc73c78-6bdb-4600-bb16-c54ec353efab,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-19766165-8b8c-4408-85b3-79c718a757e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-fe12b530-b59a-41e4-aacd-8c80197c31c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-e051cf3e-4766-4f01-9246-8707ced9fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-1275829f-2c1c-4d83-ba88-35b1be55dc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-59696b79-895b-4913-9d71-37cddb5e37c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-a1da515a-6d26-4b62-86b9-b487b03099ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-5c1c7e87-6c45-4de5-a48c-f965661d34bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562397662-172.17.0.3-1597662143081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38038,DS-8cc73c78-6bdb-4600-bb16-c54ec353efab,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-19766165-8b8c-4408-85b3-79c718a757e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-fe12b530-b59a-41e4-aacd-8c80197c31c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-e051cf3e-4766-4f01-9246-8707ced9fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-1275829f-2c1c-4d83-ba88-35b1be55dc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-59696b79-895b-4913-9d71-37cddb5e37c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-a1da515a-6d26-4b62-86b9-b487b03099ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-5c1c7e87-6c45-4de5-a48c-f965661d34bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794557216-172.17.0.3-1597662183768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-5e7c80d4-da9d-4909-832d-e0810ef98d50,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-b0757dac-5ec7-4dcb-8f04-baa0234ab57f,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-6f65daf7-58e0-4d1a-9ea8-38c7e3882ede,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-f65c9fbc-7435-4c1b-b981-a58ebce574df,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-04ee6d9d-dfbd-4270-b7e3-e988c78fb713,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-752b72f3-2adc-4bf7-a7e6-ce3fc53e35f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-e9addc11-cd9e-4f45-b37b-03a038b22ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-deec0fae-1388-4b4e-8be4-ddcc6e027726,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794557216-172.17.0.3-1597662183768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-5e7c80d4-da9d-4909-832d-e0810ef98d50,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-b0757dac-5ec7-4dcb-8f04-baa0234ab57f,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-6f65daf7-58e0-4d1a-9ea8-38c7e3882ede,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-f65c9fbc-7435-4c1b-b981-a58ebce574df,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-04ee6d9d-dfbd-4270-b7e3-e988c78fb713,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-752b72f3-2adc-4bf7-a7e6-ce3fc53e35f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-e9addc11-cd9e-4f45-b37b-03a038b22ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-deec0fae-1388-4b4e-8be4-ddcc6e027726,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248537005-172.17.0.3-1597662263346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-60fe5899-61bf-4046-a8a4-680e5f9e72ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-0617eb57-8a04-4178-a121-67129b3e06eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-4d5e13fa-d07d-4536-bd16-4bca202bee4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-8c092594-aaf7-4a0c-91b3-65802b3bc4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-e4bf14fc-0e9c-4069-a1c4-2155d9796144,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-99ab7cc5-cf1f-4de0-a625-2c5e972a6372,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-0864311f-0314-4e36-9100-96d3f655cbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-d8b9589d-b888-4b3a-a3cf-be2554cdbfb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248537005-172.17.0.3-1597662263346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-60fe5899-61bf-4046-a8a4-680e5f9e72ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-0617eb57-8a04-4178-a121-67129b3e06eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-4d5e13fa-d07d-4536-bd16-4bca202bee4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-8c092594-aaf7-4a0c-91b3-65802b3bc4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-e4bf14fc-0e9c-4069-a1c4-2155d9796144,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-99ab7cc5-cf1f-4de0-a625-2c5e972a6372,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-0864311f-0314-4e36-9100-96d3f655cbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-d8b9589d-b888-4b3a-a3cf-be2554cdbfb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082447023-172.17.0.3-1597662370766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-e1f033ae-8e25-4e87-a709-6f1ff374453e,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-43b807a8-b179-46b3-87ca-2364a3cefa51,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-b0cb1c37-1420-43da-859f-3ff1427b1dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-7cb318da-ccc2-425f-918b-54fa72b8e5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-31286eec-4e04-4523-8129-85e7838160e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-ff463d23-f607-4f3d-a1d4-4a8d6b6c9c16,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-51ece38c-78b6-43f0-8956-6583260273a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-24f6040c-9ce5-4b62-8c04-902c08828f79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082447023-172.17.0.3-1597662370766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-e1f033ae-8e25-4e87-a709-6f1ff374453e,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-43b807a8-b179-46b3-87ca-2364a3cefa51,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-b0cb1c37-1420-43da-859f-3ff1427b1dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-7cb318da-ccc2-425f-918b-54fa72b8e5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-31286eec-4e04-4523-8129-85e7838160e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-ff463d23-f607-4f3d-a1d4-4a8d6b6c9c16,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-51ece38c-78b6-43f0-8956-6583260273a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-24f6040c-9ce5-4b62-8c04-902c08828f79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158912093-172.17.0.3-1597662529157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-56dc392c-db5f-448f-bc0a-b5604b8d0828,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-ff65a7fb-fd3c-4525-9966-15e7ac01d855,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-2490168b-a06a-4a3b-9679-e210ea89b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-3980b9ed-cf32-43c5-ad2d-d2170dc59a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-6148d99b-7236-4b08-81be-dd470f2e965c,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-3532e42e-9c73-4522-b290-7bf4b7bcadad,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-7bc00770-e34a-4ac0-bec2-488605d23c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-5574842c-5c8d-486b-983c-2b4e926c7b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158912093-172.17.0.3-1597662529157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-56dc392c-db5f-448f-bc0a-b5604b8d0828,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-ff65a7fb-fd3c-4525-9966-15e7ac01d855,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-2490168b-a06a-4a3b-9679-e210ea89b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-3980b9ed-cf32-43c5-ad2d-d2170dc59a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-6148d99b-7236-4b08-81be-dd470f2e965c,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-3532e42e-9c73-4522-b290-7bf4b7bcadad,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-7bc00770-e34a-4ac0-bec2-488605d23c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-5574842c-5c8d-486b-983c-2b4e926c7b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597199602-172.17.0.3-1597662979023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46651,DS-e76aaaf7-2497-4993-9b6c-54a95f932084,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-bf844170-447d-47ef-92f8-31890d410f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-8831b982-89cb-45cb-9f30-acb0a2c96fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-f3ea0f79-3599-4cc3-b841-462b80e93e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-5df84a2d-399a-45af-b2f4-d44dcdafd1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-731732a6-c90b-4154-9fea-3d2706dad67e,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-e8380864-1de0-4bf8-ad63-adf87958ddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-8134501e-6437-4479-8302-acdbd7aaba16,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597199602-172.17.0.3-1597662979023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46651,DS-e76aaaf7-2497-4993-9b6c-54a95f932084,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-bf844170-447d-47ef-92f8-31890d410f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-8831b982-89cb-45cb-9f30-acb0a2c96fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-f3ea0f79-3599-4cc3-b841-462b80e93e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-5df84a2d-399a-45af-b2f4-d44dcdafd1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-731732a6-c90b-4154-9fea-3d2706dad67e,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-e8380864-1de0-4bf8-ad63-adf87958ddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-8134501e-6437-4479-8302-acdbd7aaba16,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382621577-172.17.0.3-1597663088532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-b9a2f532-7f50-4ef5-b4c6-62bbabc70b37,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-92c2314e-f760-48eb-b953-85d045eb4603,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-60ec9d30-34fa-4aa2-8b08-4b02a432f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-fcf7fbe4-5fb9-4bdf-9593-a01487249cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-8cb135b5-8314-46e7-9872-40feb904149a,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-5e4a3877-4ced-4834-b5a1-3282925a6b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-bb861f6d-5a8b-4a0c-8a6e-24eb56fcdaad,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-5bc1614b-8c6f-4f53-99cc-112f410f8ea2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382621577-172.17.0.3-1597663088532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44545,DS-b9a2f532-7f50-4ef5-b4c6-62bbabc70b37,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-92c2314e-f760-48eb-b953-85d045eb4603,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-60ec9d30-34fa-4aa2-8b08-4b02a432f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-fcf7fbe4-5fb9-4bdf-9593-a01487249cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-8cb135b5-8314-46e7-9872-40feb904149a,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-5e4a3877-4ced-4834-b5a1-3282925a6b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-bb861f6d-5a8b-4a0c-8a6e-24eb56fcdaad,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-5bc1614b-8c6f-4f53-99cc-112f410f8ea2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334970486-172.17.0.3-1597663250565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-75504392-b550-48ef-9976-4e02ac1a88cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-8c6349d2-8149-4b62-9deb-3a1a3df3a8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-f8ad95ff-db28-49fe-8bed-964bc43a4f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-4e47f432-bb6e-41cd-a78c-4c217978f66b,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-f3238be6-3c51-4856-a8c8-fb99e7bc311f,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0721fd7f-ba2b-4e29-9843-84ab146b75e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-ba40091b-dc60-4cf4-88ad-d620977e99ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-a62b6d8c-dd84-44c6-a315-acada3078034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334970486-172.17.0.3-1597663250565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-75504392-b550-48ef-9976-4e02ac1a88cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-8c6349d2-8149-4b62-9deb-3a1a3df3a8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-f8ad95ff-db28-49fe-8bed-964bc43a4f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-4e47f432-bb6e-41cd-a78c-4c217978f66b,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-f3238be6-3c51-4856-a8c8-fb99e7bc311f,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0721fd7f-ba2b-4e29-9843-84ab146b75e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-ba40091b-dc60-4cf4-88ad-d620977e99ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-a62b6d8c-dd84-44c6-a315-acada3078034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568558822-172.17.0.3-1597663737077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-0e3fc9db-46df-4be5-980e-88981a8834eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-933508bd-8733-4d82-9af0-707c0de354c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d86bcd98-3cf0-486f-bf94-bf3e2ac5a675,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-9a40b273-1045-46d0-9c6b-1a375ef0b104,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-e6fe856f-d1e7-404f-ae83-6022252f9a24,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-2420ed5a-495f-4341-8158-0b91f46f0081,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-bca950a9-39e6-4817-bcb5-cf1988d5b783,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-52746c64-ac3c-43d7-91a1-09b038e65f7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568558822-172.17.0.3-1597663737077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-0e3fc9db-46df-4be5-980e-88981a8834eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-933508bd-8733-4d82-9af0-707c0de354c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d86bcd98-3cf0-486f-bf94-bf3e2ac5a675,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-9a40b273-1045-46d0-9c6b-1a375ef0b104,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-e6fe856f-d1e7-404f-ae83-6022252f9a24,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-2420ed5a-495f-4341-8158-0b91f46f0081,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-bca950a9-39e6-4817-bcb5-cf1988d5b783,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-52746c64-ac3c-43d7-91a1-09b038e65f7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777294801-172.17.0.3-1597663841030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36929,DS-7ad4af32-a64e-42c8-bd1a-34f886804460,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-c42608f8-9c1a-4f0f-9960-7c69c8d7d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-83d62fdb-5766-4876-ba10-6923c69c84e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-a8ab0c44-31a1-4fa6-9d50-8ea5f827b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-1393e9c0-e5bc-47d3-b009-52f821eb3f33,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-bdd0040b-0ee4-4ff8-8859-3b4ee30129ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-28b81051-fe1a-4713-b0ee-cee4fb0ebb45,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-f935a578-f7d6-416e-9d4e-6eb6b559487e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777294801-172.17.0.3-1597663841030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36929,DS-7ad4af32-a64e-42c8-bd1a-34f886804460,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-c42608f8-9c1a-4f0f-9960-7c69c8d7d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-83d62fdb-5766-4876-ba10-6923c69c84e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-a8ab0c44-31a1-4fa6-9d50-8ea5f827b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-1393e9c0-e5bc-47d3-b009-52f821eb3f33,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-bdd0040b-0ee4-4ff8-8859-3b4ee30129ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-28b81051-fe1a-4713-b0ee-cee4fb0ebb45,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-f935a578-f7d6-416e-9d4e-6eb6b559487e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154497145-172.17.0.3-1597664003107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42702,DS-aa697e5e-3669-4e65-8c4b-ae9f862daf29,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-f274d645-6f66-4402-b9fe-041ed3ec7a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-cf56857c-7c6e-4f4b-9ddc-b3e3f9ec3df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-57490fc6-2273-4cb6-b2e8-87c04d00738c,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-02997eb7-4108-4c20-b249-3458f6c36e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-894f24f3-cca7-4476-b6ce-8d0b5229e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-e01f0c53-0035-41e3-b0a5-68635af8b8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-d21ca5c3-de69-4e5c-9a89-b99d423ca3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154497145-172.17.0.3-1597664003107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42702,DS-aa697e5e-3669-4e65-8c4b-ae9f862daf29,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-f274d645-6f66-4402-b9fe-041ed3ec7a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-cf56857c-7c6e-4f4b-9ddc-b3e3f9ec3df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-57490fc6-2273-4cb6-b2e8-87c04d00738c,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-02997eb7-4108-4c20-b249-3458f6c36e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-894f24f3-cca7-4476-b6ce-8d0b5229e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-e01f0c53-0035-41e3-b0a5-68635af8b8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-d21ca5c3-de69-4e5c-9a89-b99d423ca3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889134122-172.17.0.3-1597664152964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-7c7c761c-540b-4b94-8a44-9173014d9a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-1133bc6c-9271-4364-a7eb-a83cacaa5c58,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-443f9ecf-832c-4dfd-8a47-dfb3f04adc86,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-a7b46939-9b00-4a00-a4cd-168152c9aaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-9e24edbd-0469-4a8c-b192-b46e7a5a3cab,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-1c27e80c-4066-41d8-b428-8c2a5cae747f,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-b0323101-d4a7-472e-ba0f-79c253e52164,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-877ca008-2241-4344-852a-b20f9c175428,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889134122-172.17.0.3-1597664152964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-7c7c761c-540b-4b94-8a44-9173014d9a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-1133bc6c-9271-4364-a7eb-a83cacaa5c58,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-443f9ecf-832c-4dfd-8a47-dfb3f04adc86,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-a7b46939-9b00-4a00-a4cd-168152c9aaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-9e24edbd-0469-4a8c-b192-b46e7a5a3cab,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-1c27e80c-4066-41d8-b428-8c2a5cae747f,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-b0323101-d4a7-472e-ba0f-79c253e52164,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-877ca008-2241-4344-852a-b20f9c175428,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444801803-172.17.0.3-1597664186011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-e0b42c49-a8f1-4f53-8817-91e04c952811,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-6ef71488-c18d-4ea4-b3a8-417f12180c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-2ee0da0e-1363-4ad8-b748-95b2f3074b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-eb82bd6c-dd11-4710-b9d0-3e0c042aa25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-648d76b6-4e77-4ce4-bc9f-a152d1e87457,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-dd8ea792-3009-422d-b4ff-e99d2ee50eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-14b3661a-f2ac-495a-936b-f6a26a7b2a36,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-2b2eb6dd-49f4-4cf4-84c6-aa5bc48bdc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444801803-172.17.0.3-1597664186011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-e0b42c49-a8f1-4f53-8817-91e04c952811,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-6ef71488-c18d-4ea4-b3a8-417f12180c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-2ee0da0e-1363-4ad8-b748-95b2f3074b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-eb82bd6c-dd11-4710-b9d0-3e0c042aa25f,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-648d76b6-4e77-4ce4-bc9f-a152d1e87457,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-dd8ea792-3009-422d-b4ff-e99d2ee50eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-14b3661a-f2ac-495a-936b-f6a26a7b2a36,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-2b2eb6dd-49f4-4cf4-84c6-aa5bc48bdc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003473539-172.17.0.3-1597664435429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-88cd949d-8fa2-46cd-b3ae-712218906483,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-97026e14-8156-4cfb-88ac-3f3697286a62,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-3203e61d-18e8-42d7-9a2d-53f4318e68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-74e5783e-3485-41b5-ae4c-4dfb29756348,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-376a5a37-0965-488b-967b-89ade4b881a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-17525e80-a180-4fce-880b-8fa4e40257dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-3753de72-206a-4647-9071-ed265d0e4d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-7f244ae1-51d5-4d60-a29c-21ed68e4bb7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003473539-172.17.0.3-1597664435429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-88cd949d-8fa2-46cd-b3ae-712218906483,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-97026e14-8156-4cfb-88ac-3f3697286a62,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-3203e61d-18e8-42d7-9a2d-53f4318e68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-74e5783e-3485-41b5-ae4c-4dfb29756348,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-376a5a37-0965-488b-967b-89ade4b881a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-17525e80-a180-4fce-880b-8fa4e40257dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-3753de72-206a-4647-9071-ed265d0e4d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-7f244ae1-51d5-4d60-a29c-21ed68e4bb7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236884983-172.17.0.3-1597664750779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43566,DS-97a15c26-7836-4003-9aa2-482cb0948264,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-0ff6bbb7-36c8-47e9-8ef9-2f6acb8942d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-97cce84a-7cbd-4aa2-8e01-1892aa69b06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-d67896ba-6e42-41a8-b1fe-a6b2034f95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-bfeabf15-cec3-4073-8845-cb641539a292,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-8b910142-e1c4-48e0-a64f-b6355f10b0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-a760c63a-253a-461c-a098-703b46479d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-f122bfdb-fdaa-469d-9246-d9a9a454a905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236884983-172.17.0.3-1597664750779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43566,DS-97a15c26-7836-4003-9aa2-482cb0948264,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-0ff6bbb7-36c8-47e9-8ef9-2f6acb8942d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-97cce84a-7cbd-4aa2-8e01-1892aa69b06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-d67896ba-6e42-41a8-b1fe-a6b2034f95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-bfeabf15-cec3-4073-8845-cb641539a292,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-8b910142-e1c4-48e0-a64f-b6355f10b0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-a760c63a-253a-461c-a098-703b46479d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-f122bfdb-fdaa-469d-9246-d9a9a454a905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774294790-172.17.0.3-1597664848544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-f6e4abdb-3bb5-4190-8fd7-7c625076f792,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-cca1333f-b78c-4842-88e1-4a9c60a72f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-5f9584f9-8770-4bef-924e-ff3de1cf6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-5ae011ed-a338-4385-9443-1411fc247d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-18aaa097-02e6-4284-9ffa-1699018078af,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-35cb332d-29f5-4622-89c7-23230cecdf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-d75e1881-97e6-457e-ad4c-42b6a8e43cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-b75d5180-5a62-4f84-a615-24fd6c9e13fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774294790-172.17.0.3-1597664848544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-f6e4abdb-3bb5-4190-8fd7-7c625076f792,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-cca1333f-b78c-4842-88e1-4a9c60a72f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-5f9584f9-8770-4bef-924e-ff3de1cf6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-5ae011ed-a338-4385-9443-1411fc247d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-18aaa097-02e6-4284-9ffa-1699018078af,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-35cb332d-29f5-4622-89c7-23230cecdf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-d75e1881-97e6-457e-ad4c-42b6a8e43cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-b75d5180-5a62-4f84-a615-24fd6c9e13fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131597729-172.17.0.3-1597664887763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45374,DS-73fc17bf-a1a1-4b53-b064-8748ace7ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-73558e1f-05a4-41b2-b686-7868894d2e03,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-b943e773-2cda-4e02-a27e-da47210a3603,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-59ee8e8f-8a30-430b-a05c-5b16e3a1ace8,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-ba52dfa8-aaf4-4fa9-b352-6ab6f5d70a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-6d0f403f-d341-468b-9b53-627248114a78,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-2df15f68-ad0a-49c9-88d7-b641b4150ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-525039c9-4fef-4383-ab4b-2188ee85ee57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131597729-172.17.0.3-1597664887763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45374,DS-73fc17bf-a1a1-4b53-b064-8748ace7ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-73558e1f-05a4-41b2-b686-7868894d2e03,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-b943e773-2cda-4e02-a27e-da47210a3603,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-59ee8e8f-8a30-430b-a05c-5b16e3a1ace8,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-ba52dfa8-aaf4-4fa9-b352-6ab6f5d70a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-6d0f403f-d341-468b-9b53-627248114a78,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-2df15f68-ad0a-49c9-88d7-b641b4150ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-525039c9-4fef-4383-ab4b-2188ee85ee57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976678143-172.17.0.3-1597664968173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37313,DS-9347c88e-d6e2-4476-a2e7-c33dd175dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8eea169b-16d4-4ab8-8438-af70de3d382d,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-80fdd895-2f8d-477e-a036-fb01e3a2e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-4141a685-963c-4760-a55c-7b60de27de76,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-db0c0e0c-ca9b-4174-8700-cd594487c8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-b21ec028-0153-4d8f-8ae8-ef3be8b9b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-e32d444e-6091-4c0a-b215-15942d67c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-1a759ffe-f586-4d0c-9460-1c00433f67c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976678143-172.17.0.3-1597664968173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37313,DS-9347c88e-d6e2-4476-a2e7-c33dd175dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8eea169b-16d4-4ab8-8438-af70de3d382d,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-80fdd895-2f8d-477e-a036-fb01e3a2e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-4141a685-963c-4760-a55c-7b60de27de76,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-db0c0e0c-ca9b-4174-8700-cd594487c8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-b21ec028-0153-4d8f-8ae8-ef3be8b9b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-e32d444e-6091-4c0a-b215-15942d67c53f,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-1a759ffe-f586-4d0c-9460-1c00433f67c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942066878-172.17.0.3-1597665006820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38426,DS-e9da9150-0bbf-4676-b593-e3b7d056bed2,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-b0267a4e-6818-4dd7-b40a-97006c0646e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-5e1d5744-bed4-4bdd-b980-d6a8dfff398a,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-4dda668d-383e-4e41-bebe-1b510e8709d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-43d941a2-9528-4c86-b01f-4ac3f9622b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-418b91b0-f4d4-4f3c-997b-9e4e0647e862,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-812ee8d2-be8c-4fff-8e83-21cad826f3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-66beb775-b912-403d-8886-01434b45f628,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942066878-172.17.0.3-1597665006820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38426,DS-e9da9150-0bbf-4676-b593-e3b7d056bed2,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-b0267a4e-6818-4dd7-b40a-97006c0646e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-5e1d5744-bed4-4bdd-b980-d6a8dfff398a,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-4dda668d-383e-4e41-bebe-1b510e8709d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-43d941a2-9528-4c86-b01f-4ac3f9622b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-418b91b0-f4d4-4f3c-997b-9e4e0647e862,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-812ee8d2-be8c-4fff-8e83-21cad826f3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-66beb775-b912-403d-8886-01434b45f628,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320886983-172.17.0.3-1597665290087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42022,DS-828a537d-48fd-4574-9b39-664744a289df,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-485f03e9-dd75-4ff1-b4f3-d674945ae402,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-ea7de3fc-8b4f-48a4-ab1c-c77703a51f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-66bce7e8-c6b6-47db-bba1-b2c26aa7e548,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-1fecc6cb-636f-48e7-b0df-884e6c304b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-60848c80-3586-47ee-9dfa-3798f1e83be8,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-0e4687cf-10d7-4f16-980a-4ed4a1f2cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-5b2a800d-12be-4301-b6b7-6d7c1e460fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320886983-172.17.0.3-1597665290087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42022,DS-828a537d-48fd-4574-9b39-664744a289df,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-485f03e9-dd75-4ff1-b4f3-d674945ae402,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-ea7de3fc-8b4f-48a4-ab1c-c77703a51f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-66bce7e8-c6b6-47db-bba1-b2c26aa7e548,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-1fecc6cb-636f-48e7-b0df-884e6c304b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-60848c80-3586-47ee-9dfa-3798f1e83be8,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-0e4687cf-10d7-4f16-980a-4ed4a1f2cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-5b2a800d-12be-4301-b6b7-6d7c1e460fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052582208-172.17.0.3-1597665514959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34990,DS-b9c12479-959f-4a5c-9aa6-7f5e0a50d44b,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-4b96c6f5-d65b-45d9-86e4-9dd84092f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-094243b6-e304-4bbf-b20f-a0507b7c677f,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-543efe8d-ec70-49b1-a701-4c93c1c00f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-46b63821-f538-41aa-8df5-f149a0516bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-cd81ca86-fbdd-4f25-8885-1f5504b2479d,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-6db82d04-ac21-4939-b92b-356507cf39fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-852f2255-4419-4166-bcc6-9658da25b198,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052582208-172.17.0.3-1597665514959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34990,DS-b9c12479-959f-4a5c-9aa6-7f5e0a50d44b,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-4b96c6f5-d65b-45d9-86e4-9dd84092f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-094243b6-e304-4bbf-b20f-a0507b7c677f,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-543efe8d-ec70-49b1-a701-4c93c1c00f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-46b63821-f538-41aa-8df5-f149a0516bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-cd81ca86-fbdd-4f25-8885-1f5504b2479d,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-6db82d04-ac21-4939-b92b-356507cf39fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-852f2255-4419-4166-bcc6-9658da25b198,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5671
