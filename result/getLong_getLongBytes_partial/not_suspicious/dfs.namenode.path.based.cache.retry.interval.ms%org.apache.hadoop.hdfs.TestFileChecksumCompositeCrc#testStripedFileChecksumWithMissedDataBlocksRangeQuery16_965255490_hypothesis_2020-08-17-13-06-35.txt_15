reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420739601-172.17.0.13-1597669611918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-08397323-4d6f-44da-8bb3-ae64e6eb1b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-0c20d29e-84f3-4dd9-a924-843e317b16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-df921202-7b4b-47e6-99d9-283882bc29a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-f590a674-d711-41bb-bbfe-481b3eeed7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-c9aaa8d1-9d68-41be-bd6a-a2bdd78a689c,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-21ebccd9-8ae7-4591-aeb5-c5964d27f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-56cfcbc0-d8ab-4707-90f8-a8791e06bd10,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-56519edb-a70f-4993-818e-7bfb5cda7da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420739601-172.17.0.13-1597669611918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-08397323-4d6f-44da-8bb3-ae64e6eb1b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-0c20d29e-84f3-4dd9-a924-843e317b16bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-df921202-7b4b-47e6-99d9-283882bc29a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-f590a674-d711-41bb-bbfe-481b3eeed7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-c9aaa8d1-9d68-41be-bd6a-a2bdd78a689c,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-21ebccd9-8ae7-4591-aeb5-c5964d27f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-56cfcbc0-d8ab-4707-90f8-a8791e06bd10,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-56519edb-a70f-4993-818e-7bfb5cda7da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733125369-172.17.0.13-1597669803140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-c1f4b846-8afd-4152-880e-ffa8898f4725,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-f057fe4f-f01c-4b31-a0e0-9b7d6de0bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-9b836871-f38f-4a04-baeb-b941510ecd67,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-963b963c-cb99-4b9e-b126-95b8896f4c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-f021a19f-4d3d-44cf-9235-34c6d1649ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-fa85cdf0-8286-4e13-9cfe-4b735bd0da80,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-4ec6789a-2bcb-48cf-b1e5-aff2c0d62761,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-7931483a-6913-4cb2-8aa7-1ad851157a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733125369-172.17.0.13-1597669803140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-c1f4b846-8afd-4152-880e-ffa8898f4725,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-f057fe4f-f01c-4b31-a0e0-9b7d6de0bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-9b836871-f38f-4a04-baeb-b941510ecd67,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-963b963c-cb99-4b9e-b126-95b8896f4c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-f021a19f-4d3d-44cf-9235-34c6d1649ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-fa85cdf0-8286-4e13-9cfe-4b735bd0da80,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-4ec6789a-2bcb-48cf-b1e5-aff2c0d62761,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-7931483a-6913-4cb2-8aa7-1ad851157a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429236094-172.17.0.13-1597670067068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41857,DS-2fa85ed1-caf9-44d0-8b63-309424c1cc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-52cbc9bd-f32b-41ab-bac4-14b3a48c3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-ba21a088-93b9-4b02-a88d-857a85c47683,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-b829b285-c1ac-4b72-a3d0-5914cf47d95b,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-4da5f252-f316-4952-8f19-ee6ca9b4d6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-e0b5edc0-8214-4259-8725-8c37f52e5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-74fbc02d-6c37-40d6-a70f-bdb722a366e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-8e5154f2-f7a2-4e2b-ae02-d82419d38435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429236094-172.17.0.13-1597670067068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41857,DS-2fa85ed1-caf9-44d0-8b63-309424c1cc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-52cbc9bd-f32b-41ab-bac4-14b3a48c3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-ba21a088-93b9-4b02-a88d-857a85c47683,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-b829b285-c1ac-4b72-a3d0-5914cf47d95b,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-4da5f252-f316-4952-8f19-ee6ca9b4d6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-e0b5edc0-8214-4259-8725-8c37f52e5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-74fbc02d-6c37-40d6-a70f-bdb722a366e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-8e5154f2-f7a2-4e2b-ae02-d82419d38435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298891872-172.17.0.13-1597670338875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-ec7d7e00-eddf-4cc7-8d83-72da011133be,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-7cfb3d51-f228-48cd-acd5-088a713d6cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-a6104701-4867-419a-bbeb-f6d051730c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-9ccceaa9-522d-4420-9677-7d2a95ee5079,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-23e3733e-7b8d-4470-b54a-18f4bae8592a,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-b5dbf595-6a13-49ce-ae7d-ad4b3d7be230,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-f045e7d9-0dec-448f-89c1-e0aa96283485,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-0b34f368-ad0e-4288-8a85-0979223de648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298891872-172.17.0.13-1597670338875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-ec7d7e00-eddf-4cc7-8d83-72da011133be,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-7cfb3d51-f228-48cd-acd5-088a713d6cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-a6104701-4867-419a-bbeb-f6d051730c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-9ccceaa9-522d-4420-9677-7d2a95ee5079,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-23e3733e-7b8d-4470-b54a-18f4bae8592a,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-b5dbf595-6a13-49ce-ae7d-ad4b3d7be230,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-f045e7d9-0dec-448f-89c1-e0aa96283485,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-0b34f368-ad0e-4288-8a85-0979223de648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767350571-172.17.0.13-1597670628502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41234,DS-5545cc25-3549-4083-b88a-68c18a4d57b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-2892a8f3-29f8-4844-b846-99efdd02ffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-97866a0a-410d-48cd-bc7f-24cf84f7dbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-7ea19712-9078-4721-adfc-d25e9390d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-cb31f662-0a49-4306-b990-6ada56aad0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-28b7b53a-d060-4488-812b-513d2bce55b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-247e5470-7603-4595-acce-a631d4f24c32,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-2f6af512-00bb-474f-94ff-8f012bbf5773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767350571-172.17.0.13-1597670628502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41234,DS-5545cc25-3549-4083-b88a-68c18a4d57b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-2892a8f3-29f8-4844-b846-99efdd02ffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-97866a0a-410d-48cd-bc7f-24cf84f7dbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-7ea19712-9078-4721-adfc-d25e9390d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-cb31f662-0a49-4306-b990-6ada56aad0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-28b7b53a-d060-4488-812b-513d2bce55b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-247e5470-7603-4595-acce-a631d4f24c32,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-2f6af512-00bb-474f-94ff-8f012bbf5773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353847484-172.17.0.13-1597670949663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-d4d7c9c2-aac3-4f95-b307-a6271ccb84f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-bcd3188e-51fa-4985-be6c-ec2c0afd976d,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-beefb344-9bff-49fe-860b-f42191e87206,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-9f7ef0bc-658a-430f-88a0-fac6f6926fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-d24c9258-37fb-4f9c-9364-55ce31f2424f,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-d96e2158-a78c-4091-9ed4-cfc750841125,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-d5c5963a-8c61-4d09-ae61-67a9372da635,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-5b72d66e-92fc-4345-8172-ce5fa7068b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353847484-172.17.0.13-1597670949663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-d4d7c9c2-aac3-4f95-b307-a6271ccb84f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-bcd3188e-51fa-4985-be6c-ec2c0afd976d,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-beefb344-9bff-49fe-860b-f42191e87206,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-9f7ef0bc-658a-430f-88a0-fac6f6926fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-d24c9258-37fb-4f9c-9364-55ce31f2424f,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-d96e2158-a78c-4091-9ed4-cfc750841125,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-d5c5963a-8c61-4d09-ae61-67a9372da635,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-5b72d66e-92fc-4345-8172-ce5fa7068b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304950207-172.17.0.13-1597671980279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38150,DS-4ef4df13-483b-4a2d-a25c-c60cfbe999d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-17d5f49e-d170-4d43-aed8-abfc60213714,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-7529bb62-be7d-4ebc-a0b2-d53975fb9dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-899fa843-b231-47bc-abf8-7cf76fe9e1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-9814b606-1abb-4cf0-9fb1-50569464ef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-710fd240-f7d6-4131-a5ea-0333b952c373,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-c5001c40-8ffb-47a5-876c-bf19ad46086e,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-d4c2a942-3211-442f-95fb-8baf498afdbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304950207-172.17.0.13-1597671980279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38150,DS-4ef4df13-483b-4a2d-a25c-c60cfbe999d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-17d5f49e-d170-4d43-aed8-abfc60213714,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-7529bb62-be7d-4ebc-a0b2-d53975fb9dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-899fa843-b231-47bc-abf8-7cf76fe9e1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-9814b606-1abb-4cf0-9fb1-50569464ef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-710fd240-f7d6-4131-a5ea-0333b952c373,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-c5001c40-8ffb-47a5-876c-bf19ad46086e,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-d4c2a942-3211-442f-95fb-8baf498afdbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355646941-172.17.0.13-1597672096407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-4be732bc-c987-4477-9d76-6ffada177b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-3b838157-ed6c-4136-8b74-936fb7f00c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-c41938ec-4d67-4c91-8af9-d4e02d9be5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-e52e87b5-093a-4763-adee-d44078bb3f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-91fef4e5-6e07-424b-ab0f-3558b3a666ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-60d3ab0d-5149-4517-9cab-f650e830b451,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-69455e5a-f404-47a2-85e9-011fe0501a03,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-812e29b8-bec2-4e36-a4e7-9bc8b34447ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355646941-172.17.0.13-1597672096407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-4be732bc-c987-4477-9d76-6ffada177b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-3b838157-ed6c-4136-8b74-936fb7f00c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-c41938ec-4d67-4c91-8af9-d4e02d9be5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-e52e87b5-093a-4763-adee-d44078bb3f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-91fef4e5-6e07-424b-ab0f-3558b3a666ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-60d3ab0d-5149-4517-9cab-f650e830b451,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-69455e5a-f404-47a2-85e9-011fe0501a03,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-812e29b8-bec2-4e36-a4e7-9bc8b34447ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861006108-172.17.0.13-1597672582540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34950,DS-dfeb540d-1ec7-4a5a-a269-385fb5fa0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-63518536-3f77-4614-8172-c7f76763b638,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-ba75b763-3ba6-4e14-b348-fa5ee45d840f,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-d3bf6e45-bfdf-4b99-b5b6-992abc6bb886,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-18fc2331-8f3e-467b-a4ab-1b6e0dbcf0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-2b6a70fc-0892-4c21-8613-3efa831c05d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-0e6c9c92-c9de-4568-9353-d9e49c89081a,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-d38a2edd-afc6-4f83-897e-21afd46ec6f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861006108-172.17.0.13-1597672582540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34950,DS-dfeb540d-1ec7-4a5a-a269-385fb5fa0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-63518536-3f77-4614-8172-c7f76763b638,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-ba75b763-3ba6-4e14-b348-fa5ee45d840f,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-d3bf6e45-bfdf-4b99-b5b6-992abc6bb886,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-18fc2331-8f3e-467b-a4ab-1b6e0dbcf0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-2b6a70fc-0892-4c21-8613-3efa831c05d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-0e6c9c92-c9de-4568-9353-d9e49c89081a,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-d38a2edd-afc6-4f83-897e-21afd46ec6f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317680565-172.17.0.13-1597673906272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43394,DS-7c26de9a-1fbf-4eef-b9e2-8fbf2369c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-5c909dd6-476f-4074-b719-89c61a970c63,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-46f67c19-42db-450b-a83f-43fc04e885fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-78968776-cc8e-4285-9d27-ffb7dd3671d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-97bfe6d1-6e67-4204-8a4d-a78d8ec4ce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-9afb3959-fb0a-49f9-93e0-62d9745cfb29,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-34d091a1-c688-4286-bf8e-5c5d31cc714b,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-632a72f8-af7e-4776-aeb2-6069b3308acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317680565-172.17.0.13-1597673906272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43394,DS-7c26de9a-1fbf-4eef-b9e2-8fbf2369c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-5c909dd6-476f-4074-b719-89c61a970c63,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-46f67c19-42db-450b-a83f-43fc04e885fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-78968776-cc8e-4285-9d27-ffb7dd3671d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-97bfe6d1-6e67-4204-8a4d-a78d8ec4ce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-9afb3959-fb0a-49f9-93e0-62d9745cfb29,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-34d091a1-c688-4286-bf8e-5c5d31cc714b,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-632a72f8-af7e-4776-aeb2-6069b3308acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026044686-172.17.0.13-1597674129359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45645,DS-8d23f764-bb7b-44ab-a40a-82d7e1258b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-67e9ea12-ac83-475c-8fa0-352ec1edd91e,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-fcd3aeb3-0d70-44a1-b816-962654f4fd27,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-2222a235-77cd-40f4-b220-eedc2009734e,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-53a98c95-40c1-4242-92af-305d2babc1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-85f2b463-727a-4ab6-aa9b-e6a402fcb32b,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-694ea1e6-bc88-42a6-bbdf-df940f4b955f,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-a51f4759-ac19-4152-b88f-c4881ae8a274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026044686-172.17.0.13-1597674129359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45645,DS-8d23f764-bb7b-44ab-a40a-82d7e1258b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-67e9ea12-ac83-475c-8fa0-352ec1edd91e,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-fcd3aeb3-0d70-44a1-b816-962654f4fd27,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-2222a235-77cd-40f4-b220-eedc2009734e,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-53a98c95-40c1-4242-92af-305d2babc1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-85f2b463-727a-4ab6-aa9b-e6a402fcb32b,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-694ea1e6-bc88-42a6-bbdf-df940f4b955f,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-a51f4759-ac19-4152-b88f-c4881ae8a274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454106401-172.17.0.13-1597674381013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-ca489c4d-14a1-413b-8fa7-2abdf68bbded,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-55b94589-9115-40ac-beb2-e2a39d934f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-58b557ec-98c9-4533-bfd4-b64e19cd39fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-6098f010-dca0-4798-9a69-ce842ea5b258,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-8c9cde25-6288-4a03-a7bf-51ef45e1797c,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-62689b19-0837-4c7c-b77a-160e84ff2987,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-59f0cbaa-1380-4969-be68-94d2bc01a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-fd541d81-ef84-48cd-bb29-e4f0bf17c4c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454106401-172.17.0.13-1597674381013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41229,DS-ca489c4d-14a1-413b-8fa7-2abdf68bbded,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-55b94589-9115-40ac-beb2-e2a39d934f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-58b557ec-98c9-4533-bfd4-b64e19cd39fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-6098f010-dca0-4798-9a69-ce842ea5b258,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-8c9cde25-6288-4a03-a7bf-51ef45e1797c,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-62689b19-0837-4c7c-b77a-160e84ff2987,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-59f0cbaa-1380-4969-be68-94d2bc01a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-fd541d81-ef84-48cd-bb29-e4f0bf17c4c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5508
