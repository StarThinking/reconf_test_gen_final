reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136708853-172.17.0.16-1597557451520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-69868614-e417-457c-9cc5-ce1fbdf2926d,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-4bc49da0-ab56-4778-bf89-d9ecb02ebddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-60aa8e75-d483-4d7d-9c0c-ea2543505148,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-168c4f0f-c05a-483d-ab35-29ec881474c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-cf420cec-344b-4c06-9d0e-67f1a9a46998,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-bad60780-11ef-4c25-993c-9d6a9696d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-5f29a22f-3a49-4c51-9ce6-a1e848b5536e,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-2cf6b34a-cf5c-4146-b517-5f24085b8522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136708853-172.17.0.16-1597557451520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-69868614-e417-457c-9cc5-ce1fbdf2926d,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-4bc49da0-ab56-4778-bf89-d9ecb02ebddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-60aa8e75-d483-4d7d-9c0c-ea2543505148,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-168c4f0f-c05a-483d-ab35-29ec881474c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-cf420cec-344b-4c06-9d0e-67f1a9a46998,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-bad60780-11ef-4c25-993c-9d6a9696d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-5f29a22f-3a49-4c51-9ce6-a1e848b5536e,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-2cf6b34a-cf5c-4146-b517-5f24085b8522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367419202-172.17.0.16-1597558024119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33732,DS-3152008f-4eb1-4055-a4dc-ac8cac1c3e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-294c7760-1635-403f-abc6-a19c2bf01879,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-79adc896-29b4-4a8d-8cb7-54b7b8cf978a,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ac3f31a4-7fd9-4760-849b-5b6be2a00e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-eaf2f7a7-91b5-42d4-9edd-45e2bb12a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-c65a2d95-3ffe-4f6d-9a96-4eccadbce281,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-a6670600-3bf2-46c8-9843-e178c0249ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-e0f854a2-7c5b-4ea5-a7d6-8bc2551437ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367419202-172.17.0.16-1597558024119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33732,DS-3152008f-4eb1-4055-a4dc-ac8cac1c3e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-294c7760-1635-403f-abc6-a19c2bf01879,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-79adc896-29b4-4a8d-8cb7-54b7b8cf978a,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ac3f31a4-7fd9-4760-849b-5b6be2a00e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-eaf2f7a7-91b5-42d4-9edd-45e2bb12a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-c65a2d95-3ffe-4f6d-9a96-4eccadbce281,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-a6670600-3bf2-46c8-9843-e178c0249ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-e0f854a2-7c5b-4ea5-a7d6-8bc2551437ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124421394-172.17.0.16-1597559483537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-5a624ada-7b98-4245-8491-43c777ad2563,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-2e33e482-61ff-4c8e-a656-574b788b4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-76eb311e-213c-4089-bd17-d2a67a6b0610,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-2cb939fd-c840-4f08-a185-cb25519f6aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-bc77ee81-9967-47d7-97d2-ff3d9b4ce18f,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-a66bd98c-61b0-43aa-8f27-1dd6c6615477,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-c8b9cc7f-1be0-4330-af2a-9908ec9e544f,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-6d344782-dc8d-499c-8d03-42698cfc2979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124421394-172.17.0.16-1597559483537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-5a624ada-7b98-4245-8491-43c777ad2563,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-2e33e482-61ff-4c8e-a656-574b788b4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-76eb311e-213c-4089-bd17-d2a67a6b0610,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-2cb939fd-c840-4f08-a185-cb25519f6aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-bc77ee81-9967-47d7-97d2-ff3d9b4ce18f,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-a66bd98c-61b0-43aa-8f27-1dd6c6615477,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-c8b9cc7f-1be0-4330-af2a-9908ec9e544f,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-6d344782-dc8d-499c-8d03-42698cfc2979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676253855-172.17.0.16-1597560003339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33398,DS-c1d02631-7c3d-4b8a-b591-d8700568f05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-503471d9-02db-49eb-afb9-9ae34160bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-2722cc25-a29d-4807-a0f6-a4f4678b9f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-74311cd4-e7d7-470d-ae14-019aa2eb7742,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-54e9a8f4-19d1-48b4-9b86-65ca87a0a18f,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-0e3c2a66-82d0-408b-9842-7ed12855c567,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-1ae56479-b2b1-483f-91ed-7091c3024617,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-da572592-e480-41e0-9275-a660f06db247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676253855-172.17.0.16-1597560003339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33398,DS-c1d02631-7c3d-4b8a-b591-d8700568f05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-503471d9-02db-49eb-afb9-9ae34160bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-2722cc25-a29d-4807-a0f6-a4f4678b9f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-74311cd4-e7d7-470d-ae14-019aa2eb7742,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-54e9a8f4-19d1-48b4-9b86-65ca87a0a18f,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-0e3c2a66-82d0-408b-9842-7ed12855c567,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-1ae56479-b2b1-483f-91ed-7091c3024617,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-da572592-e480-41e0-9275-a660f06db247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885756630-172.17.0.16-1597560265789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-e0467f7a-daae-4155-9b20-bb8839300573,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c201a23e-236f-449e-b193-dad14f00bd24,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-c7164b3c-bad8-46de-853b-4895f73ba564,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-142cc3b4-48e5-4076-aabc-bd422527114d,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-fe765888-a3bc-45e7-934a-a1b6b3ffccce,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-dde8b9bc-8301-4828-9050-ac80a0c5ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-ee206bd9-fd8d-4dec-90b7-88aaa60324a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-13152e64-5378-46ac-b3c2-5242b5c93363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885756630-172.17.0.16-1597560265789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-e0467f7a-daae-4155-9b20-bb8839300573,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-c201a23e-236f-449e-b193-dad14f00bd24,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-c7164b3c-bad8-46de-853b-4895f73ba564,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-142cc3b4-48e5-4076-aabc-bd422527114d,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-fe765888-a3bc-45e7-934a-a1b6b3ffccce,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-dde8b9bc-8301-4828-9050-ac80a0c5ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-ee206bd9-fd8d-4dec-90b7-88aaa60324a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-13152e64-5378-46ac-b3c2-5242b5c93363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823391678-172.17.0.16-1597560372354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-46dcd948-8dd3-4b5c-82e2-13ea67804be2,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-814e8485-2c37-483c-889b-5f652191c45c,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-f29b6bd8-285a-4e27-b87c-18115acab49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-2898b460-517f-40cf-abb9-8482dd361f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-9ae5444c-f644-4d2b-bdd5-e2c91a717ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-5e99a490-a1db-4fb0-b788-0c4a21d9a647,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-f1c07366-7e6b-4e6b-bcdd-d64e51bd9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-71c2b1cc-8563-4512-ac15-3d3609032368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823391678-172.17.0.16-1597560372354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-46dcd948-8dd3-4b5c-82e2-13ea67804be2,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-814e8485-2c37-483c-889b-5f652191c45c,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-f29b6bd8-285a-4e27-b87c-18115acab49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-2898b460-517f-40cf-abb9-8482dd361f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-9ae5444c-f644-4d2b-bdd5-e2c91a717ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-5e99a490-a1db-4fb0-b788-0c4a21d9a647,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-f1c07366-7e6b-4e6b-bcdd-d64e51bd9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-71c2b1cc-8563-4512-ac15-3d3609032368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253629609-172.17.0.16-1597561883965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-71c57c93-0cc0-45b1-a53c-6f8959ba9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-c7a8a0fd-1e31-46f0-ae79-d860baec5c73,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-63ecbb3c-4c5e-48aa-88fe-cc3cb993f470,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-84412a5c-3757-4532-939f-ca00a8d12886,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-0714df5c-642f-460a-90c8-a112b8d7f26a,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d158f52b-e5ec-4ff2-a17a-f3f029487c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-101f5036-0571-4d58-b5a6-6897d184a584,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-63a4321c-edaf-4e66-b375-1be58c7421e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253629609-172.17.0.16-1597561883965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-71c57c93-0cc0-45b1-a53c-6f8959ba9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-c7a8a0fd-1e31-46f0-ae79-d860baec5c73,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-63ecbb3c-4c5e-48aa-88fe-cc3cb993f470,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-84412a5c-3757-4532-939f-ca00a8d12886,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-0714df5c-642f-460a-90c8-a112b8d7f26a,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d158f52b-e5ec-4ff2-a17a-f3f029487c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-101f5036-0571-4d58-b5a6-6897d184a584,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-63a4321c-edaf-4e66-b375-1be58c7421e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874992553-172.17.0.16-1597561985602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-b2d7ea29-64ca-4d34-8cb5-416864ae25ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-7409e87f-0c09-4a85-b9d3-190cf4fc597a,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-af0c8e07-f06b-47f7-8175-be846d616834,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-b6683b31-c6f1-4405-8436-4fac38769af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-e986d0af-0960-4141-83f2-c4b2f52a4f50,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-36b86a99-67e2-4b71-963f-8936c8d12c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-1a5933a5-9bd1-4e63-8243-c39627512467,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-d31c42ff-6fcd-49a3-adb4-ac2dd1fa45ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874992553-172.17.0.16-1597561985602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-b2d7ea29-64ca-4d34-8cb5-416864ae25ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-7409e87f-0c09-4a85-b9d3-190cf4fc597a,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-af0c8e07-f06b-47f7-8175-be846d616834,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-b6683b31-c6f1-4405-8436-4fac38769af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-e986d0af-0960-4141-83f2-c4b2f52a4f50,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-36b86a99-67e2-4b71-963f-8936c8d12c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-1a5933a5-9bd1-4e63-8243-c39627512467,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-d31c42ff-6fcd-49a3-adb4-ac2dd1fa45ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656233471-172.17.0.16-1597562077685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-61a929e1-fd2d-434a-9faa-48c742a0dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-e59fac08-1602-4e24-bb24-9d43e28d025e,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-4017e7ef-0953-4866-853d-9b604483b969,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-70fd29cc-c482-4aee-8637-8f2ff3fe65ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-65d0792a-54c1-4a01-9a00-dd1821548735,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-65083c06-f844-42d6-acdb-a4138da3c5db,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-489ae891-0520-49dd-a98f-7260519047d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-2b7c6883-c66e-4fea-8222-ed7b8ecadc79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656233471-172.17.0.16-1597562077685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-61a929e1-fd2d-434a-9faa-48c742a0dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-e59fac08-1602-4e24-bb24-9d43e28d025e,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-4017e7ef-0953-4866-853d-9b604483b969,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-70fd29cc-c482-4aee-8637-8f2ff3fe65ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-65d0792a-54c1-4a01-9a00-dd1821548735,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-65083c06-f844-42d6-acdb-a4138da3c5db,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-489ae891-0520-49dd-a98f-7260519047d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-2b7c6883-c66e-4fea-8222-ed7b8ecadc79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126998247-172.17.0.16-1597562318207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-a98a5635-0466-4106-a6d1-7be5ae7b68b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-2074450d-677e-434d-b446-f5e8e5afd099,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-636ee8fb-1d64-4eb7-9900-b15483a697e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-8045deeb-ff7e-48b1-bec1-c8dd49ee136d,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-0799a350-0a3b-4f1c-8110-83505c1fd26e,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-86a40a0c-96d6-4733-bc75-75b4fd8b667d,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-a972506a-e023-4bb0-b102-2038cf6effc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-949a6d6d-fe2d-4084-87f5-d7a3fbcc5bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126998247-172.17.0.16-1597562318207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-a98a5635-0466-4106-a6d1-7be5ae7b68b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-2074450d-677e-434d-b446-f5e8e5afd099,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-636ee8fb-1d64-4eb7-9900-b15483a697e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-8045deeb-ff7e-48b1-bec1-c8dd49ee136d,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-0799a350-0a3b-4f1c-8110-83505c1fd26e,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-86a40a0c-96d6-4733-bc75-75b4fd8b667d,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-a972506a-e023-4bb0-b102-2038cf6effc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-949a6d6d-fe2d-4084-87f5-d7a3fbcc5bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191307542-172.17.0.16-1597562786202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44737,DS-e869e38d-aa0f-4ccc-b4ac-14dcdcf3c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-d928616e-6056-4b05-b5e3-c070030a7379,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-3c3f910f-c63a-40c5-a983-7024eeff7269,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-5b675ceb-ec27-4b4b-a79f-42c41bd09eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-77799edf-8951-4b20-acbd-287ac5aa43a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-deb7d1fc-a910-497d-bb4a-7a583bb668b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-95593b3b-1a53-47d9-a8b0-ba23eb19222b,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-b1f6cc71-0829-4492-a34f-acb4603ae1c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191307542-172.17.0.16-1597562786202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44737,DS-e869e38d-aa0f-4ccc-b4ac-14dcdcf3c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-d928616e-6056-4b05-b5e3-c070030a7379,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-3c3f910f-c63a-40c5-a983-7024eeff7269,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-5b675ceb-ec27-4b4b-a79f-42c41bd09eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-77799edf-8951-4b20-acbd-287ac5aa43a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-deb7d1fc-a910-497d-bb4a-7a583bb668b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-95593b3b-1a53-47d9-a8b0-ba23eb19222b,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-b1f6cc71-0829-4492-a34f-acb4603ae1c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998197279-172.17.0.16-1597563066935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46795,DS-95fe363e-3f6b-45a0-b9c2-c1a8882e8b31,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-a13fa40b-c1a2-4e7b-b435-9c9cd33a72fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-73c68bec-734f-4600-a161-1989d7cac4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-4d7586fc-ebf1-4aa8-8f28-781b357630e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-a84c7cc4-c204-4f31-a904-6f7ff2f81651,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-64e43a22-35d8-4ba9-ac86-cc71ad897bff,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-0c2b16a6-c889-4632-84b4-5e51c32197f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-c2fbf4ed-0f2c-4547-a04a-13a0a1f633c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-998197279-172.17.0.16-1597563066935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46795,DS-95fe363e-3f6b-45a0-b9c2-c1a8882e8b31,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-a13fa40b-c1a2-4e7b-b435-9c9cd33a72fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-73c68bec-734f-4600-a161-1989d7cac4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-4d7586fc-ebf1-4aa8-8f28-781b357630e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-a84c7cc4-c204-4f31-a904-6f7ff2f81651,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-64e43a22-35d8-4ba9-ac86-cc71ad897bff,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-0c2b16a6-c889-4632-84b4-5e51c32197f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-c2fbf4ed-0f2c-4547-a04a-13a0a1f633c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891036481-172.17.0.16-1597563380724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-ceeadb21-7bff-4b82-9c2e-4edef9c94b22,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-b38b2f3c-8bf7-4f84-a525-25e5a8e19854,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-6ec5aac8-877a-487a-b27d-93c76f0a6e05,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-af6a6ffa-4fb2-4fc9-842f-622be39fc23e,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-2540771a-a5b0-4f83-ae3d-ffd340535221,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-2c529ff0-0886-4729-9c2f-a4de6dc932d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-fa7cf395-025f-4818-9013-5b71bc8ad082,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-e86b5ada-2d4d-412f-8d64-02275b4455d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891036481-172.17.0.16-1597563380724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-ceeadb21-7bff-4b82-9c2e-4edef9c94b22,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-b38b2f3c-8bf7-4f84-a525-25e5a8e19854,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-6ec5aac8-877a-487a-b27d-93c76f0a6e05,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-af6a6ffa-4fb2-4fc9-842f-622be39fc23e,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-2540771a-a5b0-4f83-ae3d-ffd340535221,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-2c529ff0-0886-4729-9c2f-a4de6dc932d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-fa7cf395-025f-4818-9013-5b71bc8ad082,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-e86b5ada-2d4d-412f-8d64-02275b4455d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101413424-172.17.0.16-1597563464179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-0668e9d6-9f26-4b81-934b-723841b95f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-8cd04d7d-c8b4-46ed-801e-493acc307338,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-1e9024d1-771e-48e0-9aef-dcb3766c5034,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-6b661db2-31b6-4010-b549-afb3375d72d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-1a765cb3-8e60-464f-b91a-34ebc7e9b99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-bd342cfe-6e5d-4b64-b6e4-14e73dec9060,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-fcbf7c12-6b61-4501-a5bc-30abee74ec45,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-487ab926-024f-4bec-b2ad-6c840f73d5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101413424-172.17.0.16-1597563464179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-0668e9d6-9f26-4b81-934b-723841b95f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-8cd04d7d-c8b4-46ed-801e-493acc307338,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-1e9024d1-771e-48e0-9aef-dcb3766c5034,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-6b661db2-31b6-4010-b549-afb3375d72d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-1a765cb3-8e60-464f-b91a-34ebc7e9b99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-bd342cfe-6e5d-4b64-b6e4-14e73dec9060,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-fcbf7c12-6b61-4501-a5bc-30abee74ec45,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-487ab926-024f-4bec-b2ad-6c840f73d5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6888
