reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484644943-172.17.0.18-1597364108730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-9f9f14e9-0a3f-45d8-852c-c082daa8a0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-b314de7f-0677-4a3e-bf57-3a0a301d6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-9034fd25-c5b3-440e-b6bf-4336e3dd4c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-02839f9c-a5f5-42d6-b157-5391a9254218,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-db10cd14-0e48-4c51-99a2-5d432124006d,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-748046d0-7232-4a5d-8c69-14babb5175fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-90902da1-8d2e-44d0-88d9-c1f7dd78d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-fae7fed0-bf40-4a3d-8e21-7cf21f1c786b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484644943-172.17.0.18-1597364108730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-9f9f14e9-0a3f-45d8-852c-c082daa8a0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-b314de7f-0677-4a3e-bf57-3a0a301d6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-9034fd25-c5b3-440e-b6bf-4336e3dd4c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-02839f9c-a5f5-42d6-b157-5391a9254218,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-db10cd14-0e48-4c51-99a2-5d432124006d,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-748046d0-7232-4a5d-8c69-14babb5175fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-90902da1-8d2e-44d0-88d9-c1f7dd78d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-fae7fed0-bf40-4a3d-8e21-7cf21f1c786b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985160850-172.17.0.18-1597364143628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38886,DS-611bb5ab-236b-4eb5-a59b-a7951f5fc2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-393f8afa-e3c6-49da-a910-0adc9de14cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-63447d31-423b-417e-b996-dd925779e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-c98f7f68-dfaa-4a44-a7e3-1f3e5891af7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-6d803bcc-1636-4af8-a4df-043ce5c2f3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-5595fdee-24ec-4265-a0c7-1d28f1420642,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-7a20467f-6dc7-49d3-97dd-bd969684b607,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-5785b39a-059c-46c6-b593-76600b84f186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985160850-172.17.0.18-1597364143628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38886,DS-611bb5ab-236b-4eb5-a59b-a7951f5fc2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-393f8afa-e3c6-49da-a910-0adc9de14cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-63447d31-423b-417e-b996-dd925779e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-c98f7f68-dfaa-4a44-a7e3-1f3e5891af7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-6d803bcc-1636-4af8-a4df-043ce5c2f3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-5595fdee-24ec-4265-a0c7-1d28f1420642,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-7a20467f-6dc7-49d3-97dd-bd969684b607,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-5785b39a-059c-46c6-b593-76600b84f186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868321452-172.17.0.18-1597364209374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-25de9538-4e6c-4776-9ab9-1b97b7aabdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-7f3378e7-0b0d-4f38-9c40-cf0ef926bc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-8a1a9980-6b97-4148-a869-67cc91ca560d,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-59d6ef35-95da-4102-bbe1-c9a3a69b257d,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-ceab757e-9463-4e73-9db1-aedcb169f71c,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-fa4944db-1064-4460-a4ea-a2f8b8a37468,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-1bf80cda-93f6-407f-9ae8-dfdfc60ac81e,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-89d13e64-9f59-4ca8-a0b7-3af95a376e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868321452-172.17.0.18-1597364209374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-25de9538-4e6c-4776-9ab9-1b97b7aabdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-7f3378e7-0b0d-4f38-9c40-cf0ef926bc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-8a1a9980-6b97-4148-a869-67cc91ca560d,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-59d6ef35-95da-4102-bbe1-c9a3a69b257d,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-ceab757e-9463-4e73-9db1-aedcb169f71c,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-fa4944db-1064-4460-a4ea-a2f8b8a37468,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-1bf80cda-93f6-407f-9ae8-dfdfc60ac81e,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-89d13e64-9f59-4ca8-a0b7-3af95a376e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549839404-172.17.0.18-1597364377803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-69fc1894-a28d-4dad-b47e-815f96c0b100,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-2100c51c-8a14-4f60-98a2-184e16db9f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-b27881ec-38bf-481c-9953-2bb187e32d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-b5975781-d9e8-4d6e-b97e-9272875a9486,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-ba3589af-5772-48ec-9045-6c8d21d62136,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-66d46d33-83e1-4e29-a704-fc192657be7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-2287af62-256e-442d-9ee7-ebb525703bee,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-45bfb3bc-e28a-48a0-85db-42281b13d9e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549839404-172.17.0.18-1597364377803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-69fc1894-a28d-4dad-b47e-815f96c0b100,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-2100c51c-8a14-4f60-98a2-184e16db9f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-b27881ec-38bf-481c-9953-2bb187e32d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-b5975781-d9e8-4d6e-b97e-9272875a9486,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-ba3589af-5772-48ec-9045-6c8d21d62136,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-66d46d33-83e1-4e29-a704-fc192657be7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-2287af62-256e-442d-9ee7-ebb525703bee,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-45bfb3bc-e28a-48a0-85db-42281b13d9e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119948561-172.17.0.18-1597364823307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-15f71d29-39c0-4bf3-8e87-7d784d6808e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-9ca3bcea-f6c0-4ca7-9ed4-9de8ed0cbe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-5e05eb30-3ca2-43f6-bd8a-b6cf3b2c6630,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-b595302e-8b85-4cc0-8b12-00e8cefa7605,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-6c22002a-ef11-4707-884a-4dac4099c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-f81f8b5d-c841-4711-9e3c-2106ff9aa96b,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-bee1bc6b-5f73-4642-b277-f312c6d3c61a,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-4e0bc147-3fb5-400b-aa37-eb364b3fc93a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119948561-172.17.0.18-1597364823307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-15f71d29-39c0-4bf3-8e87-7d784d6808e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-9ca3bcea-f6c0-4ca7-9ed4-9de8ed0cbe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-5e05eb30-3ca2-43f6-bd8a-b6cf3b2c6630,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-b595302e-8b85-4cc0-8b12-00e8cefa7605,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-6c22002a-ef11-4707-884a-4dac4099c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-f81f8b5d-c841-4711-9e3c-2106ff9aa96b,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-bee1bc6b-5f73-4642-b277-f312c6d3c61a,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-4e0bc147-3fb5-400b-aa37-eb364b3fc93a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745945050-172.17.0.18-1597365021612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44309,DS-2e88512a-56f9-4a5b-a4c3-54cf122f3a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-c183aacf-62ae-417f-a070-49db784f0713,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-4572ad49-40d4-42d5-bf5c-90d014a8a936,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-adbec39f-0979-448d-9ba2-146720b095f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-85766020-37c9-4edf-9445-f0fc74bce3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-03e5f2f4-8c60-4304-82e2-e1dcd3ff6264,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-732b6c63-fe06-4f56-a769-7fc9a72f445e,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-f14370df-07ef-4391-bd46-099cd3ede7d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745945050-172.17.0.18-1597365021612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44309,DS-2e88512a-56f9-4a5b-a4c3-54cf122f3a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-c183aacf-62ae-417f-a070-49db784f0713,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-4572ad49-40d4-42d5-bf5c-90d014a8a936,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-adbec39f-0979-448d-9ba2-146720b095f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-85766020-37c9-4edf-9445-f0fc74bce3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-03e5f2f4-8c60-4304-82e2-e1dcd3ff6264,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-732b6c63-fe06-4f56-a769-7fc9a72f445e,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-f14370df-07ef-4391-bd46-099cd3ede7d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775214277-172.17.0.18-1597365100517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40542,DS-dc515ee3-fb0c-4c44-8e71-05d798810ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-cfc2c33f-b98d-4e23-bf5b-6ab98e0c1df8,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-aa4e615b-977a-4162-b5d1-616ce1916dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-371db6af-8111-4b04-bf28-ba5c65dd0ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-ffe6cea8-f643-42f9-98e3-a33f7895db1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-bd99b5ca-bb00-4a60-b782-f26e072220c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-fc5aad74-7aa2-4f2d-9a1e-c7a26aad66a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-a1ae904b-59c5-4019-a249-9348617439a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775214277-172.17.0.18-1597365100517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40542,DS-dc515ee3-fb0c-4c44-8e71-05d798810ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-cfc2c33f-b98d-4e23-bf5b-6ab98e0c1df8,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-aa4e615b-977a-4162-b5d1-616ce1916dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-371db6af-8111-4b04-bf28-ba5c65dd0ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-ffe6cea8-f643-42f9-98e3-a33f7895db1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-bd99b5ca-bb00-4a60-b782-f26e072220c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-fc5aad74-7aa2-4f2d-9a1e-c7a26aad66a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-a1ae904b-59c5-4019-a249-9348617439a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457672116-172.17.0.18-1597365628459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39262,DS-7105a63f-4ba7-4fe7-ae93-55f4c21c64df,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-06c50135-53fc-4d37-beb1-1497b3421d52,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-a42d6586-0326-4384-a615-017da41e0ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-7830257f-f1e9-4f2f-ab30-cafef5e248e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-5073672c-95e3-4fdc-a1b4-676591984533,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-150148ed-b619-4320-901e-f6030652af86,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-6d6fb9cf-cfdf-44e3-b711-b44efda9e3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-a531664a-96fa-4f34-8d67-80596f55d415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457672116-172.17.0.18-1597365628459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39262,DS-7105a63f-4ba7-4fe7-ae93-55f4c21c64df,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-06c50135-53fc-4d37-beb1-1497b3421d52,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-a42d6586-0326-4384-a615-017da41e0ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-7830257f-f1e9-4f2f-ab30-cafef5e248e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-5073672c-95e3-4fdc-a1b4-676591984533,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-150148ed-b619-4320-901e-f6030652af86,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-6d6fb9cf-cfdf-44e3-b711-b44efda9e3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-a531664a-96fa-4f34-8d67-80596f55d415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486183157-172.17.0.18-1597366342595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46316,DS-e5307c18-cadd-4c1e-b583-46b95727d388,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-8c95a8d7-71dd-44b6-8bc3-b5e81e4185fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-6596ecbe-9816-4164-83ac-7c2fd1a75767,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-a260cbe7-7a4d-4f9e-a443-31727efcb3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-896721dd-5c9f-4054-8c14-3dcbd319a136,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-c4fe3522-4bb9-4357-86b9-756108373c45,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-95f6c0c9-bb5e-444e-85c7-17ac9759505f,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-49b150aa-0dbf-4100-924d-e9f9809d6093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486183157-172.17.0.18-1597366342595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46316,DS-e5307c18-cadd-4c1e-b583-46b95727d388,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-8c95a8d7-71dd-44b6-8bc3-b5e81e4185fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-6596ecbe-9816-4164-83ac-7c2fd1a75767,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-a260cbe7-7a4d-4f9e-a443-31727efcb3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-896721dd-5c9f-4054-8c14-3dcbd319a136,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-c4fe3522-4bb9-4357-86b9-756108373c45,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-95f6c0c9-bb5e-444e-85c7-17ac9759505f,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-49b150aa-0dbf-4100-924d-e9f9809d6093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305690524-172.17.0.18-1597366579355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34531,DS-98456975-11b8-479b-8f62-aef48b1616ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-d8db18b7-238f-4071-9b83-7a018ece0106,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-5848c2e8-7cc1-450d-9527-8e62d5ee2151,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-bd3b536f-aa15-41b0-a3c1-1790add7e511,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-4c778ea0-78e8-42cf-a3a9-60754e983341,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-00901e95-1d39-42ee-9c32-507e4e291ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-8d557361-2ae8-4062-8f08-4e03aaeb33f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-261e2b6f-cc92-477a-a99e-793e25023ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305690524-172.17.0.18-1597366579355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34531,DS-98456975-11b8-479b-8f62-aef48b1616ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-d8db18b7-238f-4071-9b83-7a018ece0106,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-5848c2e8-7cc1-450d-9527-8e62d5ee2151,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-bd3b536f-aa15-41b0-a3c1-1790add7e511,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-4c778ea0-78e8-42cf-a3a9-60754e983341,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-00901e95-1d39-42ee-9c32-507e4e291ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-8d557361-2ae8-4062-8f08-4e03aaeb33f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-261e2b6f-cc92-477a-a99e-793e25023ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694586578-172.17.0.18-1597366791557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41273,DS-deab3f34-7736-4a92-8a7f-e44c76339a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-458288f4-463a-4c7a-835e-cf9c3cf131d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-50cd4d4b-2b63-4c60-9081-9e9e994791c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-d8d4e51c-03de-4206-996a-27a29e4dd4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-8573c4af-1214-488e-9013-612caa315178,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-01200d3b-14b8-46fb-b5cc-e4212c04b237,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-74f6a1d0-9efb-4e20-98b7-5559b9cb36a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-e9e65c65-c4cb-4c4d-8c39-5d32ac5360f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694586578-172.17.0.18-1597366791557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41273,DS-deab3f34-7736-4a92-8a7f-e44c76339a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-458288f4-463a-4c7a-835e-cf9c3cf131d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-50cd4d4b-2b63-4c60-9081-9e9e994791c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-d8d4e51c-03de-4206-996a-27a29e4dd4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-8573c4af-1214-488e-9013-612caa315178,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-01200d3b-14b8-46fb-b5cc-e4212c04b237,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-74f6a1d0-9efb-4e20-98b7-5559b9cb36a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-e9e65c65-c4cb-4c4d-8c39-5d32ac5360f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541681139-172.17.0.18-1597366830159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-071a5bd5-77f1-4ba9-99aa-8991c0b1d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-c03f9623-cb45-43ce-b80c-95102e3692f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-84ad5fc9-242d-4dee-a9f8-9721b0a43c06,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-735aa08e-3b87-4eb9-9f80-55340fc634db,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-ffc869f2-564a-44f2-b1d3-94aeb8c8975b,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-dfff3a0c-5a0a-4d1e-b63b-e93254be8aef,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-76833134-0b61-4cfa-9866-f6667ddc5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-2c188b94-4578-4f9e-b028-f535b671f1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541681139-172.17.0.18-1597366830159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-071a5bd5-77f1-4ba9-99aa-8991c0b1d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-c03f9623-cb45-43ce-b80c-95102e3692f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-84ad5fc9-242d-4dee-a9f8-9721b0a43c06,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-735aa08e-3b87-4eb9-9f80-55340fc634db,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-ffc869f2-564a-44f2-b1d3-94aeb8c8975b,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-dfff3a0c-5a0a-4d1e-b63b-e93254be8aef,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-76833134-0b61-4cfa-9866-f6667ddc5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-2c188b94-4578-4f9e-b028-f535b671f1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770381222-172.17.0.18-1597367156219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37836,DS-c4e03b9b-a7ee-4455-bacd-65a86d8a8662,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-85b65402-b588-4d94-a720-ba4248bdebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-d7f88f45-386f-497f-8e82-621e9b660813,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-2f1f3d0f-dd94-4cc4-9d10-d669498be31f,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-19abfd15-8f60-45bf-8554-7e0169b27a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-e2dfa042-426f-4bca-ac0a-48d3f384550b,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-9a9663b0-eaaf-4c49-a104-a42773bc5e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-2bb542d6-2afd-40a2-baf2-f607cb0cbb98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770381222-172.17.0.18-1597367156219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37836,DS-c4e03b9b-a7ee-4455-bacd-65a86d8a8662,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-85b65402-b588-4d94-a720-ba4248bdebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-d7f88f45-386f-497f-8e82-621e9b660813,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-2f1f3d0f-dd94-4cc4-9d10-d669498be31f,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-19abfd15-8f60-45bf-8554-7e0169b27a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-e2dfa042-426f-4bca-ac0a-48d3f384550b,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-9a9663b0-eaaf-4c49-a104-a42773bc5e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-2bb542d6-2afd-40a2-baf2-f607cb0cbb98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49900214-172.17.0.18-1597367659378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45216,DS-3ca95dae-3606-4845-b3cf-a6ec79d42d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-9add2fd8-967a-4bb5-be80-523a9e0c8640,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-2d470932-9f9d-441f-a75f-a3c44f927e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-7ce5c36f-ce9e-4871-b6e5-2416cc1df9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ed593058-8e70-4c56-a153-c4db11e5ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-c6c1208f-8867-4713-b612-5b917baf03ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-1dfb786d-e743-4e27-92f5-99a3da43e8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-ea36212d-ebe3-4d8e-b1ff-8fe2d3ff568d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49900214-172.17.0.18-1597367659378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45216,DS-3ca95dae-3606-4845-b3cf-a6ec79d42d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-9add2fd8-967a-4bb5-be80-523a9e0c8640,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-2d470932-9f9d-441f-a75f-a3c44f927e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-7ce5c36f-ce9e-4871-b6e5-2416cc1df9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ed593058-8e70-4c56-a153-c4db11e5ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-c6c1208f-8867-4713-b612-5b917baf03ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-1dfb786d-e743-4e27-92f5-99a3da43e8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-ea36212d-ebe3-4d8e-b1ff-8fe2d3ff568d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039451404-172.17.0.18-1597368738429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38835,DS-cb199b9d-f297-4bdb-837a-ffac2ef22d22,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-24e1f9ff-faf6-48a2-89f6-2799c05a851d,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-fa60c9d7-5c63-4308-b629-3d2351658077,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-575f7cb3-60f5-4867-bc83-c45a5eedb003,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-5985f748-8a52-46e5-bb36-079e88c55c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-2c963319-5544-48f0-92c0-7bea0381eb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-cbf124ea-93ff-4922-8e12-4258686f31fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-c4ec9471-6862-425e-9d7c-007fb6d57199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039451404-172.17.0.18-1597368738429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38835,DS-cb199b9d-f297-4bdb-837a-ffac2ef22d22,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-24e1f9ff-faf6-48a2-89f6-2799c05a851d,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-fa60c9d7-5c63-4308-b629-3d2351658077,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-575f7cb3-60f5-4867-bc83-c45a5eedb003,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-5985f748-8a52-46e5-bb36-079e88c55c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-2c963319-5544-48f0-92c0-7bea0381eb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-cbf124ea-93ff-4922-8e12-4258686f31fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-c4ec9471-6862-425e-9d7c-007fb6d57199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292111813-172.17.0.18-1597369007869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42984,DS-5d55dcf5-8148-4526-bb50-4e6194c49b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-6fffe448-03d4-4164-b4be-f5af9fc8023e,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-5938e3ad-9831-43c3-a4ed-8690d9f80eff,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-ae621c5b-3161-446e-88be-e2dc250d50ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-f046365e-c265-4f30-a560-428022691978,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-ed2b7277-1e42-40a5-be55-85ee63edb733,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-dca12cd1-bd13-4f3f-adae-14fcc720e68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e3223200-96d2-4c5e-98f5-1e59dafbdd49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292111813-172.17.0.18-1597369007869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42984,DS-5d55dcf5-8148-4526-bb50-4e6194c49b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-6fffe448-03d4-4164-b4be-f5af9fc8023e,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-5938e3ad-9831-43c3-a4ed-8690d9f80eff,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-ae621c5b-3161-446e-88be-e2dc250d50ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-f046365e-c265-4f30-a560-428022691978,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-ed2b7277-1e42-40a5-be55-85ee63edb733,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-dca12cd1-bd13-4f3f-adae-14fcc720e68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e3223200-96d2-4c5e-98f5-1e59dafbdd49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856107608-172.17.0.18-1597369484496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42036,DS-ca3def9b-197e-42f5-b78d-bf761645638c,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-5b57316e-f1be-4dd5-9a9b-411ae25e15af,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-5ab3da5b-1af7-4792-95de-0830ac108a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-ae223e43-ecad-4a7c-8dac-b2e547b130ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-55481fa5-38d5-406e-939b-786492fae0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-e93d2cd6-e7dc-4e28-adf5-14852b50766c,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-a828a196-e89b-43a2-aa0a-7aea9cde7499,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-4eeee6ba-d0c9-4240-bf3c-6a1ba0a7d28f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856107608-172.17.0.18-1597369484496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42036,DS-ca3def9b-197e-42f5-b78d-bf761645638c,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-5b57316e-f1be-4dd5-9a9b-411ae25e15af,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-5ab3da5b-1af7-4792-95de-0830ac108a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-ae223e43-ecad-4a7c-8dac-b2e547b130ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-55481fa5-38d5-406e-939b-786492fae0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-e93d2cd6-e7dc-4e28-adf5-14852b50766c,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-a828a196-e89b-43a2-aa0a-7aea9cde7499,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-4eeee6ba-d0c9-4240-bf3c-6a1ba0a7d28f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266880564-172.17.0.18-1597369520755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-8a199a21-e630-457f-9a06-f2a6d48127a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-f5c7d801-1c42-4f32-9860-b71aad41bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-4c2f8b37-79a2-4a99-939f-e130d8b0fe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-3a00e29f-2fe6-4132-992d-2c5c9dcefd69,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-2c730862-6685-43df-a332-704501ee301f,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-a7813b9b-d791-4571-987a-51c446971ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-21a17c8a-8d39-4a1a-9996-01491939e208,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-9e859e86-b72a-4ea6-9d6b-446d82fa74d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266880564-172.17.0.18-1597369520755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36808,DS-8a199a21-e630-457f-9a06-f2a6d48127a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-f5c7d801-1c42-4f32-9860-b71aad41bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-4c2f8b37-79a2-4a99-939f-e130d8b0fe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-3a00e29f-2fe6-4132-992d-2c5c9dcefd69,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-2c730862-6685-43df-a332-704501ee301f,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-a7813b9b-d791-4571-987a-51c446971ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-21a17c8a-8d39-4a1a-9996-01491939e208,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-9e859e86-b72a-4ea6-9d6b-446d82fa74d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5529
