reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789665422-172.17.0.17-1597507945417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41489,DS-ea219d57-c2b1-4d55-ae34-ae9e75fad481,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-e7c8af7d-efa6-42cd-b78a-f254f513b31b,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-a279208c-05d3-486d-b808-d0dbe301bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-618d8ef5-fe4c-4655-9f85-79d7d2c846c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-29a629d1-e891-4105-bca9-6eaabb29c6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-f45a1e13-a7f4-407b-9965-2605ea6f8d36,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-f7380a99-9c3a-4079-9750-50bf645ca001,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-c95d3322-9c53-4b03-a6d3-556c200310d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789665422-172.17.0.17-1597507945417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41489,DS-ea219d57-c2b1-4d55-ae34-ae9e75fad481,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-e7c8af7d-efa6-42cd-b78a-f254f513b31b,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-a279208c-05d3-486d-b808-d0dbe301bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-618d8ef5-fe4c-4655-9f85-79d7d2c846c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-29a629d1-e891-4105-bca9-6eaabb29c6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-f45a1e13-a7f4-407b-9965-2605ea6f8d36,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-f7380a99-9c3a-4079-9750-50bf645ca001,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-c95d3322-9c53-4b03-a6d3-556c200310d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082758072-172.17.0.17-1597508226432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-fdf03dc1-41ab-477b-899c-33ffef910178,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-3b87455c-a06c-4460-987c-f68056396106,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-f92b3004-514c-4bb8-858c-c0a78a1d6d13,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-d49f8ef7-dce4-443f-b72c-acf716ca6e22,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-90e82f09-40f3-429a-9ec8-1a20379a6473,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-f1a63c15-3127-46b2-b809-7a25f9c88fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-b1ff9afd-0e4a-43bc-a829-3349e4187e82,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-ab26190e-dcc5-4f00-90bf-2b08237bb1c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082758072-172.17.0.17-1597508226432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-fdf03dc1-41ab-477b-899c-33ffef910178,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-3b87455c-a06c-4460-987c-f68056396106,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-f92b3004-514c-4bb8-858c-c0a78a1d6d13,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-d49f8ef7-dce4-443f-b72c-acf716ca6e22,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-90e82f09-40f3-429a-9ec8-1a20379a6473,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-f1a63c15-3127-46b2-b809-7a25f9c88fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-b1ff9afd-0e4a-43bc-a829-3349e4187e82,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-ab26190e-dcc5-4f00-90bf-2b08237bb1c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145398562-172.17.0.17-1597508375160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-b2c7bf9d-f9f8-471f-923e-2e6b89ae6286,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-6006ef82-6ed6-4d9a-8cbf-426b237ce827,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-46c04d6a-5ff7-4b89-a9b2-d1da83deed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-6e52f122-05c3-4a48-a71b-2a9150ec870f,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-3981ced9-773f-4460-ba95-bbb5d180a215,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-e0a6f182-7b09-4a91-80f0-34a899eaf533,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-e99ccb80-3f05-449c-a968-2a283cf905cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-6fcb3266-eae3-44ae-b06c-a715d5ffb922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145398562-172.17.0.17-1597508375160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-b2c7bf9d-f9f8-471f-923e-2e6b89ae6286,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-6006ef82-6ed6-4d9a-8cbf-426b237ce827,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-46c04d6a-5ff7-4b89-a9b2-d1da83deed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-6e52f122-05c3-4a48-a71b-2a9150ec870f,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-3981ced9-773f-4460-ba95-bbb5d180a215,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-e0a6f182-7b09-4a91-80f0-34a899eaf533,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-e99ccb80-3f05-449c-a968-2a283cf905cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-6fcb3266-eae3-44ae-b06c-a715d5ffb922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541835052-172.17.0.17-1597508460869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36712,DS-88089397-075d-4cf2-a518-1c50fb7a0b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-f452882d-46fd-43cc-880e-70ed0135de9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-90efd1ec-03ee-45dd-acc3-de480120449a,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-ca6c1a95-bfc0-4fb0-a045-cd6c871f0811,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-de8ee06c-ddd5-4740-a323-97525db91c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-de43be30-b2df-47db-a716-1a20d6fa45f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-cb5430ca-c63f-471a-a207-321f8272b6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-7b897dcc-5d69-48a6-b491-3e65df96bad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541835052-172.17.0.17-1597508460869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36712,DS-88089397-075d-4cf2-a518-1c50fb7a0b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-f452882d-46fd-43cc-880e-70ed0135de9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-90efd1ec-03ee-45dd-acc3-de480120449a,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-ca6c1a95-bfc0-4fb0-a045-cd6c871f0811,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-de8ee06c-ddd5-4740-a323-97525db91c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-de43be30-b2df-47db-a716-1a20d6fa45f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-cb5430ca-c63f-471a-a207-321f8272b6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-7b897dcc-5d69-48a6-b491-3e65df96bad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886459954-172.17.0.17-1597509362907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42908,DS-16a2925d-7dd6-4b58-9b36-1c4cf95ed535,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-b14ae479-92d7-48e2-8a9a-383ab0525c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-94500c24-29b9-4515-bb9a-72c8fdae6e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-e24607f4-19cf-43ce-b595-81c7a2b42f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-96dba2ef-b2be-421d-a092-36e7241c19db,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-498fdbbb-8d8c-4947-9bfa-30cb49bb6ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-64c51f2b-ee07-438a-9609-71d082b50c46,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-2a4c83d9-29b4-4e5e-a6fd-1bf8a647605c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886459954-172.17.0.17-1597509362907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42908,DS-16a2925d-7dd6-4b58-9b36-1c4cf95ed535,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-b14ae479-92d7-48e2-8a9a-383ab0525c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-94500c24-29b9-4515-bb9a-72c8fdae6e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-e24607f4-19cf-43ce-b595-81c7a2b42f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-96dba2ef-b2be-421d-a092-36e7241c19db,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-498fdbbb-8d8c-4947-9bfa-30cb49bb6ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-64c51f2b-ee07-438a-9609-71d082b50c46,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-2a4c83d9-29b4-4e5e-a6fd-1bf8a647605c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569502239-172.17.0.17-1597509397690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-b2bce35c-abdf-4212-98bc-8305b818c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-22ad5abc-31b0-4ed4-b4ab-13103612d576,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-7caa2743-2502-4539-aca9-e747ff0ccdad,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-5be4b369-8af4-4077-aa0c-2884391a5a25,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-f378d148-db0e-47ff-a663-4a9538748731,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-046b80be-c9fd-4bd1-9713-8087a5fc5ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-edc15a94-b473-4102-a921-6aefcc6be04c,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-415738b2-7e03-4552-b09e-7ba57ce7a55b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569502239-172.17.0.17-1597509397690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-b2bce35c-abdf-4212-98bc-8305b818c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-22ad5abc-31b0-4ed4-b4ab-13103612d576,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-7caa2743-2502-4539-aca9-e747ff0ccdad,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-5be4b369-8af4-4077-aa0c-2884391a5a25,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-f378d148-db0e-47ff-a663-4a9538748731,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-046b80be-c9fd-4bd1-9713-8087a5fc5ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-edc15a94-b473-4102-a921-6aefcc6be04c,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-415738b2-7e03-4552-b09e-7ba57ce7a55b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768797595-172.17.0.17-1597509440302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46066,DS-50ed59b0-8c69-4278-8864-6cfcc19110e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-6d8a0ea6-e56e-43b8-8ef4-1229ef83144e,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-ebcd7440-68ab-47e8-a00a-c8683e159291,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-864c6448-a491-4df4-a28d-4b4f2b8fb4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-9e151515-2030-4017-9104-4475dc47cfec,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-4fb3792a-fe58-486b-ace2-5af0fd88fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-5a69eba9-be5a-431c-acce-ee36cf8c5cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-c6b4654d-67be-4428-b961-ea3dcf92d798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768797595-172.17.0.17-1597509440302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46066,DS-50ed59b0-8c69-4278-8864-6cfcc19110e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-6d8a0ea6-e56e-43b8-8ef4-1229ef83144e,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-ebcd7440-68ab-47e8-a00a-c8683e159291,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-864c6448-a491-4df4-a28d-4b4f2b8fb4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-9e151515-2030-4017-9104-4475dc47cfec,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-4fb3792a-fe58-486b-ace2-5af0fd88fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-5a69eba9-be5a-431c-acce-ee36cf8c5cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-c6b4654d-67be-4428-b961-ea3dcf92d798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983853238-172.17.0.17-1597510853718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-7aa0d966-04b6-42a1-83f7-ba9f65c51da2,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-cd2b362c-843b-4264-ba94-cf77f46de5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-5523e89a-20c0-4678-907c-19cfcec5a25f,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-6016f56d-78ba-4710-9fa4-8b11d5148b06,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-bb6e9a49-3483-40a7-a63d-319984031293,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-b2ceb44b-3705-4e22-a592-a5f2c5d80c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-06f36b3c-d1be-4aa2-b36f-f29bd2f26916,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-8b5de7c1-3437-42d9-bcd1-093a59caa6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983853238-172.17.0.17-1597510853718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-7aa0d966-04b6-42a1-83f7-ba9f65c51da2,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-cd2b362c-843b-4264-ba94-cf77f46de5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-5523e89a-20c0-4678-907c-19cfcec5a25f,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-6016f56d-78ba-4710-9fa4-8b11d5148b06,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-bb6e9a49-3483-40a7-a63d-319984031293,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-b2ceb44b-3705-4e22-a592-a5f2c5d80c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-06f36b3c-d1be-4aa2-b36f-f29bd2f26916,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-8b5de7c1-3437-42d9-bcd1-093a59caa6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847563157-172.17.0.17-1597511130702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40485,DS-5707f541-e504-4aef-896f-c9b96faa7dad,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-05a4fbfd-b19f-462f-b70f-4c04bc619882,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-7919f293-b789-407c-a420-792f8921dfce,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-2204abe0-69a3-4185-89bf-1631d24f90d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-cf80bd21-30bf-4fcd-9434-1e4fee07c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-86229a65-849c-4a57-92e7-3a48675db4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-82c1c378-f6a0-45ff-a3e3-c5de858f20e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-8b46624d-c2d1-4e6e-a5da-8779c56e5fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847563157-172.17.0.17-1597511130702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40485,DS-5707f541-e504-4aef-896f-c9b96faa7dad,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-05a4fbfd-b19f-462f-b70f-4c04bc619882,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-7919f293-b789-407c-a420-792f8921dfce,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-2204abe0-69a3-4185-89bf-1631d24f90d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-cf80bd21-30bf-4fcd-9434-1e4fee07c4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-86229a65-849c-4a57-92e7-3a48675db4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-82c1c378-f6a0-45ff-a3e3-c5de858f20e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-8b46624d-c2d1-4e6e-a5da-8779c56e5fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563470415-172.17.0.17-1597511436506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45278,DS-176bcb91-99ab-4001-87b9-1720439c2135,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-8fdb72fe-9c49-4c9c-87d2-80e453987307,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-4c101239-3b8b-42d2-99b7-c5f18248bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-b318297d-c486-43b2-bfac-a1ed9506fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-b54241a7-39a2-4497-8c10-2a015ed5f3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-bec21fca-00d2-4f3b-b5e6-28d52c569475,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-ebece509-c8fd-41bb-bf11-dd195fa11f43,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-04fc1512-358b-4666-9e2f-89f3f2d60b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563470415-172.17.0.17-1597511436506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45278,DS-176bcb91-99ab-4001-87b9-1720439c2135,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-8fdb72fe-9c49-4c9c-87d2-80e453987307,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-4c101239-3b8b-42d2-99b7-c5f18248bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-b318297d-c486-43b2-bfac-a1ed9506fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-b54241a7-39a2-4497-8c10-2a015ed5f3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-bec21fca-00d2-4f3b-b5e6-28d52c569475,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-ebece509-c8fd-41bb-bf11-dd195fa11f43,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-04fc1512-358b-4666-9e2f-89f3f2d60b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79970539-172.17.0.17-1597512114183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33376,DS-a79165b5-b64f-4b5d-9a5f-74b8388c8bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-6bb68822-360e-4998-b796-5b4ab4b7deb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-e9713b0e-beed-4426-b3b0-0c2ee618bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8c01ad72-9b67-4b5d-82ea-9f36278f84a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-1da5fc0b-3bab-4d43-8ccc-132f83d2c127,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-d6154658-52f0-4ee9-be17-0bdfc1ae00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-a0f94894-875d-40f5-b90e-cbd306b7c200,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-21940ca9-d79a-449b-a5f3-bfcd19d572c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79970539-172.17.0.17-1597512114183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33376,DS-a79165b5-b64f-4b5d-9a5f-74b8388c8bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-6bb68822-360e-4998-b796-5b4ab4b7deb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-e9713b0e-beed-4426-b3b0-0c2ee618bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8c01ad72-9b67-4b5d-82ea-9f36278f84a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-1da5fc0b-3bab-4d43-8ccc-132f83d2c127,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-d6154658-52f0-4ee9-be17-0bdfc1ae00e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-a0f94894-875d-40f5-b90e-cbd306b7c200,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-21940ca9-d79a-449b-a5f3-bfcd19d572c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654467220-172.17.0.17-1597512388558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44024,DS-90775c02-c92b-455f-841b-5fe44b3eb434,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-c269b836-1b30-4ebd-a1ca-66fb4f29daf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-f88b57df-17ab-46df-992a-201bbd908e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-5dd4e7d0-b781-4703-959b-992eb362e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-5562271e-5081-49eb-bd63-9eae99724c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-30bb4623-92dd-4a16-bfe2-6fa76ba87159,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-90253329-6914-4e8d-9a4a-019417fa8916,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-2980666b-ebc6-48cb-94ae-0d81863a846a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654467220-172.17.0.17-1597512388558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44024,DS-90775c02-c92b-455f-841b-5fe44b3eb434,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-c269b836-1b30-4ebd-a1ca-66fb4f29daf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-f88b57df-17ab-46df-992a-201bbd908e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-5dd4e7d0-b781-4703-959b-992eb362e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-5562271e-5081-49eb-bd63-9eae99724c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-30bb4623-92dd-4a16-bfe2-6fa76ba87159,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-90253329-6914-4e8d-9a4a-019417fa8916,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-2980666b-ebc6-48cb-94ae-0d81863a846a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819176248-172.17.0.17-1597512864379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-15017f24-4dcd-472a-aaad-b430ab9876e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-821ce536-d17b-49f4-98dc-e6fc19e1c587,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-693ccf86-bac2-4238-b6b4-c2719d222067,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-26cca585-830b-4626-8f0c-47a04e26ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-ce22e68b-ceae-42c8-9f2a-02f10c70defe,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-f5376708-492b-485b-b0cc-8cc0f3de977a,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-a8c8ebc9-1436-4f76-a7a9-54186db707ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-55423aac-7199-47ce-b155-0d02956b572e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819176248-172.17.0.17-1597512864379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-15017f24-4dcd-472a-aaad-b430ab9876e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-821ce536-d17b-49f4-98dc-e6fc19e1c587,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-693ccf86-bac2-4238-b6b4-c2719d222067,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-26cca585-830b-4626-8f0c-47a04e26ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-ce22e68b-ceae-42c8-9f2a-02f10c70defe,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-f5376708-492b-485b-b0cc-8cc0f3de977a,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-a8c8ebc9-1436-4f76-a7a9-54186db707ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-55423aac-7199-47ce-b155-0d02956b572e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046398666-172.17.0.17-1597513063794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43560,DS-07e30894-28ab-4201-b986-b3b437d1cb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-4b7b5e7b-63e2-4925-8c14-3055219017b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-c8a5d08a-4987-4816-8c3f-c8156d2e1eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-51a2e318-1ac2-4364-b19e-a58a606c1de7,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-195e1385-003c-4081-bf39-ffd213c6da3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-9dfc6341-0470-47d5-a390-d9de9a4f90c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-ff89c426-ac11-4590-ab4a-32d4cfe5903f,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-aa6aca57-97ff-45b5-986f-033c63801cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046398666-172.17.0.17-1597513063794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43560,DS-07e30894-28ab-4201-b986-b3b437d1cb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-4b7b5e7b-63e2-4925-8c14-3055219017b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-c8a5d08a-4987-4816-8c3f-c8156d2e1eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-51a2e318-1ac2-4364-b19e-a58a606c1de7,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-195e1385-003c-4081-bf39-ffd213c6da3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-9dfc6341-0470-47d5-a390-d9de9a4f90c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-ff89c426-ac11-4590-ab4a-32d4cfe5903f,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-aa6aca57-97ff-45b5-986f-033c63801cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299080496-172.17.0.17-1597513108286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-c0bf3d34-fc00-4637-afcc-1e5b6028ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-a087ddf3-ec22-422e-ac50-12b4a6206831,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-bca0660d-d013-4e8a-b777-16d857f59a03,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-1acc4b08-2e4a-46cc-b262-57c8b7d0bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-7202afc1-b3d1-4370-ac5c-65010f372078,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-089dee5e-9213-4d64-b126-211184696744,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-5b33a0b1-bede-46c1-a6e6-3d84762e8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-2f2ffd53-0380-424b-a7f5-9035c3abb7e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299080496-172.17.0.17-1597513108286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-c0bf3d34-fc00-4637-afcc-1e5b6028ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-a087ddf3-ec22-422e-ac50-12b4a6206831,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-bca0660d-d013-4e8a-b777-16d857f59a03,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-1acc4b08-2e4a-46cc-b262-57c8b7d0bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-7202afc1-b3d1-4370-ac5c-65010f372078,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-089dee5e-9213-4d64-b126-211184696744,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-5b33a0b1-bede-46c1-a6e6-3d84762e8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-2f2ffd53-0380-424b-a7f5-9035c3abb7e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007577790-172.17.0.17-1597513456021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41439,DS-e19d0f8d-782f-4557-a00d-65b2cd5388e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-9deb5b22-3bdb-48c1-84f8-4bb742ae1198,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-bd8d5314-ae1a-44fe-9a0a-df767896528e,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-cb1534c6-f141-476d-827f-fbb075569921,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-b4fe88c9-61cb-4eda-84bd-ad618b46d787,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-e748a0cf-5d83-4c72-8760-f0a13414e303,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-eae970cf-00cc-4ad9-afb5-59b03e76a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-0c3bd497-e3e1-4c62-b619-d2a0fed9a2f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007577790-172.17.0.17-1597513456021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41439,DS-e19d0f8d-782f-4557-a00d-65b2cd5388e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-9deb5b22-3bdb-48c1-84f8-4bb742ae1198,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-bd8d5314-ae1a-44fe-9a0a-df767896528e,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-cb1534c6-f141-476d-827f-fbb075569921,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-b4fe88c9-61cb-4eda-84bd-ad618b46d787,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-e748a0cf-5d83-4c72-8760-f0a13414e303,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-eae970cf-00cc-4ad9-afb5-59b03e76a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-0c3bd497-e3e1-4c62-b619-d2a0fed9a2f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368018253-172.17.0.17-1597514044988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45371,DS-21400b74-13a4-45c7-b909-5e7ea74e31dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-722fd38d-5a98-43c9-87d8-52f5fbde951a,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-9618136b-e881-4deb-9bed-9b1509117fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-c367749d-9d83-4c11-ae98-243e76e87800,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-df0fae8c-ac51-455a-9673-30dd51c0a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-4e7c93c7-e514-4840-8c3f-90b6273c07c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-f198c437-e96c-404d-a042-26620ed165f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-d9d494fb-e98d-44c3-abb6-918d79908391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368018253-172.17.0.17-1597514044988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45371,DS-21400b74-13a4-45c7-b909-5e7ea74e31dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-722fd38d-5a98-43c9-87d8-52f5fbde951a,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-9618136b-e881-4deb-9bed-9b1509117fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-c367749d-9d83-4c11-ae98-243e76e87800,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-df0fae8c-ac51-455a-9673-30dd51c0a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-4e7c93c7-e514-4840-8c3f-90b6273c07c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-f198c437-e96c-404d-a042-26620ed165f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-d9d494fb-e98d-44c3-abb6-918d79908391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923450750-172.17.0.17-1597514840367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33384,DS-ca358e85-7e4d-4090-a29f-9642665880ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-a555c31c-2f1f-49ee-853c-8de7163cc57c,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-549f422a-4dd9-4edd-a73b-52c367b9721a,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-2eec2301-3b75-468d-8b7e-491442f0a6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-becaf1a2-e6fc-44ff-b5de-a4ebf4dfc0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-68f7b69a-f951-484b-bc13-0d9bc2b9ec2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-cb1e2031-c76a-427d-85ef-62a9bfeb6fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-8c612454-35a2-4c97-b1e0-cedcbaadbd9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923450750-172.17.0.17-1597514840367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33384,DS-ca358e85-7e4d-4090-a29f-9642665880ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-a555c31c-2f1f-49ee-853c-8de7163cc57c,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-549f422a-4dd9-4edd-a73b-52c367b9721a,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-2eec2301-3b75-468d-8b7e-491442f0a6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-becaf1a2-e6fc-44ff-b5de-a4ebf4dfc0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-68f7b69a-f951-484b-bc13-0d9bc2b9ec2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-cb1e2031-c76a-427d-85ef-62a9bfeb6fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-8c612454-35a2-4c97-b1e0-cedcbaadbd9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7187
