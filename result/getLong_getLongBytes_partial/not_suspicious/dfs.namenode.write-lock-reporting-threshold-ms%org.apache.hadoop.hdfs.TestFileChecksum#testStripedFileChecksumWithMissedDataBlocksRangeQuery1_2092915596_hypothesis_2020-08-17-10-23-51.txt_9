reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283790196-172.17.0.21-1597660407874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36665,DS-a3bc4ddf-2df2-45aa-880b-96fe425fe196,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-a97bf3d7-33e0-4289-8d77-4f31ced2ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-6bbe0de0-4936-459d-bfd6-14789ba88063,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-0ff153e9-b9d7-48f2-bbf3-bdad6717a703,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-a6202872-4d22-44aa-bc37-9c81ea9eb276,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-3c8435e3-e847-4099-b87d-42b4db6a72b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-80c0e617-6f39-424e-a12c-bd1acf796b07,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-c3ba2a01-e8ff-49b8-9c75-63fb23717085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283790196-172.17.0.21-1597660407874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36665,DS-a3bc4ddf-2df2-45aa-880b-96fe425fe196,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-a97bf3d7-33e0-4289-8d77-4f31ced2ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-6bbe0de0-4936-459d-bfd6-14789ba88063,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-0ff153e9-b9d7-48f2-bbf3-bdad6717a703,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-a6202872-4d22-44aa-bc37-9c81ea9eb276,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-3c8435e3-e847-4099-b87d-42b4db6a72b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-80c0e617-6f39-424e-a12c-bd1acf796b07,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-c3ba2a01-e8ff-49b8-9c75-63fb23717085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40908446-172.17.0.21-1597661358602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36063,DS-0fa81deb-9bec-4a5b-9a9b-ffe358fe300c,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-f8a6b833-f9e7-499b-820a-2b4f7de6c0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-f98a5a19-81c8-4b30-b2dc-8ecd07e45eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-b8cc8ece-dd94-4de1-b4f0-2a9445476d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-6c591e86-8c1d-47d0-8c6b-f487e66428ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-1c35a89d-471d-4605-8be0-89b907e4df57,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-ccbb84e3-d09c-4c75-8dd9-f688f33fe417,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-dc2ca69a-89fa-4be0-9e3b-83651e3936b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40908446-172.17.0.21-1597661358602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36063,DS-0fa81deb-9bec-4a5b-9a9b-ffe358fe300c,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-f8a6b833-f9e7-499b-820a-2b4f7de6c0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-f98a5a19-81c8-4b30-b2dc-8ecd07e45eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-b8cc8ece-dd94-4de1-b4f0-2a9445476d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-6c591e86-8c1d-47d0-8c6b-f487e66428ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-1c35a89d-471d-4605-8be0-89b907e4df57,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-ccbb84e3-d09c-4c75-8dd9-f688f33fe417,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-dc2ca69a-89fa-4be0-9e3b-83651e3936b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673766066-172.17.0.21-1597662377882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34851,DS-51e68c9e-5db4-4128-86fb-59363d1b0526,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-321708f0-2906-4726-8390-10603e25fa73,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-3c893c10-323a-42cc-b16f-5b8c43e1658b,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-00087f79-ae8c-4d86-96ee-6636ff5f5672,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-6ba5c71d-d6dc-45b8-b823-ad337a3f8737,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-fc332e08-7ceb-4b19-8ae1-8b5ee1aa0f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-92efa2d5-d437-4607-8c09-473f4435ecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-14e7a4b4-cfe9-45b5-8086-234e436fe1ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673766066-172.17.0.21-1597662377882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34851,DS-51e68c9e-5db4-4128-86fb-59363d1b0526,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-321708f0-2906-4726-8390-10603e25fa73,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-3c893c10-323a-42cc-b16f-5b8c43e1658b,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-00087f79-ae8c-4d86-96ee-6636ff5f5672,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-6ba5c71d-d6dc-45b8-b823-ad337a3f8737,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-fc332e08-7ceb-4b19-8ae1-8b5ee1aa0f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-92efa2d5-d437-4607-8c09-473f4435ecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-14e7a4b4-cfe9-45b5-8086-234e436fe1ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55994622-172.17.0.21-1597662420689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44036,DS-5b169a45-7d19-4e8e-9135-22a8f1c64335,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-c56a26eb-8b92-4765-96ac-4ed610cd5187,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-3763f7e3-9d7c-4df4-98f6-71c0bfb1bcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-b637992e-ddb3-4995-9502-be4b3b269059,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-8cb5c727-70da-4ea6-bb16-8733db220fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c48ee86b-0e01-4ff4-90c2-696f99625624,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-ee398113-e8bc-4c03-9b9c-37cd6b89aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-5914da88-f301-4580-8227-42ee72461db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55994622-172.17.0.21-1597662420689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44036,DS-5b169a45-7d19-4e8e-9135-22a8f1c64335,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-c56a26eb-8b92-4765-96ac-4ed610cd5187,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-3763f7e3-9d7c-4df4-98f6-71c0bfb1bcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-b637992e-ddb3-4995-9502-be4b3b269059,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-8cb5c727-70da-4ea6-bb16-8733db220fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c48ee86b-0e01-4ff4-90c2-696f99625624,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-ee398113-e8bc-4c03-9b9c-37cd6b89aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-5914da88-f301-4580-8227-42ee72461db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568092052-172.17.0.21-1597662590942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44873,DS-b630702a-88e3-42e2-a3a2-97158db929ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-10f013cc-fcb7-4b85-8013-db0ae6749410,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-0a01b0c2-1ca1-4c05-98c3-5aa478144ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-2b7b7da3-b52c-4c7b-9521-39000b52eeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-c502be02-07db-4053-abb5-d317ecc6afab,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-fde2af76-07f4-4a25-bd6c-b56f6c9c54f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-21fbf5cd-cf01-40b1-bf23-539507d302bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-d135305f-ea0c-4f3d-bb2b-a852d5c24c82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568092052-172.17.0.21-1597662590942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44873,DS-b630702a-88e3-42e2-a3a2-97158db929ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-10f013cc-fcb7-4b85-8013-db0ae6749410,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-0a01b0c2-1ca1-4c05-98c3-5aa478144ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-2b7b7da3-b52c-4c7b-9521-39000b52eeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-c502be02-07db-4053-abb5-d317ecc6afab,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-fde2af76-07f4-4a25-bd6c-b56f6c9c54f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-21fbf5cd-cf01-40b1-bf23-539507d302bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-d135305f-ea0c-4f3d-bb2b-a852d5c24c82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827434341-172.17.0.21-1597662642644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-fb1aaeb7-296a-4835-8575-94657e0fe736,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-428351e6-fc1f-4290-ae00-1ed4d16c003c,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-3263527f-005b-47a1-a0b2-ecfec6c3bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-add1143a-c41f-4bde-b822-e204018a5d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-27a9f13c-2bcf-4b89-856f-3c75fd2f1ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-3205ef74-bae3-4dea-b715-91e90a07e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-91e45167-ee34-4c3a-8230-189fea45dfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-0135ea89-f8c8-4213-af1e-0ead80d0570c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827434341-172.17.0.21-1597662642644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-fb1aaeb7-296a-4835-8575-94657e0fe736,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-428351e6-fc1f-4290-ae00-1ed4d16c003c,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-3263527f-005b-47a1-a0b2-ecfec6c3bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-add1143a-c41f-4bde-b822-e204018a5d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-27a9f13c-2bcf-4b89-856f-3c75fd2f1ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-3205ef74-bae3-4dea-b715-91e90a07e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-91e45167-ee34-4c3a-8230-189fea45dfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-0135ea89-f8c8-4213-af1e-0ead80d0570c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543806695-172.17.0.21-1597663279456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33271,DS-e8a6eccb-9bf5-482e-9828-e31a71b44bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-6281bb19-94d0-4f72-8c13-07243aa9955e,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-2abe33d1-4232-4b85-b515-29479456d868,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-f9f97fff-cb5f-42e6-aebe-f7c816944036,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-1b83a29d-4d54-4e26-9061-7c2d2547069a,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-d180d1d8-f7bc-42fd-95f5-b62406df5f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-4e01834c-d630-4a6c-9d71-c9454c3471f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-34bf865e-7ffd-417e-8970-67cc7cf058c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543806695-172.17.0.21-1597663279456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33271,DS-e8a6eccb-9bf5-482e-9828-e31a71b44bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-6281bb19-94d0-4f72-8c13-07243aa9955e,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-2abe33d1-4232-4b85-b515-29479456d868,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-f9f97fff-cb5f-42e6-aebe-f7c816944036,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-1b83a29d-4d54-4e26-9061-7c2d2547069a,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-d180d1d8-f7bc-42fd-95f5-b62406df5f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-4e01834c-d630-4a6c-9d71-c9454c3471f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-34bf865e-7ffd-417e-8970-67cc7cf058c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280786286-172.17.0.21-1597663571780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-a37a875f-3043-4e42-9727-e60229acb06e,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-feead01e-42b0-4502-adc7-581b393784db,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-fdb87da9-6ea1-40ae-909c-67acb45ff77c,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-51637791-fc3a-4770-bce1-7ba6d2ad47a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-6086de0a-f73b-4aef-a358-2367cd17a0af,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-04469c68-6969-461d-906b-1ef7009fb8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-545c377c-032f-4b3e-89c2-76cc7710bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-785b2b26-99a8-4b88-870a-7cc312824fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280786286-172.17.0.21-1597663571780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-a37a875f-3043-4e42-9727-e60229acb06e,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-feead01e-42b0-4502-adc7-581b393784db,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-fdb87da9-6ea1-40ae-909c-67acb45ff77c,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-51637791-fc3a-4770-bce1-7ba6d2ad47a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-6086de0a-f73b-4aef-a358-2367cd17a0af,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-04469c68-6969-461d-906b-1ef7009fb8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-545c377c-032f-4b3e-89c2-76cc7710bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-785b2b26-99a8-4b88-870a-7cc312824fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111745980-172.17.0.21-1597663616614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-12a0635a-e32b-4db7-a202-675a07d98058,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-10d56691-8e3e-443b-91a3-94239d209976,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-ec91bf54-95f9-410b-bd24-890a03d1c281,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-d061468f-aeb7-4d5c-bea8-6d3398b673ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-c4cdfa0e-e8e1-4037-8166-9756d0004a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-88347a26-86ea-435c-9c63-f8be926abee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-925211e4-7e97-45f1-b19d-4d69a71da27e,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-cb3d4500-2ab6-4f20-97df-58a9e7596cf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111745980-172.17.0.21-1597663616614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-12a0635a-e32b-4db7-a202-675a07d98058,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-10d56691-8e3e-443b-91a3-94239d209976,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-ec91bf54-95f9-410b-bd24-890a03d1c281,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-d061468f-aeb7-4d5c-bea8-6d3398b673ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-c4cdfa0e-e8e1-4037-8166-9756d0004a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-88347a26-86ea-435c-9c63-f8be926abee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-925211e4-7e97-45f1-b19d-4d69a71da27e,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-cb3d4500-2ab6-4f20-97df-58a9e7596cf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840624413-172.17.0.21-1597663784354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35810,DS-d66d9476-e740-499f-9809-e346472334b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-94ca6510-9709-4a98-a78b-dd3657213062,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-3db4b636-e0d1-487b-bfa2-0bde04e4f951,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-3dfcadca-4fd6-442a-9312-488557f3d3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-2885aabd-a37f-481a-aaa0-d3240e3e44bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-b8313e0e-27c2-427f-a167-1c2690cf84bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-3baaf5e4-c90e-4a6d-bd88-c3f4d1abb478,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-45cfe140-aa5e-4a9f-b8b1-64488e8789a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840624413-172.17.0.21-1597663784354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35810,DS-d66d9476-e740-499f-9809-e346472334b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-94ca6510-9709-4a98-a78b-dd3657213062,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-3db4b636-e0d1-487b-bfa2-0bde04e4f951,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-3dfcadca-4fd6-442a-9312-488557f3d3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-2885aabd-a37f-481a-aaa0-d3240e3e44bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-b8313e0e-27c2-427f-a167-1c2690cf84bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-3baaf5e4-c90e-4a6d-bd88-c3f4d1abb478,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-45cfe140-aa5e-4a9f-b8b1-64488e8789a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738320265-172.17.0.21-1597663827017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43100,DS-5142ebce-513c-4036-ae87-43f6241bed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-6bef8ef4-f214-40ae-ace2-ce94ac7e1203,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-93e4ba64-d41a-4568-8fdd-41da7dc426d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-6c4f8f9d-de90-44de-903b-7c2b0e5848fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-c7f22564-39ee-4b35-ad27-883e13fd8e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-ac2003c6-6975-4f13-a6ab-7c542820d502,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-f55a81bd-b4a6-4b31-a961-f0f76d223b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-645f9ca7-adc3-4714-9267-aa36996d9f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738320265-172.17.0.21-1597663827017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43100,DS-5142ebce-513c-4036-ae87-43f6241bed2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-6bef8ef4-f214-40ae-ace2-ce94ac7e1203,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-93e4ba64-d41a-4568-8fdd-41da7dc426d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-6c4f8f9d-de90-44de-903b-7c2b0e5848fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-c7f22564-39ee-4b35-ad27-883e13fd8e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-ac2003c6-6975-4f13-a6ab-7c542820d502,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-f55a81bd-b4a6-4b31-a961-f0f76d223b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-645f9ca7-adc3-4714-9267-aa36996d9f38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218993222-172.17.0.21-1597664444393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-0f930746-2135-4ea3-a712-2f150f479c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-c8b0db0f-b3ed-40d7-a4e7-7ae09b8accee,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-b215d6e4-6aa1-494d-ad2b-c4fb5df6c8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-da32c53f-04e7-4d3b-ada3-493f6ce02dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-57e6732e-8bb9-4dc5-9b61-459d36a05f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-b4b5ab34-ef89-4c59-9bf9-eba78e3aabad,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-3a10163a-beb4-452c-90c3-e3f9f7c90f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-77f35691-105b-46f0-bfb6-1ffe06697d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218993222-172.17.0.21-1597664444393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-0f930746-2135-4ea3-a712-2f150f479c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-c8b0db0f-b3ed-40d7-a4e7-7ae09b8accee,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-b215d6e4-6aa1-494d-ad2b-c4fb5df6c8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-da32c53f-04e7-4d3b-ada3-493f6ce02dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-57e6732e-8bb9-4dc5-9b61-459d36a05f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-b4b5ab34-ef89-4c59-9bf9-eba78e3aabad,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-3a10163a-beb4-452c-90c3-e3f9f7c90f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-77f35691-105b-46f0-bfb6-1ffe06697d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505504346-172.17.0.21-1597664532075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43692,DS-40d0aec5-0bb1-4859-bb91-012f73e01393,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-1fbaa748-43af-49dd-96e3-e6e7ec0b7597,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-1eb0e828-b109-4151-96e2-82fefc1f2f58,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-d3527a32-1913-4518-a006-20324ba3b332,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-84dba566-426e-4a90-9cf1-1e76d6415c85,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-84a8b341-51a5-424f-b53a-052cb4ebf0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-be29d3bc-4f66-424f-9ba1-45b2d8c4eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-a517846d-88d1-41de-8fcd-beb5ce462547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505504346-172.17.0.21-1597664532075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43692,DS-40d0aec5-0bb1-4859-bb91-012f73e01393,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-1fbaa748-43af-49dd-96e3-e6e7ec0b7597,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-1eb0e828-b109-4151-96e2-82fefc1f2f58,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-d3527a32-1913-4518-a006-20324ba3b332,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-84dba566-426e-4a90-9cf1-1e76d6415c85,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-84a8b341-51a5-424f-b53a-052cb4ebf0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-be29d3bc-4f66-424f-9ba1-45b2d8c4eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-a517846d-88d1-41de-8fcd-beb5ce462547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606141985-172.17.0.21-1597664843467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-c6e700f4-879b-47ba-a827-bbe48f3e660f,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-26d84ac9-16f0-4802-abb3-2b8ba68b9ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-2b449a32-aa96-4578-af1c-71046bae6527,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-0de261ba-720b-4040-a999-ea71bfc4cb74,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-a6f389f9-1d3d-45f2-aa77-8156dd0a8cea,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-c39e1939-d855-4d04-9d49-0e8ed43b2521,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-d5119f2a-fa19-44aa-8699-ca79ce29ab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-5ee01b42-3945-4cdd-b14e-6b5c2c1c10a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606141985-172.17.0.21-1597664843467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-c6e700f4-879b-47ba-a827-bbe48f3e660f,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-26d84ac9-16f0-4802-abb3-2b8ba68b9ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-2b449a32-aa96-4578-af1c-71046bae6527,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-0de261ba-720b-4040-a999-ea71bfc4cb74,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-a6f389f9-1d3d-45f2-aa77-8156dd0a8cea,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-c39e1939-d855-4d04-9d49-0e8ed43b2521,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-d5119f2a-fa19-44aa-8699-ca79ce29ab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-5ee01b42-3945-4cdd-b14e-6b5c2c1c10a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707022271-172.17.0.21-1597665426259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-f341dbe0-527e-480a-92ec-470669a48e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-318dc50c-bf0a-4e4c-b944-5df9d3f12b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-614ba3d2-e5c4-48b0-bde6-af39af56bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-0dfa1bc8-7db1-4d13-afb6-7ef88f3da396,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-62cefadb-bb38-47d5-80f6-bd32720007bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-baa8f5ba-edc7-4071-add1-7badb9a6a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-57503907-19d0-49e2-aa82-57de62090327,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-828354e3-4d64-4aa4-b4b5-b8dc681cd87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707022271-172.17.0.21-1597665426259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-f341dbe0-527e-480a-92ec-470669a48e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-318dc50c-bf0a-4e4c-b944-5df9d3f12b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-614ba3d2-e5c4-48b0-bde6-af39af56bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-0dfa1bc8-7db1-4d13-afb6-7ef88f3da396,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-62cefadb-bb38-47d5-80f6-bd32720007bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-baa8f5ba-edc7-4071-add1-7badb9a6a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-57503907-19d0-49e2-aa82-57de62090327,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-828354e3-4d64-4aa4-b4b5-b8dc681cd87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672868620-172.17.0.21-1597665596836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-edcb8562-5b85-4507-8e7a-4a711ab3e1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-dfc60923-8ebe-4a0f-8289-ead5904ea317,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-cdd2819f-7403-4821-b6e9-7127ea4e339c,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-79d954d8-f4c7-4c2a-95b0-6828a821f073,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-6f2fe6e6-5fa4-4178-a5b0-c27d785ff986,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-34b75264-18aa-4be7-b9b3-8d944c75e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-e745796c-40d4-4bf5-a0f3-8afbba6cdf65,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-70dee54d-60a2-4d50-ab9f-3145b879f810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672868620-172.17.0.21-1597665596836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-edcb8562-5b85-4507-8e7a-4a711ab3e1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-dfc60923-8ebe-4a0f-8289-ead5904ea317,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-cdd2819f-7403-4821-b6e9-7127ea4e339c,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-79d954d8-f4c7-4c2a-95b0-6828a821f073,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-6f2fe6e6-5fa4-4178-a5b0-c27d785ff986,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-34b75264-18aa-4be7-b9b3-8d944c75e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-e745796c-40d4-4bf5-a0f3-8afbba6cdf65,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-70dee54d-60a2-4d50-ab9f-3145b879f810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712281058-172.17.0.21-1597666005973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33592,DS-b6d462f9-8f38-4647-8d32-7460f2051f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-90aa06b6-085e-47f7-9580-9d08ce7e1a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-ba0ccad3-473d-4531-90a9-c4fe2083debe,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-d8724d0f-bf50-4ba4-8867-a85abf172940,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-024cb10d-77b1-48e3-9dbb-b3ba14545f75,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-ea7a2103-96f2-4368-ba18-d64a99b5914d,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-a3430f49-fbc4-40f3-b700-9b04bc798277,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-6101dc5a-7e52-44bf-9054-12e16071baa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712281058-172.17.0.21-1597666005973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33592,DS-b6d462f9-8f38-4647-8d32-7460f2051f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-90aa06b6-085e-47f7-9580-9d08ce7e1a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-ba0ccad3-473d-4531-90a9-c4fe2083debe,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-d8724d0f-bf50-4ba4-8867-a85abf172940,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-024cb10d-77b1-48e3-9dbb-b3ba14545f75,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-ea7a2103-96f2-4368-ba18-d64a99b5914d,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-a3430f49-fbc4-40f3-b700-9b04bc798277,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-6101dc5a-7e52-44bf-9054-12e16071baa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074799437-172.17.0.21-1597666502015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-f59a8fcb-35c9-43e2-8827-5c05cd98034c,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-6eaa5260-3c9c-4a0d-9bf3-fef3151e80ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-3ee660d4-c866-438f-b20b-1ce3406b8771,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-c596177d-dfed-4021-b9ae-e1f83b6d29b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-d4632a8a-0f12-4592-aa23-6f95df7d953e,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-8b03623b-f489-4576-b82e-36ace103b06d,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-7bfac4f6-bc03-4594-ad16-a5b44661129b,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-fa5a501e-c81d-45ea-8f2c-dfff122a92b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074799437-172.17.0.21-1597666502015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-f59a8fcb-35c9-43e2-8827-5c05cd98034c,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-6eaa5260-3c9c-4a0d-9bf3-fef3151e80ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-3ee660d4-c866-438f-b20b-1ce3406b8771,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-c596177d-dfed-4021-b9ae-e1f83b6d29b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-d4632a8a-0f12-4592-aa23-6f95df7d953e,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-8b03623b-f489-4576-b82e-36ace103b06d,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-7bfac4f6-bc03-4594-ad16-a5b44661129b,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-fa5a501e-c81d-45ea-8f2c-dfff122a92b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6834
