reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753771872-172.17.0.10-1597268992950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37239,DS-36bc3638-b122-426c-9f66-019d9b1cf65a,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-ed10ddd2-95a9-4999-a7e8-8dcce1573d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-9228bb84-7d07-4f11-8060-1de5f6b5a3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-02f8590f-622f-462a-9675-6882e63af43b,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-8badff7a-149f-459a-8106-94232b0aab4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-797d82ab-b6f5-4af7-b1cf-c439ef28ccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-2a1ec27d-1840-4f4c-8c32-d948b869fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-62a75a23-78fc-4f4c-bcb9-8bac7e3ce77d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753771872-172.17.0.10-1597268992950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37239,DS-36bc3638-b122-426c-9f66-019d9b1cf65a,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-ed10ddd2-95a9-4999-a7e8-8dcce1573d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-9228bb84-7d07-4f11-8060-1de5f6b5a3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-02f8590f-622f-462a-9675-6882e63af43b,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-8badff7a-149f-459a-8106-94232b0aab4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-797d82ab-b6f5-4af7-b1cf-c439ef28ccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-2a1ec27d-1840-4f4c-8c32-d948b869fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-62a75a23-78fc-4f4c-bcb9-8bac7e3ce77d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353536993-172.17.0.10-1597269357307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-9ce59583-027d-4517-a9df-3ef62298c608,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-27f93648-42e3-484e-9477-fa6dbd812607,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-0e77fb69-1e06-4a9b-8342-a1ce56df781f,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-64439c5b-5684-4044-8e4b-08479b20db47,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-79072ae4-93da-4a09-a456-83fbb7ae043c,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-7f2c6ec6-b02c-4ea3-9ede-4665cb192499,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-0fcddc8c-7e72-4e79-bd7e-c2490aa26769,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-a0787d18-bdf0-4acd-9809-40c78b230857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353536993-172.17.0.10-1597269357307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-9ce59583-027d-4517-a9df-3ef62298c608,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-27f93648-42e3-484e-9477-fa6dbd812607,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-0e77fb69-1e06-4a9b-8342-a1ce56df781f,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-64439c5b-5684-4044-8e4b-08479b20db47,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-79072ae4-93da-4a09-a456-83fbb7ae043c,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-7f2c6ec6-b02c-4ea3-9ede-4665cb192499,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-0fcddc8c-7e72-4e79-bd7e-c2490aa26769,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-a0787d18-bdf0-4acd-9809-40c78b230857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76309485-172.17.0.10-1597269711624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44634,DS-a531c50c-fa8b-461a-b94a-91081c732547,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-4db9bb27-8632-49fd-ae20-72f1efce727c,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-885ca05e-8305-4976-9dd1-27d82e25674f,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-18b051f3-bf04-4ffe-a56d-a99b00691a78,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-a19f77cf-2228-4693-8e15-dcfcf228bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-495e8659-aa61-46ed-b205-eddadbe0bedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-480be4d5-cd03-4928-9837-f84ac4c88269,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-04c18f79-9525-4f77-9cf2-36e8b0c11932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76309485-172.17.0.10-1597269711624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44634,DS-a531c50c-fa8b-461a-b94a-91081c732547,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-4db9bb27-8632-49fd-ae20-72f1efce727c,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-885ca05e-8305-4976-9dd1-27d82e25674f,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-18b051f3-bf04-4ffe-a56d-a99b00691a78,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-a19f77cf-2228-4693-8e15-dcfcf228bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-495e8659-aa61-46ed-b205-eddadbe0bedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-480be4d5-cd03-4928-9837-f84ac4c88269,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-04c18f79-9525-4f77-9cf2-36e8b0c11932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124996801-172.17.0.10-1597269928690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-7e74a4fd-9349-430f-a600-8c627446d740,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-7bba6596-5bb6-40d5-96a9-5ada9d382342,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-b2502211-3068-472c-ab06-a57ae9ae01a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-4a2044f0-e55a-492a-a7cc-76585b027b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-60e98342-d174-49e2-8864-f97a9064ae35,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-6b970808-7053-451b-818a-edd3385285ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-af5ff741-9cd4-4fe0-8ea3-5d4fa78e9c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-2970e81a-c0cd-4b43-a3da-39bf4be855d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124996801-172.17.0.10-1597269928690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-7e74a4fd-9349-430f-a600-8c627446d740,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-7bba6596-5bb6-40d5-96a9-5ada9d382342,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-b2502211-3068-472c-ab06-a57ae9ae01a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-4a2044f0-e55a-492a-a7cc-76585b027b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-60e98342-d174-49e2-8864-f97a9064ae35,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-6b970808-7053-451b-818a-edd3385285ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-af5ff741-9cd4-4fe0-8ea3-5d4fa78e9c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-2970e81a-c0cd-4b43-a3da-39bf4be855d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776949476-172.17.0.10-1597270074587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-b362907d-aef6-4c0e-811a-1f5c8ed30e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-666bdab4-aef6-43c8-9ea7-57392a89696d,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-cdb4d38f-4c41-4d7a-abea-a8909906577c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-6ed7be9b-d2e9-4e53-b228-8a582dd45e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-2c686f27-37d7-4b8a-bf8c-5c6310dded72,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-3ec5b8bc-70c5-4ac0-beba-d198e72dff32,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-a3c071a2-2e7d-45a9-bd9c-8bb06b1f0f46,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-e288859f-ac4f-47d2-9803-e165e90839da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776949476-172.17.0.10-1597270074587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-b362907d-aef6-4c0e-811a-1f5c8ed30e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-666bdab4-aef6-43c8-9ea7-57392a89696d,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-cdb4d38f-4c41-4d7a-abea-a8909906577c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-6ed7be9b-d2e9-4e53-b228-8a582dd45e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-2c686f27-37d7-4b8a-bf8c-5c6310dded72,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-3ec5b8bc-70c5-4ac0-beba-d198e72dff32,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-a3c071a2-2e7d-45a9-bd9c-8bb06b1f0f46,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-e288859f-ac4f-47d2-9803-e165e90839da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-942617544-172.17.0.10-1597270245706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41423,DS-7c927e76-9972-4617-8f91-961646de844f,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-983812ed-b4ff-4fe3-b37e-280bc0f07d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-bf316e4c-4e8d-4220-b827-49ef9b0c00c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-4ceaad9c-2df1-4a87-aa71-363e3abe3301,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-40b001e8-f30b-4d8e-a71c-c7bc8b4877cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-3322f131-20d9-40e2-8cb0-eec643163cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-5b014801-315e-43e0-a5bd-55fffb150944,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-143175a4-6cff-4051-a2d5-d7177583f1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-942617544-172.17.0.10-1597270245706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41423,DS-7c927e76-9972-4617-8f91-961646de844f,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-983812ed-b4ff-4fe3-b37e-280bc0f07d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-bf316e4c-4e8d-4220-b827-49ef9b0c00c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-4ceaad9c-2df1-4a87-aa71-363e3abe3301,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-40b001e8-f30b-4d8e-a71c-c7bc8b4877cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-3322f131-20d9-40e2-8cb0-eec643163cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-5b014801-315e-43e0-a5bd-55fffb150944,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-143175a4-6cff-4051-a2d5-d7177583f1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526338620-172.17.0.10-1597270319850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-bc3ab44e-eb58-4b4b-a68d-d06640ca9caf,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-64a07769-a0e0-4255-a5af-9dcee929aeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-167fc372-d82a-46be-9782-7b5a37859712,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-40088bc5-6bb4-4ae1-8f10-8ae3c4784f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-c272281a-bf5c-44ab-b7b3-ee85b92b3ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-dc5e33d5-251a-4873-94d3-1e9898dd68cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-a76a541b-d8a2-4ead-ba2b-67689ed553d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-f9259b1f-3576-4604-b46d-8517bad40367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526338620-172.17.0.10-1597270319850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-bc3ab44e-eb58-4b4b-a68d-d06640ca9caf,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-64a07769-a0e0-4255-a5af-9dcee929aeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-167fc372-d82a-46be-9782-7b5a37859712,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-40088bc5-6bb4-4ae1-8f10-8ae3c4784f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-c272281a-bf5c-44ab-b7b3-ee85b92b3ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-dc5e33d5-251a-4873-94d3-1e9898dd68cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-a76a541b-d8a2-4ead-ba2b-67689ed553d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-f9259b1f-3576-4604-b46d-8517bad40367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438067070-172.17.0.10-1597270692230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-44301b85-cca6-45ae-a08b-7c63e4182807,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-cd115482-433f-40ce-a9bc-29f4a702bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-bf7c1479-f345-424b-9a50-7f35e1814894,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-d0efa53e-5794-42f0-b16a-f59539b4d2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-9b27839d-0bc8-4971-bf3b-a9433b288b34,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-de699761-3a80-401d-a4eb-523dceb26ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-2f1bae71-4d81-4027-83c0-f9d2f48bda62,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-eefac6da-0b35-423f-926a-64300664afec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438067070-172.17.0.10-1597270692230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-44301b85-cca6-45ae-a08b-7c63e4182807,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-cd115482-433f-40ce-a9bc-29f4a702bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-bf7c1479-f345-424b-9a50-7f35e1814894,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-d0efa53e-5794-42f0-b16a-f59539b4d2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-9b27839d-0bc8-4971-bf3b-a9433b288b34,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-de699761-3a80-401d-a4eb-523dceb26ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-2f1bae71-4d81-4027-83c0-f9d2f48bda62,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-eefac6da-0b35-423f-926a-64300664afec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489490935-172.17.0.10-1597270884116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-d9fbdb83-a011-45ff-8337-30e5bec73c02,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-f45376fd-b023-4e7f-b185-80e7d3372679,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-bc2413bb-3a70-4064-a6cc-3e5c1f0f0c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-f7c21e91-cb9a-4c38-8626-d94c33eda794,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-470bf49a-5c74-41ed-91a5-7db174d38580,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-239a529e-575b-4fc0-850a-bc29c85c4075,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-c769b314-07d8-48e4-942c-758593c406fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-79aeb027-3b8f-4e9e-9eb1-67bbeeeb9f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489490935-172.17.0.10-1597270884116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-d9fbdb83-a011-45ff-8337-30e5bec73c02,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-f45376fd-b023-4e7f-b185-80e7d3372679,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-bc2413bb-3a70-4064-a6cc-3e5c1f0f0c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-f7c21e91-cb9a-4c38-8626-d94c33eda794,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-470bf49a-5c74-41ed-91a5-7db174d38580,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-239a529e-575b-4fc0-850a-bc29c85c4075,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-c769b314-07d8-48e4-942c-758593c406fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-79aeb027-3b8f-4e9e-9eb1-67bbeeeb9f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830167666-172.17.0.10-1597270918376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39808,DS-39fd2ff9-cbf5-47df-aed9-3ea6c34270d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-40baaad6-fd6f-42a1-ad5d-8e1349869841,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-2260d53a-6836-42d1-b060-dcd7992751f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-8990a258-4515-4f83-8905-98a22c259c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-d050a9bd-29a8-4f4f-96f9-d2fc2d0b0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-8f8f210d-d901-45e8-b104-b08ac860d37f,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-4b856cca-2bf9-4bbb-8077-c7975b23fd12,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-78570157-2b1f-4d75-947e-318af44cfa99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830167666-172.17.0.10-1597270918376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39808,DS-39fd2ff9-cbf5-47df-aed9-3ea6c34270d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-40baaad6-fd6f-42a1-ad5d-8e1349869841,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-2260d53a-6836-42d1-b060-dcd7992751f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-8990a258-4515-4f83-8905-98a22c259c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-d050a9bd-29a8-4f4f-96f9-d2fc2d0b0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-8f8f210d-d901-45e8-b104-b08ac860d37f,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-4b856cca-2bf9-4bbb-8077-c7975b23fd12,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-78570157-2b1f-4d75-947e-318af44cfa99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954170765-172.17.0.10-1597271137894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-ff0b2604-6ca6-4b6e-8abf-dca26cb39f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-cca8e8cd-e35f-4547-8728-ec477ce68a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-e65656b8-07ef-4756-8dd5-c2e29d419642,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-9dcb4d78-c852-46c9-a717-cc163f62a3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-55bcaf61-b087-4ce2-93f0-1c4867574adf,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-fb07523e-65b2-4f29-8918-2c0d9030fa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-08d636e0-a1ec-4ce3-9de4-e36b195d34ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-ac70ecf4-1b29-4c32-9041-c7648d9cd523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954170765-172.17.0.10-1597271137894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-ff0b2604-6ca6-4b6e-8abf-dca26cb39f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-cca8e8cd-e35f-4547-8728-ec477ce68a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-e65656b8-07ef-4756-8dd5-c2e29d419642,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-9dcb4d78-c852-46c9-a717-cc163f62a3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-55bcaf61-b087-4ce2-93f0-1c4867574adf,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-fb07523e-65b2-4f29-8918-2c0d9030fa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-08d636e0-a1ec-4ce3-9de4-e36b195d34ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-ac70ecf4-1b29-4c32-9041-c7648d9cd523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398944123-172.17.0.10-1597272659278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39616,DS-9beb3f9c-042b-4f1d-85ef-0d0a8859adf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-fed5c800-9362-4822-b739-36281613da30,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-b60d269e-7f3e-42cc-9493-efda72a8e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-bb1f810c-57b8-4752-b740-3372788f96cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-4b85858d-302a-4d47-8240-d314427023cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-cc758d74-4db5-4c26-a616-91ba93135d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-f7724277-66c2-4789-9137-662d351827b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-33b7de03-7a80-441d-9fda-0daa1f1ca7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398944123-172.17.0.10-1597272659278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39616,DS-9beb3f9c-042b-4f1d-85ef-0d0a8859adf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-fed5c800-9362-4822-b739-36281613da30,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-b60d269e-7f3e-42cc-9493-efda72a8e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-bb1f810c-57b8-4752-b740-3372788f96cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-4b85858d-302a-4d47-8240-d314427023cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-cc758d74-4db5-4c26-a616-91ba93135d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-f7724277-66c2-4789-9137-662d351827b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-33b7de03-7a80-441d-9fda-0daa1f1ca7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011641731-172.17.0.10-1597272983486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-7303d228-24e2-4134-8f17-19b1db3698c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-69c0dbbe-be5e-4ae8-a55e-c355bc90e50c,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-a0174276-989c-4660-9597-1cf70be1baa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-9056a7bc-5747-4eda-b4aa-bfa3a1d410b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-7d0d084d-7824-47ea-8193-f6d7792f1b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-c14646f6-07eb-41ce-8268-22b7419b9c28,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-cc731b8c-b149-4212-aa46-59de8148c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-ac0e3cdd-dc4f-40cb-a018-831121e95e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011641731-172.17.0.10-1597272983486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-7303d228-24e2-4134-8f17-19b1db3698c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-69c0dbbe-be5e-4ae8-a55e-c355bc90e50c,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-a0174276-989c-4660-9597-1cf70be1baa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-9056a7bc-5747-4eda-b4aa-bfa3a1d410b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-7d0d084d-7824-47ea-8193-f6d7792f1b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-c14646f6-07eb-41ce-8268-22b7419b9c28,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-cc731b8c-b149-4212-aa46-59de8148c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-ac0e3cdd-dc4f-40cb-a018-831121e95e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383168355-172.17.0.10-1597273056418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-9abe6742-3b62-4be2-810d-e8c83f8d6ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-7de69d27-2ae7-42a8-af5f-f6c8906925bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-a7c44a65-b189-4379-b79f-395ba6510b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-0b1168fc-f1ed-47c5-9021-d726eb9ff5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-2e7b09ac-c806-4960-9715-66b83544df13,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-314ffad9-868e-4de6-a7c1-2c22083534a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-db0e292d-6328-478b-83cd-98cf5330072f,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-19adbb4c-9457-4cbc-a61d-4b50dbc90891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383168355-172.17.0.10-1597273056418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-9abe6742-3b62-4be2-810d-e8c83f8d6ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-7de69d27-2ae7-42a8-af5f-f6c8906925bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-a7c44a65-b189-4379-b79f-395ba6510b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-0b1168fc-f1ed-47c5-9021-d726eb9ff5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-2e7b09ac-c806-4960-9715-66b83544df13,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-314ffad9-868e-4de6-a7c1-2c22083534a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-db0e292d-6328-478b-83cd-98cf5330072f,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-19adbb4c-9457-4cbc-a61d-4b50dbc90891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409068244-172.17.0.10-1597273168664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38538,DS-b0fbf14d-4119-4355-8f5b-5e5f5b347c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-82f93271-8015-40b3-b0cb-d0df98d449ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-5d22dbfe-87b3-43c6-a968-4d9dd6586bab,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-00b45969-3ea4-41cc-8519-5a7d6322d715,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-4d7cd25b-579e-4d14-993e-55f9aae04354,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-95920005-2f44-419d-be6e-752ac7e7de24,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-b878832d-fe6f-4cd2-8561-8a7fbd53ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-be5cf947-14d9-4ae9-9b8e-1e795b784cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409068244-172.17.0.10-1597273168664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38538,DS-b0fbf14d-4119-4355-8f5b-5e5f5b347c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-82f93271-8015-40b3-b0cb-d0df98d449ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-5d22dbfe-87b3-43c6-a968-4d9dd6586bab,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-00b45969-3ea4-41cc-8519-5a7d6322d715,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-4d7cd25b-579e-4d14-993e-55f9aae04354,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-95920005-2f44-419d-be6e-752ac7e7de24,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-b878832d-fe6f-4cd2-8561-8a7fbd53ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-be5cf947-14d9-4ae9-9b8e-1e795b784cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162904110-172.17.0.10-1597273341197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42786,DS-0461dbb7-072d-47f5-8e9d-908b6c5d3395,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-497fb0f2-fefb-4ff4-b10c-5ff515f82a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-02be892d-c8b0-42a2-ab98-506c4473692c,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-f0a4e0ce-02b4-4fde-a755-c95d1128163e,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-3726b23d-cf35-4b2b-a217-1f0d509883af,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-253a86ae-4aca-41fc-a213-67a4b6bea784,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-93bc8d86-2327-4358-a785-1f0f36b3e736,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-a960825e-0ecb-4954-995f-5785ce3cdf39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162904110-172.17.0.10-1597273341197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42786,DS-0461dbb7-072d-47f5-8e9d-908b6c5d3395,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-497fb0f2-fefb-4ff4-b10c-5ff515f82a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-02be892d-c8b0-42a2-ab98-506c4473692c,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-f0a4e0ce-02b4-4fde-a755-c95d1128163e,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-3726b23d-cf35-4b2b-a217-1f0d509883af,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-253a86ae-4aca-41fc-a213-67a4b6bea784,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-93bc8d86-2327-4358-a785-1f0f36b3e736,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-a960825e-0ecb-4954-995f-5785ce3cdf39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649419971-172.17.0.10-1597273650302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-5cb44b29-f6cd-4eda-8637-b15ea058f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-2cd81d3f-317f-44f5-af84-cdaa97e06365,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-e31c9b02-4780-4385-87fc-53f8ab19be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-5c696069-53f9-49ed-b311-9b94111ce9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-8711e71b-8e97-4cee-9d78-69aab362f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-2eafd0c2-77fd-4bea-9381-9d53e3d09b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-f38d660b-c9ae-4ff1-9f4e-0328a9d3ed86,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-3328d70f-413e-41c5-a27e-22ed24b1396d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649419971-172.17.0.10-1597273650302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-5cb44b29-f6cd-4eda-8637-b15ea058f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-2cd81d3f-317f-44f5-af84-cdaa97e06365,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-e31c9b02-4780-4385-87fc-53f8ab19be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-5c696069-53f9-49ed-b311-9b94111ce9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-8711e71b-8e97-4cee-9d78-69aab362f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-2eafd0c2-77fd-4bea-9381-9d53e3d09b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-f38d660b-c9ae-4ff1-9f4e-0328a9d3ed86,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-3328d70f-413e-41c5-a27e-22ed24b1396d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884893821-172.17.0.10-1597273686191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44377,DS-2b7412fa-0fc2-47bd-8f5e-632fc0e8c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-37103585-c617-4864-a8e4-b85f6bef8c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b9328044-723e-46d0-8c1d-50cc0a40d332,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-d27a6e09-b415-4864-b954-14c946074036,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-2e0536de-7f0a-4563-894c-cbcca250a02e,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-9877ffe8-a239-456f-8ed1-4e092eb635dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-6140820a-41e2-4894-b9c7-31699fe7bb66,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-ef763805-a832-4a4e-801d-bceadad31eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884893821-172.17.0.10-1597273686191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44377,DS-2b7412fa-0fc2-47bd-8f5e-632fc0e8c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-37103585-c617-4864-a8e4-b85f6bef8c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b9328044-723e-46d0-8c1d-50cc0a40d332,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-d27a6e09-b415-4864-b954-14c946074036,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-2e0536de-7f0a-4563-894c-cbcca250a02e,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-9877ffe8-a239-456f-8ed1-4e092eb635dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-6140820a-41e2-4894-b9c7-31699fe7bb66,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-ef763805-a832-4a4e-801d-bceadad31eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894372888-172.17.0.10-1597273790245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37558,DS-43d77597-ca3f-439a-b253-fb3cf1239977,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-f6058a75-7d4c-4217-a0cb-45f10473ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-171bf12b-aa2f-4bad-9817-4e3faf0ebb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-f8377542-be42-4638-9a7c-97f3f49afa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-512aa1dd-566b-41a6-bfdb-6df52d73797c,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-c23f6538-1c7d-4b27-ab5b-ea41bed083ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-826efca6-c8df-465d-b9a7-6fe09b0f0670,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-0769088f-aa65-443e-b633-2ae65b47239a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894372888-172.17.0.10-1597273790245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37558,DS-43d77597-ca3f-439a-b253-fb3cf1239977,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-f6058a75-7d4c-4217-a0cb-45f10473ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-171bf12b-aa2f-4bad-9817-4e3faf0ebb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-f8377542-be42-4638-9a7c-97f3f49afa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-512aa1dd-566b-41a6-bfdb-6df52d73797c,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-c23f6538-1c7d-4b27-ab5b-ea41bed083ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-826efca6-c8df-465d-b9a7-6fe09b0f0670,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-0769088f-aa65-443e-b633-2ae65b47239a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5433
