reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525986888-172.17.0.20-1597390214596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-8e2740d7-d842-4c9d-83fc-7f978a6e725e,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-abc8ab1b-024b-472a-8176-7a9904cb4827,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-17416ad2-52bd-496e-8beb-44ef3d0081de,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-bfc42d68-ce6d-4ff9-bd9c-5dee6a52cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-506a6aa9-3764-4f9b-b6eb-5cef6d48d602,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-19294ae6-c0f5-4335-a3fc-39c04f19bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-8569386c-357e-4e14-9d83-80482d3e0705,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-c51123e8-72cf-410c-a3a1-84d2bf68d234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525986888-172.17.0.20-1597390214596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-8e2740d7-d842-4c9d-83fc-7f978a6e725e,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-abc8ab1b-024b-472a-8176-7a9904cb4827,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-17416ad2-52bd-496e-8beb-44ef3d0081de,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-bfc42d68-ce6d-4ff9-bd9c-5dee6a52cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-506a6aa9-3764-4f9b-b6eb-5cef6d48d602,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-19294ae6-c0f5-4335-a3fc-39c04f19bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-8569386c-357e-4e14-9d83-80482d3e0705,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-c51123e8-72cf-410c-a3a1-84d2bf68d234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77424813-172.17.0.20-1597390390162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35572,DS-2e3f9ced-bd72-4401-9fc6-4d3b03296110,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-81541c51-bf4c-4238-8e68-75fb54aced56,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-b1defb3c-ff81-4a76-a53b-a905f2682275,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-25a00ce3-ce3f-4c8a-bf6b-13998d008bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-c4de6097-8b25-4959-bbe0-ab231eb588a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-4ed94fc4-22f9-4570-8d91-63c14c39fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-4f82f749-e80f-442e-b9ef-f77b8bd5e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-0f7d2ad8-82e0-402b-8a9b-47d510a6824c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77424813-172.17.0.20-1597390390162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35572,DS-2e3f9ced-bd72-4401-9fc6-4d3b03296110,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-81541c51-bf4c-4238-8e68-75fb54aced56,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-b1defb3c-ff81-4a76-a53b-a905f2682275,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-25a00ce3-ce3f-4c8a-bf6b-13998d008bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-c4de6097-8b25-4959-bbe0-ab231eb588a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-4ed94fc4-22f9-4570-8d91-63c14c39fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-4f82f749-e80f-442e-b9ef-f77b8bd5e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-0f7d2ad8-82e0-402b-8a9b-47d510a6824c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057069669-172.17.0.20-1597390492486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-f8cf392f-367c-445f-a4c4-2eedeb2da725,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-2fd8c664-7ee9-4bfa-944f-ab86bfccfb49,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-a3a4235f-bc4b-430d-b199-e7356c01c51f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-ea1650a7-0a63-4468-bf8e-2bf2a9d40c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-23770c32-069d-4439-b399-5abf7c8322a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-e5647f96-7310-4d67-af8b-1034ec33d818,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-31855d88-21e8-4a61-9808-ca0ea50f42d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-48465a96-3e3e-4016-b6a8-cf0f32e87bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057069669-172.17.0.20-1597390492486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-f8cf392f-367c-445f-a4c4-2eedeb2da725,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-2fd8c664-7ee9-4bfa-944f-ab86bfccfb49,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-a3a4235f-bc4b-430d-b199-e7356c01c51f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-ea1650a7-0a63-4468-bf8e-2bf2a9d40c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-23770c32-069d-4439-b399-5abf7c8322a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-e5647f96-7310-4d67-af8b-1034ec33d818,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-31855d88-21e8-4a61-9808-ca0ea50f42d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-48465a96-3e3e-4016-b6a8-cf0f32e87bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567763460-172.17.0.20-1597390599785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36226,DS-1d66cbd5-75c2-45f9-8e98-bff06ab9783f,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-d949bdb8-8f89-4ef2-aad4-6e7c19cec3be,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-1eb10496-91bb-42b9-b48a-c37a0773d507,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-b3332618-9c2e-42ec-af2a-72a29ff5dda3,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-001632c4-c009-466e-99e1-4f4248a16fed,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-cc68d24e-04df-4247-8581-a9e6a6613b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-ffac43bd-a19e-481a-90ef-23764b77db17,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-a0469248-d76d-4593-b963-083f8863c200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567763460-172.17.0.20-1597390599785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36226,DS-1d66cbd5-75c2-45f9-8e98-bff06ab9783f,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-d949bdb8-8f89-4ef2-aad4-6e7c19cec3be,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-1eb10496-91bb-42b9-b48a-c37a0773d507,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-b3332618-9c2e-42ec-af2a-72a29ff5dda3,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-001632c4-c009-466e-99e1-4f4248a16fed,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-cc68d24e-04df-4247-8581-a9e6a6613b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-ffac43bd-a19e-481a-90ef-23764b77db17,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-a0469248-d76d-4593-b963-083f8863c200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730580735-172.17.0.20-1597391206921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39621,DS-e8524a28-b15f-49ba-9bd0-3905ad8c922e,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-909186e6-ca90-4898-99af-b5e1dd91d6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-d12ded0f-d4c1-4854-b07f-f11a6c8616d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-cda4dc72-112e-4968-b7c6-f5066bad7f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-845c31d5-c0c8-4375-9274-0198439d7b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-69f39915-6ed7-4729-8e76-bbdaeabd1c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-ba6d14cd-e60e-4638-ae5d-5e05312e362a,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-e0237424-31ea-4a43-94dc-6eabe4d839dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730580735-172.17.0.20-1597391206921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39621,DS-e8524a28-b15f-49ba-9bd0-3905ad8c922e,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-909186e6-ca90-4898-99af-b5e1dd91d6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-d12ded0f-d4c1-4854-b07f-f11a6c8616d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-cda4dc72-112e-4968-b7c6-f5066bad7f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-845c31d5-c0c8-4375-9274-0198439d7b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-69f39915-6ed7-4729-8e76-bbdaeabd1c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-ba6d14cd-e60e-4638-ae5d-5e05312e362a,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-e0237424-31ea-4a43-94dc-6eabe4d839dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698250782-172.17.0.20-1597391502141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43135,DS-6861fcce-e2e4-4f03-8b81-5219a1173001,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-5bce24fc-c9cd-4a0c-b0fd-549a2f4d323c,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-c4a67f21-d6e1-4a07-badc-4f93d62c7cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-3401c48e-8b1b-4d57-b322-ceaeb43fcc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-a0ea140d-2d45-47fe-8ac2-76a415110506,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-f479d85a-86b0-4476-a57e-ec88e096ba09,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-a4f585c7-8293-46bb-8edd-6b626d4da091,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-35eb25a2-14f6-4cd2-8650-43b4f28025a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698250782-172.17.0.20-1597391502141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43135,DS-6861fcce-e2e4-4f03-8b81-5219a1173001,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-5bce24fc-c9cd-4a0c-b0fd-549a2f4d323c,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-c4a67f21-d6e1-4a07-badc-4f93d62c7cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-3401c48e-8b1b-4d57-b322-ceaeb43fcc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-a0ea140d-2d45-47fe-8ac2-76a415110506,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-f479d85a-86b0-4476-a57e-ec88e096ba09,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-a4f585c7-8293-46bb-8edd-6b626d4da091,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-35eb25a2-14f6-4cd2-8650-43b4f28025a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994165520-172.17.0.20-1597391953205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42183,DS-82eaeeff-9580-49f3-bc7b-9413d30fbe70,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-8979f84c-7cca-463d-a9bd-3fbc9f7703d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-ed121684-83c1-47df-818b-b17170f4212a,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-4c353cf3-addf-4a77-8ded-eb9de78c94da,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-8c9f29c6-ce74-4cea-9866-66bc117a391d,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-e65e25f5-8097-42bb-b7e1-26fda31cddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-200baa52-90bc-425e-a325-1a43398d986a,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-84f498c3-b320-4e61-afa1-22b9c57ebd55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994165520-172.17.0.20-1597391953205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42183,DS-82eaeeff-9580-49f3-bc7b-9413d30fbe70,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-8979f84c-7cca-463d-a9bd-3fbc9f7703d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-ed121684-83c1-47df-818b-b17170f4212a,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-4c353cf3-addf-4a77-8ded-eb9de78c94da,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-8c9f29c6-ce74-4cea-9866-66bc117a391d,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-e65e25f5-8097-42bb-b7e1-26fda31cddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-200baa52-90bc-425e-a325-1a43398d986a,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-84f498c3-b320-4e61-afa1-22b9c57ebd55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488035898-172.17.0.20-1597392251261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36573,DS-31ea6ca2-a562-4c03-a7b0-a1f520e4c037,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-de1d3302-48c2-402b-bb8e-0894b8da8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-6a26ccca-463e-4539-a98a-afe27cd658ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-ee03080a-5849-490f-82a2-89fba04b1ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-338ce689-f554-444e-aa07-7b68a806b218,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-8deac76e-ad62-443c-8b4e-8805aec9da68,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-e78c8bb3-1887-49a0-8d40-1766bd74eefd,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-2ae4cff0-aab9-4ade-8dbd-476601c8673e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488035898-172.17.0.20-1597392251261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36573,DS-31ea6ca2-a562-4c03-a7b0-a1f520e4c037,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-de1d3302-48c2-402b-bb8e-0894b8da8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-6a26ccca-463e-4539-a98a-afe27cd658ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-ee03080a-5849-490f-82a2-89fba04b1ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-338ce689-f554-444e-aa07-7b68a806b218,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-8deac76e-ad62-443c-8b4e-8805aec9da68,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-e78c8bb3-1887-49a0-8d40-1766bd74eefd,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-2ae4cff0-aab9-4ade-8dbd-476601c8673e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001413374-172.17.0.20-1597392450253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33979,DS-0099d90c-b8ff-4004-aafb-2951e7633226,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-2a7193ed-1e20-4644-8a2d-7f1180cd4b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-adbf5454-c7ed-4ca0-82bc-bdaa7bb59761,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-b17b3a1c-cfa4-4c43-9271-3e03bdb1dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-3887786d-60e7-4e66-88dd-8c5b59e576e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-f2613065-9181-443f-8b5b-16324dfb31eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-a55821c6-584c-45cb-b42f-80416777d1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-35e1e3a7-c80f-433d-89b0-8d52d0a099e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001413374-172.17.0.20-1597392450253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33979,DS-0099d90c-b8ff-4004-aafb-2951e7633226,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-2a7193ed-1e20-4644-8a2d-7f1180cd4b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-adbf5454-c7ed-4ca0-82bc-bdaa7bb59761,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-b17b3a1c-cfa4-4c43-9271-3e03bdb1dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-3887786d-60e7-4e66-88dd-8c5b59e576e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-f2613065-9181-443f-8b5b-16324dfb31eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-a55821c6-584c-45cb-b42f-80416777d1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-35e1e3a7-c80f-433d-89b0-8d52d0a099e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042201154-172.17.0.20-1597393222543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-3d3d0314-3d03-46a0-9ab9-d56537fa3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-8d336f4c-1564-4d85-b9c9-228743ff9602,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-b1d745b8-3f65-453b-8077-11d342b76ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-fa5d5b60-1232-4794-80f1-7cab008b6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-a3486c6a-c785-46f5-a93c-a125f8de01b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-b766733d-e1c1-4210-a3d9-e8cd2b4239b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-4babe78a-2683-40a5-a39a-aab4291c0436,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-efc1f92b-248b-4cfe-9c0f-28b522e5eca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042201154-172.17.0.20-1597393222543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-3d3d0314-3d03-46a0-9ab9-d56537fa3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-8d336f4c-1564-4d85-b9c9-228743ff9602,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-b1d745b8-3f65-453b-8077-11d342b76ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-fa5d5b60-1232-4794-80f1-7cab008b6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-a3486c6a-c785-46f5-a93c-a125f8de01b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-b766733d-e1c1-4210-a3d9-e8cd2b4239b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-4babe78a-2683-40a5-a39a-aab4291c0436,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-efc1f92b-248b-4cfe-9c0f-28b522e5eca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490545466-172.17.0.20-1597393286118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-970d6e70-1714-40a0-bd90-d9da020b8d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-4fcc0c16-0e2c-4eeb-a596-cdb9dcf613bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-84d023b6-615a-49ae-90c3-15a2e65accf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-a9180e96-4e2b-49cb-9f42-43ac7d6dc0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-00b3823f-918e-490f-b9f4-a22ae1fb23d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-0205da66-27c1-44ed-a81a-2e62392eac57,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-1ea8cf43-a04c-4e82-9d11-4e9da35b9ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-6f3d2319-4225-41ba-99f4-03fff9650d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490545466-172.17.0.20-1597393286118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-970d6e70-1714-40a0-bd90-d9da020b8d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-4fcc0c16-0e2c-4eeb-a596-cdb9dcf613bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-84d023b6-615a-49ae-90c3-15a2e65accf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-a9180e96-4e2b-49cb-9f42-43ac7d6dc0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-00b3823f-918e-490f-b9f4-a22ae1fb23d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-0205da66-27c1-44ed-a81a-2e62392eac57,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-1ea8cf43-a04c-4e82-9d11-4e9da35b9ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-6f3d2319-4225-41ba-99f4-03fff9650d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8771015-172.17.0.20-1597393746777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-1fed4ee0-d6a3-4448-a346-efed31dbd4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-7ee3f725-9953-497c-b993-a703aa47d244,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-cfb8572d-6530-4c69-b249-26447746f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-5cb1bc6d-db98-42b3-851b-07f2f2a9ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-bbeb5097-fc21-46b3-a3d8-bd846341d6af,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-b2ac7360-2f14-4111-be3c-727c0522ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-6afa1de6-2b17-49a0-a8fa-2bafedab3db0,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-e8e358e7-c7d2-4e95-9bf6-4cc20cccc0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8771015-172.17.0.20-1597393746777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-1fed4ee0-d6a3-4448-a346-efed31dbd4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-7ee3f725-9953-497c-b993-a703aa47d244,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-cfb8572d-6530-4c69-b249-26447746f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-5cb1bc6d-db98-42b3-851b-07f2f2a9ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-bbeb5097-fc21-46b3-a3d8-bd846341d6af,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-b2ac7360-2f14-4111-be3c-727c0522ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-6afa1de6-2b17-49a0-a8fa-2bafedab3db0,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-e8e358e7-c7d2-4e95-9bf6-4cc20cccc0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913543131-172.17.0.20-1597394166259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36424,DS-c2dcb4f3-93ed-48cb-a9b3-66f08dab20a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-2f092e0b-5c10-4db3-ad7c-a14148c5401d,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-6b1e47a6-4051-46e7-8f16-70c173dfbc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-b9fae459-3fcf-47bb-8da4-b63741a74ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-cc2c9cda-96e0-4431-8b72-827d73ac5c12,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-0b11e180-b747-4704-be3c-0e16e6dc0643,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-4d46fd7f-3e77-4500-a532-3808c30f2a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-1e6dbc98-f764-4a78-b842-47aa03cc366e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913543131-172.17.0.20-1597394166259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36424,DS-c2dcb4f3-93ed-48cb-a9b3-66f08dab20a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-2f092e0b-5c10-4db3-ad7c-a14148c5401d,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-6b1e47a6-4051-46e7-8f16-70c173dfbc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-b9fae459-3fcf-47bb-8da4-b63741a74ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-cc2c9cda-96e0-4431-8b72-827d73ac5c12,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-0b11e180-b747-4704-be3c-0e16e6dc0643,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-4d46fd7f-3e77-4500-a532-3808c30f2a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-1e6dbc98-f764-4a78-b842-47aa03cc366e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315108942-172.17.0.20-1597394268711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-4b665609-3705-4744-991b-19b75ce299da,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-9c8380fc-1f35-4a99-bdd5-040a22c75fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-d4c1da1d-526a-4c09-9925-4aed53847be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-b2fbb21c-2478-480e-994c-cce10a5ebee1,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-4bf82638-b65f-4ee1-b345-a01c15eb0582,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-b28f10c3-43e6-46f9-95e8-35a1712cd3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-5d556e2e-cca6-4fb1-abc9-f4930b5ca0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-b2ec5732-a249-4249-abc7-22a25bd82b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315108942-172.17.0.20-1597394268711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-4b665609-3705-4744-991b-19b75ce299da,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-9c8380fc-1f35-4a99-bdd5-040a22c75fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-d4c1da1d-526a-4c09-9925-4aed53847be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-b2fbb21c-2478-480e-994c-cce10a5ebee1,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-4bf82638-b65f-4ee1-b345-a01c15eb0582,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-b28f10c3-43e6-46f9-95e8-35a1712cd3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-5d556e2e-cca6-4fb1-abc9-f4930b5ca0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-b2ec5732-a249-4249-abc7-22a25bd82b87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381377735-172.17.0.20-1597394303196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34106,DS-dae886c0-753e-4cae-972c-4737c136cb83,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-ee4a1968-be57-40a1-8454-f4078e9e9d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-5c8934e9-2d94-4822-bd62-50907a102bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-7ee79cfd-3f11-4ef5-a2bd-c8830f517c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f3c17636-2318-4a2a-be32-74c27a9ea994,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-9f761d23-cd5c-4c4d-9cb6-d11629b7148d,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-fa3825bd-f94b-4557-b33e-2e83620f8c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-0feea30f-3a0f-4550-83e5-108bae1c774f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381377735-172.17.0.20-1597394303196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34106,DS-dae886c0-753e-4cae-972c-4737c136cb83,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-ee4a1968-be57-40a1-8454-f4078e9e9d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-5c8934e9-2d94-4822-bd62-50907a102bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-7ee79cfd-3f11-4ef5-a2bd-c8830f517c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f3c17636-2318-4a2a-be32-74c27a9ea994,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-9f761d23-cd5c-4c4d-9cb6-d11629b7148d,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-fa3825bd-f94b-4557-b33e-2e83620f8c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-0feea30f-3a0f-4550-83e5-108bae1c774f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048362360-172.17.0.20-1597394379343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43039,DS-fb43e18a-2573-4f7d-affd-e7104cf418c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-69250ecb-e101-4a69-a952-6108afbd0d01,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-eda1201a-2901-41ea-abd4-35429f3f0cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-5002b0f6-dd4c-4887-be87-5089d5f86810,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-da465b3c-cc9c-4821-913b-e26dda9b8c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-e170a346-2ddf-43fd-a9ff-f14d2f6e4649,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-6f0383c1-b6e8-4d34-a360-739a482d170d,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-c123e96e-e25e-41a4-94c3-2aed4f86ca8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048362360-172.17.0.20-1597394379343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43039,DS-fb43e18a-2573-4f7d-affd-e7104cf418c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-69250ecb-e101-4a69-a952-6108afbd0d01,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-eda1201a-2901-41ea-abd4-35429f3f0cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-5002b0f6-dd4c-4887-be87-5089d5f86810,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-da465b3c-cc9c-4821-913b-e26dda9b8c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-e170a346-2ddf-43fd-a9ff-f14d2f6e4649,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-6f0383c1-b6e8-4d34-a360-739a482d170d,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-c123e96e-e25e-41a4-94c3-2aed4f86ca8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460569822-172.17.0.20-1597394546793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-d904eb45-fe25-48a0-808a-d8388b981818,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-b75f6bf2-c0f0-4953-86ae-5fc570eb098a,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-2ec400c6-6a51-4cea-869e-90be7c50ce93,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-c5c47a15-3465-42c1-9643-eec7262d325a,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-006c06b6-3a3b-428e-88c3-4c64a0d6cc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-69b3389f-726d-48e0-a851-2a73effd1dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-86091a1e-4268-4854-95aa-58133a6e1941,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-86c77d5c-2a38-4720-aab3-666473f7b213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460569822-172.17.0.20-1597394546793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-d904eb45-fe25-48a0-808a-d8388b981818,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-b75f6bf2-c0f0-4953-86ae-5fc570eb098a,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-2ec400c6-6a51-4cea-869e-90be7c50ce93,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-c5c47a15-3465-42c1-9643-eec7262d325a,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-006c06b6-3a3b-428e-88c3-4c64a0d6cc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-69b3389f-726d-48e0-a851-2a73effd1dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-86091a1e-4268-4854-95aa-58133a6e1941,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-86c77d5c-2a38-4720-aab3-666473f7b213,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131188001-172.17.0.20-1597394843925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-c5cf0304-55f0-45bd-b2d0-a5ac12a269a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-c7536908-1432-4ac0-bc25-9242486c07e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-b1152a10-0340-4771-9aeb-772177e6c85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-a55c7d56-f8d0-4b88-9247-2e508f82532b,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-32d18323-fe3b-4645-988a-b644b4ffedd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-22519636-b6ea-417e-ba8d-f599656da242,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-b7228ffd-108a-481f-8806-1a815e07da33,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e3b5abec-8810-497e-9f9b-4d09693c2542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131188001-172.17.0.20-1597394843925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-c5cf0304-55f0-45bd-b2d0-a5ac12a269a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-c7536908-1432-4ac0-bc25-9242486c07e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-b1152a10-0340-4771-9aeb-772177e6c85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-a55c7d56-f8d0-4b88-9247-2e508f82532b,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-32d18323-fe3b-4645-988a-b644b4ffedd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-22519636-b6ea-417e-ba8d-f599656da242,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-b7228ffd-108a-481f-8806-1a815e07da33,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e3b5abec-8810-497e-9f9b-4d09693c2542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336132814-172.17.0.20-1597395051013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33556,DS-e3ed202e-53a3-423c-844d-811707344cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-09856549-bfcb-4ecc-bb33-5a07f013e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-ca0a1fd6-af48-473a-9d3d-1d22e15c99f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-864ee58c-438f-4987-82ed-808bb12d9427,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-04254a0f-28bd-453c-bc1a-4eb029896328,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-c544406a-fbc2-4fa1-b809-e2f4a45ddfad,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-25f1283c-dd71-459e-959e-3602c192416f,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-6bcbdcfb-7f84-4816-8f7e-bbda17d2c6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336132814-172.17.0.20-1597395051013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33556,DS-e3ed202e-53a3-423c-844d-811707344cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-09856549-bfcb-4ecc-bb33-5a07f013e3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-ca0a1fd6-af48-473a-9d3d-1d22e15c99f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-864ee58c-438f-4987-82ed-808bb12d9427,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-04254a0f-28bd-453c-bc1a-4eb029896328,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-c544406a-fbc2-4fa1-b809-e2f4a45ddfad,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-25f1283c-dd71-459e-959e-3602c192416f,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-6bcbdcfb-7f84-4816-8f7e-bbda17d2c6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542891415-172.17.0.20-1597395119907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-b6324d7c-6744-4185-90c7-a817ba8c1b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-1c5dd85e-e4fc-400c-a3b1-3bdd1cb772a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-ee4ecfd1-79f5-41b1-85ff-b79f70a327c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-8f44f704-8b97-4995-ab54-07a9396cf106,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-fe71271f-7f9b-487c-869c-de6f6adfa241,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-3f0c8ea2-9717-44ee-9ceb-307099bd7192,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-7d76f924-d3a4-4ef6-b450-408c71cbe7be,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-0ca2e9d6-15a6-4d3f-9cef-324b22c156f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542891415-172.17.0.20-1597395119907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-b6324d7c-6744-4185-90c7-a817ba8c1b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-1c5dd85e-e4fc-400c-a3b1-3bdd1cb772a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-ee4ecfd1-79f5-41b1-85ff-b79f70a327c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-8f44f704-8b97-4995-ab54-07a9396cf106,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-fe71271f-7f9b-487c-869c-de6f6adfa241,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-3f0c8ea2-9717-44ee-9ceb-307099bd7192,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-7d76f924-d3a4-4ef6-b450-408c71cbe7be,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-0ca2e9d6-15a6-4d3f-9cef-324b22c156f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5042
