reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521755214-172.17.0.18-1597548442531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-ccf06065-be0c-4933-8fc0-f6fcf8a0c674,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-8debe76c-8dfa-4eea-b4f8-187eb9524661,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-a5a4292e-828d-44b8-a883-23fbf57242a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-a94b6aad-6429-49f4-80bc-19e546330e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-57ef5cf6-4de9-426f-bc0e-905a74d5391d,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-c87c6bbd-d778-437c-8101-1ad25468e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-ad0fb421-b27d-4500-940f-1837965967b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-d7179053-556e-41aa-94f8-94e408817573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521755214-172.17.0.18-1597548442531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-ccf06065-be0c-4933-8fc0-f6fcf8a0c674,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-8debe76c-8dfa-4eea-b4f8-187eb9524661,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-a5a4292e-828d-44b8-a883-23fbf57242a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-a94b6aad-6429-49f4-80bc-19e546330e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-57ef5cf6-4de9-426f-bc0e-905a74d5391d,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-c87c6bbd-d778-437c-8101-1ad25468e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-ad0fb421-b27d-4500-940f-1837965967b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-d7179053-556e-41aa-94f8-94e408817573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424899582-172.17.0.18-1597548840633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-639896de-aaa2-4117-b170-bd3d162807e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-8ea6a336-719d-4484-931d-7f5a1bbd1556,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-e4b6429f-c664-4383-af05-19aa2e6eb691,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-6ec28e29-11b6-4970-8dc4-29092c9689df,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-b9cfc5dd-45ec-4836-939d-5dd36bfd3ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-119a8d0d-b4ca-4cf9-bccb-508c76861e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-b4f70a95-2426-4009-a8d8-4efbd2cd92d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-9e6c271d-a586-4023-8826-3a92d13cafda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424899582-172.17.0.18-1597548840633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-639896de-aaa2-4117-b170-bd3d162807e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-8ea6a336-719d-4484-931d-7f5a1bbd1556,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-e4b6429f-c664-4383-af05-19aa2e6eb691,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-6ec28e29-11b6-4970-8dc4-29092c9689df,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-b9cfc5dd-45ec-4836-939d-5dd36bfd3ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-119a8d0d-b4ca-4cf9-bccb-508c76861e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-b4f70a95-2426-4009-a8d8-4efbd2cd92d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-9e6c271d-a586-4023-8826-3a92d13cafda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904144645-172.17.0.18-1597548882927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-08f62c06-4cfd-4fd2-a11c-54eea16c719d,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-5aa1d848-4796-482e-b0ea-73c70b63ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-39553a60-d368-485f-9c4c-2d6765e73063,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-ba25d08d-a639-4c98-932a-3a913b28d05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-267505a2-d511-48bf-90c8-c58faca1fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-ebca311d-ce75-4348-96f7-b56407cf35a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-46751e86-c81c-4313-8ad9-6601929ef6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-e32f1c0b-75dc-4282-8386-d7d57113d2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904144645-172.17.0.18-1597548882927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-08f62c06-4cfd-4fd2-a11c-54eea16c719d,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-5aa1d848-4796-482e-b0ea-73c70b63ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-39553a60-d368-485f-9c4c-2d6765e73063,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-ba25d08d-a639-4c98-932a-3a913b28d05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-267505a2-d511-48bf-90c8-c58faca1fd44,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-ebca311d-ce75-4348-96f7-b56407cf35a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-46751e86-c81c-4313-8ad9-6601929ef6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-e32f1c0b-75dc-4282-8386-d7d57113d2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395679421-172.17.0.18-1597548932580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33385,DS-1bb7d479-8ec1-48ab-bbb5-544947e28677,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-6fcdeedf-07c3-492e-855a-9fca01ee4758,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-a6225db6-b2e8-4297-80ee-04555a10ff68,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-2a021da8-b311-48c3-b0ac-2422e508675e,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-b478d0f4-e410-432f-9fc9-a71c20ed0d85,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-1ed6fd33-7dba-4ae1-be35-9f56a14fdf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-65bfd4a4-89ff-4e5e-9b92-44ed4a789d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-8f127f39-8c22-4f24-9309-e9a572814015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395679421-172.17.0.18-1597548932580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33385,DS-1bb7d479-8ec1-48ab-bbb5-544947e28677,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-6fcdeedf-07c3-492e-855a-9fca01ee4758,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-a6225db6-b2e8-4297-80ee-04555a10ff68,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-2a021da8-b311-48c3-b0ac-2422e508675e,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-b478d0f4-e410-432f-9fc9-a71c20ed0d85,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-1ed6fd33-7dba-4ae1-be35-9f56a14fdf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-65bfd4a4-89ff-4e5e-9b92-44ed4a789d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-8f127f39-8c22-4f24-9309-e9a572814015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693934149-172.17.0.18-1597549968630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-43123046-b6b2-49cf-a351-7e24b9352f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-e4c515a2-d13d-483d-83f9-00a5a71a36a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-da96e0d8-ea0a-4af8-a420-ef851899bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-5ed898ca-66c2-41ff-8377-afd09bfe0748,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-1fb223de-1e08-4445-a068-cdf76b282bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-a2656546-abd2-4170-abdf-2668c0b4e3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-7f25e4b4-e231-4460-b626-5343530b0736,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-97bd11c5-a9ed-4aa8-8541-f4e3f4fc687e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693934149-172.17.0.18-1597549968630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-43123046-b6b2-49cf-a351-7e24b9352f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-e4c515a2-d13d-483d-83f9-00a5a71a36a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-da96e0d8-ea0a-4af8-a420-ef851899bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-5ed898ca-66c2-41ff-8377-afd09bfe0748,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-1fb223de-1e08-4445-a068-cdf76b282bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-a2656546-abd2-4170-abdf-2668c0b4e3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-7f25e4b4-e231-4460-b626-5343530b0736,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-97bd11c5-a9ed-4aa8-8541-f4e3f4fc687e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938196580-172.17.0.18-1597550272623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-2bee8b18-5bb8-4c66-b59f-591a52ec15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-1c41e976-965d-45b8-a6c6-48c44caa510a,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-68d0eea8-8686-45ed-a156-7c31f25ee7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-a8e554f3-f555-4a16-bd54-ebac0f15575e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-d896ef4a-c1af-4f43-942f-e4af7ff186aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-3f38b99a-ba60-43b3-ae3e-03ef785327ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-861a6852-1287-4061-bb18-31d2a9ad8212,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-29c9a177-7ec0-410c-8dd2-c7606a5f14a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938196580-172.17.0.18-1597550272623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-2bee8b18-5bb8-4c66-b59f-591a52ec15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-1c41e976-965d-45b8-a6c6-48c44caa510a,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-68d0eea8-8686-45ed-a156-7c31f25ee7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-a8e554f3-f555-4a16-bd54-ebac0f15575e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-d896ef4a-c1af-4f43-942f-e4af7ff186aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-3f38b99a-ba60-43b3-ae3e-03ef785327ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-861a6852-1287-4061-bb18-31d2a9ad8212,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-29c9a177-7ec0-410c-8dd2-c7606a5f14a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118760054-172.17.0.18-1597551961920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46026,DS-249fe7ba-4390-4050-93c8-08d12deb14a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-ecbacb34-bbc4-48c8-b800-7a5e719a8877,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-08e367d6-c6ec-43ff-84cd-29f4711b06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-4d4518f7-fffd-49b3-817b-b8e6aaac0afe,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-bec866b9-9a6b-424b-a8f1-e9697d6ce244,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-614ca7b0-d430-43c8-8ae6-40bc70680342,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-70c1961f-364f-43bf-b999-05dab9bdd16d,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-73606f78-419f-4d53-8291-5a48c7b03dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118760054-172.17.0.18-1597551961920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46026,DS-249fe7ba-4390-4050-93c8-08d12deb14a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-ecbacb34-bbc4-48c8-b800-7a5e719a8877,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-08e367d6-c6ec-43ff-84cd-29f4711b06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-4d4518f7-fffd-49b3-817b-b8e6aaac0afe,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-bec866b9-9a6b-424b-a8f1-e9697d6ce244,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-614ca7b0-d430-43c8-8ae6-40bc70680342,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-70c1961f-364f-43bf-b999-05dab9bdd16d,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-73606f78-419f-4d53-8291-5a48c7b03dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412322008-172.17.0.18-1597552396667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39156,DS-75396986-60e6-40c8-b54f-c04fdd3d1735,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-901b4449-d387-4a37-943f-ec4999955998,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-cc7d8784-4ca6-4777-887d-a96b5347515a,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-412128c8-366c-4c6e-9235-1e9fa6ea0056,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-d71e6b44-662c-4c5d-997d-74485fd48bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-b79b809d-5417-4820-9788-8c7c452cd4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-648ac848-1f98-4b6f-9f9e-9542f637b6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-f4e9cd9a-c10e-4887-b837-83a32cf62d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412322008-172.17.0.18-1597552396667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39156,DS-75396986-60e6-40c8-b54f-c04fdd3d1735,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-901b4449-d387-4a37-943f-ec4999955998,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-cc7d8784-4ca6-4777-887d-a96b5347515a,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-412128c8-366c-4c6e-9235-1e9fa6ea0056,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-d71e6b44-662c-4c5d-997d-74485fd48bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-b79b809d-5417-4820-9788-8c7c452cd4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-648ac848-1f98-4b6f-9f9e-9542f637b6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-f4e9cd9a-c10e-4887-b837-83a32cf62d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699589392-172.17.0.18-1597552447863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-84d44057-1c6d-4abc-8ae2-5dd155c2d9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-448d3755-60aa-482a-ba38-f721fd0606b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-7cc70bf7-aa9a-44a2-85c7-fcb4455cff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-907672ad-dc28-409f-a39a-c62ed60f5544,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-cb12408a-9149-4245-b6f9-4bb76c27c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-281aa100-af81-4831-ad1a-087313d10142,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-12e0d744-55ab-47e9-88ed-21f07017b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-c77e13ca-6e0c-46b5-89d0-37c788eef7f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699589392-172.17.0.18-1597552447863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-84d44057-1c6d-4abc-8ae2-5dd155c2d9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-448d3755-60aa-482a-ba38-f721fd0606b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-7cc70bf7-aa9a-44a2-85c7-fcb4455cff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-907672ad-dc28-409f-a39a-c62ed60f5544,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-cb12408a-9149-4245-b6f9-4bb76c27c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-281aa100-af81-4831-ad1a-087313d10142,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-12e0d744-55ab-47e9-88ed-21f07017b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-c77e13ca-6e0c-46b5-89d0-37c788eef7f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-890503133-172.17.0.18-1597553091248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-7e982ea9-6b47-4dcf-b380-932f9cc0780a,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-0e8c5e17-ae98-4f7a-a4e7-67c54a89073d,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-ad4737e9-ceeb-4d5a-b189-dc33ee931441,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-23e792e9-5474-4e12-ada2-70c5a94821e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-c7f9d5da-6eca-46c3-bef2-b2cfdbba0111,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-83e429e6-2150-4f1f-b16b-60408b837cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-11cd6089-13f1-4119-90e0-b257e1906bed,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-8a786ded-302e-44bc-ba45-710f101b2de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-890503133-172.17.0.18-1597553091248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-7e982ea9-6b47-4dcf-b380-932f9cc0780a,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-0e8c5e17-ae98-4f7a-a4e7-67c54a89073d,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-ad4737e9-ceeb-4d5a-b189-dc33ee931441,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-23e792e9-5474-4e12-ada2-70c5a94821e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-c7f9d5da-6eca-46c3-bef2-b2cfdbba0111,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-83e429e6-2150-4f1f-b16b-60408b837cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-11cd6089-13f1-4119-90e0-b257e1906bed,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-8a786ded-302e-44bc-ba45-710f101b2de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969128539-172.17.0.18-1597553293295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-3e8bfc84-2550-4b11-9a3b-4836118cff65,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-c0eb5b35-f0c7-4a7c-924b-bdfe499bdb82,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-33868821-70f0-4e1e-a82c-58e5789e7ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-f23774b4-b002-472b-ad86-1a530f96213f,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-abcb09b0-77a5-41ed-8000-fd852005e583,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-53d7d1c3-799f-4a62-8d86-580394310881,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-38e5334d-e9c6-47e7-a043-b47b75cd7f30,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-1dae2f67-f3ea-4c9e-99a0-7662e8d60e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969128539-172.17.0.18-1597553293295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-3e8bfc84-2550-4b11-9a3b-4836118cff65,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-c0eb5b35-f0c7-4a7c-924b-bdfe499bdb82,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-33868821-70f0-4e1e-a82c-58e5789e7ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-f23774b4-b002-472b-ad86-1a530f96213f,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-abcb09b0-77a5-41ed-8000-fd852005e583,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-53d7d1c3-799f-4a62-8d86-580394310881,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-38e5334d-e9c6-47e7-a043-b47b75cd7f30,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-1dae2f67-f3ea-4c9e-99a0-7662e8d60e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76737560-172.17.0.18-1597553816395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-64db455c-42a4-4d53-ad45-8bc795dece60,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-4cfbd96f-acb7-41ad-880b-2bd53d220244,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-1f128eaa-f4da-44fc-b09a-28fb2211d58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-54dc45ac-ec3c-45f2-b80a-037dc6f00eee,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-fdea24ac-e464-4b9a-b9e7-3074a3b48317,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-dab5ad87-46f1-403e-bc6b-c4dd3d57b090,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-44773b4f-8552-43df-af73-e6f9af03c4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-28e55d6e-e8e5-4071-ac9d-166617cdb1a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76737560-172.17.0.18-1597553816395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35111,DS-64db455c-42a4-4d53-ad45-8bc795dece60,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-4cfbd96f-acb7-41ad-880b-2bd53d220244,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-1f128eaa-f4da-44fc-b09a-28fb2211d58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-54dc45ac-ec3c-45f2-b80a-037dc6f00eee,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-fdea24ac-e464-4b9a-b9e7-3074a3b48317,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-dab5ad87-46f1-403e-bc6b-c4dd3d57b090,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-44773b4f-8552-43df-af73-e6f9af03c4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-28e55d6e-e8e5-4071-ac9d-166617cdb1a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352573710-172.17.0.18-1597554446194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36442,DS-8b8c1361-6b19-4b57-8b49-97ebfabd5016,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-d91c015c-b18b-41d8-ac54-d552d01f8472,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-c5baa40a-55b4-4be2-ad6d-6604ee8799b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-459e0c32-9e17-45fe-9e33-7c683a555966,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-770ac3a5-bae1-4b20-8a22-c1422b20156c,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-e5ffac4f-76f2-4078-be7f-ba54e13814c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-789dfd80-1ae7-462e-a695-4414fc6210b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-97937bba-bd75-4c52-8e1d-d8d4767510d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352573710-172.17.0.18-1597554446194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36442,DS-8b8c1361-6b19-4b57-8b49-97ebfabd5016,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-d91c015c-b18b-41d8-ac54-d552d01f8472,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-c5baa40a-55b4-4be2-ad6d-6604ee8799b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-459e0c32-9e17-45fe-9e33-7c683a555966,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-770ac3a5-bae1-4b20-8a22-c1422b20156c,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-e5ffac4f-76f2-4078-be7f-ba54e13814c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-789dfd80-1ae7-462e-a695-4414fc6210b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-97937bba-bd75-4c52-8e1d-d8d4767510d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756026693-172.17.0.18-1597554862678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-998987b2-5611-4aea-9f8b-a9c09c7007bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-39dcedfe-85f0-4c26-bb51-26dcf40fa778,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-2c1db4ab-13d3-47ca-8864-03edf301637d,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-cbcafba8-945c-497c-9f90-58d511367e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-b4db0b82-51fa-4ee1-8562-3ebc74586431,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-bff9564d-4e8b-4d7c-8a58-a14392cfc266,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-129842ac-f80b-486b-96c4-3afed104bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-310c5f58-b37d-4f39-a08e-6942b01ee40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756026693-172.17.0.18-1597554862678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-998987b2-5611-4aea-9f8b-a9c09c7007bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-39dcedfe-85f0-4c26-bb51-26dcf40fa778,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-2c1db4ab-13d3-47ca-8864-03edf301637d,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-cbcafba8-945c-497c-9f90-58d511367e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-b4db0b82-51fa-4ee1-8562-3ebc74586431,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-bff9564d-4e8b-4d7c-8a58-a14392cfc266,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-129842ac-f80b-486b-96c4-3afed104bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-310c5f58-b37d-4f39-a08e-6942b01ee40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813068862-172.17.0.18-1597555104014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-aba552f5-8bae-4517-b6ee-b50e264da668,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-ecd3b51f-d367-4483-ba59-d843cabed18d,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-58f394ed-1132-475c-a745-6533ee802ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-8aae7390-a6b9-4ecf-990f-c40c6733c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a4746351-a2c5-4a46-ba01-bacbf7df82e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-4aa93629-c7e0-4e96-8db2-cfb243f722f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-40e237d6-3156-49ca-a4e7-7576e008f003,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-609b5cc6-ec7b-454b-b6a2-973158c1f8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813068862-172.17.0.18-1597555104014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-aba552f5-8bae-4517-b6ee-b50e264da668,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-ecd3b51f-d367-4483-ba59-d843cabed18d,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-58f394ed-1132-475c-a745-6533ee802ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-8aae7390-a6b9-4ecf-990f-c40c6733c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a4746351-a2c5-4a46-ba01-bacbf7df82e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-4aa93629-c7e0-4e96-8db2-cfb243f722f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-40e237d6-3156-49ca-a4e7-7576e008f003,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-609b5cc6-ec7b-454b-b6a2-973158c1f8e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6711
