reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162172323-172.17.0.18-1597472451665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34191,DS-e7b75846-f424-4a41-9a2f-6caa5815d195,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-10eefcf4-69e8-4b95-96f9-65334026f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-23b0647d-9000-4d1a-8d11-18d59aa29dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-6af7ae03-7d73-43ff-9748-e97baedafa72,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-ec9b628f-e1c3-4697-9ae6-2c346403ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-18271488-f7df-4c98-a426-f7e22c750a70,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-85c19323-725c-480d-8c90-f732e738eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-c8945529-b5d3-4300-a717-181806919bca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162172323-172.17.0.18-1597472451665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34191,DS-e7b75846-f424-4a41-9a2f-6caa5815d195,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-10eefcf4-69e8-4b95-96f9-65334026f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-23b0647d-9000-4d1a-8d11-18d59aa29dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-6af7ae03-7d73-43ff-9748-e97baedafa72,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-ec9b628f-e1c3-4697-9ae6-2c346403ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-18271488-f7df-4c98-a426-f7e22c750a70,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-85c19323-725c-480d-8c90-f732e738eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-c8945529-b5d3-4300-a717-181806919bca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141921669-172.17.0.18-1597472557414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-1f9726b5-0c80-4684-a7f1-3a9ae089daac,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-e3519ab5-4fd0-4513-93bc-a64d31a19d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-e9395548-952c-4930-af1c-02e1c93fc125,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-6a215908-48c7-4044-bed4-3305c49f6644,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-059c121c-cbcc-4535-86bf-538894270b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-e0a6b09d-d411-475b-8d8f-71f9d76b9d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-dac2be75-4ad1-4ee1-91f0-261e46ef05bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-ea72bcf0-7489-4520-b0a2-7d8b168fb309,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141921669-172.17.0.18-1597472557414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36703,DS-1f9726b5-0c80-4684-a7f1-3a9ae089daac,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-e3519ab5-4fd0-4513-93bc-a64d31a19d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-e9395548-952c-4930-af1c-02e1c93fc125,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-6a215908-48c7-4044-bed4-3305c49f6644,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-059c121c-cbcc-4535-86bf-538894270b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-e0a6b09d-d411-475b-8d8f-71f9d76b9d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-dac2be75-4ad1-4ee1-91f0-261e46ef05bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-ea72bcf0-7489-4520-b0a2-7d8b168fb309,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013366354-172.17.0.18-1597472647730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-1a6968cf-394b-4c40-a540-b84a24420940,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-adfb907a-2e91-48c5-8cc1-9ddba0b89e95,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-33ee4048-9060-49f2-9dac-464520293423,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-5587cd2d-6eab-4d6f-82f4-e24fe0db47a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-a760aac3-5f18-4467-997e-29acc44e9335,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-c8a463a4-cf81-43fa-8751-0046977f01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-859d94c1-9968-4fad-9dac-6acda6b2a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-306ddb2b-37f0-42eb-b7bb-f73fe13f2896,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013366354-172.17.0.18-1597472647730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-1a6968cf-394b-4c40-a540-b84a24420940,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-adfb907a-2e91-48c5-8cc1-9ddba0b89e95,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-33ee4048-9060-49f2-9dac-464520293423,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-5587cd2d-6eab-4d6f-82f4-e24fe0db47a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-a760aac3-5f18-4467-997e-29acc44e9335,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-c8a463a4-cf81-43fa-8751-0046977f01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-859d94c1-9968-4fad-9dac-6acda6b2a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-306ddb2b-37f0-42eb-b7bb-f73fe13f2896,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587569349-172.17.0.18-1597472936687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44770,DS-edbd1abc-1c96-449d-98b5-9bc215c7c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-51e75853-36d7-4291-bcdf-c3a899553241,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-eac29aa1-4fbc-4047-805a-1af2943ffc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-ccf38a38-86b4-45dc-b56a-d792f23d103d,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-6bc2d022-83ff-47a7-b91f-725f07cfe459,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-b735dd49-1473-4cf6-8850-68424c18afbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-aa8a7cf7-32e9-43a5-bc94-c48fee26f902,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-370a58d4-f84f-4f1a-977c-c18c60c757bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587569349-172.17.0.18-1597472936687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44770,DS-edbd1abc-1c96-449d-98b5-9bc215c7c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-51e75853-36d7-4291-bcdf-c3a899553241,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-eac29aa1-4fbc-4047-805a-1af2943ffc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-ccf38a38-86b4-45dc-b56a-d792f23d103d,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-6bc2d022-83ff-47a7-b91f-725f07cfe459,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-b735dd49-1473-4cf6-8850-68424c18afbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-aa8a7cf7-32e9-43a5-bc94-c48fee26f902,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-370a58d4-f84f-4f1a-977c-c18c60c757bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275976449-172.17.0.18-1597472983585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46588,DS-63c09aae-a08c-4479-9ef1-161b53edee28,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-625311d2-e083-4ed1-8f1b-4c47d611892e,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-27e11bf6-f7b5-4ca4-8f72-36406d10096e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-043738bf-f2e7-4ecb-9be1-844ef72fb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-fd5fa93c-965b-49b8-a1fa-344d51e0674d,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-39f4d79a-3de7-4dfb-8614-7d844998dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-544173f5-6098-473d-8788-e086510e50ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-843fb194-b70c-4322-864b-df0fdd784a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275976449-172.17.0.18-1597472983585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46588,DS-63c09aae-a08c-4479-9ef1-161b53edee28,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-625311d2-e083-4ed1-8f1b-4c47d611892e,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-27e11bf6-f7b5-4ca4-8f72-36406d10096e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-043738bf-f2e7-4ecb-9be1-844ef72fb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-fd5fa93c-965b-49b8-a1fa-344d51e0674d,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-39f4d79a-3de7-4dfb-8614-7d844998dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-544173f5-6098-473d-8788-e086510e50ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-843fb194-b70c-4322-864b-df0fdd784a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127398120-172.17.0.18-1597473224817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-c320bfc6-fdcf-4c07-92c8-2531b614a690,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-a207250a-65e0-4a47-a99d-f867dca6b745,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-6faea129-1c07-4cc1-be55-a4a1ab7ff648,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-3cd1b925-85a1-4c32-b342-38a19ad241d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-dbefeea2-93af-4bce-8865-73a0f4a3f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-23cb9c16-47c8-4cfa-a1d9-c89fdcee1c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-55ae0516-7a73-4b6c-9618-eb68b485e3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-b9fc5886-ca94-4671-9a43-e4c747ddc498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127398120-172.17.0.18-1597473224817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-c320bfc6-fdcf-4c07-92c8-2531b614a690,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-a207250a-65e0-4a47-a99d-f867dca6b745,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-6faea129-1c07-4cc1-be55-a4a1ab7ff648,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-3cd1b925-85a1-4c32-b342-38a19ad241d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-dbefeea2-93af-4bce-8865-73a0f4a3f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-23cb9c16-47c8-4cfa-a1d9-c89fdcee1c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-55ae0516-7a73-4b6c-9618-eb68b485e3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-b9fc5886-ca94-4671-9a43-e4c747ddc498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165784617-172.17.0.18-1597473272141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-29128999-097a-4055-be0a-1db7ca8baca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-b64c73cf-c38e-45dc-932f-d6cfc4bf608e,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-1b4168ed-7ab0-412b-a1d8-b3fa7c5af279,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-f144e841-d3d3-4224-95b5-1f24b093323b,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-d4804bd3-dd88-4d8e-8fc2-3646f8bf4d16,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-843f518f-f6f0-47de-9293-7f8a438c66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-a9416127-1173-4a85-a5d0-8571f7863ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-2f6208ea-cd2c-4859-9092-1dd5b15858f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165784617-172.17.0.18-1597473272141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-29128999-097a-4055-be0a-1db7ca8baca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-b64c73cf-c38e-45dc-932f-d6cfc4bf608e,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-1b4168ed-7ab0-412b-a1d8-b3fa7c5af279,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-f144e841-d3d3-4224-95b5-1f24b093323b,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-d4804bd3-dd88-4d8e-8fc2-3646f8bf4d16,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-843f518f-f6f0-47de-9293-7f8a438c66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-a9416127-1173-4a85-a5d0-8571f7863ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-2f6208ea-cd2c-4859-9092-1dd5b15858f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479938054-172.17.0.18-1597473326889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38906,DS-4075caf5-134b-4764-92c2-38e0433b42aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-53182f09-0deb-4ea7-8a65-690a9eddf63e,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-00fa701e-9d43-411a-959d-28035d6a63a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-7a8153bf-5e6f-4d29-bfbe-c7ba012b5a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-89de92eb-e7b1-41fc-a005-dff4fe4ec41e,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-0486c4d2-1b41-4f4e-9485-d92033f606f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-7d4c810c-9d4e-4e36-8983-a660287a27bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-2f01abc6-deb3-47e6-87b3-75501eb4f13e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479938054-172.17.0.18-1597473326889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38906,DS-4075caf5-134b-4764-92c2-38e0433b42aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-53182f09-0deb-4ea7-8a65-690a9eddf63e,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-00fa701e-9d43-411a-959d-28035d6a63a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-7a8153bf-5e6f-4d29-bfbe-c7ba012b5a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-89de92eb-e7b1-41fc-a005-dff4fe4ec41e,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-0486c4d2-1b41-4f4e-9485-d92033f606f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-7d4c810c-9d4e-4e36-8983-a660287a27bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-2f01abc6-deb3-47e6-87b3-75501eb4f13e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601567459-172.17.0.18-1597473468099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-28476d44-1461-4611-8729-734edf7d733f,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-f541dc9b-baa0-45f9-bcbd-fb6c0f70edf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-bc900f4c-e453-4cbb-a068-d50ff5b98cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-57766ff8-1c3c-464f-9079-6c5f9d8d2217,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-0945152a-bf08-48d4-9d3a-173ba2eefe24,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-b56bc3d1-ea8f-4f0d-ba09-e078f9b70ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-e2e64a23-f90b-4a09-8311-ab820f869411,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-063a9c96-5254-46ae-abf0-7befd9e0e6cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601567459-172.17.0.18-1597473468099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-28476d44-1461-4611-8729-734edf7d733f,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-f541dc9b-baa0-45f9-bcbd-fb6c0f70edf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-bc900f4c-e453-4cbb-a068-d50ff5b98cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-57766ff8-1c3c-464f-9079-6c5f9d8d2217,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-0945152a-bf08-48d4-9d3a-173ba2eefe24,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-b56bc3d1-ea8f-4f0d-ba09-e078f9b70ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-e2e64a23-f90b-4a09-8311-ab820f869411,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-063a9c96-5254-46ae-abf0-7befd9e0e6cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263447589-172.17.0.18-1597473738594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33567,DS-13fe1450-7177-4fb2-9052-49a526248b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-60ff9398-f153-4223-8a3b-e3f3b6f8c084,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-7d508987-fff8-41ee-9178-61672461aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-6ef92375-0f26-4511-a3cd-d0b45d90d089,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-f64d5768-753b-4ac9-9f75-276a8e6f5b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-ef7a6f4f-cf56-4260-984e-2be1f3905a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-0cabd578-2aae-4b0a-a47c-3e9dc594619b,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-44c8d20b-39a4-4a26-9f24-f25599143155,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263447589-172.17.0.18-1597473738594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33567,DS-13fe1450-7177-4fb2-9052-49a526248b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-60ff9398-f153-4223-8a3b-e3f3b6f8c084,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-7d508987-fff8-41ee-9178-61672461aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-6ef92375-0f26-4511-a3cd-d0b45d90d089,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-f64d5768-753b-4ac9-9f75-276a8e6f5b45,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-ef7a6f4f-cf56-4260-984e-2be1f3905a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-0cabd578-2aae-4b0a-a47c-3e9dc594619b,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-44c8d20b-39a4-4a26-9f24-f25599143155,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128715501-172.17.0.18-1597473979556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-5c727a12-9a69-43d4-94f9-bbb221931bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-a9511d95-92a6-4ce4-8b00-76073b6259aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-c448d12e-a54a-4d59-b844-0efa3817d478,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-a678fe0c-a897-47fe-a7c2-93f0a0d6bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-fd56a920-33c5-4987-a5a1-135d92868d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-7ff2bc2b-c522-4673-a4e9-9bf964941ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-29b66993-efab-421a-b6db-e351ed99713b,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-ad95f27c-2cb3-433b-95f6-9d620ad036f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128715501-172.17.0.18-1597473979556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-5c727a12-9a69-43d4-94f9-bbb221931bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-a9511d95-92a6-4ce4-8b00-76073b6259aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-c448d12e-a54a-4d59-b844-0efa3817d478,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-a678fe0c-a897-47fe-a7c2-93f0a0d6bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-fd56a920-33c5-4987-a5a1-135d92868d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-7ff2bc2b-c522-4673-a4e9-9bf964941ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-29b66993-efab-421a-b6db-e351ed99713b,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-ad95f27c-2cb3-433b-95f6-9d620ad036f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907351626-172.17.0.18-1597474475153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36420,DS-21748d8f-a18c-4339-8060-89ee45ba12b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-a3ef7ea4-b9d4-40f4-90fe-1cd08e259fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-ce05250a-ffed-45e2-8359-59019fa25509,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-46426836-724d-4b1e-a7d1-cb328a560eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-067d369c-6fe6-4497-9627-c384e4d4e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-908d0262-3a1d-4cbd-adbc-7837ab18e720,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-fa2dac1f-9a83-41e5-a55a-c4e1e33b4b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-3201432d-2d3a-4aa9-91ee-bc908a164c17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907351626-172.17.0.18-1597474475153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36420,DS-21748d8f-a18c-4339-8060-89ee45ba12b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-a3ef7ea4-b9d4-40f4-90fe-1cd08e259fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-ce05250a-ffed-45e2-8359-59019fa25509,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-46426836-724d-4b1e-a7d1-cb328a560eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-067d369c-6fe6-4497-9627-c384e4d4e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-908d0262-3a1d-4cbd-adbc-7837ab18e720,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-fa2dac1f-9a83-41e5-a55a-c4e1e33b4b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-3201432d-2d3a-4aa9-91ee-bc908a164c17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438907823-172.17.0.18-1597474624680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-c8c506f3-6a16-48e6-a246-1b36f4e692c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-a343fe44-cc54-420c-be5f-76dc1cb9814c,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-c886e586-709c-40d2-a3b0-9467d11573bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-aa0ba309-8214-4c27-9527-16dffc583930,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-e6187f35-1e89-4bc0-923a-63735adf4dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ac30ffea-eb4b-442d-ac78-de4c926a8b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-613ea027-b070-48db-9a02-eca66b98d853,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-27235e95-6824-4fb8-8783-793083cb1535,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438907823-172.17.0.18-1597474624680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-c8c506f3-6a16-48e6-a246-1b36f4e692c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-a343fe44-cc54-420c-be5f-76dc1cb9814c,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-c886e586-709c-40d2-a3b0-9467d11573bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-aa0ba309-8214-4c27-9527-16dffc583930,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-e6187f35-1e89-4bc0-923a-63735adf4dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ac30ffea-eb4b-442d-ac78-de4c926a8b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-613ea027-b070-48db-9a02-eca66b98d853,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-27235e95-6824-4fb8-8783-793083cb1535,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206861327-172.17.0.18-1597474811893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41516,DS-461d08e4-85fc-4d05-9eb7-898a64f60325,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-6d9ce580-5744-4116-a167-26cb90d269b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-93ebe086-ce22-4d3b-bac4-492fb8da09eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-5258ba21-9e13-414f-bd6c-9db7f26b49ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-1031d96d-022e-40ad-9a9c-a46dd45ee519,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-506ed887-709f-4e59-af87-4a86a912e31d,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-a6d8582e-f746-458b-96b7-42a9c351c2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-22058596-11d3-4b1b-b428-4b06428cd4c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206861327-172.17.0.18-1597474811893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41516,DS-461d08e4-85fc-4d05-9eb7-898a64f60325,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-6d9ce580-5744-4116-a167-26cb90d269b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-93ebe086-ce22-4d3b-bac4-492fb8da09eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-5258ba21-9e13-414f-bd6c-9db7f26b49ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-1031d96d-022e-40ad-9a9c-a46dd45ee519,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-506ed887-709f-4e59-af87-4a86a912e31d,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-a6d8582e-f746-458b-96b7-42a9c351c2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-22058596-11d3-4b1b-b428-4b06428cd4c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789169235-172.17.0.18-1597474857153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37844,DS-a7a9b321-ab20-45f4-921d-12453e11478b,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-4af57dcc-010e-4901-bd63-03993a979b03,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-689cf1ce-3607-49b3-81ab-2c1d8d59841c,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-ae39043e-acb3-48ab-b4da-a4719d79c908,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-bd5e3cf6-bfbd-486b-8f4d-645624a8b2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-eb9acf9d-a3b3-4a2f-8c8a-608712e30e38,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ac017322-1161-4e5e-a561-7139aabdbad5,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-0b14c1ad-5deb-4eb5-8922-d981007fb751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789169235-172.17.0.18-1597474857153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37844,DS-a7a9b321-ab20-45f4-921d-12453e11478b,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-4af57dcc-010e-4901-bd63-03993a979b03,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-689cf1ce-3607-49b3-81ab-2c1d8d59841c,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-ae39043e-acb3-48ab-b4da-a4719d79c908,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-bd5e3cf6-bfbd-486b-8f4d-645624a8b2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-eb9acf9d-a3b3-4a2f-8c8a-608712e30e38,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ac017322-1161-4e5e-a561-7139aabdbad5,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-0b14c1ad-5deb-4eb5-8922-d981007fb751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884185019-172.17.0.18-1597474951930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37813,DS-e02ab297-8b6a-47b9-8ad7-9fc88faa800b,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-76159f93-6b81-4d48-8783-71ca8cc3d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-60c7e14a-22e7-4369-ad23-5f4211382bae,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-526f5493-f4af-4a46-8a86-0214f5e562ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-44dd63b9-450e-4195-a011-14c30552f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-6293ffc0-146f-4e7e-9f89-2759b3b36ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-e46413f3-fac8-44c4-931a-909394e7225f,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-061747bc-ad8a-48f1-865e-83c886b18948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884185019-172.17.0.18-1597474951930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37813,DS-e02ab297-8b6a-47b9-8ad7-9fc88faa800b,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-76159f93-6b81-4d48-8783-71ca8cc3d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-60c7e14a-22e7-4369-ad23-5f4211382bae,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-526f5493-f4af-4a46-8a86-0214f5e562ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-44dd63b9-450e-4195-a011-14c30552f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-6293ffc0-146f-4e7e-9f89-2759b3b36ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-e46413f3-fac8-44c4-931a-909394e7225f,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-061747bc-ad8a-48f1-865e-83c886b18948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665144875-172.17.0.18-1597475043679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-0b6089a2-92f3-4c2b-ac41-2879daf9db83,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-a3b8f03b-2e6d-4267-82f8-701a2a86eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-09e52091-81c6-4778-91a9-7dc5bbfcb6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-54189c51-f28c-4054-ba56-83930533b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-2f03d64d-d20f-466b-a59a-bb750826221a,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-125e6848-d1ff-403e-9193-d1c3bd10beb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-7222abce-6991-4135-9c72-0530e163ecd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-27dc7926-fbcf-4a8a-9d44-e471c809bce7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665144875-172.17.0.18-1597475043679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-0b6089a2-92f3-4c2b-ac41-2879daf9db83,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-a3b8f03b-2e6d-4267-82f8-701a2a86eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-09e52091-81c6-4778-91a9-7dc5bbfcb6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-54189c51-f28c-4054-ba56-83930533b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-2f03d64d-d20f-466b-a59a-bb750826221a,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-125e6848-d1ff-403e-9193-d1c3bd10beb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-7222abce-6991-4135-9c72-0530e163ecd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-27dc7926-fbcf-4a8a-9d44-e471c809bce7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582570130-172.17.0.18-1597475142865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-026022b3-cc87-40ac-8103-dcdc42e6da67,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-d35390da-37e6-4846-beed-2e94a577171a,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-5f5a38a9-7392-4e61-bdb5-49efceb6fe14,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8c843712-51ba-4b71-8f6e-573fb4b9c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-d0f6c174-ceb0-4d04-969e-e6e181509189,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-f4ffe62b-f3e2-49e7-9044-e6d9b6422ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-edcbf558-5a4b-47e3-b68c-b0cf11b586e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-01220802-0b5f-4353-850e-012d672c3673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582570130-172.17.0.18-1597475142865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-026022b3-cc87-40ac-8103-dcdc42e6da67,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-d35390da-37e6-4846-beed-2e94a577171a,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-5f5a38a9-7392-4e61-bdb5-49efceb6fe14,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8c843712-51ba-4b71-8f6e-573fb4b9c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-d0f6c174-ceb0-4d04-969e-e6e181509189,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-f4ffe62b-f3e2-49e7-9044-e6d9b6422ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-edcbf558-5a4b-47e3-b68c-b0cf11b586e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-01220802-0b5f-4353-850e-012d672c3673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121807349-172.17.0.18-1597475243945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37896,DS-b7c867ac-c6ee-4766-af24-317ddbf7330f,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-c35b2e4d-054a-49fc-8305-0c6b4e308f23,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-fd5a1362-03f0-41f7-8828-acd7ac4989cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-f98e9195-fad6-4266-99da-8952219961ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-4781b0ed-3575-47af-8839-ed1a9d458301,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-4d32acd4-0db6-45af-85ad-edf3df8053d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-2fb4f511-e046-4e2a-b861-39affd7e00f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-a0eee72f-cd1c-4dde-9c5c-ae99250fec11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121807349-172.17.0.18-1597475243945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37896,DS-b7c867ac-c6ee-4766-af24-317ddbf7330f,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-c35b2e4d-054a-49fc-8305-0c6b4e308f23,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-fd5a1362-03f0-41f7-8828-acd7ac4989cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-f98e9195-fad6-4266-99da-8952219961ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-4781b0ed-3575-47af-8839-ed1a9d458301,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-4d32acd4-0db6-45af-85ad-edf3df8053d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-2fb4f511-e046-4e2a-b861-39affd7e00f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-a0eee72f-cd1c-4dde-9c5c-ae99250fec11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253136057-172.17.0.18-1597475671805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33046,DS-c5ffda0a-7dc3-46c2-829d-20deefcfc797,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-82a0dc2d-9b1f-4c69-83c2-3602f611fe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-d4ef080e-d125-4161-ac5d-e55fb1a42319,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-f923f5d7-ac9f-4838-94f7-58f92ce2c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-eff20d22-b6d2-472a-b9f6-95a67d86bec7,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-210a657a-7a80-40e8-a6da-e715de5e3fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-eaccbe8c-854f-4038-b411-195430daa423,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-e09010fc-f41e-4a87-a379-c8d2035bce2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253136057-172.17.0.18-1597475671805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33046,DS-c5ffda0a-7dc3-46c2-829d-20deefcfc797,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-82a0dc2d-9b1f-4c69-83c2-3602f611fe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-d4ef080e-d125-4161-ac5d-e55fb1a42319,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-f923f5d7-ac9f-4838-94f7-58f92ce2c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-eff20d22-b6d2-472a-b9f6-95a67d86bec7,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-210a657a-7a80-40e8-a6da-e715de5e3fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-eaccbe8c-854f-4038-b411-195430daa423,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-e09010fc-f41e-4a87-a379-c8d2035bce2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168968559-172.17.0.18-1597475726601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-9e081581-c133-45ca-99d5-b1d84bae9839,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-488bf45b-8b6d-441b-895e-f170ddbec66f,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-5e3c4dd7-05eb-4349-8e4c-901c88208cae,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-c9478d02-9324-449a-9cf3-409eac45951c,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-745374fc-6858-49bb-ba17-c39a51e15f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-f567aff0-eec9-40f7-a4eb-2d5d6d66f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-6797fac5-594b-4d2e-8dbc-44bcc91a476f,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-305af8f1-d2cd-43df-9215-e213058f5e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168968559-172.17.0.18-1597475726601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-9e081581-c133-45ca-99d5-b1d84bae9839,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-488bf45b-8b6d-441b-895e-f170ddbec66f,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-5e3c4dd7-05eb-4349-8e4c-901c88208cae,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-c9478d02-9324-449a-9cf3-409eac45951c,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-745374fc-6858-49bb-ba17-c39a51e15f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-f567aff0-eec9-40f7-a4eb-2d5d6d66f49e,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-6797fac5-594b-4d2e-8dbc-44bcc91a476f,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-305af8f1-d2cd-43df-9215-e213058f5e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018310692-172.17.0.18-1597475863732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-ce1a7e61-9a1c-4052-bf7a-ae8af73aea65,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-9d406cf0-a3bb-4ee2-914d-b3715de6f3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-cab96952-b8d5-41f2-ae26-511a4de5204d,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-8f0f239c-2f8e-4478-8cd3-2d610b81baf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-73266c6b-a05f-4faf-acc7-c0c80573de34,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-95513880-29b0-4246-9d99-82b06d2430c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-886eaaab-1336-4c98-bb1e-960738ec0418,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-4943812e-da34-4b3a-8233-cd9869c32544,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018310692-172.17.0.18-1597475863732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-ce1a7e61-9a1c-4052-bf7a-ae8af73aea65,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-9d406cf0-a3bb-4ee2-914d-b3715de6f3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-cab96952-b8d5-41f2-ae26-511a4de5204d,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-8f0f239c-2f8e-4478-8cd3-2d610b81baf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-73266c6b-a05f-4faf-acc7-c0c80573de34,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-95513880-29b0-4246-9d99-82b06d2430c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-886eaaab-1336-4c98-bb1e-960738ec0418,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-4943812e-da34-4b3a-8233-cd9869c32544,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132841452-172.17.0.18-1597476097526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-1f9a14d4-35fd-46f0-8087-dabbb909da3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-3bfa7bd6-5e10-49d5-8118-37766a625233,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-f4a3160f-b395-450a-948e-7c2e6a5fa954,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-a6be235c-c133-4776-b35c-66e07c8947f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-17bcbb10-6cf3-4ac0-997f-d54963c1e878,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-1e6f769a-e42c-4201-ab8c-d40cb8bc37e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-653e2b1a-c30d-48be-a55c-6e54e80ab99f,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-47fb8907-f538-44fb-96c5-0b0d0e5a79b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132841452-172.17.0.18-1597476097526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-1f9a14d4-35fd-46f0-8087-dabbb909da3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-3bfa7bd6-5e10-49d5-8118-37766a625233,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-f4a3160f-b395-450a-948e-7c2e6a5fa954,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-a6be235c-c133-4776-b35c-66e07c8947f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-17bcbb10-6cf3-4ac0-997f-d54963c1e878,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-1e6f769a-e42c-4201-ab8c-d40cb8bc37e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-653e2b1a-c30d-48be-a55c-6e54e80ab99f,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-47fb8907-f538-44fb-96c5-0b0d0e5a79b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066277709-172.17.0.18-1597476229789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-6d69c93e-c981-4bf7-9031-cb33e624a049,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-ff64c2d2-425f-471f-9eb3-395e712267ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-e9c79d63-9cec-4ae5-9ba5-7fd479909ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-1497d066-7c1b-4bd9-8d07-d312f9c6331a,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-fd2531c9-52c6-4800-ad5c-6e0490c7fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-29f4e449-1ef4-48d1-8bbc-f70fcfd58a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-46ab95f7-eb18-4006-8a1e-a53397a62c68,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-dc4ad32d-0a77-4ba9-8291-a7f30e584420,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066277709-172.17.0.18-1597476229789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-6d69c93e-c981-4bf7-9031-cb33e624a049,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-ff64c2d2-425f-471f-9eb3-395e712267ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-e9c79d63-9cec-4ae5-9ba5-7fd479909ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-1497d066-7c1b-4bd9-8d07-d312f9c6331a,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-fd2531c9-52c6-4800-ad5c-6e0490c7fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-29f4e449-1ef4-48d1-8bbc-f70fcfd58a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-46ab95f7-eb18-4006-8a1e-a53397a62c68,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-dc4ad32d-0a77-4ba9-8291-a7f30e584420,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959713231-172.17.0.18-1597476335353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-dd0b24bd-c27c-4d06-a1e5-ef210e8ef6de,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-90834cc7-ea56-4be1-b3d1-320e2c1d2834,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-1006aac2-9615-470d-a407-2eb1963b85fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-9760f6e7-a930-4f58-8b6a-f1bfdc1b341a,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-76f02eb2-28f1-48f0-8d3d-10d08dae9408,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-0dac2e99-f2f2-4581-9004-f41300eea4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-5512f7b7-dca7-4c98-94f9-a89562d62bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-0e24472a-9296-4ec4-a9b4-19940fae2be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959713231-172.17.0.18-1597476335353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-dd0b24bd-c27c-4d06-a1e5-ef210e8ef6de,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-90834cc7-ea56-4be1-b3d1-320e2c1d2834,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-1006aac2-9615-470d-a407-2eb1963b85fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-9760f6e7-a930-4f58-8b6a-f1bfdc1b341a,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-76f02eb2-28f1-48f0-8d3d-10d08dae9408,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-0dac2e99-f2f2-4581-9004-f41300eea4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-5512f7b7-dca7-4c98-94f9-a89562d62bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-0e24472a-9296-4ec4-a9b4-19940fae2be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721574465-172.17.0.18-1597476632783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35962,DS-a3cf261e-a313-4bd6-a018-d6d32da31ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-8f59f28c-d066-47e7-8045-9276e3c49014,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-7f11be2e-b72a-4ac0-a6d4-31c5cb541a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-c63e5258-7210-4d62-ac76-549712bb622e,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-5630922b-9575-49fb-894c-86fadaa8c193,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-3238d51b-39f2-44ff-bbe5-313c5f88d413,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-ee646327-fef0-4a42-b0f8-3db8f1076d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-eee60c36-4881-4e0a-83cd-ae07aee18ba4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721574465-172.17.0.18-1597476632783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35962,DS-a3cf261e-a313-4bd6-a018-d6d32da31ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-8f59f28c-d066-47e7-8045-9276e3c49014,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-7f11be2e-b72a-4ac0-a6d4-31c5cb541a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-c63e5258-7210-4d62-ac76-549712bb622e,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-5630922b-9575-49fb-894c-86fadaa8c193,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-3238d51b-39f2-44ff-bbe5-313c5f88d413,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-ee646327-fef0-4a42-b0f8-3db8f1076d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-eee60c36-4881-4e0a-83cd-ae07aee18ba4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059658472-172.17.0.18-1597476756362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-f442cab3-ab0a-4de8-ba3e-56d932f12c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-606d4851-9877-495f-a0a3-e702949b9118,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-7e3943c9-dbf7-4f0b-9651-07d5cb667aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-ee09ebeb-7f30-4b96-9de3-814004607d53,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-80a635c2-e31d-47ac-9e67-7d88de5bea10,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-b3a751d5-04e9-4aff-8f0b-524839373e78,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-6a2feb1c-4a53-4bcd-b65f-bde8333180d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-5a7193ba-eec4-456e-9cc1-8a9662778e6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059658472-172.17.0.18-1597476756362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-f442cab3-ab0a-4de8-ba3e-56d932f12c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-606d4851-9877-495f-a0a3-e702949b9118,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-7e3943c9-dbf7-4f0b-9651-07d5cb667aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-ee09ebeb-7f30-4b96-9de3-814004607d53,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-80a635c2-e31d-47ac-9e67-7d88de5bea10,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-b3a751d5-04e9-4aff-8f0b-524839373e78,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-6a2feb1c-4a53-4bcd-b65f-bde8333180d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-5a7193ba-eec4-456e-9cc1-8a9662778e6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226677532-172.17.0.18-1597476949914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33504,DS-b9eef13c-cc4b-44cf-9e28-86055835fb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-451024af-fa52-47c4-a9f1-c649d4a4c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-ec9049b3-8c0b-4112-bd2f-2f81609a54d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-f30c13eb-b614-4bed-aaef-bcc0c5bda942,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-01b2814b-1ad2-443f-b105-c7c21d7d5851,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-ff30eb8d-fa74-4d6b-907c-fca892b8de4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-f05bc89a-deef-4143-a019-2ea7ea046ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-77cd7b13-7b03-42b1-948d-0a89f9d9bcb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226677532-172.17.0.18-1597476949914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33504,DS-b9eef13c-cc4b-44cf-9e28-86055835fb94,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-451024af-fa52-47c4-a9f1-c649d4a4c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-ec9049b3-8c0b-4112-bd2f-2f81609a54d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-f30c13eb-b614-4bed-aaef-bcc0c5bda942,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-01b2814b-1ad2-443f-b105-c7c21d7d5851,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-ff30eb8d-fa74-4d6b-907c-fca892b8de4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-f05bc89a-deef-4143-a019-2ea7ea046ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-77cd7b13-7b03-42b1-948d-0a89f9d9bcb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461360865-172.17.0.18-1597477033100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37903,DS-6fdfa345-9dad-4558-8c0d-28b62c0b7bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-94bce8a9-2351-4d2a-b52b-7f54eb899e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-17e9ff94-76d4-4a49-80b1-99457da8d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-c869ddcf-c47c-4af1-9a7f-d1fb5209ea61,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-b200af77-2865-4f32-afa7-43442d2b26bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-f85b5d3e-9e15-4c2f-8465-8a44f7e1abd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-e4330a6c-f002-4dfe-ab8f-f3fc26ea93e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-c0dedfd9-88e4-4cff-a025-b163e87b78b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461360865-172.17.0.18-1597477033100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37903,DS-6fdfa345-9dad-4558-8c0d-28b62c0b7bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-94bce8a9-2351-4d2a-b52b-7f54eb899e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-17e9ff94-76d4-4a49-80b1-99457da8d7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-c869ddcf-c47c-4af1-9a7f-d1fb5209ea61,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-b200af77-2865-4f32-afa7-43442d2b26bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-f85b5d3e-9e15-4c2f-8465-8a44f7e1abd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-e4330a6c-f002-4dfe-ab8f-f3fc26ea93e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-c0dedfd9-88e4-4cff-a025-b163e87b78b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835388417-172.17.0.18-1597477130372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33289,DS-095f2186-45f8-4f1c-b402-eb8071e60874,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-8e64324e-aa9c-40c6-911e-ad36d3f0817a,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-6de9a0ed-1f7a-425e-a99f-3383c3d9ca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-fba2b7a1-d9ad-4842-8c0d-c613c05e0c62,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-03dab24f-f728-4046-ace3-5dad401ce5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-a217a9e8-bb7e-4b90-9ce2-1ed851ddde9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-69f9f802-1052-441d-8421-89dc5bf20106,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-8df716b5-5d3e-4db0-b200-b94e6e21e674,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835388417-172.17.0.18-1597477130372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33289,DS-095f2186-45f8-4f1c-b402-eb8071e60874,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-8e64324e-aa9c-40c6-911e-ad36d3f0817a,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-6de9a0ed-1f7a-425e-a99f-3383c3d9ca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-fba2b7a1-d9ad-4842-8c0d-c613c05e0c62,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-03dab24f-f728-4046-ace3-5dad401ce5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-a217a9e8-bb7e-4b90-9ce2-1ed851ddde9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-69f9f802-1052-441d-8421-89dc5bf20106,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-8df716b5-5d3e-4db0-b200-b94e6e21e674,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335697648-172.17.0.18-1597477332862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34245,DS-311f6437-278e-4f1b-8994-2c5ec1719653,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-c98e392a-df46-40c1-9ce9-a5b89555a9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-0121e2b2-14b2-40bb-b34a-01842d56377d,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-3f03fae3-6a65-48be-bcc1-b33e3b5457e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-908ccb71-ce5c-49e5-a622-faa0b6e607b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-15e7adb5-db51-45ea-93be-a71c34672a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-51b0cbdf-d367-41d2-831a-94db310def8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-4e30872a-0ae9-4927-9e77-bc096b333881,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335697648-172.17.0.18-1597477332862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34245,DS-311f6437-278e-4f1b-8994-2c5ec1719653,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-c98e392a-df46-40c1-9ce9-a5b89555a9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-0121e2b2-14b2-40bb-b34a-01842d56377d,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-3f03fae3-6a65-48be-bcc1-b33e3b5457e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-908ccb71-ce5c-49e5-a622-faa0b6e607b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-15e7adb5-db51-45ea-93be-a71c34672a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-51b0cbdf-d367-41d2-831a-94db310def8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-4e30872a-0ae9-4927-9e77-bc096b333881,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083138768-172.17.0.18-1597477467225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-a5010dcb-f41e-4878-8cc7-a3d641e2ce8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-df904b67-968d-4947-ba7c-deea74437fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-5c7c50ed-1d32-4a57-8b55-bb0c6fb18bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-45fa8683-6330-400f-bdd9-9287f3e49497,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-22d8d579-5581-41b4-8513-31853fe98b58,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-314553a2-e138-43f3-97a5-aef6ba9744b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-a09a0008-f5c4-42c7-96c5-6383eb9d91e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-3d8a9e71-7f99-4169-9278-54f7fabd97eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083138768-172.17.0.18-1597477467225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-a5010dcb-f41e-4878-8cc7-a3d641e2ce8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-df904b67-968d-4947-ba7c-deea74437fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-5c7c50ed-1d32-4a57-8b55-bb0c6fb18bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-45fa8683-6330-400f-bdd9-9287f3e49497,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-22d8d579-5581-41b4-8513-31853fe98b58,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-314553a2-e138-43f3-97a5-aef6ba9744b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-a09a0008-f5c4-42c7-96c5-6383eb9d91e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-3d8a9e71-7f99-4169-9278-54f7fabd97eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966516212-172.17.0.18-1597477589971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42727,DS-107f8ca4-683f-4863-aa3e-e0887d6ff7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-200f64de-b165-4ad6-ab25-6491725cb483,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-f195dca3-4713-40cc-895a-ceecf836ab0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-4a3b9826-d34a-4862-981a-92e00aa93a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-9333ec41-80c4-4b82-b3a4-126a70d3ae74,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-98c26707-67f4-4c26-8d03-62a6e4ef9d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-a7116918-3092-446a-86b0-e6e8d792c899,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-bdb6251f-1d13-4662-ad59-ecfca021d990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966516212-172.17.0.18-1597477589971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42727,DS-107f8ca4-683f-4863-aa3e-e0887d6ff7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-200f64de-b165-4ad6-ab25-6491725cb483,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-f195dca3-4713-40cc-895a-ceecf836ab0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-4a3b9826-d34a-4862-981a-92e00aa93a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-9333ec41-80c4-4b82-b3a4-126a70d3ae74,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-98c26707-67f4-4c26-8d03-62a6e4ef9d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-a7116918-3092-446a-86b0-e6e8d792c899,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-bdb6251f-1d13-4662-ad59-ecfca021d990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109020807-172.17.0.18-1597477781333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45448,DS-e48ebe94-de08-46ee-b41c-fe07b1740c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-30385a0a-df90-4fcd-b79d-d0ee84804598,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-0153e38f-d4a0-495a-a436-3b6dc696eaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-46acb48a-422b-4653-80b7-e5ca54d47f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-b1be34b0-749f-415a-801a-4e3925b151c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-b9681580-efbd-495d-91df-b6b4073927ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-85217950-9cfe-4881-9037-a0f0d2900a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-4ce4b258-a288-4538-b439-2596d0551ac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109020807-172.17.0.18-1597477781333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45448,DS-e48ebe94-de08-46ee-b41c-fe07b1740c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-30385a0a-df90-4fcd-b79d-d0ee84804598,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-0153e38f-d4a0-495a-a436-3b6dc696eaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-46acb48a-422b-4653-80b7-e5ca54d47f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-b1be34b0-749f-415a-801a-4e3925b151c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-b9681580-efbd-495d-91df-b6b4073927ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-85217950-9cfe-4881-9037-a0f0d2900a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-4ce4b258-a288-4538-b439-2596d0551ac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543121173-172.17.0.18-1597477923830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35339,DS-413b26d4-4f35-41e2-92d3-fbe70b5a015f,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-f059081f-b4ec-4fd5-8031-e28b1f6ed6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-a0956ed5-d377-4579-9a19-fe43772e95f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-c62a7821-8f18-4113-bb08-86074731767c,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-5410ba78-efdf-4ad3-ae92-782e54861949,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-087fb6c5-7ab9-4211-940b-1347268fb1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-54e13b15-dc49-4d84-9e3d-389e1e17e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-a733220b-e77b-4f94-970a-1d0bb00ab516,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543121173-172.17.0.18-1597477923830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35339,DS-413b26d4-4f35-41e2-92d3-fbe70b5a015f,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-f059081f-b4ec-4fd5-8031-e28b1f6ed6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-a0956ed5-d377-4579-9a19-fe43772e95f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-c62a7821-8f18-4113-bb08-86074731767c,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-5410ba78-efdf-4ad3-ae92-782e54861949,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-087fb6c5-7ab9-4211-940b-1347268fb1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-54e13b15-dc49-4d84-9e3d-389e1e17e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-a733220b-e77b-4f94-970a-1d0bb00ab516,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886477824-172.17.0.18-1597478151015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-2829a5a6-126d-4ef6-9751-184411aa3c07,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-d8b34768-57eb-4140-9c4c-f641ea3a8954,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-850edcf7-9aca-4a4b-b2d8-edd350098425,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-c6e97e71-a604-436b-afb0-d52d2ea09b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-20c2fe30-a533-480e-a3e0-66fae918a458,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-4eeec2f1-a409-4c34-af09-28635faa9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-ed66bf28-a260-4957-bb60-cb0e5de6fed3,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-79f98a70-215c-40e4-9f35-5ee6a9e50c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886477824-172.17.0.18-1597478151015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-2829a5a6-126d-4ef6-9751-184411aa3c07,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-d8b34768-57eb-4140-9c4c-f641ea3a8954,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-850edcf7-9aca-4a4b-b2d8-edd350098425,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-c6e97e71-a604-436b-afb0-d52d2ea09b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-20c2fe30-a533-480e-a3e0-66fae918a458,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-4eeec2f1-a409-4c34-af09-28635faa9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-ed66bf28-a260-4957-bb60-cb0e5de6fed3,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-79f98a70-215c-40e4-9f35-5ee6a9e50c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126325785-172.17.0.18-1597478744032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-20459614-f0b7-47a7-a153-a3b277578fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-745e6b43-07a1-4ef9-9296-b83bfe80286b,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-cdd8c97f-1874-41ea-a953-0a24e9800ded,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-b37931ed-ceb4-489b-81ed-f86049a59633,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-f758f544-77ec-4691-af13-95cb4c749f80,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-b45d279b-b9e5-4db3-961a-7759068db8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-acef65d7-5152-4e8e-a465-e044c2cfd3df,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-66af275e-fd42-4065-8a44-78846280038a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126325785-172.17.0.18-1597478744032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43502,DS-20459614-f0b7-47a7-a153-a3b277578fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-745e6b43-07a1-4ef9-9296-b83bfe80286b,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-cdd8c97f-1874-41ea-a953-0a24e9800ded,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-b37931ed-ceb4-489b-81ed-f86049a59633,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-f758f544-77ec-4691-af13-95cb4c749f80,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-b45d279b-b9e5-4db3-961a-7759068db8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-acef65d7-5152-4e8e-a465-e044c2cfd3df,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-66af275e-fd42-4065-8a44-78846280038a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936323170-172.17.0.18-1597478933208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44849,DS-028921f0-67c7-4830-b350-c4b8af1a2084,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-24efb06f-98f6-4b8f-91c8-65a2cac4ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-ae29ab19-c356-4a0d-a108-cce4a3c5bc32,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-cabe1e3c-ae42-4861-88e5-c1187ad89f82,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-b983a8ea-8914-4f99-9ee8-441405267000,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-89e08646-c577-420c-9c36-ead4a5860348,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-2d80340d-c9d8-480b-9715-ec3d3fd752b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-29b7425a-3179-405a-9c79-2bdc8b81b0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936323170-172.17.0.18-1597478933208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44849,DS-028921f0-67c7-4830-b350-c4b8af1a2084,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-24efb06f-98f6-4b8f-91c8-65a2cac4ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-ae29ab19-c356-4a0d-a108-cce4a3c5bc32,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-cabe1e3c-ae42-4861-88e5-c1187ad89f82,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-b983a8ea-8914-4f99-9ee8-441405267000,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-89e08646-c577-420c-9c36-ead4a5860348,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-2d80340d-c9d8-480b-9715-ec3d3fd752b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-29b7425a-3179-405a-9c79-2bdc8b81b0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078450703-172.17.0.18-1597479022245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38687,DS-04e57f7f-f9c1-4035-bdc3-03abb97be165,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-85750af1-3873-4e91-8479-3cc1061b7e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-d1c374ff-66cf-4131-ad02-72c17c1a8e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-4f9ddc1f-fb73-44b6-b02f-6957b5cd2b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-a0744dad-cbf3-4d93-be42-c09ef47c5872,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-f2613d9e-a059-4893-9ee4-55bc3693ca87,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-d0dbd4c6-cfc2-4093-ae91-d40cd4eb6d19,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-58b2ddec-50ef-4297-8503-d22d01276aae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078450703-172.17.0.18-1597479022245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38687,DS-04e57f7f-f9c1-4035-bdc3-03abb97be165,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-85750af1-3873-4e91-8479-3cc1061b7e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-d1c374ff-66cf-4131-ad02-72c17c1a8e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-4f9ddc1f-fb73-44b6-b02f-6957b5cd2b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-a0744dad-cbf3-4d93-be42-c09ef47c5872,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-f2613d9e-a059-4893-9ee4-55bc3693ca87,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-d0dbd4c6-cfc2-4093-ae91-d40cd4eb6d19,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-58b2ddec-50ef-4297-8503-d22d01276aae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662010325-172.17.0.18-1597479159469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37844,DS-466c21dc-f8e2-41bb-894d-7a35f7f30515,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-10c32ca8-cc37-4b2f-9679-8af7ba2c3d67,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-255e2020-3cf1-4a15-81e0-becdcbfa2767,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-8e85b7cf-38e4-43fe-aa7c-ad13c9e89955,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-e195de75-2e93-421d-89b6-0f72ef723a79,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-6561d0cd-bbe6-468b-ac62-971584af84d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-8fd93dae-0bea-4b49-82c1-21e8c4e94393,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-058a3174-eb01-4e9c-8832-da2b5a0f5143,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662010325-172.17.0.18-1597479159469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37844,DS-466c21dc-f8e2-41bb-894d-7a35f7f30515,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-10c32ca8-cc37-4b2f-9679-8af7ba2c3d67,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-255e2020-3cf1-4a15-81e0-becdcbfa2767,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-8e85b7cf-38e4-43fe-aa7c-ad13c9e89955,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-e195de75-2e93-421d-89b6-0f72ef723a79,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-6561d0cd-bbe6-468b-ac62-971584af84d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-8fd93dae-0bea-4b49-82c1-21e8c4e94393,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-058a3174-eb01-4e9c-8832-da2b5a0f5143,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032494609-172.17.0.18-1597479246706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42749,DS-8e4ea4c7-e5af-4282-a084-22d323b676e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-32810f7a-af4b-4617-9194-405c571e21cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-0c26a83a-5a04-4c08-9ed3-4ead0ccc2e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-cea78fe9-b3e7-44d2-aeb6-01e6b4cb5541,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-7a90ef1a-429f-4d60-9a79-c90f65f5be21,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-cd149695-2693-4158-a6c4-5ba9cc9a3c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-2c1c759c-920f-4542-a3d6-41a6406b3675,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-4116244e-c6a6-44a4-a092-731eb330416b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032494609-172.17.0.18-1597479246706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42749,DS-8e4ea4c7-e5af-4282-a084-22d323b676e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-32810f7a-af4b-4617-9194-405c571e21cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-0c26a83a-5a04-4c08-9ed3-4ead0ccc2e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-cea78fe9-b3e7-44d2-aeb6-01e6b4cb5541,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-7a90ef1a-429f-4d60-9a79-c90f65f5be21,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-cd149695-2693-4158-a6c4-5ba9cc9a3c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-2c1c759c-920f-4542-a3d6-41a6406b3675,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-4116244e-c6a6-44a4-a092-731eb330416b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 20 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 7035
