reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264297017-172.17.0.12-1597684853755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33689,DS-312d4f91-1a62-4f20-9205-b96509fc4037,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-528448ad-d1b7-4494-a42d-e5edc7db1b79,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-8c19a1c8-05fc-4c9e-8aa5-cfd91d9444e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-efe3b1c4-8a23-4fff-b800-02eac003e8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-882d87a9-8f10-4469-a888-c4d4affd5227,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-50daa9fa-c154-4732-b6ed-b5e53bd588b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-ec6aef55-4ad6-489a-b6ee-7f53ec6e75b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-cc496298-830d-4af6-86c1-2d59ce8acc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264297017-172.17.0.12-1597684853755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33689,DS-312d4f91-1a62-4f20-9205-b96509fc4037,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-528448ad-d1b7-4494-a42d-e5edc7db1b79,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-8c19a1c8-05fc-4c9e-8aa5-cfd91d9444e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-efe3b1c4-8a23-4fff-b800-02eac003e8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-882d87a9-8f10-4469-a888-c4d4affd5227,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-50daa9fa-c154-4732-b6ed-b5e53bd588b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-ec6aef55-4ad6-489a-b6ee-7f53ec6e75b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-cc496298-830d-4af6-86c1-2d59ce8acc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499166420-172.17.0.12-1597684974076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40802,DS-a50c3c17-ddaa-4302-b25b-6950f22a6790,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-631d3ffa-1d44-476c-b8ed-f24c25948bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-62a103af-36aa-4bb2-92c5-1e56dbf8c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-313b1464-ba6e-4aab-a360-6610fbe367ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-5d674c00-4275-4923-84e0-440f6dbc2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-af7d7506-8b7c-4ce1-9ec8-f436b8679c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-1318014f-acc5-479d-a708-524f6d03ba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-c6c2c1d3-e80e-4ffd-9100-948e856130ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499166420-172.17.0.12-1597684974076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40802,DS-a50c3c17-ddaa-4302-b25b-6950f22a6790,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-631d3ffa-1d44-476c-b8ed-f24c25948bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-62a103af-36aa-4bb2-92c5-1e56dbf8c66b,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-313b1464-ba6e-4aab-a360-6610fbe367ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-5d674c00-4275-4923-84e0-440f6dbc2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-af7d7506-8b7c-4ce1-9ec8-f436b8679c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-1318014f-acc5-479d-a708-524f6d03ba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-c6c2c1d3-e80e-4ffd-9100-948e856130ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963599515-172.17.0.12-1597685079374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-597b5c29-5818-4ae7-bf9f-b7bca9151c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-f06240f2-89a0-4183-bd2c-bd1a9afb00f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-6787e60b-fe89-4f13-b544-fc975971c173,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-89b39f36-5cd6-4d42-a784-8453a2e62acf,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-b3e67583-9fdd-4904-b12d-dc2e87e170d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-c60aa5fe-99ce-48dc-a4c8-6f09e484e871,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-aa421e46-fc30-4c77-ba88-94fe3dbda830,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-9fda6cad-db53-4199-bf9b-6745fb77a04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963599515-172.17.0.12-1597685079374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-597b5c29-5818-4ae7-bf9f-b7bca9151c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-f06240f2-89a0-4183-bd2c-bd1a9afb00f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-6787e60b-fe89-4f13-b544-fc975971c173,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-89b39f36-5cd6-4d42-a784-8453a2e62acf,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-b3e67583-9fdd-4904-b12d-dc2e87e170d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-c60aa5fe-99ce-48dc-a4c8-6f09e484e871,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-aa421e46-fc30-4c77-ba88-94fe3dbda830,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-9fda6cad-db53-4199-bf9b-6745fb77a04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842979397-172.17.0.12-1597685458851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41022,DS-c28d2d31-1df1-4bdb-b8f0-d99fb76d2150,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-83f6cd8a-a39b-4e51-93b8-aebd43a872e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-7b1ee7b4-32da-4d3e-a227-c684c379d3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-dbf130a5-0dd7-472f-9986-15f5c0bac920,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-67a3fa60-e3e4-4058-8986-1c1fdf6c3c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-5ec699f5-515c-4089-95d7-ea428172ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-dba7da83-6532-414a-82c2-8ac35df9d20c,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-d92c71c9-5d1d-49ee-8de8-94d34039e459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842979397-172.17.0.12-1597685458851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41022,DS-c28d2d31-1df1-4bdb-b8f0-d99fb76d2150,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-83f6cd8a-a39b-4e51-93b8-aebd43a872e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-7b1ee7b4-32da-4d3e-a227-c684c379d3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-dbf130a5-0dd7-472f-9986-15f5c0bac920,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-67a3fa60-e3e4-4058-8986-1c1fdf6c3c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-5ec699f5-515c-4089-95d7-ea428172ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-dba7da83-6532-414a-82c2-8ac35df9d20c,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-d92c71c9-5d1d-49ee-8de8-94d34039e459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216075033-172.17.0.12-1597685567959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-c65fae18-9a7b-427b-b430-c7f40e9d2c90,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-2e83ca57-9da9-4311-9a5c-616ee0500fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-acb880cb-3595-4f73-bb41-2b36c5b3953f,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-ef7909af-2da3-4f83-ab9e-1c8d9499ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-bfcdd716-5028-4245-a29b-9f53f413cf80,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-12094978-acc8-48c8-9634-dad06e762254,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-f67ddc38-5dc3-411f-baeb-4e396c7ce263,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-faa5b903-60d8-496e-94be-c027c68be5d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216075033-172.17.0.12-1597685567959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-c65fae18-9a7b-427b-b430-c7f40e9d2c90,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-2e83ca57-9da9-4311-9a5c-616ee0500fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-acb880cb-3595-4f73-bb41-2b36c5b3953f,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-ef7909af-2da3-4f83-ab9e-1c8d9499ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-bfcdd716-5028-4245-a29b-9f53f413cf80,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-12094978-acc8-48c8-9634-dad06e762254,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-f67ddc38-5dc3-411f-baeb-4e396c7ce263,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-faa5b903-60d8-496e-94be-c027c68be5d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043564631-172.17.0.12-1597685965211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39502,DS-982715b6-a0aa-4162-b62e-3603932c3e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-01052562-98ca-488b-a238-b1d27e26da82,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-ebba4a9e-d098-494c-ab09-929c50215019,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-e1005b06-241f-4e20-b345-882a4bbecef7,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-859825d5-41e8-4ba8-854c-1fde324b9e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-8a8fa52a-5c5c-401c-afcc-81b29c3b9e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-f661fb26-0154-49f2-b5c9-832afabf40dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-98697598-cf88-4030-b005-169e5689ccc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043564631-172.17.0.12-1597685965211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39502,DS-982715b6-a0aa-4162-b62e-3603932c3e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-01052562-98ca-488b-a238-b1d27e26da82,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-ebba4a9e-d098-494c-ab09-929c50215019,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-e1005b06-241f-4e20-b345-882a4bbecef7,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-859825d5-41e8-4ba8-854c-1fde324b9e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-8a8fa52a-5c5c-401c-afcc-81b29c3b9e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-f661fb26-0154-49f2-b5c9-832afabf40dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-98697598-cf88-4030-b005-169e5689ccc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48078603-172.17.0.12-1597686264513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-585278ce-7940-4deb-a857-04c68446c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-722225b7-950f-4a2c-8d60-e50dca8b5655,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-50935a35-ce9b-4448-8b8b-3f87425e5155,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-c5fcb600-0b40-4b97-ab00-15816c08c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-2f86f5dc-1f3f-4dcd-ae97-0c9ca62ffa02,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-cf3f77ee-2c51-4d03-86f1-775b0da4d8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-24211e0a-4b6c-40f1-b772-bd10bcd3b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-60f1e8d7-a804-4a26-b308-1bb05fe7c383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48078603-172.17.0.12-1597686264513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-585278ce-7940-4deb-a857-04c68446c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-722225b7-950f-4a2c-8d60-e50dca8b5655,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-50935a35-ce9b-4448-8b8b-3f87425e5155,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-c5fcb600-0b40-4b97-ab00-15816c08c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-2f86f5dc-1f3f-4dcd-ae97-0c9ca62ffa02,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-cf3f77ee-2c51-4d03-86f1-775b0da4d8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-24211e0a-4b6c-40f1-b772-bd10bcd3b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-60f1e8d7-a804-4a26-b308-1bb05fe7c383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617030552-172.17.0.12-1597686914395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-1ffecc6a-e1ab-4f4b-9df6-959947b19993,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-0409bcba-e537-4be8-9568-6a7922c1fb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-434bbe7c-4eb9-4475-a8ec-6f9719840fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-2256d803-70d9-4f8d-9726-3da7b6473244,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-09dbb98d-4332-4582-9262-8e5a2c119d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-fa664e39-faad-4b42-8731-2a591a9b43f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-e3d3995b-0197-4097-9b20-c84afa35777e,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-8f90188e-a671-42ff-929f-b8431eddaa8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617030552-172.17.0.12-1597686914395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-1ffecc6a-e1ab-4f4b-9df6-959947b19993,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-0409bcba-e537-4be8-9568-6a7922c1fb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-434bbe7c-4eb9-4475-a8ec-6f9719840fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-2256d803-70d9-4f8d-9726-3da7b6473244,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-09dbb98d-4332-4582-9262-8e5a2c119d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-fa664e39-faad-4b42-8731-2a591a9b43f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-e3d3995b-0197-4097-9b20-c84afa35777e,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-8f90188e-a671-42ff-929f-b8431eddaa8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804246865-172.17.0.12-1597687227141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44279,DS-b1f85da9-d9bf-4f66-a0a6-00e7f21be077,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-002b8889-eda8-449e-8d2a-926e836c0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-2532ebc8-d76d-4e4c-b85b-128c0129eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-00691c1a-1975-4192-9f84-67594129a502,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-f8295994-0cd3-44ac-9648-97b3a036082e,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-04172ebc-bd7d-4dcc-9ed3-0695ea5476d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-032c3034-20b2-40c5-998e-1e76310fadab,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-62e71a3c-7746-498b-8405-3321ce267c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804246865-172.17.0.12-1597687227141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44279,DS-b1f85da9-d9bf-4f66-a0a6-00e7f21be077,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-002b8889-eda8-449e-8d2a-926e836c0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-2532ebc8-d76d-4e4c-b85b-128c0129eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-00691c1a-1975-4192-9f84-67594129a502,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-f8295994-0cd3-44ac-9648-97b3a036082e,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-04172ebc-bd7d-4dcc-9ed3-0695ea5476d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-032c3034-20b2-40c5-998e-1e76310fadab,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-62e71a3c-7746-498b-8405-3321ce267c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136169958-172.17.0.12-1597687262791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-ecafa7e5-7a0f-4165-bd96-a7fce7bcbbea,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-9f0493b9-7b7f-4ab2-9044-2483122f55a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-d03966bf-ef94-427d-8c50-1e542e421838,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-faca2c53-1293-4d1d-a37d-731d87cbdc00,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-b79b1e66-6e2a-4d6c-b0bb-2c6e6ddb33ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-d01f3913-e385-424c-b5b1-0c253bc076ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-2dc555bb-7ab9-4ff3-85df-362430cbf655,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-7a2d1033-10f0-4596-8a02-aa81eaaacf74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136169958-172.17.0.12-1597687262791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-ecafa7e5-7a0f-4165-bd96-a7fce7bcbbea,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-9f0493b9-7b7f-4ab2-9044-2483122f55a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-d03966bf-ef94-427d-8c50-1e542e421838,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-faca2c53-1293-4d1d-a37d-731d87cbdc00,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-b79b1e66-6e2a-4d6c-b0bb-2c6e6ddb33ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-d01f3913-e385-424c-b5b1-0c253bc076ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-2dc555bb-7ab9-4ff3-85df-362430cbf655,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-7a2d1033-10f0-4596-8a02-aa81eaaacf74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400378517-172.17.0.12-1597687370974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-a09dfd31-f0a4-4a99-b4c5-233a4e3af22b,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-b481fe51-fb2e-465c-84a0-aad3d2d40008,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-c2a3e749-d4e0-4fda-afc4-7053631e03b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c25cbd76-e49a-4ce1-aa87-b995827f26c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-664214b8-735d-4419-bf3e-92ae504a3f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-25d2340b-8f54-4a37-818a-ff289536e633,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-0e4934b2-535d-4d22-98e9-bfcd8c5b901a,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-e5781aed-bd20-40c4-96fd-4fe5639162b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400378517-172.17.0.12-1597687370974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41254,DS-a09dfd31-f0a4-4a99-b4c5-233a4e3af22b,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-b481fe51-fb2e-465c-84a0-aad3d2d40008,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-c2a3e749-d4e0-4fda-afc4-7053631e03b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c25cbd76-e49a-4ce1-aa87-b995827f26c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-664214b8-735d-4419-bf3e-92ae504a3f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-25d2340b-8f54-4a37-818a-ff289536e633,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-0e4934b2-535d-4d22-98e9-bfcd8c5b901a,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-e5781aed-bd20-40c4-96fd-4fe5639162b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904446848-172.17.0.12-1597687733035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-04149f1c-87d1-4eaa-a862-a0a8a7141845,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-7412678c-a784-4439-af30-001551a31eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-73b7772d-d1c5-4782-a659-771aa6194f42,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-d644660d-cc52-4673-bc6e-13fe4d5339f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-155d061c-9d12-4e12-bdab-2b6f0f4a665b,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-198377d4-16aa-48e1-a304-3cf0e3382a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-1d4a77a7-61c6-4a7e-9082-78652fa36743,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-4822ee5e-cd7f-431b-a8a3-62aaa45a7694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904446848-172.17.0.12-1597687733035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-04149f1c-87d1-4eaa-a862-a0a8a7141845,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-7412678c-a784-4439-af30-001551a31eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-73b7772d-d1c5-4782-a659-771aa6194f42,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-d644660d-cc52-4673-bc6e-13fe4d5339f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-155d061c-9d12-4e12-bdab-2b6f0f4a665b,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-198377d4-16aa-48e1-a304-3cf0e3382a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-1d4a77a7-61c6-4a7e-9082-78652fa36743,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-4822ee5e-cd7f-431b-a8a3-62aaa45a7694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359809524-172.17.0.12-1597687868673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45286,DS-7b1e381e-030b-43b2-824c-60d0552e41bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-b3810e4b-dbd5-40a3-a20d-ec43510960f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-3f4a0eac-114f-41aa-9e6c-6a0be869f86c,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-11a42607-9b04-4c7e-ac8b-6f76bc1b5ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-452878b1-a4a6-4e89-a7d9-5a28994a08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-1364cc52-ae20-42b2-b6a5-daf4b2d7cc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-c9dedcdf-d78f-4c33-9136-4edd2493b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-0e61758d-b2c0-4f2e-8e7b-719e7145c561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359809524-172.17.0.12-1597687868673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45286,DS-7b1e381e-030b-43b2-824c-60d0552e41bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-b3810e4b-dbd5-40a3-a20d-ec43510960f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-3f4a0eac-114f-41aa-9e6c-6a0be869f86c,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-11a42607-9b04-4c7e-ac8b-6f76bc1b5ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-452878b1-a4a6-4e89-a7d9-5a28994a08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-1364cc52-ae20-42b2-b6a5-daf4b2d7cc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-c9dedcdf-d78f-4c33-9136-4edd2493b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-0e61758d-b2c0-4f2e-8e7b-719e7145c561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126317826-172.17.0.12-1597688939412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34522,DS-ace09cff-c13a-4794-906a-c9f10cac20c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-2e9b36a9-d1ff-4863-8348-707761a851d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-0a5e0e15-29a6-47e1-81ad-d4486e9b9587,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-c448fdd1-badb-4b0c-a246-2aa556536e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-366b6dbc-4c26-48ca-978e-21a1096d5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-8755f911-a99a-403b-a0a6-53043b108321,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-01eaa913-991e-46e9-aff9-9f4109f1dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-f8bfc8e8-9f33-4d49-9e38-9cd2a64764f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126317826-172.17.0.12-1597688939412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34522,DS-ace09cff-c13a-4794-906a-c9f10cac20c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-2e9b36a9-d1ff-4863-8348-707761a851d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-0a5e0e15-29a6-47e1-81ad-d4486e9b9587,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-c448fdd1-badb-4b0c-a246-2aa556536e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-366b6dbc-4c26-48ca-978e-21a1096d5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-8755f911-a99a-403b-a0a6-53043b108321,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-01eaa913-991e-46e9-aff9-9f4109f1dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-f8bfc8e8-9f33-4d49-9e38-9cd2a64764f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252896582-172.17.0.12-1597689073908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39223,DS-0bea8dec-aa54-4a99-bd74-9c8cb5bf789c,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-df665bf8-6fe7-4e37-9bab-0dcd55daefb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-16810b2e-8415-4b18-bd8d-844b22d31dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-57ba2326-830c-4c34-b1b0-9f8d2660b642,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-aeb335b1-3643-42f4-a1d8-a17450bdefc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-29edc5cf-6bfe-42d5-b6e5-9b75601cbbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-68b0580a-55e9-4177-99e8-52ba450e449a,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-f32cc1ba-ca26-4a09-b3c7-2d3dc9127dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252896582-172.17.0.12-1597689073908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39223,DS-0bea8dec-aa54-4a99-bd74-9c8cb5bf789c,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-df665bf8-6fe7-4e37-9bab-0dcd55daefb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-16810b2e-8415-4b18-bd8d-844b22d31dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-57ba2326-830c-4c34-b1b0-9f8d2660b642,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-aeb335b1-3643-42f4-a1d8-a17450bdefc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-29edc5cf-6bfe-42d5-b6e5-9b75601cbbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-68b0580a-55e9-4177-99e8-52ba450e449a,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-f32cc1ba-ca26-4a09-b3c7-2d3dc9127dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860708360-172.17.0.12-1597689244501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-7d2678e1-a780-4cfa-afa7-e96f572c2797,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-fa128d05-2367-4443-b7eb-26d3dfe4fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-c86e7f5e-3a2b-46bd-b13c-ad9f5ba737ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-c47fda0c-5115-4a60-86fe-b9e36ba8f24f,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-b98868d8-8e36-4b15-83a2-56b49ad84265,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-c8e9f8b6-cd37-4b38-8b2f-431ef10bf734,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-de31e1f0-f368-42d7-a1e9-a4e304d73c24,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-7999d44f-f053-4a89-80f6-057caecd0ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-860708360-172.17.0.12-1597689244501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-7d2678e1-a780-4cfa-afa7-e96f572c2797,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-fa128d05-2367-4443-b7eb-26d3dfe4fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-c86e7f5e-3a2b-46bd-b13c-ad9f5ba737ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-c47fda0c-5115-4a60-86fe-b9e36ba8f24f,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-b98868d8-8e36-4b15-83a2-56b49ad84265,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-c8e9f8b6-cd37-4b38-8b2f-431ef10bf734,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-de31e1f0-f368-42d7-a1e9-a4e304d73c24,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-7999d44f-f053-4a89-80f6-057caecd0ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302092378-172.17.0.12-1597689421411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-c9481bb8-c682-4bc7-9791-aaca5627a5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-878cb999-584a-471e-ad91-f5aeaf9e5785,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-4acc166d-e0e2-4aa6-9151-78253b74f586,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-0ab58430-f68a-4e92-a6cf-46a33ad05299,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-e3e59e16-f223-4fab-83f7-7ce8f17d7223,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-1a54e79e-61ab-429d-b113-6d82e9f7f386,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-638b0f7b-6d30-4877-8ea2-719edfc8f745,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-dda8a393-7705-4498-b9d8-c0c198321150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302092378-172.17.0.12-1597689421411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-c9481bb8-c682-4bc7-9791-aaca5627a5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-878cb999-584a-471e-ad91-f5aeaf9e5785,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-4acc166d-e0e2-4aa6-9151-78253b74f586,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-0ab58430-f68a-4e92-a6cf-46a33ad05299,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-e3e59e16-f223-4fab-83f7-7ce8f17d7223,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-1a54e79e-61ab-429d-b113-6d82e9f7f386,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-638b0f7b-6d30-4877-8ea2-719edfc8f745,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-dda8a393-7705-4498-b9d8-c0c198321150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867886732-172.17.0.12-1597689676402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42008,DS-f53cffdd-0b89-4ba7-956c-ba20d7b8e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-9554c288-f8e5-4c14-9791-0cbaccdcfd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-23acb5f6-937b-4c65-9980-be2320413123,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-41de702a-e89a-42c0-9dca-c5e729b759c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-02eb2732-e6e2-45c3-8b3a-a6ec07d81eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-3b187772-f327-47fe-abd0-8a93e187b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-bf12c417-df9a-4882-abe4-5b6901f8f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-744a2b50-02db-40d2-9949-0e8f2c46b221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867886732-172.17.0.12-1597689676402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42008,DS-f53cffdd-0b89-4ba7-956c-ba20d7b8e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-9554c288-f8e5-4c14-9791-0cbaccdcfd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-23acb5f6-937b-4c65-9980-be2320413123,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-41de702a-e89a-42c0-9dca-c5e729b759c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-02eb2732-e6e2-45c3-8b3a-a6ec07d81eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-3b187772-f327-47fe-abd0-8a93e187b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-bf12c417-df9a-4882-abe4-5b6901f8f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-744a2b50-02db-40d2-9949-0e8f2c46b221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5463
