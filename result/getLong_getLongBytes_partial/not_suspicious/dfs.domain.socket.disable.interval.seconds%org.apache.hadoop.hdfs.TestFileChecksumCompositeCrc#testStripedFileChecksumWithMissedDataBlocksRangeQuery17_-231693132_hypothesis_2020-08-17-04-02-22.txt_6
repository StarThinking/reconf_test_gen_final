reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823420130-172.17.0.6-1597637436767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-4576ae18-2f3e-41ad-8f50-e7d6ab83ce07,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-93f223c4-a7f5-4b5f-89f9-70985154e380,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-1eb6c692-c902-4c50-ab40-ececbf9c4f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-60758675-c381-47e0-9ccc-22d0b5b8861d,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-40882074-5532-4dea-a7d6-55b26a6c3fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-0e23071c-f18b-420a-8d56-bc9bf5bfa775,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-8c528bbb-4d21-4635-9b08-07a90b9f9550,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-a54cda1c-eeb9-4d47-9770-dc9bb2669c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823420130-172.17.0.6-1597637436767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-4576ae18-2f3e-41ad-8f50-e7d6ab83ce07,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-93f223c4-a7f5-4b5f-89f9-70985154e380,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-1eb6c692-c902-4c50-ab40-ececbf9c4f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-60758675-c381-47e0-9ccc-22d0b5b8861d,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-40882074-5532-4dea-a7d6-55b26a6c3fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-0e23071c-f18b-420a-8d56-bc9bf5bfa775,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-8c528bbb-4d21-4635-9b08-07a90b9f9550,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-a54cda1c-eeb9-4d47-9770-dc9bb2669c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243595010-172.17.0.6-1597637473869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-471209d5-c64d-4e87-b676-aa7d419fbaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-44dd5aaf-fe25-4508-beb2-2730ffdd9c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-3d0ca212-683f-4e6b-bb26-19a0cf13a319,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-db882576-af51-4955-a6af-82905b1c20a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-0cf7a9ca-a09d-4c71-bd18-832bcc9f1af0,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-99d5ef7f-d261-4fc1-a3aa-6bf7583f8b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-c2aad414-89b1-486f-bb34-82ae203c17b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-51a2587b-0bcc-4be9-937b-b6f829114e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243595010-172.17.0.6-1597637473869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-471209d5-c64d-4e87-b676-aa7d419fbaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-44dd5aaf-fe25-4508-beb2-2730ffdd9c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-3d0ca212-683f-4e6b-bb26-19a0cf13a319,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-db882576-af51-4955-a6af-82905b1c20a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-0cf7a9ca-a09d-4c71-bd18-832bcc9f1af0,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-99d5ef7f-d261-4fc1-a3aa-6bf7583f8b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-c2aad414-89b1-486f-bb34-82ae203c17b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-51a2587b-0bcc-4be9-937b-b6f829114e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391294516-172.17.0.6-1597637771452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33476,DS-e68373ca-d986-4cd0-917c-9a23ac278429,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-9ee8b449-7526-44ea-a62e-194a0da931b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-37cfede4-8064-4b0b-a879-a0c2ff1d844e,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-f4adf439-89c2-4126-9f68-11d7f4d74220,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-338bfbb7-3305-48a9-8262-0a41c48512bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-5aefe8af-9d5a-48fc-a81a-adf8ff57533e,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-0367d2bd-6df5-470a-8b65-ef51c4237f41,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-1fc861cc-a5fe-4f05-a0a4-26a0075dab08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391294516-172.17.0.6-1597637771452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33476,DS-e68373ca-d986-4cd0-917c-9a23ac278429,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-9ee8b449-7526-44ea-a62e-194a0da931b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-37cfede4-8064-4b0b-a879-a0c2ff1d844e,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-f4adf439-89c2-4126-9f68-11d7f4d74220,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-338bfbb7-3305-48a9-8262-0a41c48512bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-5aefe8af-9d5a-48fc-a81a-adf8ff57533e,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-0367d2bd-6df5-470a-8b65-ef51c4237f41,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-1fc861cc-a5fe-4f05-a0a4-26a0075dab08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968391566-172.17.0.6-1597638189384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42998,DS-eadd7eff-4294-4e90-94e0-83ea860ea2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-a5fbe890-5889-433f-b9f3-0e83b871a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-0636464a-3ca7-496f-8287-60239f588db1,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-1982be73-570e-473e-b45d-5aa6c85612c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-92ddbd71-9e89-4613-9a35-a7b57f506941,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-64bec24c-841e-4258-b355-3e5022e2f38f,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-11b03b75-ac46-4804-af57-a4e8c7c99e61,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-80be6653-ca66-4fc5-96a0-074f413b363a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968391566-172.17.0.6-1597638189384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42998,DS-eadd7eff-4294-4e90-94e0-83ea860ea2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-a5fbe890-5889-433f-b9f3-0e83b871a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-0636464a-3ca7-496f-8287-60239f588db1,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-1982be73-570e-473e-b45d-5aa6c85612c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-92ddbd71-9e89-4613-9a35-a7b57f506941,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-64bec24c-841e-4258-b355-3e5022e2f38f,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-11b03b75-ac46-4804-af57-a4e8c7c99e61,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-80be6653-ca66-4fc5-96a0-074f413b363a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524236965-172.17.0.6-1597638521729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-83bc84c0-1452-4d07-a66d-4f134e6a30db,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-ceaee7a9-3430-4924-b7b1-16c4a5098503,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-6380f40b-d3c0-4f64-bd1c-42f106f12316,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-d17b7012-7d77-4393-9fc8-0bb32dd91d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-66aec418-fd35-413e-873e-5542360333e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-963e2f67-179c-48cb-9eba-07d62a8c4ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-ade2e57f-5941-421f-a2a2-b2e4ed620d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-ead592c3-55bf-46ff-bbb5-426aad234f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524236965-172.17.0.6-1597638521729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-83bc84c0-1452-4d07-a66d-4f134e6a30db,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-ceaee7a9-3430-4924-b7b1-16c4a5098503,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-6380f40b-d3c0-4f64-bd1c-42f106f12316,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-d17b7012-7d77-4393-9fc8-0bb32dd91d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-66aec418-fd35-413e-873e-5542360333e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-963e2f67-179c-48cb-9eba-07d62a8c4ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-ade2e57f-5941-421f-a2a2-b2e4ed620d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-ead592c3-55bf-46ff-bbb5-426aad234f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220891491-172.17.0.6-1597638668864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35702,DS-83ea8787-8478-4b89-ac58-1e23ce202d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-1d48ddcd-df14-4cdc-af10-682394687078,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-743e547b-dac3-4d8a-be35-4e1d01dae009,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-5d9a3851-66ad-4425-bb7a-db26196f7763,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-b7868e7d-b493-4bd8-85e9-624287a966db,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-39a9217a-a0f1-4128-ab90-abff70dffac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-ca13478f-d0f7-4f6f-aa81-07aaf9353754,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-54446ac2-17ca-49b5-a1ea-98d39ca70f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220891491-172.17.0.6-1597638668864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35702,DS-83ea8787-8478-4b89-ac58-1e23ce202d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-1d48ddcd-df14-4cdc-af10-682394687078,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-743e547b-dac3-4d8a-be35-4e1d01dae009,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-5d9a3851-66ad-4425-bb7a-db26196f7763,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-b7868e7d-b493-4bd8-85e9-624287a966db,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-39a9217a-a0f1-4128-ab90-abff70dffac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-ca13478f-d0f7-4f6f-aa81-07aaf9353754,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-54446ac2-17ca-49b5-a1ea-98d39ca70f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999732792-172.17.0.6-1597638779954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-2525bdeb-710d-45c1-b1a1-d8b77726ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-91e1814b-e955-4bd1-9ead-ff9dd97338cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-e70596bc-f0f4-4327-b686-275a1dd02dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-53144373-8023-4f04-8492-ebef3336628f,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-5ff28033-81dd-4069-88cf-938314b772f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-839b1dd0-eaed-4d4c-a193-ca845ab14973,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-097f0a41-080f-4bf0-beb3-0f6895dcf81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-8fcbc227-5867-4820-b32c-76dc31c0e8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999732792-172.17.0.6-1597638779954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-2525bdeb-710d-45c1-b1a1-d8b77726ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-91e1814b-e955-4bd1-9ead-ff9dd97338cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-e70596bc-f0f4-4327-b686-275a1dd02dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-53144373-8023-4f04-8492-ebef3336628f,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-5ff28033-81dd-4069-88cf-938314b772f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-839b1dd0-eaed-4d4c-a193-ca845ab14973,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-097f0a41-080f-4bf0-beb3-0f6895dcf81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-8fcbc227-5867-4820-b32c-76dc31c0e8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63929867-172.17.0.6-1597639549351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34397,DS-9ce933fd-f765-4020-bcef-a0ddf2a4752d,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-738b479f-2843-4e67-a8ab-cfe4de5184ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-436f360f-395b-4263-8265-7b4b6b34b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-53771390-734b-47fe-a76f-b06aca2e8bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-86e5bd08-2bcb-4315-9ad0-73f802ade792,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-ebcf1110-5180-4168-918c-7c4cf5ef8083,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-abc86e79-57fc-4a42-b646-7a201df9cc48,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-c6ce7460-9f61-4591-83d5-84d6d5853612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63929867-172.17.0.6-1597639549351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34397,DS-9ce933fd-f765-4020-bcef-a0ddf2a4752d,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-738b479f-2843-4e67-a8ab-cfe4de5184ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-436f360f-395b-4263-8265-7b4b6b34b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-53771390-734b-47fe-a76f-b06aca2e8bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-86e5bd08-2bcb-4315-9ad0-73f802ade792,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-ebcf1110-5180-4168-918c-7c4cf5ef8083,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-abc86e79-57fc-4a42-b646-7a201df9cc48,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-c6ce7460-9f61-4591-83d5-84d6d5853612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110099519-172.17.0.6-1597639775309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-bf9d7d76-b824-4f84-977a-6258b9977738,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-76c2eaa2-47cd-40e0-a1b2-1f318d81e51b,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-929124b8-b431-4050-86ac-77d0ce675978,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-efa71cc5-ca58-4aaf-816b-7db99ad545f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-d115114a-fdbd-45cd-b994-d54fc9bd4bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-83139a56-4001-482a-9a4b-07f5fefdf7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-948dbb0f-1915-40ba-ae8a-a6bec01cdaad,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-3cd3ff3f-8b97-4be4-ad73-18af02520191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110099519-172.17.0.6-1597639775309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-bf9d7d76-b824-4f84-977a-6258b9977738,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-76c2eaa2-47cd-40e0-a1b2-1f318d81e51b,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-929124b8-b431-4050-86ac-77d0ce675978,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-efa71cc5-ca58-4aaf-816b-7db99ad545f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-d115114a-fdbd-45cd-b994-d54fc9bd4bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-83139a56-4001-482a-9a4b-07f5fefdf7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-948dbb0f-1915-40ba-ae8a-a6bec01cdaad,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-3cd3ff3f-8b97-4be4-ad73-18af02520191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80060451-172.17.0.6-1597640855662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39313,DS-837defb4-502e-445e-8829-cc2a95543bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-ce18897b-09ae-4480-ade7-f8276058a632,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-9a55f112-a52e-4ffd-b014-f2a0737a24cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-5a6e1602-9b0c-4ac1-b23a-514591ae86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-b66f3361-69ad-41e3-b68e-932d49bc2ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-11bda913-e3e6-4b8d-9257-fdf51ca6c27e,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-4dd6db03-afff-4b94-b784-174925fd56cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-346386aa-14d2-4c38-8aad-768dd1dcb1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80060451-172.17.0.6-1597640855662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39313,DS-837defb4-502e-445e-8829-cc2a95543bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-ce18897b-09ae-4480-ade7-f8276058a632,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-9a55f112-a52e-4ffd-b014-f2a0737a24cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-5a6e1602-9b0c-4ac1-b23a-514591ae86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-b66f3361-69ad-41e3-b68e-932d49bc2ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-11bda913-e3e6-4b8d-9257-fdf51ca6c27e,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-4dd6db03-afff-4b94-b784-174925fd56cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-346386aa-14d2-4c38-8aad-768dd1dcb1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793030653-172.17.0.6-1597641221921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38389,DS-1ffa38b4-ffe8-44de-a81e-f9afa6d09163,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-d8c15b43-4822-4aea-be52-9c05537ecfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-e8928871-3339-41bc-b276-6398fe1f303a,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-1d6e3ca9-167f-45c4-a6f4-981a2298b457,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-dc559637-692b-44ad-aa1c-b00e3949d642,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-3a82485e-c78b-47b1-82ca-4bf06d32d153,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-241b7992-f58a-4574-a1d0-a6b6b3e28207,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-fb68963b-d4e1-4fe0-8ebb-6b4644454b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793030653-172.17.0.6-1597641221921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38389,DS-1ffa38b4-ffe8-44de-a81e-f9afa6d09163,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-d8c15b43-4822-4aea-be52-9c05537ecfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-e8928871-3339-41bc-b276-6398fe1f303a,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-1d6e3ca9-167f-45c4-a6f4-981a2298b457,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-dc559637-692b-44ad-aa1c-b00e3949d642,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-3a82485e-c78b-47b1-82ca-4bf06d32d153,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-241b7992-f58a-4574-a1d0-a6b6b3e28207,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-fb68963b-d4e1-4fe0-8ebb-6b4644454b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599552781-172.17.0.6-1597641295786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-0045fecf-e218-49e0-bb4f-05912e499c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-dec35a8f-eb81-4930-9807-a18fc1124404,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-914c3848-b22a-46a7-8b20-68b32469cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-ff69ae22-6f31-4e95-baa4-993805a40c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-fd0285bb-149b-4f82-ba0a-863ed7d5d3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-60d530de-92b0-4669-845f-d82a715004a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-4502c031-b745-488d-b8e4-d509b17ef1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-19964875-67ae-410f-8a91-d0148268f197,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599552781-172.17.0.6-1597641295786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-0045fecf-e218-49e0-bb4f-05912e499c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-dec35a8f-eb81-4930-9807-a18fc1124404,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-914c3848-b22a-46a7-8b20-68b32469cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-ff69ae22-6f31-4e95-baa4-993805a40c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-fd0285bb-149b-4f82-ba0a-863ed7d5d3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-60d530de-92b0-4669-845f-d82a715004a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-4502c031-b745-488d-b8e4-d509b17ef1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-19964875-67ae-410f-8a91-d0148268f197,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156564287-172.17.0.6-1597641604181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45508,DS-e3b86fde-8bf5-4009-8154-07eff64bc94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-7f5330a6-09aa-404b-a960-adf5e65e1268,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-e1d3a4f7-5188-4d63-b6e2-ba6a400ecdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-d382250d-baaf-4d5d-b6c8-8fd59a8fcf15,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-ddfdcf51-1fe3-4896-a409-bfdeb48e7706,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-1a1ede73-83cb-4286-8e69-de0c13200196,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-68d68261-4f60-4ddd-b85f-364ef2268598,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-8708a023-9cb9-425a-929f-0b56ac33ccd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156564287-172.17.0.6-1597641604181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45508,DS-e3b86fde-8bf5-4009-8154-07eff64bc94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-7f5330a6-09aa-404b-a960-adf5e65e1268,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-e1d3a4f7-5188-4d63-b6e2-ba6a400ecdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-d382250d-baaf-4d5d-b6c8-8fd59a8fcf15,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-ddfdcf51-1fe3-4896-a409-bfdeb48e7706,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-1a1ede73-83cb-4286-8e69-de0c13200196,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-68d68261-4f60-4ddd-b85f-364ef2268598,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-8708a023-9cb9-425a-929f-0b56ac33ccd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462865463-172.17.0.6-1597641757804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-a9eea3a2-c6a3-4445-8de8-455227207459,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-13372738-450b-42f0-bace-6799c081c62c,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-33d9d83d-14ba-4a9f-8062-6c9b255a57b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-bca348b7-4eb0-42b9-977d-1b0f98f1b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-0ead643e-6802-43c2-8dca-7f01184cb438,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-abb0b537-101b-4bef-ad61-712d2e267da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-b8227fce-bc36-4867-a7ab-e0dec5f04c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-0fc04a51-edaa-4696-af0f-b21b42700ba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462865463-172.17.0.6-1597641757804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-a9eea3a2-c6a3-4445-8de8-455227207459,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-13372738-450b-42f0-bace-6799c081c62c,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-33d9d83d-14ba-4a9f-8062-6c9b255a57b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-bca348b7-4eb0-42b9-977d-1b0f98f1b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-0ead643e-6802-43c2-8dca-7f01184cb438,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-abb0b537-101b-4bef-ad61-712d2e267da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-b8227fce-bc36-4867-a7ab-e0dec5f04c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-0fc04a51-edaa-4696-af0f-b21b42700ba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156794078-172.17.0.6-1597641800066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39961,DS-609a759e-449e-44de-b522-6c67a9622b37,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-54061cef-ce06-4370-954a-f017e2367be8,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-9b4bd7ee-67bf-4a49-936b-4735d96aba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-90f997ac-8e75-4fea-a86a-e1ef55c1b510,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-b825f174-2ca3-45c0-9b46-82651d429933,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-08583a32-bf98-4d52-a2d4-7146a955266a,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-9262de48-6fb3-407d-9fd0-9805b6b46b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-b2848168-4180-4769-8d85-f213f13c2d39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156794078-172.17.0.6-1597641800066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39961,DS-609a759e-449e-44de-b522-6c67a9622b37,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-54061cef-ce06-4370-954a-f017e2367be8,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-9b4bd7ee-67bf-4a49-936b-4735d96aba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-90f997ac-8e75-4fea-a86a-e1ef55c1b510,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-b825f174-2ca3-45c0-9b46-82651d429933,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-08583a32-bf98-4d52-a2d4-7146a955266a,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-9262de48-6fb3-407d-9fd0-9805b6b46b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-b2848168-4180-4769-8d85-f213f13c2d39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546936848-172.17.0.6-1597641839922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36550,DS-8040d6b3-b323-4673-bcc0-4465027c50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-52204d27-db42-4786-8014-06171cedab09,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-0866757d-8725-491f-9963-d61f890ef8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-47956422-c593-4078-85e3-518fc9233560,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-dff24d0f-8325-4ba4-9bb0-a596c4e45ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-3a592d21-0c67-45af-ae77-e85fb8be1c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-ac44781c-7822-4132-9ab8-f118dcf71a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-0c32ddd4-0220-4159-8deb-3d4281eb7ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546936848-172.17.0.6-1597641839922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36550,DS-8040d6b3-b323-4673-bcc0-4465027c50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-52204d27-db42-4786-8014-06171cedab09,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-0866757d-8725-491f-9963-d61f890ef8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-47956422-c593-4078-85e3-518fc9233560,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-dff24d0f-8325-4ba4-9bb0-a596c4e45ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-3a592d21-0c67-45af-ae77-e85fb8be1c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-ac44781c-7822-4132-9ab8-f118dcf71a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-0c32ddd4-0220-4159-8deb-3d4281eb7ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124011844-172.17.0.6-1597642067757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45676,DS-5ef45880-f23f-4703-9ec2-37353947d467,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-cba53a73-d38e-4b12-a43a-8f919e1c7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-e24cb150-07b3-4d32-bb99-813e2bffc187,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-0d800b72-27c1-44e5-94ca-2010b542ab82,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-05263ec3-bb6a-419d-a507-7f07d0f8167a,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-6a3098b0-67d9-43dc-80b0-3e5d89e7bed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-d5623dbc-0e90-4a3c-8358-a89d308e08f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-1fd8641f-11e3-439c-9839-d060d4036c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124011844-172.17.0.6-1597642067757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45676,DS-5ef45880-f23f-4703-9ec2-37353947d467,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-cba53a73-d38e-4b12-a43a-8f919e1c7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-e24cb150-07b3-4d32-bb99-813e2bffc187,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-0d800b72-27c1-44e5-94ca-2010b542ab82,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-05263ec3-bb6a-419d-a507-7f07d0f8167a,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-6a3098b0-67d9-43dc-80b0-3e5d89e7bed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-d5623dbc-0e90-4a3c-8358-a89d308e08f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-1fd8641f-11e3-439c-9839-d060d4036c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52633745-172.17.0.6-1597642243056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33435,DS-c1a5698b-d206-4b5d-a87b-19ae4739732b,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-2bc6f605-3a8d-41a0-a0a8-4d7bd908e923,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-89c5930a-a672-4d43-bf3b-2d3968b4c8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-15f7317e-078f-4933-9c26-cc218aa2f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-a999c4ad-f257-48d0-8f42-25b3b811fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-48e2c593-670a-4eab-af9e-4269597602bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-36445d1d-864a-4fcb-bceb-19e2e2977990,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-a9ec087e-1537-45e7-af04-939a93abc204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52633745-172.17.0.6-1597642243056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33435,DS-c1a5698b-d206-4b5d-a87b-19ae4739732b,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-2bc6f605-3a8d-41a0-a0a8-4d7bd908e923,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-89c5930a-a672-4d43-bf3b-2d3968b4c8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-15f7317e-078f-4933-9c26-cc218aa2f28f,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-a999c4ad-f257-48d0-8f42-25b3b811fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-48e2c593-670a-4eab-af9e-4269597602bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-36445d1d-864a-4fcb-bceb-19e2e2977990,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-a9ec087e-1537-45e7-af04-939a93abc204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817834231-172.17.0.6-1597642309311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44548,DS-8ff7a93f-7f6e-40a4-9123-e0bf3ad03942,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-3a9d7055-0fc1-439e-ac95-e80d23c984b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-f55a3ea4-cc4a-41ee-94c4-f2841c20745f,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-1764055d-0cea-4f4b-a165-8b5c96f729e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-bd104cc0-74a0-48f9-a10d-f53538b5b434,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-6f5731d7-c635-436f-94a1-1b5956d6a660,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-a2c62678-9ff0-43db-868c-3799ad759bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-5ec63429-8643-43ae-9d25-9741718277a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817834231-172.17.0.6-1597642309311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44548,DS-8ff7a93f-7f6e-40a4-9123-e0bf3ad03942,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-3a9d7055-0fc1-439e-ac95-e80d23c984b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-f55a3ea4-cc4a-41ee-94c4-f2841c20745f,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-1764055d-0cea-4f4b-a165-8b5c96f729e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-bd104cc0-74a0-48f9-a10d-f53538b5b434,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-6f5731d7-c635-436f-94a1-1b5956d6a660,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-a2c62678-9ff0-43db-868c-3799ad759bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-5ec63429-8643-43ae-9d25-9741718277a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-259911763-172.17.0.6-1597642421315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42976,DS-1aada942-1671-4cda-9117-9f465f6b7f64,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-28cb9101-c370-468c-87de-bd8feedd6c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-bbdb9c06-9216-4427-ad4d-d0664d303872,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-61e654a4-5e1a-4127-83c9-6db1700586a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-d7161fc9-1537-4b11-a0a4-8559f7cbb7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-e654d966-17f0-4950-967f-22fa3c23c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-edb48ea9-50f4-45c4-acea-b9a4fae35115,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-5eb28573-4c25-4f0e-aca6-384a29917263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-259911763-172.17.0.6-1597642421315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42976,DS-1aada942-1671-4cda-9117-9f465f6b7f64,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-28cb9101-c370-468c-87de-bd8feedd6c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-bbdb9c06-9216-4427-ad4d-d0664d303872,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-61e654a4-5e1a-4127-83c9-6db1700586a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-d7161fc9-1537-4b11-a0a4-8559f7cbb7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-e654d966-17f0-4950-967f-22fa3c23c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-edb48ea9-50f4-45c4-acea-b9a4fae35115,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-5eb28573-4c25-4f0e-aca6-384a29917263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5504
