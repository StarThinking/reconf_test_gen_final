reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348269184-172.17.0.20-1597278147478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-216e3506-6708-4961-b6c0-11b10cae80db,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-03a20ad4-2b3f-4cf5-ac35-0e4c9dcc8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-1c071d3d-6e03-413f-9f78-6eb4c9f370d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-01affcf9-35aa-4307-a544-00a2f22aabd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-7f2632d2-3e71-4812-ba61-691ad8e3a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-1b948e76-b0ca-46bb-9a79-291e923dded1,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-174cf883-3b13-4338-a997-e176dba49ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-17730707-5485-4327-9be1-cf927d98810e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348269184-172.17.0.20-1597278147478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-216e3506-6708-4961-b6c0-11b10cae80db,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-03a20ad4-2b3f-4cf5-ac35-0e4c9dcc8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-1c071d3d-6e03-413f-9f78-6eb4c9f370d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-01affcf9-35aa-4307-a544-00a2f22aabd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-7f2632d2-3e71-4812-ba61-691ad8e3a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-1b948e76-b0ca-46bb-9a79-291e923dded1,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-174cf883-3b13-4338-a997-e176dba49ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-17730707-5485-4327-9be1-cf927d98810e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28105973-172.17.0.20-1597278880199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-58d4eec9-76c8-4046-8aa6-3e0d1645f798,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-a765d7e9-75a6-4266-a7e9-94b793cc15b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-dcf79f81-d664-4076-b0ef-01cee1239450,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-e1ea6591-4b06-49bf-aaa3-19571edf6761,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-e0e65239-6961-4946-8e1d-7af123d9e1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-d2a5782c-0f7e-465e-aed6-0a2828e2ce16,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-55af4348-e1fd-4961-a078-5a43786f39f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-07e18c8e-50cf-45fa-b831-77275eae5812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28105973-172.17.0.20-1597278880199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-58d4eec9-76c8-4046-8aa6-3e0d1645f798,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-a765d7e9-75a6-4266-a7e9-94b793cc15b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-dcf79f81-d664-4076-b0ef-01cee1239450,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-e1ea6591-4b06-49bf-aaa3-19571edf6761,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-e0e65239-6961-4946-8e1d-7af123d9e1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-d2a5782c-0f7e-465e-aed6-0a2828e2ce16,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-55af4348-e1fd-4961-a078-5a43786f39f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-07e18c8e-50cf-45fa-b831-77275eae5812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045296081-172.17.0.20-1597279815245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-6cb76283-6fb1-4859-80b0-aeb3ba7de0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-73f2ac6d-0915-4461-97b8-f1e1bae0054f,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-362b403c-c8ff-4867-8915-4895c8061825,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-423a24a0-f7bc-47f0-ab12-568ac57bd1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-368fa628-0f04-4483-9e8d-73c91d2edd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-e92bf7ba-5a9b-48eb-9b8c-bcb3cfc2676c,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-b96f207b-9792-46ef-98f5-1cc07510d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-52e83aa5-5b3a-4ddf-a28f-67cc94332cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045296081-172.17.0.20-1597279815245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-6cb76283-6fb1-4859-80b0-aeb3ba7de0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-73f2ac6d-0915-4461-97b8-f1e1bae0054f,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-362b403c-c8ff-4867-8915-4895c8061825,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-423a24a0-f7bc-47f0-ab12-568ac57bd1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-368fa628-0f04-4483-9e8d-73c91d2edd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-e92bf7ba-5a9b-48eb-9b8c-bcb3cfc2676c,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-b96f207b-9792-46ef-98f5-1cc07510d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-52e83aa5-5b3a-4ddf-a28f-67cc94332cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485375042-172.17.0.20-1597280760176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36908,DS-ac1b9015-ac3c-4702-bb45-20f7a1b63a52,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-59d2bc68-8c38-4f72-99b8-c4a3f0b73dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-293e91d0-d677-4bd4-a000-5fe44303212a,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-7d3ed48b-67ab-4273-9935-11e06943469c,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-7637a2c7-b620-44ba-b0a7-95a0d034a13b,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-bd1e1da9-1fed-4792-b0b9-ef7bf1f446d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-64a378c6-0eb3-46e2-aec4-cf03c2964b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-4006ef96-aadb-4340-9654-02786bd49fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485375042-172.17.0.20-1597280760176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36908,DS-ac1b9015-ac3c-4702-bb45-20f7a1b63a52,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-59d2bc68-8c38-4f72-99b8-c4a3f0b73dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-293e91d0-d677-4bd4-a000-5fe44303212a,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-7d3ed48b-67ab-4273-9935-11e06943469c,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-7637a2c7-b620-44ba-b0a7-95a0d034a13b,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-bd1e1da9-1fed-4792-b0b9-ef7bf1f446d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-64a378c6-0eb3-46e2-aec4-cf03c2964b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-4006ef96-aadb-4340-9654-02786bd49fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956195229-172.17.0.20-1597281079567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-095c9fc2-8bd0-4622-85c3-9d6ab1284946,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-4ca6e42c-dfbf-475b-a59f-90c392f07adb,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-70186ace-7abc-4b3b-8645-b78b92ef91c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7b7946f9-fc4a-4c35-b7e3-b96ac8a51018,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-8a320318-1840-4e40-8883-c9497f48d3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-b9538016-9883-4222-a2e5-2d8982a5b762,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-c9b3c979-d62a-4ab3-b9d7-5dddf2259aef,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-f7ffb11a-e89a-4b1d-a6a8-dfe2dc8064e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956195229-172.17.0.20-1597281079567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-095c9fc2-8bd0-4622-85c3-9d6ab1284946,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-4ca6e42c-dfbf-475b-a59f-90c392f07adb,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-70186ace-7abc-4b3b-8645-b78b92ef91c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7b7946f9-fc4a-4c35-b7e3-b96ac8a51018,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-8a320318-1840-4e40-8883-c9497f48d3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-b9538016-9883-4222-a2e5-2d8982a5b762,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-c9b3c979-d62a-4ab3-b9d7-5dddf2259aef,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-f7ffb11a-e89a-4b1d-a6a8-dfe2dc8064e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054510682-172.17.0.20-1597281224762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-971d902a-fa07-4a0d-b368-6585ec18a59a,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-1876cee3-2185-4910-b9d7-8ee2af851951,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-39b62f08-2dde-4719-b703-bb9e64a7559c,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-15ca0a2b-0d03-493c-9d31-be48b903b470,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5cd1ecb5-2a5b-49ed-8746-6772f55a2061,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-87973ca3-7eda-40e6-abe2-0d9fb30bf502,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-6010f6ad-a80b-419d-8770-c29a4db5de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-a00f7edb-6c2f-4613-84db-3c420fd71992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054510682-172.17.0.20-1597281224762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-971d902a-fa07-4a0d-b368-6585ec18a59a,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-1876cee3-2185-4910-b9d7-8ee2af851951,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-39b62f08-2dde-4719-b703-bb9e64a7559c,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-15ca0a2b-0d03-493c-9d31-be48b903b470,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5cd1ecb5-2a5b-49ed-8746-6772f55a2061,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-87973ca3-7eda-40e6-abe2-0d9fb30bf502,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-6010f6ad-a80b-419d-8770-c29a4db5de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-a00f7edb-6c2f-4613-84db-3c420fd71992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522428505-172.17.0.20-1597281552231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-19847206-e0ec-4d62-84f5-90e2e320474e,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-fca5c1cb-8e1f-42da-a1dc-4a3099344a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-90d75bc8-464a-4157-9d12-56fc85dda4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-aee858f8-2213-48ae-8299-214d4da21a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-04067e05-c552-4635-bfaf-b23680e04a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-fc391f9c-59d8-4ae0-a512-c6abbc9bdbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-6fd68b4a-ae94-4845-86ab-07b4846ecbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-445da9fa-b5e8-4d26-8c6c-cedf59a4199e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522428505-172.17.0.20-1597281552231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-19847206-e0ec-4d62-84f5-90e2e320474e,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-fca5c1cb-8e1f-42da-a1dc-4a3099344a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-90d75bc8-464a-4157-9d12-56fc85dda4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-aee858f8-2213-48ae-8299-214d4da21a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-04067e05-c552-4635-bfaf-b23680e04a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-fc391f9c-59d8-4ae0-a512-c6abbc9bdbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-6fd68b4a-ae94-4845-86ab-07b4846ecbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-445da9fa-b5e8-4d26-8c6c-cedf59a4199e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9909014-172.17.0.20-1597282024178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38069,DS-751e6e58-4001-47a5-b501-adf05af882a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-81f6647d-57c7-4ce3-b2c8-23730acfa307,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-050dc48a-af77-4e0e-9d23-ecced9edbc26,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-c2c98985-bab6-423f-adce-ac44511948ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-d9389610-f053-4819-9ef3-700f9e49e1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-46c364dc-bae6-4aca-b39f-8daedb951fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-f93d5d03-000b-435f-9024-5ea78c074d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-e37635f7-aae2-410e-a66b-f981ffa9ebd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9909014-172.17.0.20-1597282024178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38069,DS-751e6e58-4001-47a5-b501-adf05af882a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-81f6647d-57c7-4ce3-b2c8-23730acfa307,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-050dc48a-af77-4e0e-9d23-ecced9edbc26,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-c2c98985-bab6-423f-adce-ac44511948ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-d9389610-f053-4819-9ef3-700f9e49e1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-46c364dc-bae6-4aca-b39f-8daedb951fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-f93d5d03-000b-435f-9024-5ea78c074d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-e37635f7-aae2-410e-a66b-f981ffa9ebd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314550442-172.17.0.20-1597282067088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-6fd791e5-5cfe-4741-816b-fe2286a15cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-c30dddc2-5fc5-430d-b6cb-86e9a59dfb45,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-27397fdf-5a49-4621-8e87-fdf1000a905d,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-40b718d7-2b01-4e5a-b70f-87a3e4c15c47,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-342a820c-2f5b-4068-8c7f-ec48b808ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-1cfb6f50-6966-4608-84d6-ea2090d56d91,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-a65007d8-809b-4795-868c-778cba3fd756,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-d45f6454-3672-40e4-8cbb-3a7566418462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314550442-172.17.0.20-1597282067088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-6fd791e5-5cfe-4741-816b-fe2286a15cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-c30dddc2-5fc5-430d-b6cb-86e9a59dfb45,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-27397fdf-5a49-4621-8e87-fdf1000a905d,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-40b718d7-2b01-4e5a-b70f-87a3e4c15c47,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-342a820c-2f5b-4068-8c7f-ec48b808ae93,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-1cfb6f50-6966-4608-84d6-ea2090d56d91,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-a65007d8-809b-4795-868c-778cba3fd756,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-d45f6454-3672-40e4-8cbb-3a7566418462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311799073-172.17.0.20-1597282254303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-611b9545-8d4b-4d2a-86dc-3f040341acae,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-6edcf325-a14d-492e-bb66-258b13288262,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-979ba145-9590-4929-822a-98b8b774fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-89583e84-8635-4170-a198-b0827e2dcde7,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-442b87d7-7c98-487d-884f-575d293986cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-3e60c5bf-f839-4934-89a5-ce0cd06cb460,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-f784919d-7079-4282-b0f2-43fe5da97fac,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-5fdeeb2a-3e89-44b8-b1ff-a2a86a2961ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311799073-172.17.0.20-1597282254303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-611b9545-8d4b-4d2a-86dc-3f040341acae,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-6edcf325-a14d-492e-bb66-258b13288262,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-979ba145-9590-4929-822a-98b8b774fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-89583e84-8635-4170-a198-b0827e2dcde7,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-442b87d7-7c98-487d-884f-575d293986cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-3e60c5bf-f839-4934-89a5-ce0cd06cb460,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-f784919d-7079-4282-b0f2-43fe5da97fac,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-5fdeeb2a-3e89-44b8-b1ff-a2a86a2961ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316488657-172.17.0.20-1597282347064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46205,DS-c87706a5-f1c4-4698-86e2-2698d4f4b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-e8b31a5e-d8fb-4502-b8c6-1e71677044e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-aeffbe4b-0e46-475e-b90e-61408e28a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-671598fe-924b-414a-b629-b47d1b61a997,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-d51c086c-362c-4bee-b1c5-b57019eaf16c,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-8587d405-f0a2-49c3-9dad-01c39f6f16a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-407d256e-c4b0-4970-8883-396b4734ee64,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-8901ccbb-af37-40a7-8a3c-3def01935560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316488657-172.17.0.20-1597282347064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46205,DS-c87706a5-f1c4-4698-86e2-2698d4f4b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-e8b31a5e-d8fb-4502-b8c6-1e71677044e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-aeffbe4b-0e46-475e-b90e-61408e28a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-671598fe-924b-414a-b629-b47d1b61a997,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-d51c086c-362c-4bee-b1c5-b57019eaf16c,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-8587d405-f0a2-49c3-9dad-01c39f6f16a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-407d256e-c4b0-4970-8883-396b4734ee64,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-8901ccbb-af37-40a7-8a3c-3def01935560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609558412-172.17.0.20-1597282436970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43870,DS-2aafd749-bab1-47bd-8fc3-4ee149ed725e,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-d63a04c7-eb92-4991-8b2a-6e28be1bf8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-e5dce26f-f6a4-4377-aa10-a6da95d77444,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-f519821d-1171-4ad9-9f0f-1ed2f885e606,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-02f2ea18-699b-43d5-b790-bbaeb18eea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-f8107bd1-9218-453e-8fcb-6ce3d09b68a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-1065d188-c35c-447f-a67c-67cd4031442c,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-d45bc4ef-ff36-4d13-b378-11a5d011bb9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609558412-172.17.0.20-1597282436970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43870,DS-2aafd749-bab1-47bd-8fc3-4ee149ed725e,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-d63a04c7-eb92-4991-8b2a-6e28be1bf8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-e5dce26f-f6a4-4377-aa10-a6da95d77444,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-f519821d-1171-4ad9-9f0f-1ed2f885e606,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-02f2ea18-699b-43d5-b790-bbaeb18eea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-f8107bd1-9218-453e-8fcb-6ce3d09b68a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-1065d188-c35c-447f-a67c-67cd4031442c,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-d45bc4ef-ff36-4d13-b378-11a5d011bb9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881339039-172.17.0.20-1597282986628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-1f37cd7e-88ab-4acc-b1ca-434c5bb51a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-0b979310-2097-4a07-905f-4529c9215663,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-7006609a-288d-4597-90cd-5493bb938507,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-e8318086-b66c-4b38-8b1f-58a7e00aaaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-93d43700-9af0-4812-9899-b877a739ec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-c8cd8749-57cc-4b48-9101-0f1dee36b814,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-822d7732-7676-41b3-9cb5-3e3687c6afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-c7177a22-1009-4d69-bf13-65e0a5aef5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881339039-172.17.0.20-1597282986628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-1f37cd7e-88ab-4acc-b1ca-434c5bb51a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-0b979310-2097-4a07-905f-4529c9215663,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-7006609a-288d-4597-90cd-5493bb938507,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-e8318086-b66c-4b38-8b1f-58a7e00aaaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-93d43700-9af0-4812-9899-b877a739ec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-c8cd8749-57cc-4b48-9101-0f1dee36b814,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-822d7732-7676-41b3-9cb5-3e3687c6afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-c7177a22-1009-4d69-bf13-65e0a5aef5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540001685-172.17.0.20-1597283300168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34184,DS-f85cab49-5eff-463f-9cd7-ec76e4f83b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-6f39ed21-6a17-4a79-b09a-70e2e09a9fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-32001e88-2116-4ef3-9f38-0b86eacd9c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-07ae4838-2c0c-408a-9311-84f6f080dc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-0ee1ec3c-b1b6-40c3-9c1a-6a332c13e764,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-a71c0cf9-dd4f-474a-8144-297c1b648da5,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-85eab8c8-024e-42c2-8207-b4eb535a606c,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-9c0d56bd-75b1-4f82-9dc7-137c1ffed719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540001685-172.17.0.20-1597283300168:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34184,DS-f85cab49-5eff-463f-9cd7-ec76e4f83b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-6f39ed21-6a17-4a79-b09a-70e2e09a9fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-32001e88-2116-4ef3-9f38-0b86eacd9c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-07ae4838-2c0c-408a-9311-84f6f080dc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-0ee1ec3c-b1b6-40c3-9c1a-6a332c13e764,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-a71c0cf9-dd4f-474a-8144-297c1b648da5,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-85eab8c8-024e-42c2-8207-b4eb535a606c,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-9c0d56bd-75b1-4f82-9dc7-137c1ffed719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862808959-172.17.0.20-1597283338713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45611,DS-cac442a0-cf60-448c-92e4-21ace63d1dab,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-5018bd00-1d25-4639-a857-7e8f4660f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-ae7b5573-8845-4e1c-a1f6-8aa1c48406de,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-009fca93-5f44-47fd-a507-d01d445757be,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-94fe11f4-d09f-4580-9486-41a968bf09c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-8eb6c7c1-b071-4de2-8d95-7cfc8a568dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-8ba29bec-85c7-4019-9b2f-d3fcdf4ce356,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-2ce0932d-878f-4301-ab1d-61dbfd5dc255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862808959-172.17.0.20-1597283338713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45611,DS-cac442a0-cf60-448c-92e4-21ace63d1dab,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-5018bd00-1d25-4639-a857-7e8f4660f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-ae7b5573-8845-4e1c-a1f6-8aa1c48406de,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-009fca93-5f44-47fd-a507-d01d445757be,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-94fe11f4-d09f-4580-9486-41a968bf09c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-8eb6c7c1-b071-4de2-8d95-7cfc8a568dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-8ba29bec-85c7-4019-9b2f-d3fcdf4ce356,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-2ce0932d-878f-4301-ab1d-61dbfd5dc255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224129705-172.17.0.20-1597283759258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-7adecf81-d84f-42ee-983f-ff237f5ecbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-8d8f56df-9ce4-4ee0-ab65-161e32a05c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-37768236-9c7a-4aff-bdd8-ac98fddf1ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-e2a01d9d-021a-46ba-ab93-c4297e7b3ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-20d78546-ef0c-4d96-b9ee-ab91572e9bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-3d017bb7-7c2d-4357-9641-1318cb06a508,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-4eaa9aa2-ec68-46a3-8fc4-d25e85b1189c,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-93277134-81a8-4bb2-8cc1-7ec644d6b684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224129705-172.17.0.20-1597283759258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-7adecf81-d84f-42ee-983f-ff237f5ecbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-8d8f56df-9ce4-4ee0-ab65-161e32a05c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-37768236-9c7a-4aff-bdd8-ac98fddf1ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-e2a01d9d-021a-46ba-ab93-c4297e7b3ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-20d78546-ef0c-4d96-b9ee-ab91572e9bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-3d017bb7-7c2d-4357-9641-1318cb06a508,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-4eaa9aa2-ec68-46a3-8fc4-d25e85b1189c,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-93277134-81a8-4bb2-8cc1-7ec644d6b684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987510548-172.17.0.20-1597283808230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37191,DS-becca6e7-2d30-4313-b83e-67b5f4dc74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-4a73d19a-3f85-45f0-9f88-cbe4d1ba5c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-0fd6cb25-13d9-403e-92c3-72dfa6a05eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-2da0501c-5f1c-4f49-907e-7690dc6dc9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-8f9bab9e-43b2-413c-808c-ff8d135ebb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-ad606172-b213-4b56-86fe-7bc8f3a7b34d,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-11aa0f98-28d4-469a-9bcd-d600c36624f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-937ce917-7225-4f24-8fe5-d838296b1b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987510548-172.17.0.20-1597283808230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37191,DS-becca6e7-2d30-4313-b83e-67b5f4dc74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-4a73d19a-3f85-45f0-9f88-cbe4d1ba5c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-0fd6cb25-13d9-403e-92c3-72dfa6a05eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-2da0501c-5f1c-4f49-907e-7690dc6dc9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-8f9bab9e-43b2-413c-808c-ff8d135ebb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-ad606172-b213-4b56-86fe-7bc8f3a7b34d,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-11aa0f98-28d4-469a-9bcd-d600c36624f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-937ce917-7225-4f24-8fe5-d838296b1b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424303676-172.17.0.20-1597284283413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-05b956cf-1475-45a2-9d9b-4d6c379caa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-d0bec253-3d2e-4160-bcf7-6d92e8470a12,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-2928a9cf-de9a-4c79-8b6b-448a164476a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-e474c6f8-61c3-4048-9b88-d3c59de667b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-59362f81-7a6a-42e0-b9ee-3c0f26871d52,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-8c3abd07-6a34-4709-8430-02e35ec6097f,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-b19c5a99-5ff4-4255-b8be-d4360d48aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-e6184181-bda8-40a8-9b7e-064d8fda2254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424303676-172.17.0.20-1597284283413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38026,DS-05b956cf-1475-45a2-9d9b-4d6c379caa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-d0bec253-3d2e-4160-bcf7-6d92e8470a12,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-2928a9cf-de9a-4c79-8b6b-448a164476a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-e474c6f8-61c3-4048-9b88-d3c59de667b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-59362f81-7a6a-42e0-b9ee-3c0f26871d52,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-8c3abd07-6a34-4709-8430-02e35ec6097f,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-b19c5a99-5ff4-4255-b8be-d4360d48aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-e6184181-bda8-40a8-9b7e-064d8fda2254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194312870-172.17.0.20-1597284504564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33814,DS-eb927819-caa8-4a0f-a041-5feacf1cb974,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-96719c3c-6381-4a10-be49-dc0d543e4002,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-7265b30d-b5c6-4e50-83cc-63bbb9536b10,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-eefb35d1-23f1-407d-85ed-a6e752b59d64,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-af5544a0-9550-4fe3-994b-0878a48f1bea,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-4a322097-6464-405b-a015-4550398d7bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-4c47c066-a8dc-435c-be4c-11b2b8da1eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-0cf986c8-d94e-4fe4-8e9d-72abb86cae2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194312870-172.17.0.20-1597284504564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33814,DS-eb927819-caa8-4a0f-a041-5feacf1cb974,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-96719c3c-6381-4a10-be49-dc0d543e4002,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-7265b30d-b5c6-4e50-83cc-63bbb9536b10,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-eefb35d1-23f1-407d-85ed-a6e752b59d64,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-af5544a0-9550-4fe3-994b-0878a48f1bea,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-4a322097-6464-405b-a015-4550398d7bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-4c47c066-a8dc-435c-be4c-11b2b8da1eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-0cf986c8-d94e-4fe4-8e9d-72abb86cae2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318724694-172.17.0.20-1597284727845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-14be5d6c-e84b-4610-a1da-3fa155ae1de0,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-20f68409-9365-41bc-8403-47b595ea8944,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-734aafa8-0cbe-42a4-a679-d9bfae83e8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-da7e35dd-944f-4414-94b8-5099ef60505d,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-49cd9966-8439-44fd-aab3-1ad0930442fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-93972f33-227e-4f7b-9421-8160779fcf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-3853eab5-fb87-45f5-be2d-1d24d01f3dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-9fbbae34-2fdf-499d-a445-76d10b8acd26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318724694-172.17.0.20-1597284727845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-14be5d6c-e84b-4610-a1da-3fa155ae1de0,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-20f68409-9365-41bc-8403-47b595ea8944,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-734aafa8-0cbe-42a4-a679-d9bfae83e8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-da7e35dd-944f-4414-94b8-5099ef60505d,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-49cd9966-8439-44fd-aab3-1ad0930442fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-93972f33-227e-4f7b-9421-8160779fcf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-3853eab5-fb87-45f5-be2d-1d24d01f3dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-9fbbae34-2fdf-499d-a445-76d10b8acd26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6805
