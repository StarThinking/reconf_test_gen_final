reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7107944-172.17.0.12-1597399748196:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-ecbd7e57-fb94-487d-b4aa-563d802e0a36,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-bc93d0b7-4c9a-4d29-99c0-234e20228a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-7e06e014-ae8a-4ced-b921-eb2c762a7d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-74e95001-f4c5-40fc-8ace-ffd976b246c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-900adac9-5e1c-49a4-bd82-d0d6b1b36da7,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-d00ae0f9-7521-4413-b124-5cc1c9217b23,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-1c32b116-5061-4456-bd27-9c28bfd874b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-7482451b-4e1d-478f-94fd-3fccdd2edbfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7107944-172.17.0.12-1597399748196:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-ecbd7e57-fb94-487d-b4aa-563d802e0a36,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-bc93d0b7-4c9a-4d29-99c0-234e20228a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-7e06e014-ae8a-4ced-b921-eb2c762a7d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-74e95001-f4c5-40fc-8ace-ffd976b246c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-900adac9-5e1c-49a4-bd82-d0d6b1b36da7,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-d00ae0f9-7521-4413-b124-5cc1c9217b23,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-1c32b116-5061-4456-bd27-9c28bfd874b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-7482451b-4e1d-478f-94fd-3fccdd2edbfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706717560-172.17.0.12-1597399929682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33625,DS-f3d45622-7eec-4ccb-9dc2-49cdff99f984,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-de9ae665-91b5-4b59-a38f-ed6522648c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-9230d9fc-a394-4ab6-981e-273aae5c54f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-11a0ed4b-9ad9-407c-b612-db5b66a6bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-32bbefe8-6d70-4eb6-b4f0-e935844e82d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-851ae72d-52da-4a65-9870-7c40e954c8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-9ed5e017-9f60-4ed7-9520-5da8e7b3c647,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-0a047633-2e85-49b2-a0bf-a7c7a86de525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706717560-172.17.0.12-1597399929682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33625,DS-f3d45622-7eec-4ccb-9dc2-49cdff99f984,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-de9ae665-91b5-4b59-a38f-ed6522648c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-9230d9fc-a394-4ab6-981e-273aae5c54f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-11a0ed4b-9ad9-407c-b612-db5b66a6bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-32bbefe8-6d70-4eb6-b4f0-e935844e82d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-851ae72d-52da-4a65-9870-7c40e954c8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-9ed5e017-9f60-4ed7-9520-5da8e7b3c647,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-0a047633-2e85-49b2-a0bf-a7c7a86de525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119474409-172.17.0.12-1597399966366:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42654,DS-5fe708a0-5f78-433f-9444-2c36f74ffe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-6b1994f5-74cc-4d44-bb7f-9a18877315f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-418a6c59-5005-4b52-a42c-4354e2c4ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-c87c4852-5b3a-4976-9bba-fcd95f5ebc31,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-4febd574-b0da-4570-899c-64a562e3b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-8cfd09d3-1deb-4eba-ae6d-cc701cd31302,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-1b841adb-3a63-4dfd-b066-0c30cf3fdc06,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-b559073d-1df6-4460-aef9-097b0b8c45bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119474409-172.17.0.12-1597399966366:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42654,DS-5fe708a0-5f78-433f-9444-2c36f74ffe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-6b1994f5-74cc-4d44-bb7f-9a18877315f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-418a6c59-5005-4b52-a42c-4354e2c4ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-c87c4852-5b3a-4976-9bba-fcd95f5ebc31,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-4febd574-b0da-4570-899c-64a562e3b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-8cfd09d3-1deb-4eba-ae6d-cc701cd31302,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-1b841adb-3a63-4dfd-b066-0c30cf3fdc06,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-b559073d-1df6-4460-aef9-097b0b8c45bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163712231-172.17.0.12-1597400559297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39508,DS-fff0d0a8-8a3f-45b6-bff1-596aab8e72a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-f638a91b-d512-4ed9-b826-a44ab32d427f,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-e7669b88-76aa-4089-9787-b736650b3c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-28747435-7c70-45ce-bfaa-a29cb99d9d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-117e4d6d-6808-4b09-bf12-4bd93e436d55,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-612774e4-7a51-4f36-a9df-8ae8c4075fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-7dddc6ce-d255-481c-8f53-b6f863ce2878,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-8454dc34-c241-4f4c-9991-383f877db3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163712231-172.17.0.12-1597400559297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39508,DS-fff0d0a8-8a3f-45b6-bff1-596aab8e72a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-f638a91b-d512-4ed9-b826-a44ab32d427f,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-e7669b88-76aa-4089-9787-b736650b3c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-28747435-7c70-45ce-bfaa-a29cb99d9d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-117e4d6d-6808-4b09-bf12-4bd93e436d55,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-612774e4-7a51-4f36-a9df-8ae8c4075fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-7dddc6ce-d255-481c-8f53-b6f863ce2878,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-8454dc34-c241-4f4c-9991-383f877db3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260012055-172.17.0.12-1597401236433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-19092dfc-0bd6-493d-ad84-3d67a2855843,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-2d2ec540-1887-489a-8053-e8c68db39980,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-19e5a509-e68a-4158-8297-ef95111ab68a,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-9e499d9e-48b7-4987-bc8f-57677505209a,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-47683cf2-4325-42c1-90bc-1fcbbcae1673,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-4884ed7c-e721-4cc9-868c-a78d3470343c,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-dabf8d1b-89a1-4e6b-a90a-30f881f37a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-e0471562-83ed-48af-aa85-8866efb16064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260012055-172.17.0.12-1597401236433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-19092dfc-0bd6-493d-ad84-3d67a2855843,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-2d2ec540-1887-489a-8053-e8c68db39980,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-19e5a509-e68a-4158-8297-ef95111ab68a,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-9e499d9e-48b7-4987-bc8f-57677505209a,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-47683cf2-4325-42c1-90bc-1fcbbcae1673,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-4884ed7c-e721-4cc9-868c-a78d3470343c,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-dabf8d1b-89a1-4e6b-a90a-30f881f37a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-e0471562-83ed-48af-aa85-8866efb16064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246835995-172.17.0.12-1597401466877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42439,DS-fef1abb1-5d85-4199-9728-3f95c00652eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-5dbb2d31-99c8-4abd-af9d-19e5bdebd774,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-68544ccf-5d38-4140-9e1a-b6a2b4436435,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-5dd2de36-19d2-472a-b475-f84033f85905,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-fe8bb52f-03c0-4aa0-8ddf-7d58c8d93286,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-cb0f044e-7c88-42ad-a662-a2893f4e0099,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-280038c7-5c44-4ff1-8ca9-223dcdd6f07c,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-04e903e0-8a5c-4bfd-accc-83eaf7c237b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246835995-172.17.0.12-1597401466877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42439,DS-fef1abb1-5d85-4199-9728-3f95c00652eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-5dbb2d31-99c8-4abd-af9d-19e5bdebd774,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-68544ccf-5d38-4140-9e1a-b6a2b4436435,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-5dd2de36-19d2-472a-b475-f84033f85905,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-fe8bb52f-03c0-4aa0-8ddf-7d58c8d93286,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-cb0f044e-7c88-42ad-a662-a2893f4e0099,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-280038c7-5c44-4ff1-8ca9-223dcdd6f07c,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-04e903e0-8a5c-4bfd-accc-83eaf7c237b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362520362-172.17.0.12-1597401935619:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39337,DS-b2b14bfa-6f3b-4bca-8e60-b0ef22f32f44,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-0b4b8289-718c-4263-9898-e4e1fd3696dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-b8937d41-1898-493b-a6bd-cd05d65fb62b,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-068fb84b-9e74-4bdd-b488-5d9e0a400a21,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-ea49b968-bfca-48c2-ba19-c65b5792f155,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-89fd6ec0-8144-4051-8793-4c957e39ddce,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-d146c866-177a-452c-901d-4ea87e580630,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-34fa4ce2-4a69-4314-97c4-dfe3c27ab3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362520362-172.17.0.12-1597401935619:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39337,DS-b2b14bfa-6f3b-4bca-8e60-b0ef22f32f44,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-0b4b8289-718c-4263-9898-e4e1fd3696dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-b8937d41-1898-493b-a6bd-cd05d65fb62b,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-068fb84b-9e74-4bdd-b488-5d9e0a400a21,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-ea49b968-bfca-48c2-ba19-c65b5792f155,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-89fd6ec0-8144-4051-8793-4c957e39ddce,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-d146c866-177a-452c-901d-4ea87e580630,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-34fa4ce2-4a69-4314-97c4-dfe3c27ab3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389363100-172.17.0.12-1597402046159:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-56e2158a-0ef0-4e20-8ba7-10520d0acdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-700d13e6-f8d9-4cc2-b5cb-ae720e34439b,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-31c3b559-0310-4ac8-8657-3ac5f9d54a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-23fb040e-0d41-4c71-8bea-4bdde19ef225,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-81add5bf-67b1-4fff-bfb9-0c702d635793,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-410a8a4d-d5c8-44d3-9eff-733227708c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-d713c289-b06b-4565-899f-255a09505ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-a33c60de-2f16-4b60-8976-b6182a194a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389363100-172.17.0.12-1597402046159:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-56e2158a-0ef0-4e20-8ba7-10520d0acdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-700d13e6-f8d9-4cc2-b5cb-ae720e34439b,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-31c3b559-0310-4ac8-8657-3ac5f9d54a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-23fb040e-0d41-4c71-8bea-4bdde19ef225,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-81add5bf-67b1-4fff-bfb9-0c702d635793,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-410a8a4d-d5c8-44d3-9eff-733227708c73,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-d713c289-b06b-4565-899f-255a09505ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-a33c60de-2f16-4b60-8976-b6182a194a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054162165-172.17.0.12-1597402117334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41727,DS-31c67968-d959-4b07-b1ea-f7b473ba98e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-30344a25-f67c-4660-8b34-5a3d2861b311,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-2334269e-a966-4fd3-a6a0-70da2e0fbb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-09fcaeee-2bf5-4039-af0f-f67bddb298ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-f7a9e6c2-b78e-4f98-94e0-767930009dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-2a82d007-6075-4ef8-a536-5420c96942f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-fee6f049-3b2e-498a-be07-6efd951479b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-cc5f7e08-b598-4718-80ff-412e89478440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054162165-172.17.0.12-1597402117334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41727,DS-31c67968-d959-4b07-b1ea-f7b473ba98e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-30344a25-f67c-4660-8b34-5a3d2861b311,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-2334269e-a966-4fd3-a6a0-70da2e0fbb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-09fcaeee-2bf5-4039-af0f-f67bddb298ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-f7a9e6c2-b78e-4f98-94e0-767930009dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-2a82d007-6075-4ef8-a536-5420c96942f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-fee6f049-3b2e-498a-be07-6efd951479b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-cc5f7e08-b598-4718-80ff-412e89478440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105914191-172.17.0.12-1597402808498:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46782,DS-e2610176-e725-4361-b7ef-daa17cfa755d,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-5f66e927-e6a8-4c89-a003-ae3184520be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-600567cf-cc7d-4334-ac0e-2b595f129c25,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-f2d5223c-96de-4ee7-b595-2a44946ef5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-9a5daf94-deaf-48a6-a3f3-5a459f1dc5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-6e3bd88d-6266-4066-80dc-fc25c929e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-c377905d-7d06-4f95-aab9-6a518c792c44,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-dd45282f-eeb1-498f-8429-abb027167431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105914191-172.17.0.12-1597402808498:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46782,DS-e2610176-e725-4361-b7ef-daa17cfa755d,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-5f66e927-e6a8-4c89-a003-ae3184520be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-600567cf-cc7d-4334-ac0e-2b595f129c25,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-f2d5223c-96de-4ee7-b595-2a44946ef5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-9a5daf94-deaf-48a6-a3f3-5a459f1dc5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-6e3bd88d-6266-4066-80dc-fc25c929e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-c377905d-7d06-4f95-aab9-6a518c792c44,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-dd45282f-eeb1-498f-8429-abb027167431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042210220-172.17.0.12-1597402930360:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34101,DS-f3d6a9ba-7a82-4b15-9080-2fece7b8e29f,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-0b75c005-d367-4d6f-834b-f09282ed99cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-0131f2c9-9f37-4db5-92bb-b5a8a8d55bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-dec28360-68da-4292-9ecb-f55713835d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-5630b665-f1cb-4ca7-bd5c-ebdb81c9f596,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-09b72577-670e-40ef-aac9-04c0eeb12663,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-be68fe07-0c82-4e35-9e87-123ff797e9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-2ee91ee9-8bfc-4764-bb74-eba69ea9d9bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042210220-172.17.0.12-1597402930360:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34101,DS-f3d6a9ba-7a82-4b15-9080-2fece7b8e29f,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-0b75c005-d367-4d6f-834b-f09282ed99cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-0131f2c9-9f37-4db5-92bb-b5a8a8d55bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-dec28360-68da-4292-9ecb-f55713835d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-5630b665-f1cb-4ca7-bd5c-ebdb81c9f596,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-09b72577-670e-40ef-aac9-04c0eeb12663,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-be68fe07-0c82-4e35-9e87-123ff797e9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-2ee91ee9-8bfc-4764-bb74-eba69ea9d9bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431683634-172.17.0.12-1597403119880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33919,DS-888e758f-9c6a-430e-b880-e0653f26dbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-460c3028-1ab2-41f2-8b9a-5a9cd3905a41,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-26f15f82-14c7-485d-b81a-a77bbaac3209,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-17e8be94-2845-41e1-a6e2-c97b1db949b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-92e66948-7e25-4688-9026-9d6bd1518a44,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-0483a2e0-941d-4b2f-9c0e-d2979716a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-21cb149f-de96-450a-b968-373e01304132,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-04b91ca7-40d5-4bb2-8c3c-fb163b43df5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431683634-172.17.0.12-1597403119880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33919,DS-888e758f-9c6a-430e-b880-e0653f26dbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-460c3028-1ab2-41f2-8b9a-5a9cd3905a41,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-26f15f82-14c7-485d-b81a-a77bbaac3209,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-17e8be94-2845-41e1-a6e2-c97b1db949b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-92e66948-7e25-4688-9026-9d6bd1518a44,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-0483a2e0-941d-4b2f-9c0e-d2979716a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-21cb149f-de96-450a-b968-373e01304132,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-04b91ca7-40d5-4bb2-8c3c-fb163b43df5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160342053-172.17.0.12-1597403197120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44713,DS-af4a0f84-41f7-4a98-82ce-f0fb12efffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-e6de0f28-750b-47e4-a7bf-8123d9204c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-777d7647-17d5-441e-bce7-4c615d7992cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-526f62a9-2404-4d70-8132-6f25e04a1416,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-6edaeb36-5892-421c-8868-4638439682cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-1f9f91c3-4417-48ff-9114-5a98983f4ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-f7e98725-6aa6-4d3a-82ed-3acfeba10bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-89186bce-3241-4284-8c9f-649dcfb1c69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160342053-172.17.0.12-1597403197120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44713,DS-af4a0f84-41f7-4a98-82ce-f0fb12efffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-e6de0f28-750b-47e4-a7bf-8123d9204c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-777d7647-17d5-441e-bce7-4c615d7992cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-526f62a9-2404-4d70-8132-6f25e04a1416,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-6edaeb36-5892-421c-8868-4638439682cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-1f9f91c3-4417-48ff-9114-5a98983f4ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-f7e98725-6aa6-4d3a-82ed-3acfeba10bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-89186bce-3241-4284-8c9f-649dcfb1c69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113837264-172.17.0.12-1597403688943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37621,DS-5cb3991f-4c0a-442c-a5f7-325e7ae74022,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-22326bbc-a43f-49dc-aced-704b1e878a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-d3b6041d-8041-4e92-91c3-b92d6ca72c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-f3ce89ce-9451-4c60-a476-1fbf5e5496aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-6436054c-b53d-4e6c-ba4a-c0fe92039e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-8d1b8554-78ae-41ee-a6d6-1deb41a4b76e,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-1029de29-35c6-4c9f-8261-c2ca6c7e12fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-56fdafd8-61be-4772-aeca-824d7ced9176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113837264-172.17.0.12-1597403688943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37621,DS-5cb3991f-4c0a-442c-a5f7-325e7ae74022,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-22326bbc-a43f-49dc-aced-704b1e878a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-d3b6041d-8041-4e92-91c3-b92d6ca72c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-f3ce89ce-9451-4c60-a476-1fbf5e5496aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-6436054c-b53d-4e6c-ba4a-c0fe92039e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-8d1b8554-78ae-41ee-a6d6-1deb41a4b76e,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-1029de29-35c6-4c9f-8261-c2ca6c7e12fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-56fdafd8-61be-4772-aeca-824d7ced9176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110120958-172.17.0.12-1597403751999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46277,DS-95ff61b7-f84a-418e-b03a-c62b576493ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-85799fc5-4d9b-4c17-a20f-3679e1d3ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-1dd56cc4-63ab-4334-b226-6118b7e2eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-658cd6e9-2a57-4e09-bba9-cf8dc2e7decf,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-226a6db1-027c-4ec3-bbd9-4dc667857099,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-e6c9dbc2-3f16-4c1e-a5b4-2b045d763146,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-85fb5df7-a50b-40c3-abb0-b4faaf2cc9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-46f03c7b-3c48-4617-bc8b-458b26bacbda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110120958-172.17.0.12-1597403751999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46277,DS-95ff61b7-f84a-418e-b03a-c62b576493ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-85799fc5-4d9b-4c17-a20f-3679e1d3ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-1dd56cc4-63ab-4334-b226-6118b7e2eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-658cd6e9-2a57-4e09-bba9-cf8dc2e7decf,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-226a6db1-027c-4ec3-bbd9-4dc667857099,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-e6c9dbc2-3f16-4c1e-a5b4-2b045d763146,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-85fb5df7-a50b-40c3-abb0-b4faaf2cc9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-46f03c7b-3c48-4617-bc8b-458b26bacbda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014503886-172.17.0.12-1597403909997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34183,DS-479b315d-d33e-4dab-b0ba-f0877e77ed81,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-a874263b-2383-4b0c-b45a-fdf25a2b6d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-39123a72-a309-40f4-880c-4bba5264555a,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-71199a27-cf45-411a-b27d-56a0e6df4859,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-1c76be2d-a6c6-421d-9914-1416ffa3d567,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-d6580679-3b64-4c0b-8141-c72c29b199e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-a562eb2f-d6b5-4543-8e15-c858b4c5073d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-b6bdc9a2-8a8b-4645-a5b3-e2855603c7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014503886-172.17.0.12-1597403909997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34183,DS-479b315d-d33e-4dab-b0ba-f0877e77ed81,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-a874263b-2383-4b0c-b45a-fdf25a2b6d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-39123a72-a309-40f4-880c-4bba5264555a,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-71199a27-cf45-411a-b27d-56a0e6df4859,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-1c76be2d-a6c6-421d-9914-1416ffa3d567,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-d6580679-3b64-4c0b-8141-c72c29b199e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-a562eb2f-d6b5-4543-8e15-c858b4c5073d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-b6bdc9a2-8a8b-4645-a5b3-e2855603c7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132579366-172.17.0.12-1597404771791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42413,DS-596d8660-188c-4fae-ac27-f31e62a8a33b,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-b59b2854-7b1f-4bc8-bcfe-443c7c961afc,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-4ba9012b-764d-4991-949b-f8f08fe80d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-8bc50e74-9ba4-4640-a163-83fd357a76f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-eaf47e57-a163-4668-b970-1a7f9be17475,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-d48cb7bc-fe81-4358-9651-80d72f2ad9df,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-fbc5d57d-3cad-461d-8d50-1fded8304615,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-f6d65800-ca39-406f-8a18-e07c6595cee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132579366-172.17.0.12-1597404771791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42413,DS-596d8660-188c-4fae-ac27-f31e62a8a33b,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-b59b2854-7b1f-4bc8-bcfe-443c7c961afc,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-4ba9012b-764d-4991-949b-f8f08fe80d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-8bc50e74-9ba4-4640-a163-83fd357a76f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-eaf47e57-a163-4668-b970-1a7f9be17475,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-d48cb7bc-fe81-4358-9651-80d72f2ad9df,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-fbc5d57d-3cad-461d-8d50-1fded8304615,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-f6d65800-ca39-406f-8a18-e07c6595cee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867161757-172.17.0.12-1597405104260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38210,DS-03552572-d0f7-40c5-a525-b1a5e0b47283,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-91c0e294-63a9-48f3-8e17-2f1ebd87d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-6b7d7bf5-5df3-40c3-aa83-b354f8319e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-f262e031-9c93-45ec-b9af-ab0ade4b1c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-0430bc8c-8a9a-45ae-9d76-01167f73fa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-7e837453-486e-4324-87d3-8b765f57ff89,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-8bc866aa-11d1-46a2-9364-64f8caa3fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-8a6f2f8e-7570-4807-a856-388dcbc9c96c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867161757-172.17.0.12-1597405104260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38210,DS-03552572-d0f7-40c5-a525-b1a5e0b47283,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-91c0e294-63a9-48f3-8e17-2f1ebd87d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-6b7d7bf5-5df3-40c3-aa83-b354f8319e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-f262e031-9c93-45ec-b9af-ab0ade4b1c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-0430bc8c-8a9a-45ae-9d76-01167f73fa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-7e837453-486e-4324-87d3-8b765f57ff89,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-8bc866aa-11d1-46a2-9364-64f8caa3fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-8a6f2f8e-7570-4807-a856-388dcbc9c96c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5543
