reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174434110-172.17.0.4-1597476625042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46790,DS-d7903540-96a2-4217-b2a1-d16498957390,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-a65a91e3-065a-48de-a5a4-1ca4f7bf8c95,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-fe961e26-3a63-44a7-823b-e6490879a1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-84edc122-dfed-452a-984d-91625d65aa13,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-696a36fd-6440-428e-a7cc-35ba956fe06f,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-f54d951f-a877-4ceb-a7a4-f4dfa00a97fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-3729719d-1033-4b27-b345-5f7c4995834a,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-afc7934a-5cbd-41da-b6bb-371e2eade4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174434110-172.17.0.4-1597476625042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46790,DS-d7903540-96a2-4217-b2a1-d16498957390,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-a65a91e3-065a-48de-a5a4-1ca4f7bf8c95,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-fe961e26-3a63-44a7-823b-e6490879a1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-84edc122-dfed-452a-984d-91625d65aa13,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-696a36fd-6440-428e-a7cc-35ba956fe06f,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-f54d951f-a877-4ceb-a7a4-f4dfa00a97fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-3729719d-1033-4b27-b345-5f7c4995834a,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-afc7934a-5cbd-41da-b6bb-371e2eade4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753787511-172.17.0.4-1597477654714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-7cc48e8c-d7a4-4d01-a2a7-d5e06374c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-2f3f0914-9c6c-480f-8db6-d32e073dcc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-eec8787c-9488-4607-b007-31f9a93dda75,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-4f8d302c-d972-49f4-b5ce-ea0825a5a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-6a11c2c4-5438-415c-9971-84119a7521f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-dc10d9fb-f57b-4ac0-a535-9f884bb99de6,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b4652c37-10fa-47f9-9554-37212dbbdbed,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-e7458a59-722c-471d-8969-76f026edab1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753787511-172.17.0.4-1597477654714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-7cc48e8c-d7a4-4d01-a2a7-d5e06374c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-2f3f0914-9c6c-480f-8db6-d32e073dcc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-eec8787c-9488-4607-b007-31f9a93dda75,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-4f8d302c-d972-49f4-b5ce-ea0825a5a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-6a11c2c4-5438-415c-9971-84119a7521f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-dc10d9fb-f57b-4ac0-a535-9f884bb99de6,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b4652c37-10fa-47f9-9554-37212dbbdbed,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-e7458a59-722c-471d-8969-76f026edab1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693278130-172.17.0.4-1597477845891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-50f0f900-ae68-47a0-9ac2-974b90279edf,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-02120d39-820d-45fe-8136-8cf21e31bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-dfcb44e6-d1ee-4b8d-9d60-754f043a6837,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-6a0a9011-3959-4218-be2a-bdcf7fa145ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-fa0ec429-6c5f-48e4-9c2b-597815bf1489,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-6deb35ba-cd12-4d3e-834e-c8e1e79de459,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-7f39b40d-5b54-4902-aaea-73a7b922d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-5b80b5cd-b280-43b7-945e-b3185d39509e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693278130-172.17.0.4-1597477845891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-50f0f900-ae68-47a0-9ac2-974b90279edf,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-02120d39-820d-45fe-8136-8cf21e31bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-dfcb44e6-d1ee-4b8d-9d60-754f043a6837,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-6a0a9011-3959-4218-be2a-bdcf7fa145ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-fa0ec429-6c5f-48e4-9c2b-597815bf1489,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-6deb35ba-cd12-4d3e-834e-c8e1e79de459,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-7f39b40d-5b54-4902-aaea-73a7b922d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-5b80b5cd-b280-43b7-945e-b3185d39509e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515933934-172.17.0.4-1597478597283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-71d197df-d7ae-4ec6-b1a5-680958fb5ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-5b767b78-7792-41c9-9d67-ac94aa059e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-5209e19c-6c4d-4f72-9af9-0fe020e72a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-93bd9289-c80e-490f-a4e0-c644fafcdea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-55c1e788-abad-4ed8-913e-f0bc9c162dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-63b8f0d5-15bf-4792-a087-b7846f45e208,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-25472866-0e05-43d4-b5e6-3f3a4b4a576a,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-31dd56c0-50de-4cb4-9ddc-f3a8785f7b77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515933934-172.17.0.4-1597478597283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-71d197df-d7ae-4ec6-b1a5-680958fb5ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-5b767b78-7792-41c9-9d67-ac94aa059e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-5209e19c-6c4d-4f72-9af9-0fe020e72a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-93bd9289-c80e-490f-a4e0-c644fafcdea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-55c1e788-abad-4ed8-913e-f0bc9c162dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-63b8f0d5-15bf-4792-a087-b7846f45e208,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-25472866-0e05-43d4-b5e6-3f3a4b4a576a,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-31dd56c0-50de-4cb4-9ddc-f3a8785f7b77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195946325-172.17.0.4-1597478632654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-c86f20b1-8217-4430-8a25-c36b2cf422df,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-c707c986-3d90-4184-ac85-14232170895a,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-ce09a9bd-9e93-406a-9177-07533d74e109,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-4dd2f26b-8e44-4686-84ea-e18b02c8d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-ebd2e9cc-43db-42a4-a47d-71dfe4d59186,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-6d12b61c-8eb1-4dfd-a8b2-fb358b4e608d,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-b0a396a6-7417-4d1c-8920-27314ddadac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-acfc7ccd-f5d3-41a3-a181-f889ce33b036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195946325-172.17.0.4-1597478632654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-c86f20b1-8217-4430-8a25-c36b2cf422df,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-c707c986-3d90-4184-ac85-14232170895a,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-ce09a9bd-9e93-406a-9177-07533d74e109,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-4dd2f26b-8e44-4686-84ea-e18b02c8d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-ebd2e9cc-43db-42a4-a47d-71dfe4d59186,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-6d12b61c-8eb1-4dfd-a8b2-fb358b4e608d,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-b0a396a6-7417-4d1c-8920-27314ddadac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-acfc7ccd-f5d3-41a3-a181-f889ce33b036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803208922-172.17.0.4-1597478854261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34559,DS-cb66d844-b09a-43e6-a7f1-fa7cfcf2411f,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-45378a8c-0f0f-4546-b835-54b254f1b7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-63dc6d9e-7789-4479-b52f-899207a6554a,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-0ed155f1-3357-4aaf-b7b3-bb4e6ebb0b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-44a8fc04-7f7b-4099-9530-585309440e21,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-8c64b09a-3b73-4c80-ac52-7880817b00af,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-790c6fe5-b5b5-4c9c-b429-af6bf4bb3a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e07ba380-311b-4a90-9c14-795140adfdb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803208922-172.17.0.4-1597478854261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34559,DS-cb66d844-b09a-43e6-a7f1-fa7cfcf2411f,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-45378a8c-0f0f-4546-b835-54b254f1b7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-63dc6d9e-7789-4479-b52f-899207a6554a,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-0ed155f1-3357-4aaf-b7b3-bb4e6ebb0b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-44a8fc04-7f7b-4099-9530-585309440e21,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-8c64b09a-3b73-4c80-ac52-7880817b00af,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-790c6fe5-b5b5-4c9c-b429-af6bf4bb3a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e07ba380-311b-4a90-9c14-795140adfdb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983242880-172.17.0.4-1597479036250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39334,DS-a0f174dc-2cd5-4b26-bfaf-45bf39d4b6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-c3423346-c7f2-4f40-8b69-fa0cbeb7d31d,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-e89dfcaf-1cc3-4efc-a7e4-16906b21da60,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-1c3c2473-58ec-4ec5-bef6-f6155bd47ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-5c2fbc8d-a57b-47d6-9985-d61c663bf435,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-2a579638-e490-4a76-9230-6c373fdb94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-a38fff46-b481-472b-b510-b99fe947321a,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-bdfc234c-5e15-472c-bf8f-a510f8317613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983242880-172.17.0.4-1597479036250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39334,DS-a0f174dc-2cd5-4b26-bfaf-45bf39d4b6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-c3423346-c7f2-4f40-8b69-fa0cbeb7d31d,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-e89dfcaf-1cc3-4efc-a7e4-16906b21da60,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-1c3c2473-58ec-4ec5-bef6-f6155bd47ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-5c2fbc8d-a57b-47d6-9985-d61c663bf435,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-2a579638-e490-4a76-9230-6c373fdb94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-a38fff46-b481-472b-b510-b99fe947321a,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-bdfc234c-5e15-472c-bf8f-a510f8317613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130239434-172.17.0.4-1597479204874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-523333d8-f9bb-4219-b0a4-5f381c2c0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-16164f52-0502-4f6b-91eb-d58b1991d5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-a9544488-9aa4-4df1-8731-2996b0ffdf42,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-e8fa46f2-04ef-4f59-969b-779831f3e855,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-2b401061-a556-413c-91f1-07b94589e3db,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-1b2e6ab3-bcce-4d32-8647-2831ec4b96cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-7ef7e53d-b03b-41d9-8a02-7112aced8863,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-f8378c6a-7a74-4a80-b52d-ec7c219bc7a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130239434-172.17.0.4-1597479204874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-523333d8-f9bb-4219-b0a4-5f381c2c0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-16164f52-0502-4f6b-91eb-d58b1991d5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-a9544488-9aa4-4df1-8731-2996b0ffdf42,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-e8fa46f2-04ef-4f59-969b-779831f3e855,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-2b401061-a556-413c-91f1-07b94589e3db,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-1b2e6ab3-bcce-4d32-8647-2831ec4b96cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-7ef7e53d-b03b-41d9-8a02-7112aced8863,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-f8378c6a-7a74-4a80-b52d-ec7c219bc7a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543108548-172.17.0.4-1597479234397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-4c954e00-ea45-4bf3-839f-82a800f934fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-c9c1cb88-2954-408e-8fa3-643abeb3dde8,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-8a5c2c35-5e5d-4c16-9a13-76c6637d09bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-53ecb9a7-34ce-4d14-becc-b14eeb724739,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-ebd5de99-5b8d-4058-972f-f1da4030b4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-97176005-8638-4794-abc5-1e89479d88a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-472d2c4e-6252-4181-85cf-232e61634413,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-88ce565b-d299-4dd0-89b0-8e8347a69f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543108548-172.17.0.4-1597479234397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-4c954e00-ea45-4bf3-839f-82a800f934fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-c9c1cb88-2954-408e-8fa3-643abeb3dde8,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-8a5c2c35-5e5d-4c16-9a13-76c6637d09bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-53ecb9a7-34ce-4d14-becc-b14eeb724739,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-ebd5de99-5b8d-4058-972f-f1da4030b4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-97176005-8638-4794-abc5-1e89479d88a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-472d2c4e-6252-4181-85cf-232e61634413,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-88ce565b-d299-4dd0-89b0-8e8347a69f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850482830-172.17.0.4-1597479308331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-add7396c-6f22-4836-9734-5cd68a79e162,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-46196bcf-cd61-4fb9-b2dc-b6935d39aa41,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-2c4a9e3f-61ec-411a-ab41-02dbd10a1a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-32e63ac9-0bc3-4632-a2a7-6b32ee8d5612,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-54749c7a-7688-46f0-9a31-79d3937bf432,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-4e7dbae0-50de-4638-a39a-ed0f3865a646,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-d380fe04-8307-404c-a9f3-dc3324fc1503,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-f36108f5-1e13-482f-aeaa-d60bf7c270da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850482830-172.17.0.4-1597479308331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-add7396c-6f22-4836-9734-5cd68a79e162,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-46196bcf-cd61-4fb9-b2dc-b6935d39aa41,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-2c4a9e3f-61ec-411a-ab41-02dbd10a1a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-32e63ac9-0bc3-4632-a2a7-6b32ee8d5612,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-54749c7a-7688-46f0-9a31-79d3937bf432,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-4e7dbae0-50de-4638-a39a-ed0f3865a646,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-d380fe04-8307-404c-a9f3-dc3324fc1503,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-f36108f5-1e13-482f-aeaa-d60bf7c270da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236311354-172.17.0.4-1597479662445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42357,DS-53b0a7d9-443c-4f96-a84e-cc8a9eec1f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-8d561445-8bf7-4453-850e-6092780e3b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-5a4de7c9-b81f-422e-b033-fcf07aafd1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-840a951e-fb92-4bbd-ac34-e7e96d08ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-c9780295-4418-46e0-9f28-52d50185d231,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-5044078e-b835-4ff7-b9be-7100c97b1440,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-032db5d5-7a26-4173-a172-c5440aa3b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-93efb146-d258-4b13-b5be-87a02940ce9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236311354-172.17.0.4-1597479662445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42357,DS-53b0a7d9-443c-4f96-a84e-cc8a9eec1f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-8d561445-8bf7-4453-850e-6092780e3b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-5a4de7c9-b81f-422e-b033-fcf07aafd1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-840a951e-fb92-4bbd-ac34-e7e96d08ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-c9780295-4418-46e0-9f28-52d50185d231,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-5044078e-b835-4ff7-b9be-7100c97b1440,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-032db5d5-7a26-4173-a172-c5440aa3b3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-93efb146-d258-4b13-b5be-87a02940ce9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779639211-172.17.0.4-1597480043678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36333,DS-09fcc0a5-434b-47d9-82d2-180afd6d16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-29025985-4349-417c-b663-f8dbee818fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-35739072-9e2b-4588-aa44-3c417744d96e,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-b59266ee-e688-4f4d-82d5-a303affdb9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-5c3ae3bd-1e48-4259-b887-544aec050953,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-fd4f5253-67cf-4b4e-a162-ae1a72a5a05d,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-102c164c-921a-4561-8e39-7a113fde072a,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-5b72830a-2e84-4be4-8eae-305a0741f062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779639211-172.17.0.4-1597480043678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36333,DS-09fcc0a5-434b-47d9-82d2-180afd6d16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-29025985-4349-417c-b663-f8dbee818fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-35739072-9e2b-4588-aa44-3c417744d96e,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-b59266ee-e688-4f4d-82d5-a303affdb9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-5c3ae3bd-1e48-4259-b887-544aec050953,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-fd4f5253-67cf-4b4e-a162-ae1a72a5a05d,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-102c164c-921a-4561-8e39-7a113fde072a,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-5b72830a-2e84-4be4-8eae-305a0741f062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472360728-172.17.0.4-1597480114203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-c078df8f-0795-49ef-acef-ec851fef516f,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-443be09c-cba4-40e5-89bb-5d93b8793391,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-28823757-3d0e-4185-b205-2e2e1b474f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-4646e0c5-339c-40d9-a023-7c85a275a6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-64896a5c-40b7-4d92-83a2-cf5edeec35d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-41ef310e-c367-4711-b3e6-dbff5b4951e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-3f3722fd-29a6-4783-883d-64a496140562,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-9463f0bd-e1e0-4ec9-9154-4770d0584348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472360728-172.17.0.4-1597480114203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-c078df8f-0795-49ef-acef-ec851fef516f,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-443be09c-cba4-40e5-89bb-5d93b8793391,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-28823757-3d0e-4185-b205-2e2e1b474f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-4646e0c5-339c-40d9-a023-7c85a275a6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-64896a5c-40b7-4d92-83a2-cf5edeec35d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-41ef310e-c367-4711-b3e6-dbff5b4951e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-3f3722fd-29a6-4783-883d-64a496140562,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-9463f0bd-e1e0-4ec9-9154-4770d0584348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650557995-172.17.0.4-1597480146972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-0f0f3347-20cc-46a5-bd0b-75b2c3009913,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-7c1315d3-950b-4baf-9851-4c7aa5fac483,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-081eadf5-4d87-4bce-b542-09d96c7b1d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-e5496af5-f6ea-4152-a902-a8f4029204c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-09152b82-cad9-4861-ba2a-09edf1d72921,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-e289b495-3948-4776-a2ee-cc1942b0bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-8173a3e4-b8d0-4426-894e-184cd31d57fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-13cf4b3c-7e17-451b-a26b-c035417d46bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650557995-172.17.0.4-1597480146972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-0f0f3347-20cc-46a5-bd0b-75b2c3009913,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-7c1315d3-950b-4baf-9851-4c7aa5fac483,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-081eadf5-4d87-4bce-b542-09d96c7b1d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-e5496af5-f6ea-4152-a902-a8f4029204c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-09152b82-cad9-4861-ba2a-09edf1d72921,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-e289b495-3948-4776-a2ee-cc1942b0bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-8173a3e4-b8d0-4426-894e-184cd31d57fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-13cf4b3c-7e17-451b-a26b-c035417d46bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785322676-172.17.0.4-1597480249656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42051,DS-f9c02526-6db6-4da0-b388-4521b9aae705,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-a2556273-cc31-4967-bcc7-1ef3373e5396,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-7afabba1-5c83-4cad-91a0-1fd1c3c8f713,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-39849bdc-fb1b-4bcf-95ce-97d19ff52c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-12733c07-c610-450b-a7fd-4d581795d00c,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-e82fe822-1897-4ac6-b1a3-8c7aa4938456,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-61396090-fef0-4ff4-81ad-649d58d1c133,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-7a522b8f-327f-48ad-80b1-ca39b4832fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785322676-172.17.0.4-1597480249656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42051,DS-f9c02526-6db6-4da0-b388-4521b9aae705,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-a2556273-cc31-4967-bcc7-1ef3373e5396,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-7afabba1-5c83-4cad-91a0-1fd1c3c8f713,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-39849bdc-fb1b-4bcf-95ce-97d19ff52c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-12733c07-c610-450b-a7fd-4d581795d00c,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-e82fe822-1897-4ac6-b1a3-8c7aa4938456,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-61396090-fef0-4ff4-81ad-649d58d1c133,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-7a522b8f-327f-48ad-80b1-ca39b4832fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195137669-172.17.0.4-1597480354384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41265,DS-20ee8760-935d-485f-bcda-b87558e05920,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-1b0519b8-af51-4986-aea7-cc170a59b689,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-783ee147-caa1-43ee-8f4a-9f553cca1902,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-39a88c7c-8198-426a-a913-fd5d3991bce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-c96ee2be-4cea-42a8-ae14-49db1844e275,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-36dc9c24-3b59-4c29-9b77-768e94aa0b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-e60ab75c-6984-47d4-a731-fcdb91e0b367,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-b2562783-b357-49ea-ae4b-2aa0947c755b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195137669-172.17.0.4-1597480354384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41265,DS-20ee8760-935d-485f-bcda-b87558e05920,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-1b0519b8-af51-4986-aea7-cc170a59b689,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-783ee147-caa1-43ee-8f4a-9f553cca1902,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-39a88c7c-8198-426a-a913-fd5d3991bce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-c96ee2be-4cea-42a8-ae14-49db1844e275,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-36dc9c24-3b59-4c29-9b77-768e94aa0b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-e60ab75c-6984-47d4-a731-fcdb91e0b367,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-b2562783-b357-49ea-ae4b-2aa0947c755b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469712813-172.17.0.4-1597480393704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-32927381-7a25-4b2b-9f3a-8e9c58228661,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-136c7b48-57d6-43b8-bcb3-ac3cc24680d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-410466ee-4390-4334-818d-26903cb9aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-7b924e65-b9b4-437b-97ab-976ebbca85ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-d93ca16e-91b4-470b-a9b9-a850e26d0efd,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-16425e93-9de4-4539-ac06-e7701f7858e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-d62c4648-e621-49ee-b493-3becbd952bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-74d7b067-dbde-48df-b396-0c0d89a91770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469712813-172.17.0.4-1597480393704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-32927381-7a25-4b2b-9f3a-8e9c58228661,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-136c7b48-57d6-43b8-bcb3-ac3cc24680d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-410466ee-4390-4334-818d-26903cb9aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-7b924e65-b9b4-437b-97ab-976ebbca85ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-d93ca16e-91b4-470b-a9b9-a850e26d0efd,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-16425e93-9de4-4539-ac06-e7701f7858e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-d62c4648-e621-49ee-b493-3becbd952bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-74d7b067-dbde-48df-b396-0c0d89a91770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500266753-172.17.0.4-1597480645533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-b28b989e-adc9-45d2-b2f1-7a57a90503f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-48588e8e-0bdc-42d2-9498-3bcc3222f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-ebda87e8-b090-4d72-8c6c-6b62e8384d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-b07cc25b-303a-43f9-b120-7226c840cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-1d4761c3-ed13-42c7-a708-e34c78da27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-b72e0be1-77b6-44fa-aee7-cfc98096a455,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-6958bd75-cd01-4dc7-b746-d78ac9ceb9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-fab70ba4-5234-4400-b12d-dc605743a1bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500266753-172.17.0.4-1597480645533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-b28b989e-adc9-45d2-b2f1-7a57a90503f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-48588e8e-0bdc-42d2-9498-3bcc3222f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-ebda87e8-b090-4d72-8c6c-6b62e8384d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-b07cc25b-303a-43f9-b120-7226c840cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-1d4761c3-ed13-42c7-a708-e34c78da27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-b72e0be1-77b6-44fa-aee7-cfc98096a455,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-6958bd75-cd01-4dc7-b746-d78ac9ceb9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-fab70ba4-5234-4400-b12d-dc605743a1bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450708866-172.17.0.4-1597480761466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-b8e54c3e-a619-4170-a768-0e97f28f0cad,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-01af457a-d72b-4422-8e69-6906450ff064,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-29e65eb8-8ef6-4046-bf90-db8f4f76eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-bb707c09-21b7-41cb-8499-575adb99b3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-21490a88-fce6-4b20-a780-7b40d492a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-72f5f867-ac93-4cda-8772-beca41b9159c,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-7f1deb7f-0289-4356-97c0-e26613692ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-bef27985-20db-459a-93c5-109cf1cd2f65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450708866-172.17.0.4-1597480761466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-b8e54c3e-a619-4170-a768-0e97f28f0cad,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-01af457a-d72b-4422-8e69-6906450ff064,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-29e65eb8-8ef6-4046-bf90-db8f4f76eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-bb707c09-21b7-41cb-8499-575adb99b3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-21490a88-fce6-4b20-a780-7b40d492a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-72f5f867-ac93-4cda-8772-beca41b9159c,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-7f1deb7f-0289-4356-97c0-e26613692ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-bef27985-20db-459a-93c5-109cf1cd2f65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101053655-172.17.0.4-1597480836059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-da1d1d4c-7b33-4127-a32d-356e5405fc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-54ac7c01-2d5a-4cb7-95d5-1ae02b0cd663,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-52526ad8-a7ff-49bb-bcd4-e129d1980b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-2d0a846d-2b06-408c-9e75-6423b12e1841,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-c0c3007c-f07f-4ace-901f-ecc761c63d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-2831815b-ce69-46bc-bd90-6c42a1f80edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-ea98a82e-c52d-4aca-9c4d-0021ca9b3e82,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-5ee1c129-6092-4511-8379-a3956807c642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101053655-172.17.0.4-1597480836059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-da1d1d4c-7b33-4127-a32d-356e5405fc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-54ac7c01-2d5a-4cb7-95d5-1ae02b0cd663,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-52526ad8-a7ff-49bb-bcd4-e129d1980b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-2d0a846d-2b06-408c-9e75-6423b12e1841,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-c0c3007c-f07f-4ace-901f-ecc761c63d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-2831815b-ce69-46bc-bd90-6c42a1f80edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-ea98a82e-c52d-4aca-9c4d-0021ca9b3e82,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-5ee1c129-6092-4511-8379-a3956807c642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229459769-172.17.0.4-1597481153947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-09145156-1066-4fd9-a302-3075430e15e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-910d305d-3b60-4b45-affe-218fe64cd311,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-9019a81c-a8cd-430d-aa69-4a01dc52f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-106e9074-4132-461a-a245-a4ce1e2a7bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-ab04ac51-a01e-417f-b038-b92cd70ffc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-3fe8ed47-7bc5-47c0-aaef-d759a3d58d44,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-3060a808-b781-43a9-99a4-c555e55f50b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-db091bf6-f69e-4320-81ca-a69b3bb59fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229459769-172.17.0.4-1597481153947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-09145156-1066-4fd9-a302-3075430e15e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-910d305d-3b60-4b45-affe-218fe64cd311,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-9019a81c-a8cd-430d-aa69-4a01dc52f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-106e9074-4132-461a-a245-a4ce1e2a7bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-ab04ac51-a01e-417f-b038-b92cd70ffc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-3fe8ed47-7bc5-47c0-aaef-d759a3d58d44,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-3060a808-b781-43a9-99a4-c555e55f50b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-db091bf6-f69e-4320-81ca-a69b3bb59fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5475
