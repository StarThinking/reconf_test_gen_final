reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924288284-172.17.0.17-1597353314748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32953,DS-b78720ca-fba1-4fa0-8040-acfeafa4861f,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-b578c356-2b94-4e78-9a77-1bb8823cd469,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-416baf32-f0d3-4701-b64c-c9cdedf71d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-eb0a3a0f-1a87-48f7-b4e9-e44eef08e51e,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-dd9301a5-4022-47fb-b916-4e11f95bafe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-4fb14f3e-9e52-40b1-ba15-4e9bfef7762b,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-40dfdfd0-3bbd-4c36-9fb2-cd52089c25dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-e41c0494-b9d8-430c-a239-ad3f7c62abe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924288284-172.17.0.17-1597353314748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32953,DS-b78720ca-fba1-4fa0-8040-acfeafa4861f,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-b578c356-2b94-4e78-9a77-1bb8823cd469,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-416baf32-f0d3-4701-b64c-c9cdedf71d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-eb0a3a0f-1a87-48f7-b4e9-e44eef08e51e,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-dd9301a5-4022-47fb-b916-4e11f95bafe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-4fb14f3e-9e52-40b1-ba15-4e9bfef7762b,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-40dfdfd0-3bbd-4c36-9fb2-cd52089c25dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-e41c0494-b9d8-430c-a239-ad3f7c62abe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352440214-172.17.0.17-1597353613714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41143,DS-58fa56c5-a1cd-4332-ab44-1abee52c3478,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-a44edab3-25c8-40ba-9e4f-d2aeadcb9074,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-790bf01c-da24-4847-b572-a77f32f5a8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-9bb2a317-cfc3-48da-b8f8-85259d9cb6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-2d8916e9-15d9-49d7-962f-155fa978c449,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-0e9c2522-1fb8-4a35-ae34-b1b8187d4207,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-e6f06204-ccb1-4106-b6b9-bcfbb445ea9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-ac6f1ccd-d102-4832-9110-ea2d2313a0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352440214-172.17.0.17-1597353613714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41143,DS-58fa56c5-a1cd-4332-ab44-1abee52c3478,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-a44edab3-25c8-40ba-9e4f-d2aeadcb9074,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-790bf01c-da24-4847-b572-a77f32f5a8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-9bb2a317-cfc3-48da-b8f8-85259d9cb6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-2d8916e9-15d9-49d7-962f-155fa978c449,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-0e9c2522-1fb8-4a35-ae34-b1b8187d4207,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-e6f06204-ccb1-4106-b6b9-bcfbb445ea9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-ac6f1ccd-d102-4832-9110-ea2d2313a0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048110920-172.17.0.17-1597353761200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-1a6a5738-15ac-4d4d-8f84-61001a8ae6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-cf007d36-2622-465e-b2cb-3f57f42d6117,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-ff4fb599-71b4-429e-b1a6-3b9eab658c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-383523d2-a95b-4b3a-8f66-4513eae20f70,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-86a9eb0b-96d2-4d92-9d37-9a2828af348b,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-7e744278-5bd6-4805-9454-2bdc4a5f67e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-3cf913ed-083c-496e-9002-2205cd5dd1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-e573f02c-65fd-4967-9869-a169bb88922a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048110920-172.17.0.17-1597353761200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-1a6a5738-15ac-4d4d-8f84-61001a8ae6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-cf007d36-2622-465e-b2cb-3f57f42d6117,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-ff4fb599-71b4-429e-b1a6-3b9eab658c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-383523d2-a95b-4b3a-8f66-4513eae20f70,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-86a9eb0b-96d2-4d92-9d37-9a2828af348b,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-7e744278-5bd6-4805-9454-2bdc4a5f67e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-3cf913ed-083c-496e-9002-2205cd5dd1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-e573f02c-65fd-4967-9869-a169bb88922a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133055469-172.17.0.17-1597355167432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33675,DS-61c1cccf-c253-4b88-8322-30806eda93a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-430c0d34-80fd-45f4-9d34-aec5fafa603c,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-dca2ee17-b7c3-4858-8218-479055e7ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-d5340670-0716-4d0a-af53-f4dfe429a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-02543a2a-895b-46a3-a50d-d836f09aee53,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-3c392a5f-7458-49bf-8114-f6241f95c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-16e62361-981d-4f6a-ae99-ddbbd57b8c45,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-1fb09a6d-15ca-4afd-9e28-e47d3f80b6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133055469-172.17.0.17-1597355167432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33675,DS-61c1cccf-c253-4b88-8322-30806eda93a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-430c0d34-80fd-45f4-9d34-aec5fafa603c,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-dca2ee17-b7c3-4858-8218-479055e7ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-d5340670-0716-4d0a-af53-f4dfe429a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-02543a2a-895b-46a3-a50d-d836f09aee53,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-3c392a5f-7458-49bf-8114-f6241f95c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-16e62361-981d-4f6a-ae99-ddbbd57b8c45,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-1fb09a6d-15ca-4afd-9e28-e47d3f80b6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421802824-172.17.0.17-1597355402864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34661,DS-66de766d-613c-4e70-87bf-cf60557a8503,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-1096dc44-16f1-4fe7-a005-b6f9e376d265,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-d45083ac-f9d5-4286-aab1-e3d27c94b3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-2f7fa3df-61e4-4589-9161-088525603e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-a52838d7-9645-4dea-8d0b-4d5cf73e0967,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-b8b5f169-cf14-4ab9-aea5-5605ca805ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-795beb00-068b-4b68-9803-fa372342627b,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-1652a4f3-ff42-4035-949f-ac2198762c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421802824-172.17.0.17-1597355402864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34661,DS-66de766d-613c-4e70-87bf-cf60557a8503,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-1096dc44-16f1-4fe7-a005-b6f9e376d265,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-d45083ac-f9d5-4286-aab1-e3d27c94b3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-2f7fa3df-61e4-4589-9161-088525603e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-a52838d7-9645-4dea-8d0b-4d5cf73e0967,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-b8b5f169-cf14-4ab9-aea5-5605ca805ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-795beb00-068b-4b68-9803-fa372342627b,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-1652a4f3-ff42-4035-949f-ac2198762c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382777682-172.17.0.17-1597355587910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34969,DS-234ae425-8cf0-4513-9dce-a95895964071,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-d0aa0154-0af2-4060-8c5d-a3290e3028eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-d7a82de6-77c8-4b0c-91db-f82d77122de4,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-17c04f65-3a86-45c9-a6de-253a768e76d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-3c53e597-e089-4725-b2be-ba348dfa82e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-f9ae2a36-9d6e-4bd0-924a-c06317bdd1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-e1105cf0-0c3d-44ac-b317-d8a28081fd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-d22c60cf-aa6b-46b8-ad4e-d88b524b1de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382777682-172.17.0.17-1597355587910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34969,DS-234ae425-8cf0-4513-9dce-a95895964071,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-d0aa0154-0af2-4060-8c5d-a3290e3028eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-d7a82de6-77c8-4b0c-91db-f82d77122de4,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-17c04f65-3a86-45c9-a6de-253a768e76d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-3c53e597-e089-4725-b2be-ba348dfa82e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-f9ae2a36-9d6e-4bd0-924a-c06317bdd1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-e1105cf0-0c3d-44ac-b317-d8a28081fd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-d22c60cf-aa6b-46b8-ad4e-d88b524b1de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695219606-172.17.0.17-1597356189450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35333,DS-f460702b-880b-49bd-bc23-ae23d9fbee44,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-68d8fb84-befc-4b1f-8b9c-f03fafb31a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-fc37b0ec-0cd9-4e49-80c4-c21af2e0f4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-e8ec70b6-fcfa-43c5-9ec3-a1fb3523c812,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-47dc6108-3566-443f-b7f0-6ea1610479f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-f6fbdb2d-0529-4ce5-b0cb-4a6be54f61ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-af1ada36-0377-4dfb-b3d5-889387742cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-1191dcd5-ccf3-4470-a613-6c35d2fda753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695219606-172.17.0.17-1597356189450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35333,DS-f460702b-880b-49bd-bc23-ae23d9fbee44,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-68d8fb84-befc-4b1f-8b9c-f03fafb31a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-fc37b0ec-0cd9-4e49-80c4-c21af2e0f4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-e8ec70b6-fcfa-43c5-9ec3-a1fb3523c812,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-47dc6108-3566-443f-b7f0-6ea1610479f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-f6fbdb2d-0529-4ce5-b0cb-4a6be54f61ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-af1ada36-0377-4dfb-b3d5-889387742cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-1191dcd5-ccf3-4470-a613-6c35d2fda753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107909758-172.17.0.17-1597356482295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39223,DS-e56135bf-cba8-44eb-9b15-f89c703bf895,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-4c443d41-7b29-4c6c-8b6b-c23fda6950ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-b88312bb-6673-4508-80d9-6d11e2a636f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-b655cf6a-ea67-422f-8b92-08436cbd52fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-84735bab-51ee-44f4-896d-c7ba24436922,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-96c09675-1ada-4fbc-9151-243ccee68185,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-727a6e79-3aa0-42c0-a54c-521120314838,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-c11c7d92-67cb-4988-b2c4-057a718f6764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107909758-172.17.0.17-1597356482295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39223,DS-e56135bf-cba8-44eb-9b15-f89c703bf895,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-4c443d41-7b29-4c6c-8b6b-c23fda6950ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-b88312bb-6673-4508-80d9-6d11e2a636f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-b655cf6a-ea67-422f-8b92-08436cbd52fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-84735bab-51ee-44f4-896d-c7ba24436922,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-96c09675-1ada-4fbc-9151-243ccee68185,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-727a6e79-3aa0-42c0-a54c-521120314838,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-c11c7d92-67cb-4988-b2c4-057a718f6764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31191276-172.17.0.17-1597356765146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43474,DS-f26a91df-d888-4ab6-9dbd-6fc230e3483f,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-13745b64-3f7d-478d-8522-a72601aaa35a,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-1a0da7f8-123d-47ee-9b05-007b24e66a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-7e40b391-d0a4-47bf-beb4-9514355dc8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-2c65e759-8781-45df-984b-994fbc63e902,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-b35ab41a-5571-4323-af06-fcc5111d29bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-bb3c7bce-a2c0-43de-b8ee-5a6d5a98feed,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-950820a9-ce23-40d5-b843-08b8f7fa37cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31191276-172.17.0.17-1597356765146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43474,DS-f26a91df-d888-4ab6-9dbd-6fc230e3483f,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-13745b64-3f7d-478d-8522-a72601aaa35a,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-1a0da7f8-123d-47ee-9b05-007b24e66a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-7e40b391-d0a4-47bf-beb4-9514355dc8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-2c65e759-8781-45df-984b-994fbc63e902,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-b35ab41a-5571-4323-af06-fcc5111d29bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-bb3c7bce-a2c0-43de-b8ee-5a6d5a98feed,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-950820a9-ce23-40d5-b843-08b8f7fa37cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392107443-172.17.0.17-1597357764272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-9393ab0d-6e8c-42b8-ae48-b8662cd22b78,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-036c63f0-dd1c-4ef9-be2d-c1ecaf776c34,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-884341ee-5d88-40ba-b063-0c74a98cb551,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-e5c68c88-410e-47b6-9a6f-ea66d65cec7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-1a885ebe-3951-4698-af9e-cc47cda8ea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-986c79c1-fada-4473-bbb1-ec06991386c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-0fcdb0ac-a078-4a6c-ac5d-e5a37e15340a,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-29c1e932-06b0-4464-b92d-f9373d942a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392107443-172.17.0.17-1597357764272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-9393ab0d-6e8c-42b8-ae48-b8662cd22b78,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-036c63f0-dd1c-4ef9-be2d-c1ecaf776c34,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-884341ee-5d88-40ba-b063-0c74a98cb551,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-e5c68c88-410e-47b6-9a6f-ea66d65cec7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-1a885ebe-3951-4698-af9e-cc47cda8ea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-986c79c1-fada-4473-bbb1-ec06991386c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-0fcdb0ac-a078-4a6c-ac5d-e5a37e15340a,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-29c1e932-06b0-4464-b92d-f9373d942a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856282302-172.17.0.17-1597358127711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-5f1a0966-2a52-4564-84c7-0031f637a9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-4387526e-87b0-4e80-8632-db16c00cd3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-c9781ce5-8459-4f87-ab11-7c0ef75cbafe,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-0ca506a6-6ad5-4a01-81e4-a175e08c2004,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-1cc42434-873c-4d1a-bf32-1a0e0932cee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-9549463c-575f-4a21-9b91-cb597326b2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-4d042c7e-d32a-4e20-a639-2467e6c8710d,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-935c11cb-1ee3-4568-82a1-6c62c6a66935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856282302-172.17.0.17-1597358127711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-5f1a0966-2a52-4564-84c7-0031f637a9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-4387526e-87b0-4e80-8632-db16c00cd3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-c9781ce5-8459-4f87-ab11-7c0ef75cbafe,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-0ca506a6-6ad5-4a01-81e4-a175e08c2004,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-1cc42434-873c-4d1a-bf32-1a0e0932cee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-9549463c-575f-4a21-9b91-cb597326b2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-4d042c7e-d32a-4e20-a639-2467e6c8710d,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-935c11cb-1ee3-4568-82a1-6c62c6a66935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105839738-172.17.0.17-1597358172973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-f8fcf99f-894b-47fb-a974-2ef97bbf5ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-cdfae839-c864-4f32-a8fb-1a19cb0e731d,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-518ab570-a722-4f7f-baa1-af614a539e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-0b67e391-5a63-4abf-9d47-1041f58755c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-f06a1045-16ce-4779-9400-b334b7052da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-0ad3dfb4-25c9-4657-9045-6296fc083d54,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-48c08372-bec5-498d-878e-c84fc96a6889,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-17ac14b3-3a82-4bcc-9e53-83d2eb21b9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105839738-172.17.0.17-1597358172973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-f8fcf99f-894b-47fb-a974-2ef97bbf5ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-cdfae839-c864-4f32-a8fb-1a19cb0e731d,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-518ab570-a722-4f7f-baa1-af614a539e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-0b67e391-5a63-4abf-9d47-1041f58755c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-f06a1045-16ce-4779-9400-b334b7052da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-0ad3dfb4-25c9-4657-9045-6296fc083d54,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-48c08372-bec5-498d-878e-c84fc96a6889,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-17ac14b3-3a82-4bcc-9e53-83d2eb21b9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1021589355-172.17.0.17-1597358351602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36642,DS-7575a69c-8805-4f1a-b2cc-a734b3417407,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-897f971b-27d4-4df5-a491-e5a78eecd818,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-0120612c-0a78-4cf3-941a-6baa0cabf21e,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-6044c333-c91b-41ba-9e74-73864262b0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-8e75aafb-c52a-4340-86c8-73dcb54b6311,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-ff9b8e11-821e-4979-9ea4-43c252d9eef7,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-b73b031c-800f-4288-8f20-cd59bf3830a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-d2ceaf76-c541-4ba1-bc4d-d4e676b8e73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1021589355-172.17.0.17-1597358351602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36642,DS-7575a69c-8805-4f1a-b2cc-a734b3417407,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-897f971b-27d4-4df5-a491-e5a78eecd818,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-0120612c-0a78-4cf3-941a-6baa0cabf21e,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-6044c333-c91b-41ba-9e74-73864262b0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-8e75aafb-c52a-4340-86c8-73dcb54b6311,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-ff9b8e11-821e-4979-9ea4-43c252d9eef7,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-b73b031c-800f-4288-8f20-cd59bf3830a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-d2ceaf76-c541-4ba1-bc4d-d4e676b8e73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678137251-172.17.0.17-1597358722480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40518,DS-fb13a3d2-3503-4579-9422-b309ffe50f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-c3868e05-3045-403d-90c2-8f18c97a9a58,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-44a7ff9c-a722-4947-9120-f1f78f08a5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-c4e96386-5420-4bfe-8686-48040f669620,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-a224ffb9-d952-41a7-a3a3-02736ef1d205,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-a89a1194-eb0e-4996-8633-57d059d8d3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-176fa43f-d20e-4a14-a450-88f1e52e317d,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-a20738f9-9b18-4510-97d7-61188b0397fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678137251-172.17.0.17-1597358722480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40518,DS-fb13a3d2-3503-4579-9422-b309ffe50f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-c3868e05-3045-403d-90c2-8f18c97a9a58,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-44a7ff9c-a722-4947-9120-f1f78f08a5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-c4e96386-5420-4bfe-8686-48040f669620,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-a224ffb9-d952-41a7-a3a3-02736ef1d205,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-a89a1194-eb0e-4996-8633-57d059d8d3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-176fa43f-d20e-4a14-a450-88f1e52e317d,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-a20738f9-9b18-4510-97d7-61188b0397fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362951765-172.17.0.17-1597358805553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-00a2df83-a38f-4281-8715-1cceb1260112,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-c16b19d4-1010-44fe-bf5a-31744ce1b25d,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-a38a61e5-49f6-4ee9-b365-0f0b75f18b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-f25f8f8b-efc4-4087-8312-93cf41704b80,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-a3ce66a0-d5b4-4ae9-9065-be2acc3e546e,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-abe21a66-f901-4a85-ae8e-e391db42b135,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-23552983-d937-4c10-a569-e813c3ae4494,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-49ca7ac5-1c57-440e-938e-86b926a5af71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362951765-172.17.0.17-1597358805553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38367,DS-00a2df83-a38f-4281-8715-1cceb1260112,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-c16b19d4-1010-44fe-bf5a-31744ce1b25d,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-a38a61e5-49f6-4ee9-b365-0f0b75f18b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-f25f8f8b-efc4-4087-8312-93cf41704b80,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-a3ce66a0-d5b4-4ae9-9065-be2acc3e546e,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-abe21a66-f901-4a85-ae8e-e391db42b135,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-23552983-d937-4c10-a569-e813c3ae4494,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-49ca7ac5-1c57-440e-938e-86b926a5af71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982950945-172.17.0.17-1597358857635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35293,DS-8eda6cf9-bbea-4e8c-9185-7fc2345ea7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-af1ac6b6-9fa8-4287-85ef-ddcb9ab06594,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-9e671284-680a-46be-b8fe-28085a8a0eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-7a172207-db04-4a83-a69e-11b0485a2e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-42701108-4e22-49ab-b4ac-55c297a4a358,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-f1a88db9-6f92-4eff-89c3-6e36f10ed565,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-d2d2dd57-d9b6-4868-b2cf-3db2bf11f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-98271a10-c9d6-448f-a7cc-6c5d83105544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982950945-172.17.0.17-1597358857635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35293,DS-8eda6cf9-bbea-4e8c-9185-7fc2345ea7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-af1ac6b6-9fa8-4287-85ef-ddcb9ab06594,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-9e671284-680a-46be-b8fe-28085a8a0eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-7a172207-db04-4a83-a69e-11b0485a2e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-42701108-4e22-49ab-b4ac-55c297a4a358,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-f1a88db9-6f92-4eff-89c3-6e36f10ed565,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-d2d2dd57-d9b6-4868-b2cf-3db2bf11f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-98271a10-c9d6-448f-a7cc-6c5d83105544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 6000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889040351-172.17.0.17-1597359042818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-72bff987-2d17-4be1-963e-3f23c18fa608,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-2eea1381-bb2e-42cc-a4e9-76a36d5154ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-b1ee73bd-7282-49cb-aa13-6b6754bd9e57,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-d2c2f1b7-c132-429f-a48a-dac8a50417f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-9700e8fa-6b57-42c9-99aa-0c056b048c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-8bad1965-a7b0-477f-877d-0ba329710f79,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-31bf8715-3dec-41d4-aafc-e6c081460c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-3bc889e3-143f-4fba-9e9e-792c462e8e56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889040351-172.17.0.17-1597359042818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-72bff987-2d17-4be1-963e-3f23c18fa608,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-2eea1381-bb2e-42cc-a4e9-76a36d5154ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-b1ee73bd-7282-49cb-aa13-6b6754bd9e57,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-d2c2f1b7-c132-429f-a48a-dac8a50417f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-9700e8fa-6b57-42c9-99aa-0c056b048c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-8bad1965-a7b0-477f-877d-0ba329710f79,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-31bf8715-3dec-41d4-aafc-e6c081460c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-3bc889e3-143f-4fba-9e9e-792c462e8e56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6978
