reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533389576-172.17.0.14-1597482293236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-593583fd-517f-478c-8614-06219049b0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-c2f1874f-9298-49e4-9c29-8950ceb212e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-541c96e0-a135-4161-8aba-b9912758615e,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-4b90c26b-a6cd-4d46-b153-2ad2c5da029b,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-9b0e648d-9682-4654-9af1-83500d310b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-ab38313d-8207-48b5-ae82-c4671a3490b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-494be5d1-6e7b-480e-ada3-e3cda3492720,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-9f00168e-ccc9-4e4f-a08b-4687cac23a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533389576-172.17.0.14-1597482293236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-593583fd-517f-478c-8614-06219049b0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-c2f1874f-9298-49e4-9c29-8950ceb212e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-541c96e0-a135-4161-8aba-b9912758615e,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-4b90c26b-a6cd-4d46-b153-2ad2c5da029b,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-9b0e648d-9682-4654-9af1-83500d310b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-ab38313d-8207-48b5-ae82-c4671a3490b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-494be5d1-6e7b-480e-ada3-e3cda3492720,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-9f00168e-ccc9-4e4f-a08b-4687cac23a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725161787-172.17.0.14-1597482407264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33009,DS-59a0538c-8832-48b9-96e9-6c955e4877e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-20df5c8c-869a-4c9f-bbc0-282d53290b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-4ba57928-3a15-4954-a0ba-3daadb8220a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-b465bbaf-1079-47e8-94c8-29b5518a6060,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-07571fdd-4bea-463d-b0c5-656c8fd10c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-03b45759-33b6-48d8-8597-04246f2d1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-d34c61c0-5d19-4b0b-a5df-281e76fcf035,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-b759df6d-9cc1-4a74-adc5-ac577ba8efe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725161787-172.17.0.14-1597482407264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33009,DS-59a0538c-8832-48b9-96e9-6c955e4877e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-20df5c8c-869a-4c9f-bbc0-282d53290b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-4ba57928-3a15-4954-a0ba-3daadb8220a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-b465bbaf-1079-47e8-94c8-29b5518a6060,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-07571fdd-4bea-463d-b0c5-656c8fd10c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-03b45759-33b6-48d8-8597-04246f2d1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-d34c61c0-5d19-4b0b-a5df-281e76fcf035,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-b759df6d-9cc1-4a74-adc5-ac577ba8efe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160022681-172.17.0.14-1597482677804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42107,DS-ea741c5e-b850-4d4d-8b1e-680a66b172c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-bf15a82a-2606-4cfe-8ba5-f4b20d4e73b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-959335d1-16d7-4573-957e-0e94e4a94ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-01eef041-2169-4b6d-aea7-35078caad09f,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-5679e030-5916-44e5-9fa5-9acb7d2bad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-64002aaa-2a06-483c-b716-334f3f443203,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-d38265a3-17e3-4ba8-8194-5232b2117139,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-4cb04d27-896d-4947-bbad-ae5eeffc5818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160022681-172.17.0.14-1597482677804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42107,DS-ea741c5e-b850-4d4d-8b1e-680a66b172c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-bf15a82a-2606-4cfe-8ba5-f4b20d4e73b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-959335d1-16d7-4573-957e-0e94e4a94ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-01eef041-2169-4b6d-aea7-35078caad09f,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-5679e030-5916-44e5-9fa5-9acb7d2bad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-64002aaa-2a06-483c-b716-334f3f443203,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-d38265a3-17e3-4ba8-8194-5232b2117139,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-4cb04d27-896d-4947-bbad-ae5eeffc5818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103003292-172.17.0.14-1597482712548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-223e6587-83e4-41dd-8005-af00f4901130,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-222d9f4e-654f-4ee6-add1-08cfacc0e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-3290db35-d7ad-4f31-9a0c-2974774ffab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-cb2197a5-641d-42a0-9815-44e6f31b3078,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-46401211-d94f-4e09-9308-2751382bd3de,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-fbb2720a-ff92-4eed-91a9-a2c96c4723d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-4524d2b8-9d55-4f92-a3e6-e632bb1ff958,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-ec9bf010-542b-4a25-a858-c1519780630c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103003292-172.17.0.14-1597482712548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-223e6587-83e4-41dd-8005-af00f4901130,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-222d9f4e-654f-4ee6-add1-08cfacc0e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-3290db35-d7ad-4f31-9a0c-2974774ffab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-cb2197a5-641d-42a0-9815-44e6f31b3078,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-46401211-d94f-4e09-9308-2751382bd3de,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-fbb2720a-ff92-4eed-91a9-a2c96c4723d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-4524d2b8-9d55-4f92-a3e6-e632bb1ff958,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-ec9bf010-542b-4a25-a858-c1519780630c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787462716-172.17.0.14-1597483700794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42772,DS-96a61cb7-afe1-4777-b5b1-5f1858c50619,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-151cae32-a7a9-4232-a7d3-4c3297841098,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-a5aa3ca1-a489-4dd3-aedd-3fe4bcdfdcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-a87961f8-712f-4e69-9567-9f9d5cb9bceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-998de7fc-0861-468c-8725-39e3339d8d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-86588f14-b3b9-4d17-9459-9eb3806419c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-b002dda9-ee23-4b30-a509-530e87922ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-7b25763c-44a3-48cd-ba81-d10a1e7d3bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787462716-172.17.0.14-1597483700794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42772,DS-96a61cb7-afe1-4777-b5b1-5f1858c50619,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-151cae32-a7a9-4232-a7d3-4c3297841098,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-a5aa3ca1-a489-4dd3-aedd-3fe4bcdfdcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-a87961f8-712f-4e69-9567-9f9d5cb9bceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-998de7fc-0861-468c-8725-39e3339d8d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-86588f14-b3b9-4d17-9459-9eb3806419c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-b002dda9-ee23-4b30-a509-530e87922ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-7b25763c-44a3-48cd-ba81-d10a1e7d3bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264718093-172.17.0.14-1597483816494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-815f34d8-82bd-4565-9475-4819828855a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-5f1f50dd-0477-4c6a-a05e-23e83954fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-7d5efb1d-d14f-4722-93a5-274df2374cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-baa932e4-3438-4290-a0d8-5733f284427b,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-07c69c26-1b9c-452c-85d6-ff5fde7f3997,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-b24067a5-102b-424e-a32d-147677b1777b,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-b9a08196-47b6-425f-bf8b-7448acf07012,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-e433cb34-c5ba-4183-917c-ed8f8dd7bbf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264718093-172.17.0.14-1597483816494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-815f34d8-82bd-4565-9475-4819828855a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-5f1f50dd-0477-4c6a-a05e-23e83954fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-7d5efb1d-d14f-4722-93a5-274df2374cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-baa932e4-3438-4290-a0d8-5733f284427b,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-07c69c26-1b9c-452c-85d6-ff5fde7f3997,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-b24067a5-102b-424e-a32d-147677b1777b,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-b9a08196-47b6-425f-bf8b-7448acf07012,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-e433cb34-c5ba-4183-917c-ed8f8dd7bbf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920503613-172.17.0.14-1597484217129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-aa75982b-e489-4466-b86f-236214b00c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-5e4dde75-2ef4-4816-beef-ad6468978e33,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-deb3a03b-9fde-413c-a246-2a457a08adfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-90f20199-8983-4e1c-b690-2b6a6e9d8fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-7f35fa80-25b6-405d-a93b-3bc41ad65b26,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-218022dd-ac07-4f4f-8cf3-692e6bc2661a,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-6fd4affc-2ca8-4b80-b4e8-8b19aedeab67,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-e0f7b980-feed-48de-841a-581bd4eb7086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920503613-172.17.0.14-1597484217129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-aa75982b-e489-4466-b86f-236214b00c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-5e4dde75-2ef4-4816-beef-ad6468978e33,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-deb3a03b-9fde-413c-a246-2a457a08adfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-90f20199-8983-4e1c-b690-2b6a6e9d8fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-7f35fa80-25b6-405d-a93b-3bc41ad65b26,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-218022dd-ac07-4f4f-8cf3-692e6bc2661a,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-6fd4affc-2ca8-4b80-b4e8-8b19aedeab67,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-e0f7b980-feed-48de-841a-581bd4eb7086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880574653-172.17.0.14-1597484480250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46879,DS-6580c187-5077-468d-b9ec-5047da117f93,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-deba4954-a389-404a-9342-9a03d75dfa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-5e0d51f6-3b0f-4a3b-96bb-7d59fe090109,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-ab5d9fec-1775-4553-b831-1d78757161d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-b71c607f-a32f-4ee2-b826-46af0ace458e,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-767cc69b-db3a-4fd6-bf91-46a5c1d5f332,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-530f5e3c-9ff9-4658-92a7-e373ff09d168,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-867e7508-26f0-4ba9-932f-8f70feecf841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880574653-172.17.0.14-1597484480250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46879,DS-6580c187-5077-468d-b9ec-5047da117f93,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-deba4954-a389-404a-9342-9a03d75dfa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-5e0d51f6-3b0f-4a3b-96bb-7d59fe090109,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-ab5d9fec-1775-4553-b831-1d78757161d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-b71c607f-a32f-4ee2-b826-46af0ace458e,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-767cc69b-db3a-4fd6-bf91-46a5c1d5f332,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-530f5e3c-9ff9-4658-92a7-e373ff09d168,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-867e7508-26f0-4ba9-932f-8f70feecf841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979786755-172.17.0.14-1597484889142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-0b439b8c-40b6-4203-b7c5-4e389a38c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-d51357c4-da07-4c7d-aa84-5d60c43e3de6,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-2804d0e3-43dc-4f84-aa17-04d5bc0342e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-641a84cc-0d23-4e29-bbd1-3c5aeab7101d,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a2393ae1-7b04-4190-aa2a-a3f40a1d9476,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-d141b78f-c584-4068-9562-5703e48537d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-5b29668b-b0dc-4346-903f-8f637eaa6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-9c29e3d1-5436-4e34-a702-6cd36f4a9d72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979786755-172.17.0.14-1597484889142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39898,DS-0b439b8c-40b6-4203-b7c5-4e389a38c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-d51357c4-da07-4c7d-aa84-5d60c43e3de6,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-2804d0e3-43dc-4f84-aa17-04d5bc0342e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-641a84cc-0d23-4e29-bbd1-3c5aeab7101d,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a2393ae1-7b04-4190-aa2a-a3f40a1d9476,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-d141b78f-c584-4068-9562-5703e48537d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-5b29668b-b0dc-4346-903f-8f637eaa6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-9c29e3d1-5436-4e34-a702-6cd36f4a9d72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906248043-172.17.0.14-1597484925985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39649,DS-750bebf9-1be6-4f7b-b6a3-4a629b45c7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-a59b7803-ef80-4357-9b6c-397eb8752924,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-c191c264-2383-4c7a-9b8a-bfe8a664922e,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-6563271c-3233-47d8-a4a2-aec44cc9427a,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ffe6a540-1a18-44e1-8f62-a03ea4f7c6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-6a7a7275-d699-4de0-8bba-86d23d015010,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-5fb3e710-4778-42bb-84d1-2be77253184e,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-da528f2b-0b1b-4aaf-8367-4164597354ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906248043-172.17.0.14-1597484925985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39649,DS-750bebf9-1be6-4f7b-b6a3-4a629b45c7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-a59b7803-ef80-4357-9b6c-397eb8752924,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-c191c264-2383-4c7a-9b8a-bfe8a664922e,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-6563271c-3233-47d8-a4a2-aec44cc9427a,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ffe6a540-1a18-44e1-8f62-a03ea4f7c6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-6a7a7275-d699-4de0-8bba-86d23d015010,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-5fb3e710-4778-42bb-84d1-2be77253184e,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-da528f2b-0b1b-4aaf-8367-4164597354ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347197978-172.17.0.14-1597485044527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-53223110-69cb-4f6b-a753-53fc81f57f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-1e7b119f-0478-4bc3-a1da-045f9c89420e,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-f1d5f0f8-e3c1-4be1-9a44-77d6c3bcb633,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-ad6555f8-eb99-44dd-89f2-7674777ed519,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-3308d67e-98b2-4132-8cf9-3bb24e544caa,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-ea3a4842-93be-4397-9f68-dc91039a4847,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-f8e8e61b-5a82-4ef0-bb76-bfdf16d831de,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-3dd7150f-82ac-490b-9c81-bafd43d9f309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347197978-172.17.0.14-1597485044527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-53223110-69cb-4f6b-a753-53fc81f57f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-1e7b119f-0478-4bc3-a1da-045f9c89420e,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-f1d5f0f8-e3c1-4be1-9a44-77d6c3bcb633,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-ad6555f8-eb99-44dd-89f2-7674777ed519,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-3308d67e-98b2-4132-8cf9-3bb24e544caa,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-ea3a4842-93be-4397-9f68-dc91039a4847,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-f8e8e61b-5a82-4ef0-bb76-bfdf16d831de,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-3dd7150f-82ac-490b-9c81-bafd43d9f309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462156700-172.17.0.14-1597485599755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39401,DS-2d47d660-f68b-4f4a-a972-81fe4fbb4071,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-7ec1b746-5805-41ef-b59c-623d6cb2af35,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-f4623fd2-bcda-4d2b-bc16-24647f869d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-538eba83-6015-4d8f-b45d-f2dfc503c106,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-c49665c8-16f1-4138-9adb-008ae9ed8ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-f7dbde6a-625e-450d-b5a8-334c57eb3037,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-c6e2baa3-f5b7-4193-8e7f-bfa9afdc732a,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-8027049b-4c55-41e6-9ec1-6381c2f24533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462156700-172.17.0.14-1597485599755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39401,DS-2d47d660-f68b-4f4a-a972-81fe4fbb4071,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-7ec1b746-5805-41ef-b59c-623d6cb2af35,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-f4623fd2-bcda-4d2b-bc16-24647f869d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-538eba83-6015-4d8f-b45d-f2dfc503c106,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-c49665c8-16f1-4138-9adb-008ae9ed8ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-f7dbde6a-625e-450d-b5a8-334c57eb3037,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-c6e2baa3-f5b7-4193-8e7f-bfa9afdc732a,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-8027049b-4c55-41e6-9ec1-6381c2f24533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892700348-172.17.0.14-1597485724585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38131,DS-81228879-c6d9-43fc-b028-75e9580118da,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-41962cd7-b0fa-429f-bdd2-c515c14199aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-4aba5a6b-aa6c-4013-82b2-a4b46c73e310,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-7b20123d-ab65-4271-943c-394e36e4066b,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-3885c51f-ca7e-4b9b-b57a-6a5a9f6c3d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-8dc86695-778e-432d-973c-6210f65b731e,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-555a2512-1f3b-4421-9230-5cc53c56b8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-612a86a9-4228-433e-a207-df3add46bff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892700348-172.17.0.14-1597485724585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38131,DS-81228879-c6d9-43fc-b028-75e9580118da,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-41962cd7-b0fa-429f-bdd2-c515c14199aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-4aba5a6b-aa6c-4013-82b2-a4b46c73e310,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-7b20123d-ab65-4271-943c-394e36e4066b,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-3885c51f-ca7e-4b9b-b57a-6a5a9f6c3d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-8dc86695-778e-432d-973c-6210f65b731e,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-555a2512-1f3b-4421-9230-5cc53c56b8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-612a86a9-4228-433e-a207-df3add46bff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65996577-172.17.0.14-1597485809355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40281,DS-84869f46-8713-40b2-95f0-6bb3dd8a050d,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-fc46b493-976a-493c-ab79-97f902744bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-ab293fe8-54a9-46c5-afa0-3e807752bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-79ca4908-3ed4-4c65-a5ea-cae686d0cdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-81f592d6-922f-4e0c-8fc8-69b0d33cb550,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-3a74bb3f-804a-4915-a279-f8b6b27afef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-acb63a23-6509-435e-af87-0e0663d67e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-f84913d0-5d47-4a68-906b-3b0e4d02bb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65996577-172.17.0.14-1597485809355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40281,DS-84869f46-8713-40b2-95f0-6bb3dd8a050d,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-fc46b493-976a-493c-ab79-97f902744bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-ab293fe8-54a9-46c5-afa0-3e807752bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-79ca4908-3ed4-4c65-a5ea-cae686d0cdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-81f592d6-922f-4e0c-8fc8-69b0d33cb550,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-3a74bb3f-804a-4915-a279-f8b6b27afef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-acb63a23-6509-435e-af87-0e0663d67e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-f84913d0-5d47-4a68-906b-3b0e4d02bb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114910141-172.17.0.14-1597486199517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35100,DS-5d1842fa-8d82-4f77-a662-340847362b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-e533a7f8-02ee-4cc0-8c8e-f9ca9e7f23ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-63dfb8d1-e2d2-4a65-922e-8fb4b397db08,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-f04accba-ed7c-4c9b-b82c-289be83776de,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-3a8f8495-f5ed-4de0-8b82-a420fefd0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-4ad7f252-e707-4ddb-bf9e-3003c8e8e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-19079b13-06fd-40de-ab53-00ec7340d4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-fe84ad0d-a611-4268-acd2-ffaa1539fd55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114910141-172.17.0.14-1597486199517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35100,DS-5d1842fa-8d82-4f77-a662-340847362b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-e533a7f8-02ee-4cc0-8c8e-f9ca9e7f23ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-63dfb8d1-e2d2-4a65-922e-8fb4b397db08,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-f04accba-ed7c-4c9b-b82c-289be83776de,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-3a8f8495-f5ed-4de0-8b82-a420fefd0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-4ad7f252-e707-4ddb-bf9e-3003c8e8e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-19079b13-06fd-40de-ab53-00ec7340d4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-fe84ad0d-a611-4268-acd2-ffaa1539fd55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197615079-172.17.0.14-1597487034044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-0da1cd13-e854-4000-b292-9c8f9b648ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-0e73f0e3-f3f3-4397-8bb8-f7caf3912f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-2c7a5ae9-1e18-4490-9305-361345509008,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e20489ca-2db2-49f1-8fe3-24b0d3219584,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-76c48a58-91e6-43e6-a350-c53ceb8957c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-534a5437-dd3a-44f9-9351-b9d4165fe6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-ddb64429-5797-4de2-9a0e-0cf5c9341263,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-b24da287-45e5-40ca-9c3e-63d38c68b8f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197615079-172.17.0.14-1597487034044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-0da1cd13-e854-4000-b292-9c8f9b648ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-0e73f0e3-f3f3-4397-8bb8-f7caf3912f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-2c7a5ae9-1e18-4490-9305-361345509008,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e20489ca-2db2-49f1-8fe3-24b0d3219584,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-76c48a58-91e6-43e6-a350-c53ceb8957c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-534a5437-dd3a-44f9-9351-b9d4165fe6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-ddb64429-5797-4de2-9a0e-0cf5c9341263,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-b24da287-45e5-40ca-9c3e-63d38c68b8f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476997530-172.17.0.14-1597487141652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35557,DS-3394fcfa-9b78-4e20-a3e7-c263301a092c,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-9af8a4da-eb32-4fb9-9867-2ebc6416c283,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-f551ddeb-abb7-44bb-a0c5-3497c932eced,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-0aefaea3-e2d9-4715-bab8-642002156fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-88b9ac8b-ba09-4278-ae53-fe7079567e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-f5cd8971-e5e4-431d-884a-515297af240b,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-57dfc5a3-d427-436f-a0e5-75eae650d857,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-287cddc4-e5a3-48e2-a2ce-4e2b1ebf9c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476997530-172.17.0.14-1597487141652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35557,DS-3394fcfa-9b78-4e20-a3e7-c263301a092c,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-9af8a4da-eb32-4fb9-9867-2ebc6416c283,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-f551ddeb-abb7-44bb-a0c5-3497c932eced,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-0aefaea3-e2d9-4715-bab8-642002156fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-88b9ac8b-ba09-4278-ae53-fe7079567e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-f5cd8971-e5e4-431d-884a-515297af240b,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-57dfc5a3-d427-436f-a0e5-75eae650d857,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-287cddc4-e5a3-48e2-a2ce-4e2b1ebf9c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270967179-172.17.0.14-1597487367649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-ae1b5071-b45f-4bfa-8ba0-ded396d6ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-40c4ec77-6544-4613-a9a4-19517a455521,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-b6ae08e5-dcb6-4bd5-974d-a026d50f1dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-eaa9f800-0615-4bee-8d8b-bd559b9963aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-014e2087-f352-454c-b4d0-51568ee0c8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-4c0c18a2-f836-40aa-9c53-502f80509e58,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-1a84bf57-040d-475c-a25a-324b29d90f53,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-a3284cb8-78b1-4b86-ab6d-5368fe1f31af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270967179-172.17.0.14-1597487367649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-ae1b5071-b45f-4bfa-8ba0-ded396d6ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-40c4ec77-6544-4613-a9a4-19517a455521,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-b6ae08e5-dcb6-4bd5-974d-a026d50f1dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-eaa9f800-0615-4bee-8d8b-bd559b9963aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-014e2087-f352-454c-b4d0-51568ee0c8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-4c0c18a2-f836-40aa-9c53-502f80509e58,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-1a84bf57-040d-475c-a25a-324b29d90f53,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-a3284cb8-78b1-4b86-ab6d-5368fe1f31af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5603
