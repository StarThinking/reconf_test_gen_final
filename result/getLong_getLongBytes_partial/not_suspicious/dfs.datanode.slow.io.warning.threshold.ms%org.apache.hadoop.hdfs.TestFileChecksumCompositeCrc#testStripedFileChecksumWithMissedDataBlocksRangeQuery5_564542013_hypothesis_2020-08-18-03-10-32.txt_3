reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817105180-172.17.0.13-1597720400386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-34c5d7d1-aa28-4f1b-bcf8-0511b3993b51,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-4d82574f-e49d-49ee-8b17-b9c2794b0878,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-fed7f73d-54a6-435f-b2fe-944ccf755856,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-44e0f85a-d8b3-44cc-841f-f9a896340433,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-adf7754e-1299-4a72-acc7-2bcf6e6ec992,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-f6d223a7-48c1-47d9-8c07-439bc0f4dca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-b04b3b99-43b6-475b-bc84-a33da76b1fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-89a949d1-fde8-4885-90dd-fa6b1e68048b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817105180-172.17.0.13-1597720400386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-34c5d7d1-aa28-4f1b-bcf8-0511b3993b51,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-4d82574f-e49d-49ee-8b17-b9c2794b0878,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-fed7f73d-54a6-435f-b2fe-944ccf755856,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-44e0f85a-d8b3-44cc-841f-f9a896340433,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-adf7754e-1299-4a72-acc7-2bcf6e6ec992,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-f6d223a7-48c1-47d9-8c07-439bc0f4dca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-b04b3b99-43b6-475b-bc84-a33da76b1fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-89a949d1-fde8-4885-90dd-fa6b1e68048b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155754939-172.17.0.13-1597720891895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37189,DS-4f3459a4-c0df-4082-9705-c2e351e12bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-ef92f0d9-0ac7-4bf3-bcd4-7446aab7c788,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-4bf536d9-8de6-47b4-836a-94b1fcb30123,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-8dbf62d1-ed9c-44ff-b588-740c049abe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-0c46df5c-3797-48c4-9d2d-326e400153a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-9841516f-093e-42e9-b337-76e34296063f,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-c4d91413-d7cb-4c6c-86fa-ab54b0f2825f,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-b70a859a-281b-4dcf-aa41-6da246303b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155754939-172.17.0.13-1597720891895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37189,DS-4f3459a4-c0df-4082-9705-c2e351e12bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-ef92f0d9-0ac7-4bf3-bcd4-7446aab7c788,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-4bf536d9-8de6-47b4-836a-94b1fcb30123,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-8dbf62d1-ed9c-44ff-b588-740c049abe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-0c46df5c-3797-48c4-9d2d-326e400153a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-9841516f-093e-42e9-b337-76e34296063f,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-c4d91413-d7cb-4c6c-86fa-ab54b0f2825f,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-b70a859a-281b-4dcf-aa41-6da246303b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449331656-172.17.0.13-1597721123044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45167,DS-3eb5014b-e2ca-4838-ae82-e440ff0989f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-d5a3bd64-ecfc-45a6-859f-8833610cdf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-1547a3c0-838b-4ca5-80fb-65a6f13b2429,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-d88870b5-8597-482a-a24d-e235700178a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-f621547b-823a-441e-ad3f-496e828216e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-5345af78-81d8-4920-b9f7-93b4549b36ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-7a186564-2aa9-4abe-a9bd-9324cbb214b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-359747ec-9463-4a9a-b1f6-55e3daff9b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449331656-172.17.0.13-1597721123044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45167,DS-3eb5014b-e2ca-4838-ae82-e440ff0989f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-d5a3bd64-ecfc-45a6-859f-8833610cdf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-1547a3c0-838b-4ca5-80fb-65a6f13b2429,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-d88870b5-8597-482a-a24d-e235700178a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-f621547b-823a-441e-ad3f-496e828216e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-5345af78-81d8-4920-b9f7-93b4549b36ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-7a186564-2aa9-4abe-a9bd-9324cbb214b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-359747ec-9463-4a9a-b1f6-55e3daff9b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432348012-172.17.0.13-1597721232609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-09070460-3bfa-4615-84a9-d67f445b2d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-ddf8b363-c1b5-49f2-92d7-8be2e1bc5249,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-c1f9dda0-eb1e-4425-9529-c3671fafa14c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-e9b6ef55-4c39-4fc6-adbe-4738d620081c,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-fa842e5c-de8d-40c0-aa37-3a78f113e0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-8a83dd31-78d2-4ea5-9992-20fcab0d7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-3d5eda8d-22e0-4138-a5a2-8d07f5e148a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-14a7d0a4-4253-4154-9400-21249e850d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432348012-172.17.0.13-1597721232609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-09070460-3bfa-4615-84a9-d67f445b2d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-ddf8b363-c1b5-49f2-92d7-8be2e1bc5249,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-c1f9dda0-eb1e-4425-9529-c3671fafa14c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-e9b6ef55-4c39-4fc6-adbe-4738d620081c,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-fa842e5c-de8d-40c0-aa37-3a78f113e0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-8a83dd31-78d2-4ea5-9992-20fcab0d7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-3d5eda8d-22e0-4138-a5a2-8d07f5e148a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-14a7d0a4-4253-4154-9400-21249e850d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181112750-172.17.0.13-1597721921090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-f3f4c593-e4d4-420b-9f97-bfcb1004bb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-3f1ef086-0c1c-42b1-a665-a7e80065bfee,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-90ad0582-e98b-48eb-87a9-2e6d355e8c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-309be1b9-67e3-4a73-a89a-dc37de991b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-1f61cd03-9049-4d19-90a6-b377f96f9e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-fdbb4f00-3009-4a6c-b83b-f01d586e54db,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-0fe8f3b7-355e-4b82-8113-89f35478cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-8b656a00-d760-4ac3-8b31-480359d130d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181112750-172.17.0.13-1597721921090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-f3f4c593-e4d4-420b-9f97-bfcb1004bb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-3f1ef086-0c1c-42b1-a665-a7e80065bfee,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-90ad0582-e98b-48eb-87a9-2e6d355e8c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-309be1b9-67e3-4a73-a89a-dc37de991b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-1f61cd03-9049-4d19-90a6-b377f96f9e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-fdbb4f00-3009-4a6c-b83b-f01d586e54db,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-0fe8f3b7-355e-4b82-8113-89f35478cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-8b656a00-d760-4ac3-8b31-480359d130d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613488843-172.17.0.13-1597722218168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41896,DS-045b06f0-9d75-4846-8dcf-efcbb2c88db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-7f66701e-fab8-44ce-b7da-6d1ed5d5e1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-48af6b20-b889-48fc-b9c6-547d5b33019e,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-7258fb39-c2a8-477c-837c-ee35f6b667aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-9bc1ffd6-2934-419b-a8ef-607704d76ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-3485443a-0d55-4283-a768-405a9f500125,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-9e5161e2-5e69-4d76-b6ce-b3d38e7c662a,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-fcc34e6d-0dfe-428c-a022-c2a4bd1fe331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613488843-172.17.0.13-1597722218168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41896,DS-045b06f0-9d75-4846-8dcf-efcbb2c88db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-7f66701e-fab8-44ce-b7da-6d1ed5d5e1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-48af6b20-b889-48fc-b9c6-547d5b33019e,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-7258fb39-c2a8-477c-837c-ee35f6b667aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-9bc1ffd6-2934-419b-a8ef-607704d76ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-3485443a-0d55-4283-a768-405a9f500125,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-9e5161e2-5e69-4d76-b6ce-b3d38e7c662a,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-fcc34e6d-0dfe-428c-a022-c2a4bd1fe331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601334296-172.17.0.13-1597722287859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-09bb74e4-a795-4b0c-b2ff-da8bfdf007b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-82845410-70e5-4ae2-8e07-f4403eb6e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-9c493d9e-9926-4222-a33f-3355dbfd5633,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-9abbb72b-32ee-4a7f-8681-57838b9e3cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6ce5cb98-ae8e-4174-94a8-b6ddd1f59c00,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-659942fb-c909-4119-8960-3799612df6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-efc715a4-f68c-4e26-8ca5-36ddaa209477,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-f1980cd2-79b5-46f2-97af-d1ec6a58327a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601334296-172.17.0.13-1597722287859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42671,DS-09bb74e4-a795-4b0c-b2ff-da8bfdf007b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-82845410-70e5-4ae2-8e07-f4403eb6e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-9c493d9e-9926-4222-a33f-3355dbfd5633,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-9abbb72b-32ee-4a7f-8681-57838b9e3cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6ce5cb98-ae8e-4174-94a8-b6ddd1f59c00,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-659942fb-c909-4119-8960-3799612df6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-efc715a4-f68c-4e26-8ca5-36ddaa209477,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-f1980cd2-79b5-46f2-97af-d1ec6a58327a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239975636-172.17.0.13-1597722755462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-41daa427-1862-4faa-a94a-a1ff23d0722c,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8a827ae3-7c54-418d-871c-5fec868748ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-042e38f8-fdf4-48dd-8997-c1331629aede,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-49f7a364-904d-4935-9da2-2a9accf5d9be,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-5dc3e963-0329-4c5c-bb0e-d7fb80f107bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-8a347ada-a0c1-47b6-bdb7-985dc645d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-2763f98a-3288-4d40-a51c-f5e95888add2,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-d1512045-3baf-40a8-9567-fb3d6ecd04a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239975636-172.17.0.13-1597722755462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-41daa427-1862-4faa-a94a-a1ff23d0722c,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8a827ae3-7c54-418d-871c-5fec868748ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-042e38f8-fdf4-48dd-8997-c1331629aede,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-49f7a364-904d-4935-9da2-2a9accf5d9be,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-5dc3e963-0329-4c5c-bb0e-d7fb80f107bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-8a347ada-a0c1-47b6-bdb7-985dc645d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-2763f98a-3288-4d40-a51c-f5e95888add2,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-d1512045-3baf-40a8-9567-fb3d6ecd04a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257251568-172.17.0.13-1597722997600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38636,DS-f7c224dd-3406-4a53-9a39-3ce07b99b9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-bdf84a1c-ab6f-4d91-922e-f248529b76fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-3f315a9d-e21f-4f08-8cb5-6f1a3f4334ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-e417ba22-e5ca-4e9a-a4cc-6cb51b391985,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-9cb3b6c7-076d-4078-9b3d-0ce32c015836,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-0d05548b-ef98-47cc-9d69-67e9c48f67b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-8ef38d86-41f5-4fb1-b144-c52032f6ede0,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-9eee55f2-87e9-4594-b7b3-459dc3f204c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257251568-172.17.0.13-1597722997600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38636,DS-f7c224dd-3406-4a53-9a39-3ce07b99b9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-bdf84a1c-ab6f-4d91-922e-f248529b76fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-3f315a9d-e21f-4f08-8cb5-6f1a3f4334ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-e417ba22-e5ca-4e9a-a4cc-6cb51b391985,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-9cb3b6c7-076d-4078-9b3d-0ce32c015836,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-0d05548b-ef98-47cc-9d69-67e9c48f67b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-8ef38d86-41f5-4fb1-b144-c52032f6ede0,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-9eee55f2-87e9-4594-b7b3-459dc3f204c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994229464-172.17.0.13-1597723274828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40698,DS-8f91f080-de2f-4425-b521-546b9d7cc281,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-48c90a0e-d083-4d8b-aac4-bb76f71dcd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-1044c009-0bf8-46a0-bf95-ee4dc99d5f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-9b0eedbd-9fac-49c6-8860-8d2a4ca83bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-1f72ed58-dc8a-499a-b40f-08f987164454,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-b38c60e5-a4c0-4eab-b730-23628a5584fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-1f75e035-ef7e-438c-a6b2-db72b182b210,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-ab4ddfcf-2bb4-4c25-aa5f-442c0690335c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994229464-172.17.0.13-1597723274828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40698,DS-8f91f080-de2f-4425-b521-546b9d7cc281,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-48c90a0e-d083-4d8b-aac4-bb76f71dcd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-1044c009-0bf8-46a0-bf95-ee4dc99d5f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-9b0eedbd-9fac-49c6-8860-8d2a4ca83bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-1f72ed58-dc8a-499a-b40f-08f987164454,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-b38c60e5-a4c0-4eab-b730-23628a5584fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-1f75e035-ef7e-438c-a6b2-db72b182b210,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-ab4ddfcf-2bb4-4c25-aa5f-442c0690335c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378897068-172.17.0.13-1597723353936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-bc293648-2406-4fdd-8e6d-630f9e894136,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-2c4f51b3-e642-49a3-b427-c27b483a2a43,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-2bffa9ba-7218-4b7f-ad12-4aa55ea9987c,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-ed973864-c9a8-4515-aedf-19747e221f18,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-496662be-45bc-47cb-879b-8ac7cdaaf2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-fafd6eb7-c877-4e4f-ad9d-528d43440a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-0ddf67f5-a4b0-4c5c-be49-13b30a3e896a,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-66ff4951-a3ce-4749-b735-46e51e932882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378897068-172.17.0.13-1597723353936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-bc293648-2406-4fdd-8e6d-630f9e894136,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-2c4f51b3-e642-49a3-b427-c27b483a2a43,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-2bffa9ba-7218-4b7f-ad12-4aa55ea9987c,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-ed973864-c9a8-4515-aedf-19747e221f18,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-496662be-45bc-47cb-879b-8ac7cdaaf2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-fafd6eb7-c877-4e4f-ad9d-528d43440a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-0ddf67f5-a4b0-4c5c-be49-13b30a3e896a,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-66ff4951-a3ce-4749-b735-46e51e932882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360764325-172.17.0.13-1597723621508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-83fe1e23-faee-4466-84b0-0cd50e8bf5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-195b4cfc-1858-4d09-bd40-2fc016ca3b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-745026be-467c-41cb-ac93-0f210695ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a1edd778-4cbf-4089-84b5-4d1945052949,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-a819435a-0d9c-4513-b81d-c273b1c6f3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-ab9dcae6-b3b9-4494-b0b7-58d5fc2b704c,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-4c325711-a72b-4046-b23e-4f649b91f571,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-bc0ee934-8419-4bcc-836e-bd72722d15bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360764325-172.17.0.13-1597723621508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-83fe1e23-faee-4466-84b0-0cd50e8bf5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-195b4cfc-1858-4d09-bd40-2fc016ca3b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-745026be-467c-41cb-ac93-0f210695ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a1edd778-4cbf-4089-84b5-4d1945052949,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-a819435a-0d9c-4513-b81d-c273b1c6f3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-ab9dcae6-b3b9-4494-b0b7-58d5fc2b704c,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-4c325711-a72b-4046-b23e-4f649b91f571,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-bc0ee934-8419-4bcc-836e-bd72722d15bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914774153-172.17.0.13-1597724970590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-f5d77c27-13c5-45de-bdee-7a9b3f3925a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-0608498c-55cd-45cb-bd67-2d48762d5b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-16aae998-8fee-4ab9-b2fe-1c2b2ec95c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-d8e12bfc-d142-485e-adb1-3ee4bd74be40,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-98d827c6-2988-4c34-9f49-3d97654a171c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-ae4218ce-9764-49e7-870a-51f0af2341c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-e5c4242a-6eee-456b-99e2-3c76e5cad257,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-f64a14e9-f128-41d2-a993-69d79e3422e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914774153-172.17.0.13-1597724970590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-f5d77c27-13c5-45de-bdee-7a9b3f3925a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-0608498c-55cd-45cb-bd67-2d48762d5b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-16aae998-8fee-4ab9-b2fe-1c2b2ec95c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-d8e12bfc-d142-485e-adb1-3ee4bd74be40,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-98d827c6-2988-4c34-9f49-3d97654a171c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-ae4218ce-9764-49e7-870a-51f0af2341c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-e5c4242a-6eee-456b-99e2-3c76e5cad257,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-f64a14e9-f128-41d2-a993-69d79e3422e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680137235-172.17.0.13-1597725499539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41746,DS-03df6dce-e367-410b-b389-58229a741d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-6b78270b-a5fb-4870-8f6f-233eed76d469,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-4e12d2ec-2ada-4a5d-83fc-772653741276,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-f4a943a7-ff98-4888-b7c2-1788c1b7ebd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-48ba5a42-0051-459b-bc6d-d4dee568f156,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-239c1323-60e4-4d0b-a2cf-78c08c5c47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-b947b26b-add2-4960-9b8e-b293f79952af,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-949ce98b-7a2c-4b87-9866-72b6eab5a151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680137235-172.17.0.13-1597725499539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41746,DS-03df6dce-e367-410b-b389-58229a741d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-6b78270b-a5fb-4870-8f6f-233eed76d469,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-4e12d2ec-2ada-4a5d-83fc-772653741276,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-f4a943a7-ff98-4888-b7c2-1788c1b7ebd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-48ba5a42-0051-459b-bc6d-d4dee568f156,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-239c1323-60e4-4d0b-a2cf-78c08c5c47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-b947b26b-add2-4960-9b8e-b293f79952af,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-949ce98b-7a2c-4b87-9866-72b6eab5a151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940634396-172.17.0.13-1597725542096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35570,DS-e3cc5726-c18c-4a18-9dba-93eed1c7a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-b9076e7e-8e8d-4c14-b12b-34b60b6e6cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-fe8afc76-b15d-4d26-8783-e8ae442501c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-13834f44-8bf2-4b4e-bd92-ad17faa94734,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-a37f169a-5943-4a5b-915b-10c67e8572bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-a3d17710-3c03-46e6-9f97-6ae44e7b111b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-5ac49fab-6c74-4a59-a481-42969b4b56e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-110d24b1-cac1-4fef-a61c-1b0a1f275f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940634396-172.17.0.13-1597725542096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35570,DS-e3cc5726-c18c-4a18-9dba-93eed1c7a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-b9076e7e-8e8d-4c14-b12b-34b60b6e6cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-fe8afc76-b15d-4d26-8783-e8ae442501c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-13834f44-8bf2-4b4e-bd92-ad17faa94734,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-a37f169a-5943-4a5b-915b-10c67e8572bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-a3d17710-3c03-46e6-9f97-6ae44e7b111b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-5ac49fab-6c74-4a59-a481-42969b4b56e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-110d24b1-cac1-4fef-a61c-1b0a1f275f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006454041-172.17.0.13-1597725866568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40334,DS-23d24697-3cbe-4c30-97d4-86eb5876fd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-e541794a-1c99-48da-af77-ea9029bbba78,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-d684a846-928d-4042-af64-c4d74cfecc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-fdcb72d6-5740-4e52-9c9d-72112df42e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-a9396020-0e9b-44e4-9fe2-7cf07746f460,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-612906b5-9e15-4dac-8bc0-babe300fd46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-80030540-5d3c-4d50-9c9a-058708aae9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-782d2108-59f9-45ac-bd17-592b24bbc3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006454041-172.17.0.13-1597725866568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40334,DS-23d24697-3cbe-4c30-97d4-86eb5876fd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-e541794a-1c99-48da-af77-ea9029bbba78,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-d684a846-928d-4042-af64-c4d74cfecc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-fdcb72d6-5740-4e52-9c9d-72112df42e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-a9396020-0e9b-44e4-9fe2-7cf07746f460,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-612906b5-9e15-4dac-8bc0-babe300fd46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-80030540-5d3c-4d50-9c9a-058708aae9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-782d2108-59f9-45ac-bd17-592b24bbc3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5762
