reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091504068-172.17.0.2-1597677641838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-bf256275-3276-4581-8497-d1079f06dda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-31bcbc22-e99a-4ef3-8788-5537fbe862e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-61e78251-fe9f-4fb7-ba67-a5b5c57b3b28,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-10e8a7a2-dfe8-4185-bf42-ee88c8d3bc36,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-17e184b1-1c63-4de4-870b-fc8c2c999464,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-a27ef2bf-5f18-46c8-940d-e5749227242a,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-054c350c-ba1b-4159-859d-807063707bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-dd0c27aa-e893-41d0-aa6c-7ac6e2bfcace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091504068-172.17.0.2-1597677641838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-bf256275-3276-4581-8497-d1079f06dda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-31bcbc22-e99a-4ef3-8788-5537fbe862e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-61e78251-fe9f-4fb7-ba67-a5b5c57b3b28,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-10e8a7a2-dfe8-4185-bf42-ee88c8d3bc36,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-17e184b1-1c63-4de4-870b-fc8c2c999464,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-a27ef2bf-5f18-46c8-940d-e5749227242a,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-054c350c-ba1b-4159-859d-807063707bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-dd0c27aa-e893-41d0-aa6c-7ac6e2bfcace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673971601-172.17.0.2-1597677673591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-6ae784ab-104e-43da-91c9-8a8bcfd9d8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-42822f6e-6bf9-4b1c-aa34-81053abf9c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-32d852a1-7ce2-47d1-9609-e397afa82bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-743e6cf6-4747-419b-87f6-742780b9bdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-316e796f-d3f1-4de0-9718-5c0d176f2fda,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-a60c3e7d-162e-4b40-b958-1456931f2422,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-19a5365d-526e-4ddd-ae03-0d4b1af4a9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-9850301b-c4da-401d-822b-f354f27b8af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673971601-172.17.0.2-1597677673591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-6ae784ab-104e-43da-91c9-8a8bcfd9d8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-42822f6e-6bf9-4b1c-aa34-81053abf9c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-32d852a1-7ce2-47d1-9609-e397afa82bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-743e6cf6-4747-419b-87f6-742780b9bdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-316e796f-d3f1-4de0-9718-5c0d176f2fda,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-a60c3e7d-162e-4b40-b958-1456931f2422,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-19a5365d-526e-4ddd-ae03-0d4b1af4a9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-9850301b-c4da-401d-822b-f354f27b8af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968674919-172.17.0.2-1597678343339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41322,DS-2fb0e5a2-f53a-461a-9005-6fb02d3360fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-de6dc726-470b-479c-8615-2ca010c9035c,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-dc989054-5f6b-475e-b896-cb663b22a557,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-ce4a3a38-a4ac-4d64-a8b2-83ce439a2a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-42eb17ff-460f-4d63-a806-df492010ed51,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-1577faf9-5e5a-415c-849b-c428df168bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-5491dbdb-e8ab-472b-bff4-8eda850dccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-4fe96e87-aa0f-4aa6-b675-0e8e718efc1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968674919-172.17.0.2-1597678343339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41322,DS-2fb0e5a2-f53a-461a-9005-6fb02d3360fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-de6dc726-470b-479c-8615-2ca010c9035c,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-dc989054-5f6b-475e-b896-cb663b22a557,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-ce4a3a38-a4ac-4d64-a8b2-83ce439a2a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-42eb17ff-460f-4d63-a806-df492010ed51,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-1577faf9-5e5a-415c-849b-c428df168bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-5491dbdb-e8ab-472b-bff4-8eda850dccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-4fe96e87-aa0f-4aa6-b675-0e8e718efc1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157482722-172.17.0.2-1597678712327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41294,DS-6158a335-f430-41a3-acef-7596b7af9e94,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-5e750633-b5ee-4ada-a44d-acc78143f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-ce917fdf-7a5a-49a2-a6a9-fd388c24a583,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-5bb63d13-f9ba-46be-900d-da22a89bf0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-83bc393a-dced-485e-bab1-a8dd7da261b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-94927709-2fd9-4d76-8c99-129a4b6e4990,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-5e79db6f-32a3-4f6a-8104-0583f1da5295,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-e7f315f1-eeb7-4434-9da0-649135c51d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157482722-172.17.0.2-1597678712327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41294,DS-6158a335-f430-41a3-acef-7596b7af9e94,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-5e750633-b5ee-4ada-a44d-acc78143f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-ce917fdf-7a5a-49a2-a6a9-fd388c24a583,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-5bb63d13-f9ba-46be-900d-da22a89bf0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-83bc393a-dced-485e-bab1-a8dd7da261b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-94927709-2fd9-4d76-8c99-129a4b6e4990,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-5e79db6f-32a3-4f6a-8104-0583f1da5295,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-e7f315f1-eeb7-4434-9da0-649135c51d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422414557-172.17.0.2-1597678931276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-6e55c21d-66dc-4161-a421-b2fa36f7d4af,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-ed981501-a82d-456d-a45c-4e049cffc3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-6202b692-9c91-4873-a251-1e8516d2fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-8f319ca5-aae9-4089-a01f-cba7d78bb523,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-8715aaca-4750-41db-bc17-4a9309152d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-ad2ba6f9-6b27-40a5-a56a-9bdb50a049a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-6b14b34b-59e9-415f-ad57-802e7bb0f338,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-c98430ad-e7d8-4247-817e-3758ee6cf83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422414557-172.17.0.2-1597678931276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-6e55c21d-66dc-4161-a421-b2fa36f7d4af,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-ed981501-a82d-456d-a45c-4e049cffc3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-6202b692-9c91-4873-a251-1e8516d2fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-8f319ca5-aae9-4089-a01f-cba7d78bb523,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-8715aaca-4750-41db-bc17-4a9309152d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-ad2ba6f9-6b27-40a5-a56a-9bdb50a049a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-6b14b34b-59e9-415f-ad57-802e7bb0f338,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-c98430ad-e7d8-4247-817e-3758ee6cf83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739535908-172.17.0.2-1597678998912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37951,DS-043a9789-d89f-483a-a058-e0e7827d967b,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-5ca21cb4-8a0e-43bf-8404-4f61e33f887d,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-7e39ec18-41a4-4df7-adc3-daf86f2971dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-2bd4cee2-8832-4ed5-bab4-3f2b1e3e3e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-8e195303-b6ae-4a83-8128-bf4c045445b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-7a8cc686-922c-4559-b670-20d6129394b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-784ae2e0-cbc3-4c8b-a95e-78648b2b0bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-c981bf12-ae75-4925-b394-ecc8dc3ba42b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739535908-172.17.0.2-1597678998912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37951,DS-043a9789-d89f-483a-a058-e0e7827d967b,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-5ca21cb4-8a0e-43bf-8404-4f61e33f887d,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-7e39ec18-41a4-4df7-adc3-daf86f2971dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-2bd4cee2-8832-4ed5-bab4-3f2b1e3e3e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-8e195303-b6ae-4a83-8128-bf4c045445b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-7a8cc686-922c-4559-b670-20d6129394b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-784ae2e0-cbc3-4c8b-a95e-78648b2b0bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-c981bf12-ae75-4925-b394-ecc8dc3ba42b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735479384-172.17.0.2-1597680582303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35322,DS-6ef8f9ce-de84-4966-ac26-093930b66dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-99a0af0c-43f9-481b-9fb8-23ed532e65b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-98996c7c-87f0-4f30-ac80-044f6e642919,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-0f163290-92d7-4fcb-a361-c6a99798e309,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-665d804f-a94e-48f8-8f38-03be632e4310,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-cd217189-6653-4c8c-ab5e-fe6c16589b44,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-b1ce7f53-ffb4-42d6-9df6-02b1a52e993f,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-1fa6c878-3776-4074-80c2-529485be558e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735479384-172.17.0.2-1597680582303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35322,DS-6ef8f9ce-de84-4966-ac26-093930b66dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-99a0af0c-43f9-481b-9fb8-23ed532e65b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-98996c7c-87f0-4f30-ac80-044f6e642919,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-0f163290-92d7-4fcb-a361-c6a99798e309,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-665d804f-a94e-48f8-8f38-03be632e4310,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-cd217189-6653-4c8c-ab5e-fe6c16589b44,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-b1ce7f53-ffb4-42d6-9df6-02b1a52e993f,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-1fa6c878-3776-4074-80c2-529485be558e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117281620-172.17.0.2-1597680778698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36259,DS-b2f1c21b-930b-4752-93f9-c42528c60c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-c19f69f7-afa9-45cf-baff-ec745c4ba196,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-778ab368-4a57-4bbe-ba1d-5714605e0627,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-7a60dcac-5390-4093-8cec-98116c8af0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-0ed64568-ed64-4229-9ab7-24185c7cf015,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-8a1b43d7-bf1b-4d9f-8cba-3bb15f3288d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-19e4e5e1-2827-4c86-bd73-be0fff64b282,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-0a619a8d-d47d-4a1a-b36d-599cd4d73056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117281620-172.17.0.2-1597680778698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36259,DS-b2f1c21b-930b-4752-93f9-c42528c60c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-c19f69f7-afa9-45cf-baff-ec745c4ba196,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-778ab368-4a57-4bbe-ba1d-5714605e0627,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-7a60dcac-5390-4093-8cec-98116c8af0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-0ed64568-ed64-4229-9ab7-24185c7cf015,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-8a1b43d7-bf1b-4d9f-8cba-3bb15f3288d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-19e4e5e1-2827-4c86-bd73-be0fff64b282,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-0a619a8d-d47d-4a1a-b36d-599cd4d73056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856795151-172.17.0.2-1597681027268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-7c0078ca-5e80-44b4-80cb-074efe16268f,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-e5509cf1-b3c8-47c9-aaff-2e535a212f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-ebb204bc-fffa-42e7-a36c-105ad4c87a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-d68977d0-8961-42e4-908e-886e333cb153,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-39dd22a4-ff29-4a87-8291-f98cc85fc0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-eca94395-d643-414c-9619-b8e6d45b288f,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-ec7c15ff-76f0-45c1-9ca8-e96b0a5cd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-69ae23c6-8073-4849-9445-696f919bf25c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856795151-172.17.0.2-1597681027268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-7c0078ca-5e80-44b4-80cb-074efe16268f,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-e5509cf1-b3c8-47c9-aaff-2e535a212f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-ebb204bc-fffa-42e7-a36c-105ad4c87a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-d68977d0-8961-42e4-908e-886e333cb153,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-39dd22a4-ff29-4a87-8291-f98cc85fc0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-eca94395-d643-414c-9619-b8e6d45b288f,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-ec7c15ff-76f0-45c1-9ca8-e96b0a5cd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-69ae23c6-8073-4849-9445-696f919bf25c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396840845-172.17.0.2-1597681065160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-b19e498b-33f3-4da0-9b9e-1c2dbf868bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-5b5d7bfd-4e85-4e04-a6d8-ea622fa8cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-f28e4b86-2f7f-4adc-a0dd-efaf746cd1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-cd4ae03e-5609-41fb-a179-3e5a3d095878,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-e8f776ca-9519-42fd-bb6c-2dbfe4543ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-0826d1de-e824-4d97-94e8-87034c1e8320,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-8b2aedf1-1026-4060-9501-2f5b70ba4522,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-42888c54-ad43-4875-8799-f8b6eb11f950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396840845-172.17.0.2-1597681065160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-b19e498b-33f3-4da0-9b9e-1c2dbf868bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-5b5d7bfd-4e85-4e04-a6d8-ea622fa8cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-f28e4b86-2f7f-4adc-a0dd-efaf746cd1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-cd4ae03e-5609-41fb-a179-3e5a3d095878,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-e8f776ca-9519-42fd-bb6c-2dbfe4543ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-0826d1de-e824-4d97-94e8-87034c1e8320,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-8b2aedf1-1026-4060-9501-2f5b70ba4522,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-42888c54-ad43-4875-8799-f8b6eb11f950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951138444-172.17.0.2-1597681418506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41788,DS-0ec051ee-d65f-4269-a4d0-bd86b04ce210,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-2e2b027f-942f-4422-9d9a-f369089b4377,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-804d835f-2ed9-464e-9fd5-1cdca5c67ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-e2acd9fc-bbb3-429e-a446-4b909e449f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-9eba8cce-8c24-4d37-afa1-ab988947876d,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-40161934-f1be-4878-b04c-04d51a61144d,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-677bbd7b-06f3-4c5c-a861-f085e5d7e626,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-9965c80e-8e5f-4767-95b0-7e00fc2272dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951138444-172.17.0.2-1597681418506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41788,DS-0ec051ee-d65f-4269-a4d0-bd86b04ce210,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-2e2b027f-942f-4422-9d9a-f369089b4377,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-804d835f-2ed9-464e-9fd5-1cdca5c67ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-e2acd9fc-bbb3-429e-a446-4b909e449f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-9eba8cce-8c24-4d37-afa1-ab988947876d,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-40161934-f1be-4878-b04c-04d51a61144d,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-677bbd7b-06f3-4c5c-a861-f085e5d7e626,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-9965c80e-8e5f-4767-95b0-7e00fc2272dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561279464-172.17.0.2-1597681497228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35835,DS-7a23b07d-2da4-4333-97e8-5b73910c1b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-910b9ff0-e3a8-4ceb-aaca-7e57d6106f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-3cb8bcd2-be99-40e6-b69a-81460bfb5fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-abd4b2e8-b71d-47a3-8948-cdbf52a106b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-947d232a-18dd-4eee-b86e-0b3912c7a1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-8fc1b224-18b2-4acb-b449-98d6535a4ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-2576f826-0adb-4381-a8bf-424820e91740,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-9f665620-ff1b-4619-9361-8b9ec4df792d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561279464-172.17.0.2-1597681497228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35835,DS-7a23b07d-2da4-4333-97e8-5b73910c1b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-910b9ff0-e3a8-4ceb-aaca-7e57d6106f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-3cb8bcd2-be99-40e6-b69a-81460bfb5fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-abd4b2e8-b71d-47a3-8948-cdbf52a106b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-947d232a-18dd-4eee-b86e-0b3912c7a1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-8fc1b224-18b2-4acb-b449-98d6535a4ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-2576f826-0adb-4381-a8bf-424820e91740,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-9f665620-ff1b-4619-9361-8b9ec4df792d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852354548-172.17.0.2-1597681775400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-cc359930-702d-4f3c-a2f8-ce1a0ddfc3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-bee82d6a-fe3e-44e0-a00d-cc7a69625f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-fb07ab10-586f-4fb1-bc20-994bf0abf0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-2b4730aa-3c6d-449c-8ed3-40d39c9315da,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-eba6d9e8-67ff-4c5a-be8b-a71e82f057ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-518e9773-9ab4-417f-b04c-ce9e745c8512,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-fb7b8d07-5867-426d-b13c-a98bab7a827e,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-9f606f13-c8f8-4288-8291-fd279a157b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852354548-172.17.0.2-1597681775400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-cc359930-702d-4f3c-a2f8-ce1a0ddfc3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-bee82d6a-fe3e-44e0-a00d-cc7a69625f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-fb07ab10-586f-4fb1-bc20-994bf0abf0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-2b4730aa-3c6d-449c-8ed3-40d39c9315da,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-eba6d9e8-67ff-4c5a-be8b-a71e82f057ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-518e9773-9ab4-417f-b04c-ce9e745c8512,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-fb7b8d07-5867-426d-b13c-a98bab7a827e,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-9f606f13-c8f8-4288-8291-fd279a157b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110325501-172.17.0.2-1597682198237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-21809adf-a62b-4380-a39a-05048f7f14aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-007cf36d-dcc2-4978-9258-65f96b9f1939,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-115a9184-d7f0-44a9-8921-1df848471ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-90f7799b-78ed-4354-a92c-ad3fd8090493,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-19679bc4-1aa3-44e7-9051-e88be95e52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-b79cf2eb-52c8-484a-afad-057f88ea9682,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-2631eed2-5499-4421-8d48-ffcdf22f8796,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-479f1d97-ed50-4b9c-9a84-0146470c799e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110325501-172.17.0.2-1597682198237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-21809adf-a62b-4380-a39a-05048f7f14aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-007cf36d-dcc2-4978-9258-65f96b9f1939,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-115a9184-d7f0-44a9-8921-1df848471ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-90f7799b-78ed-4354-a92c-ad3fd8090493,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-19679bc4-1aa3-44e7-9051-e88be95e52a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-b79cf2eb-52c8-484a-afad-057f88ea9682,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-2631eed2-5499-4421-8d48-ffcdf22f8796,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-479f1d97-ed50-4b9c-9a84-0146470c799e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032783060-172.17.0.2-1597682687422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-b65580d1-2f29-4b7f-8136-7e2774da87bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-be945309-2d5c-43a3-9a7b-cbc6821847bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-0f5c1372-9bf2-4033-9319-5c5608ad228a,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-d83c85d9-244b-4f34-9e14-7a6594be3082,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-c78db439-9096-43b5-88e5-f4dee9469920,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-af47ac84-6ece-4a82-8bb5-81060532b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-c94579e7-1f02-421a-9244-ac05a3e55c60,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-2aef37e8-bc02-4ee7-8f8f-e2983aa49145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032783060-172.17.0.2-1597682687422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-b65580d1-2f29-4b7f-8136-7e2774da87bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-be945309-2d5c-43a3-9a7b-cbc6821847bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-0f5c1372-9bf2-4033-9319-5c5608ad228a,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-d83c85d9-244b-4f34-9e14-7a6594be3082,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-c78db439-9096-43b5-88e5-f4dee9469920,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-af47ac84-6ece-4a82-8bb5-81060532b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-c94579e7-1f02-421a-9244-ac05a3e55c60,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-2aef37e8-bc02-4ee7-8f8f-e2983aa49145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020050226-172.17.0.2-1597682984221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36297,DS-e869d126-bb1c-42e6-9813-64d78dda3da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-e1ab75fc-8a9c-4d2d-a9bc-b929cf221851,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-5b5e8616-3e2d-4ee2-92dd-fb8ce7cb12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-ad0b8381-c035-4342-975e-4a26bac3de52,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-b373d292-dc15-483e-915a-f165a03c7382,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-08464596-fbf2-43e6-a79c-498b1dc6223e,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-8af55893-adc1-4c9e-89ba-2a8c6f27bc04,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-7b4aff72-f79b-4d76-a02f-639f57f0d078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020050226-172.17.0.2-1597682984221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36297,DS-e869d126-bb1c-42e6-9813-64d78dda3da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-e1ab75fc-8a9c-4d2d-a9bc-b929cf221851,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-5b5e8616-3e2d-4ee2-92dd-fb8ce7cb12bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-ad0b8381-c035-4342-975e-4a26bac3de52,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-b373d292-dc15-483e-915a-f165a03c7382,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-08464596-fbf2-43e6-a79c-498b1dc6223e,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-8af55893-adc1-4c9e-89ba-2a8c6f27bc04,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-7b4aff72-f79b-4d76-a02f-639f57f0d078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948253091-172.17.0.2-1597683021084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-be32e6dd-9c66-4882-8b04-b6012e73894c,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-749afa1e-c007-4c54-9f64-f4b8ef474850,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-cc1d399e-39bb-45c3-aa10-ea9f83c2240c,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a7023d0d-f313-49fe-b1bf-5666aea24b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-d5c46342-9397-45f0-9350-15a00b88fb60,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-810f676a-0df6-4773-afad-dc31cddfc472,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-e3769efc-ad28-470d-8290-3f4e440fc402,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-057a5448-4599-4ef2-8f6d-d376920fbf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948253091-172.17.0.2-1597683021084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-be32e6dd-9c66-4882-8b04-b6012e73894c,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-749afa1e-c007-4c54-9f64-f4b8ef474850,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-cc1d399e-39bb-45c3-aa10-ea9f83c2240c,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a7023d0d-f313-49fe-b1bf-5666aea24b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-d5c46342-9397-45f0-9350-15a00b88fb60,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-810f676a-0df6-4773-afad-dc31cddfc472,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-e3769efc-ad28-470d-8290-3f4e440fc402,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-057a5448-4599-4ef2-8f6d-d376920fbf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5583
