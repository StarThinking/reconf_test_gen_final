reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443398604-172.17.0.21-1597400350123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-d7de29cd-7ca9-408a-a234-b26d4a8c335d,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-584fefc0-826c-4993-8be7-9cb90ff814bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-8d1fdb3d-8213-4654-8f63-df52307907af,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-8e043f18-af11-4d49-b75b-a49d23b71337,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-af95d615-f03e-40c6-bece-72cbafc6c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-7da078ae-cb84-4d26-b29a-5a73dfacc0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-c4763065-7452-451a-9556-2bf243c1f504,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-3b8f712b-54e3-4fac-8529-d217e2c67502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443398604-172.17.0.21-1597400350123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-d7de29cd-7ca9-408a-a234-b26d4a8c335d,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-584fefc0-826c-4993-8be7-9cb90ff814bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-8d1fdb3d-8213-4654-8f63-df52307907af,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-8e043f18-af11-4d49-b75b-a49d23b71337,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-af95d615-f03e-40c6-bece-72cbafc6c76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-7da078ae-cb84-4d26-b29a-5a73dfacc0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-c4763065-7452-451a-9556-2bf243c1f504,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-3b8f712b-54e3-4fac-8529-d217e2c67502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706836603-172.17.0.21-1597400762928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39845,DS-d56f61ef-1822-4233-a923-24d1b2daf23e,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-362d7817-81ea-4118-a429-218452b52af5,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-1efb9aac-25af-43ce-9e71-0f08a8ae5f81,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-5483eb5f-3536-49b3-a690-3dabd15bf566,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-ea7e8be0-b1c1-4953-a2ac-29551348e19c,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-80a1a6c5-7a05-4109-9a5c-b35a47c2f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-fcb7dcf4-71fe-4999-aee0-af39df3ec2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-6e65f26a-4f80-4295-b200-3cc3767b2f26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706836603-172.17.0.21-1597400762928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39845,DS-d56f61ef-1822-4233-a923-24d1b2daf23e,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-362d7817-81ea-4118-a429-218452b52af5,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-1efb9aac-25af-43ce-9e71-0f08a8ae5f81,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-5483eb5f-3536-49b3-a690-3dabd15bf566,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-ea7e8be0-b1c1-4953-a2ac-29551348e19c,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-80a1a6c5-7a05-4109-9a5c-b35a47c2f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-fcb7dcf4-71fe-4999-aee0-af39df3ec2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-6e65f26a-4f80-4295-b200-3cc3767b2f26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467900140-172.17.0.21-1597400900401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42350,DS-3aa899f4-1889-4aff-bd0a-4c7cd82f8e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-5c9a8967-70f1-4ce8-bd8e-f101a57e9563,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-fd0a6372-9d65-4d72-bb10-ec191feff014,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-23499c97-1907-4b3f-b24a-e391442cf7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-ac581867-eca4-4142-9e79-5a14802cee53,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-25cc807e-aea9-47c3-a76f-d8e085d21f41,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-af5d1b19-dad7-448b-bb59-aaded0209d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-c2bb5a52-6346-4786-b6f5-ef3517657191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467900140-172.17.0.21-1597400900401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42350,DS-3aa899f4-1889-4aff-bd0a-4c7cd82f8e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-5c9a8967-70f1-4ce8-bd8e-f101a57e9563,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-fd0a6372-9d65-4d72-bb10-ec191feff014,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-23499c97-1907-4b3f-b24a-e391442cf7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-ac581867-eca4-4142-9e79-5a14802cee53,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-25cc807e-aea9-47c3-a76f-d8e085d21f41,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-af5d1b19-dad7-448b-bb59-aaded0209d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-c2bb5a52-6346-4786-b6f5-ef3517657191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898030596-172.17.0.21-1597400943055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35735,DS-fd9cae07-b20a-4158-910e-f9d88ca8d416,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-959db0e6-8931-42e4-a7bb-3073caf95e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-5b77121d-784e-4fa8-9b0d-432df1e91d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-0dfbb2d9-c6bf-476c-9fed-7e5d901e19cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-4070dafa-6963-4e40-9d1f-578fb2a670b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-872db7be-70e4-49a8-a288-b65d3cdf940d,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-ebc08746-8c2f-4d4a-b844-81497757a979,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-b9997845-2798-4188-9a29-0d1f00a639bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898030596-172.17.0.21-1597400943055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35735,DS-fd9cae07-b20a-4158-910e-f9d88ca8d416,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-959db0e6-8931-42e4-a7bb-3073caf95e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-5b77121d-784e-4fa8-9b0d-432df1e91d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-0dfbb2d9-c6bf-476c-9fed-7e5d901e19cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-4070dafa-6963-4e40-9d1f-578fb2a670b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-872db7be-70e4-49a8-a288-b65d3cdf940d,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-ebc08746-8c2f-4d4a-b844-81497757a979,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-b9997845-2798-4188-9a29-0d1f00a639bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771770611-172.17.0.21-1597401125144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-3ce2a0fb-6d83-419e-a268-737eaad6d155,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-7a85dbfd-2d68-4fb6-bdd3-ec280133833a,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-9404a86f-e5b7-468b-8ab9-f857f36faad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-5501b155-763c-47fb-9242-fdfe00c6641f,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-a977c939-c72b-47e2-b9c2-4e91f60609d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-9bbaf7dc-e270-4be8-a14d-1154e9024adf,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-68592339-9238-4037-8c82-a7f9afbd511f,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-59c314dc-dff8-4c5f-b6a6-e574e32c8d42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771770611-172.17.0.21-1597401125144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-3ce2a0fb-6d83-419e-a268-737eaad6d155,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-7a85dbfd-2d68-4fb6-bdd3-ec280133833a,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-9404a86f-e5b7-468b-8ab9-f857f36faad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-5501b155-763c-47fb-9242-fdfe00c6641f,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-a977c939-c72b-47e2-b9c2-4e91f60609d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-9bbaf7dc-e270-4be8-a14d-1154e9024adf,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-68592339-9238-4037-8c82-a7f9afbd511f,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-59c314dc-dff8-4c5f-b6a6-e574e32c8d42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989739271-172.17.0.21-1597401430316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44644,DS-6d2cfb83-1dd1-4ac1-9290-279fc216a04a,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-1cec91d0-399a-4039-af04-d1d123c2e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-3f3b0d48-c7b1-4389-bf2a-7a087ffd7415,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-f78b7525-f94b-46e3-b368-45b425a03f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-57aba62e-50cc-4eba-b62a-eeae47ea70c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-6e952767-9f5f-47cc-9082-73e0d6c8c484,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-7619007a-fa6e-4751-80de-415d8434fa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-66f181ef-3341-4560-8988-d2d1c6c894c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989739271-172.17.0.21-1597401430316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44644,DS-6d2cfb83-1dd1-4ac1-9290-279fc216a04a,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-1cec91d0-399a-4039-af04-d1d123c2e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-3f3b0d48-c7b1-4389-bf2a-7a087ffd7415,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-f78b7525-f94b-46e3-b368-45b425a03f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-57aba62e-50cc-4eba-b62a-eeae47ea70c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-6e952767-9f5f-47cc-9082-73e0d6c8c484,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-7619007a-fa6e-4751-80de-415d8434fa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-66f181ef-3341-4560-8988-d2d1c6c894c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253490746-172.17.0.21-1597401777116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43124,DS-4e7dcc35-8892-4931-a6bd-80b4e8bd6a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-f6f9b336-47e6-4dec-b958-16ea02664e23,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-f30f4308-2e98-47cf-84bc-4fd0d7717be8,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-12113fee-e166-411d-b55d-c1cefcc6759c,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-13b0b9aa-0375-4710-9105-0a46416d7d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-27c1704b-7e93-4a45-b5e5-fc957340a034,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-fd05a2a4-18f3-4612-aa10-a88cf394007b,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-7df47b06-07db-4816-8577-154de8f04465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253490746-172.17.0.21-1597401777116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43124,DS-4e7dcc35-8892-4931-a6bd-80b4e8bd6a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-f6f9b336-47e6-4dec-b958-16ea02664e23,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-f30f4308-2e98-47cf-84bc-4fd0d7717be8,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-12113fee-e166-411d-b55d-c1cefcc6759c,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-13b0b9aa-0375-4710-9105-0a46416d7d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-27c1704b-7e93-4a45-b5e5-fc957340a034,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-fd05a2a4-18f3-4612-aa10-a88cf394007b,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-7df47b06-07db-4816-8577-154de8f04465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960764387-172.17.0.21-1597402123084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-ddc100c4-91d7-400a-8c00-6d39f705937c,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-ee9e2ffb-3efa-4147-986d-6d1ed2594793,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-a432704f-a11f-4d34-813e-93abf51d40f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-65f68c9c-a449-4b6f-ae57-2da2d06915b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-35b92c31-645e-403d-8f1f-130bd25daf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-78599faf-5aac-43be-8978-71cd8b778228,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-c70c416b-3f83-48e0-a2de-7d92d80d179c,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-b286ceb6-a276-4b90-a991-e2927e0420f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960764387-172.17.0.21-1597402123084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-ddc100c4-91d7-400a-8c00-6d39f705937c,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-ee9e2ffb-3efa-4147-986d-6d1ed2594793,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-a432704f-a11f-4d34-813e-93abf51d40f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-65f68c9c-a449-4b6f-ae57-2da2d06915b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-35b92c31-645e-403d-8f1f-130bd25daf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-78599faf-5aac-43be-8978-71cd8b778228,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-c70c416b-3f83-48e0-a2de-7d92d80d179c,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-b286ceb6-a276-4b90-a991-e2927e0420f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1820489755-172.17.0.21-1597402608564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-8937038a-d41c-4f2d-853c-65e561178637,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-08eb1c2f-15af-4768-b1bb-acff80f01da1,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-200ffe35-0471-43a0-a7ae-deb8e679d253,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-50b2b34a-406f-411f-908e-e2e53a2453a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-868e0a2e-cf6f-40b0-8ce5-f339f8ec3180,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-49cce295-ce0a-4d5e-a8da-d15f2197edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-be6ec8a8-0988-4801-b7fd-52c4d80c1281,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-e28c0947-4d69-4665-a6b1-43286092f31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1820489755-172.17.0.21-1597402608564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-8937038a-d41c-4f2d-853c-65e561178637,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-08eb1c2f-15af-4768-b1bb-acff80f01da1,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-200ffe35-0471-43a0-a7ae-deb8e679d253,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-50b2b34a-406f-411f-908e-e2e53a2453a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-868e0a2e-cf6f-40b0-8ce5-f339f8ec3180,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-49cce295-ce0a-4d5e-a8da-d15f2197edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-be6ec8a8-0988-4801-b7fd-52c4d80c1281,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-e28c0947-4d69-4665-a6b1-43286092f31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645404924-172.17.0.21-1597402786511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-8bf66acd-783c-4f8f-92d9-38f40a91e861,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-62d0b172-796c-4621-ae4b-051dd5403ced,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-0115ae32-e2cc-4027-8899-82caeaa097d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-ce96ebdc-720f-4fb2-85e7-c2e090480ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-04552623-eaa4-4c13-ba17-8a08e7ed6773,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-779d40bb-8949-4cf8-b888-f19238cb093d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-0e880a64-bbea-4623-a430-f6151395693c,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-ac0eaa87-c71a-48a4-9d08-b1a15812ede7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645404924-172.17.0.21-1597402786511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-8bf66acd-783c-4f8f-92d9-38f40a91e861,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-62d0b172-796c-4621-ae4b-051dd5403ced,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-0115ae32-e2cc-4027-8899-82caeaa097d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-ce96ebdc-720f-4fb2-85e7-c2e090480ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-04552623-eaa4-4c13-ba17-8a08e7ed6773,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-779d40bb-8949-4cf8-b888-f19238cb093d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-0e880a64-bbea-4623-a430-f6151395693c,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-ac0eaa87-c71a-48a4-9d08-b1a15812ede7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234668309-172.17.0.21-1597403002743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-651b745b-1bf5-49d6-9c40-079df314ccda,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-74d9e9be-8dc6-40a9-88cc-f6bddabd366f,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-87ca754d-9700-4c4f-a9bb-6fbe3c3b5107,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-d8e11b36-ffcc-410f-93cb-693c7bfa253f,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-bcc9592d-29e0-400c-8c08-11268c302900,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-fcb26eff-fd1d-45ac-b6a1-81b37794f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-a43206b7-fe1e-4147-82b7-42df91d02479,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-ec0ee4c4-ed10-4316-9229-b7e0d6b65476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234668309-172.17.0.21-1597403002743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-651b745b-1bf5-49d6-9c40-079df314ccda,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-74d9e9be-8dc6-40a9-88cc-f6bddabd366f,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-87ca754d-9700-4c4f-a9bb-6fbe3c3b5107,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-d8e11b36-ffcc-410f-93cb-693c7bfa253f,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-bcc9592d-29e0-400c-8c08-11268c302900,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-fcb26eff-fd1d-45ac-b6a1-81b37794f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-a43206b7-fe1e-4147-82b7-42df91d02479,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-ec0ee4c4-ed10-4316-9229-b7e0d6b65476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319528094-172.17.0.21-1597403120388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-025d1435-d9c1-4f4a-bb9e-aff80cf00df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-25886cf7-bdd2-4425-b78d-798f07892a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-97184008-9004-43b9-a230-96609f8db541,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-c41616df-fe7e-40a2-bfe1-f2eca23656ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-f603a32c-4722-46ad-9a0d-855280eb6981,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-c27cbe1c-5651-4782-a32d-3d64c7f70a82,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-cb7437d5-200a-45c3-8c54-103cb2ef915f,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-462131a3-a571-4354-91bb-f37570c37a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1319528094-172.17.0.21-1597403120388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-025d1435-d9c1-4f4a-bb9e-aff80cf00df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-25886cf7-bdd2-4425-b78d-798f07892a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-97184008-9004-43b9-a230-96609f8db541,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-c41616df-fe7e-40a2-bfe1-f2eca23656ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-f603a32c-4722-46ad-9a0d-855280eb6981,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-c27cbe1c-5651-4782-a32d-3d64c7f70a82,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-cb7437d5-200a-45c3-8c54-103cb2ef915f,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-462131a3-a571-4354-91bb-f37570c37a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069664026-172.17.0.21-1597403519186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34076,DS-8ae6a4a6-1230-4c37-aa39-65c3562498bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-1cbe3cae-c515-4280-8ff3-cfc14443ed35,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-4a51b215-15e6-45fa-88c5-9d7922ca345a,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-6f68fa5c-0e78-4516-a267-04f39fb284d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-5d2fc824-0d40-47d8-a6e6-d7720ecf1ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-5a05211c-1bad-4299-9b35-d1e23c0c9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-560cedf8-21e8-46eb-8105-125970aa4d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-1e1c6156-b774-48a2-a16f-d45b47e506dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069664026-172.17.0.21-1597403519186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34076,DS-8ae6a4a6-1230-4c37-aa39-65c3562498bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-1cbe3cae-c515-4280-8ff3-cfc14443ed35,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-4a51b215-15e6-45fa-88c5-9d7922ca345a,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-6f68fa5c-0e78-4516-a267-04f39fb284d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-5d2fc824-0d40-47d8-a6e6-d7720ecf1ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-5a05211c-1bad-4299-9b35-d1e23c0c9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-560cedf8-21e8-46eb-8105-125970aa4d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-1e1c6156-b774-48a2-a16f-d45b47e506dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17057401-172.17.0.21-1597404075327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-95563d08-4581-44a4-9575-ec94bf138cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-6760ab69-2f34-4c1d-bab2-00f3982d0356,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-731759c4-8123-400d-ae91-ef86eddafe63,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-5c1c2f55-92ad-4987-9ab5-622018929034,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-80aaed9e-6dae-4138-acbf-1a594255fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-feb5749c-95d0-4b97-83b2-7dcbe0478de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-ecad73d3-44c4-427b-a41d-de4e780210fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-6e0962c7-ac6a-44bb-abd3-3975b45d908f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17057401-172.17.0.21-1597404075327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-95563d08-4581-44a4-9575-ec94bf138cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-6760ab69-2f34-4c1d-bab2-00f3982d0356,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-731759c4-8123-400d-ae91-ef86eddafe63,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-5c1c2f55-92ad-4987-9ab5-622018929034,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-80aaed9e-6dae-4138-acbf-1a594255fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-feb5749c-95d0-4b97-83b2-7dcbe0478de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-ecad73d3-44c4-427b-a41d-de4e780210fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-6e0962c7-ac6a-44bb-abd3-3975b45d908f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100808615-172.17.0.21-1597404264263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-72d64dc1-d9f5-43ac-9ba4-3e7cbbb13d15,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-978f3fda-bcdd-4722-b1db-b0a2bebae7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-a06f60ce-3d81-4307-b01a-cf98e5742d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-e72ad037-6685-40a6-958f-a6ddd14632b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-fa49c1d0-7213-49dd-abb2-c245515a7311,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-3be6cfea-f84c-4f0b-9b6d-dbd5d3f0f419,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-ff7863af-d942-4d2d-9643-0f6cacc93354,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-de96a5aa-7b48-46d6-8030-037018fb5f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100808615-172.17.0.21-1597404264263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-72d64dc1-d9f5-43ac-9ba4-3e7cbbb13d15,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-978f3fda-bcdd-4722-b1db-b0a2bebae7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-a06f60ce-3d81-4307-b01a-cf98e5742d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-e72ad037-6685-40a6-958f-a6ddd14632b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-fa49c1d0-7213-49dd-abb2-c245515a7311,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-3be6cfea-f84c-4f0b-9b6d-dbd5d3f0f419,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-ff7863af-d942-4d2d-9643-0f6cacc93354,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-de96a5aa-7b48-46d6-8030-037018fb5f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627512116-172.17.0.21-1597404357004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40850,DS-7f0fc595-49dd-4151-b76c-01cf8212d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-017ab7e2-e883-426e-830b-6fc70272fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-03da86c3-1530-4a84-92e4-03e27ac363f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-3caeea18-011e-49bc-881e-cdc0d7818b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-f0073176-2c7c-40d0-a3d2-ee4542bfefe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-d4d7d59e-7131-4c92-80cc-bb35a884ee64,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-4a4bf9a1-f610-41ac-9ecc-4ff853c1a7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-5b1207a9-db71-485e-aba6-7cda3846bf7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627512116-172.17.0.21-1597404357004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40850,DS-7f0fc595-49dd-4151-b76c-01cf8212d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-017ab7e2-e883-426e-830b-6fc70272fa95,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-03da86c3-1530-4a84-92e4-03e27ac363f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-3caeea18-011e-49bc-881e-cdc0d7818b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-f0073176-2c7c-40d0-a3d2-ee4542bfefe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-d4d7d59e-7131-4c92-80cc-bb35a884ee64,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-4a4bf9a1-f610-41ac-9ecc-4ff853c1a7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-5b1207a9-db71-485e-aba6-7cda3846bf7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894400983-172.17.0.21-1597404600796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-4964c39e-ebab-489d-9f8b-a62453abb39f,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-2bdfde17-8f79-49b3-9729-90978ee95e96,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-a2d183f3-5ce7-4ebb-8a59-0dad88ea9962,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-0dbb6089-d5c1-40d6-86bf-93d85185b8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-f732f3b3-eab6-4f43-83e4-2fb194dabdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-a1ad6384-5371-465d-a3d1-4e7ee3865ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-eb4ac7a2-836a-4235-84f4-252ec0443c18,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-9fbb126b-5406-4a4a-b001-ef20f7d3b194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894400983-172.17.0.21-1597404600796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-4964c39e-ebab-489d-9f8b-a62453abb39f,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-2bdfde17-8f79-49b3-9729-90978ee95e96,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-a2d183f3-5ce7-4ebb-8a59-0dad88ea9962,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-0dbb6089-d5c1-40d6-86bf-93d85185b8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-f732f3b3-eab6-4f43-83e4-2fb194dabdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-a1ad6384-5371-465d-a3d1-4e7ee3865ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-eb4ac7a2-836a-4235-84f4-252ec0443c18,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-9fbb126b-5406-4a4a-b001-ef20f7d3b194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613565046-172.17.0.21-1597404641764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-c411cb96-d1b8-4bc9-ac75-9661a0f2abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-1f960467-fc71-40ae-80bd-11ed3e96d70d,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-f266cc8e-5377-415e-b9e6-6b1c85916b11,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-37e0b12e-3647-458d-a873-93c47263567f,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-9f676653-521c-4372-897b-9c23db383482,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-e623c996-80e0-41f6-bec6-046e36bb17e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4da06cee-7cc3-4be5-a24d-b9b73a8e2d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-7e9948c3-2afb-437c-adae-6520b23f5440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613565046-172.17.0.21-1597404641764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-c411cb96-d1b8-4bc9-ac75-9661a0f2abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-1f960467-fc71-40ae-80bd-11ed3e96d70d,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-f266cc8e-5377-415e-b9e6-6b1c85916b11,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-37e0b12e-3647-458d-a873-93c47263567f,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-9f676653-521c-4372-897b-9c23db383482,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-e623c996-80e0-41f6-bec6-046e36bb17e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-4da06cee-7cc3-4be5-a24d-b9b73a8e2d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-7e9948c3-2afb-437c-adae-6520b23f5440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824195446-172.17.0.21-1597404864904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-2ef656a0-f662-4b7c-aed1-a7791c4f1091,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-f1925b3b-5d0e-4ab5-b2b8-4859f9702b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-131f975c-9398-4a77-afb5-b7c84786c66f,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-a0a3032a-5371-4bbb-9df1-6f6f6d83d68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-ccb6c42d-0064-43ee-8a59-b37125618b98,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-81554761-3be3-426d-8ac8-511a42edd530,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-5a589dac-e4fb-4ecd-b531-624b23ef1a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-8ee39e62-7491-4b36-a5bb-1be316eb6869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824195446-172.17.0.21-1597404864904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-2ef656a0-f662-4b7c-aed1-a7791c4f1091,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-f1925b3b-5d0e-4ab5-b2b8-4859f9702b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-131f975c-9398-4a77-afb5-b7c84786c66f,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-a0a3032a-5371-4bbb-9df1-6f6f6d83d68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-ccb6c42d-0064-43ee-8a59-b37125618b98,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-81554761-3be3-426d-8ac8-511a42edd530,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-5a589dac-e4fb-4ecd-b531-624b23ef1a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-8ee39e62-7491-4b36-a5bb-1be316eb6869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810493842-172.17.0.21-1597405056452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-ddb2fb7d-6675-4039-ab04-c7b181f0648d,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-ae7c601f-083b-4f3c-9cd9-4b3cf7f8c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-2fe4ad23-3de7-42f9-b798-3d333b89d4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-93011b9e-d5d5-442a-a4cc-bd96a21d4147,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-f50b8229-ee33-49d2-b0b1-47b27a520a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-6e373dc3-d02b-4c8b-8201-ba3a4ef9e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-008a589e-c16e-4b4d-a53e-77e9357e9f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-37d09a8e-2e51-47b8-a359-f59b5690d684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810493842-172.17.0.21-1597405056452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-ddb2fb7d-6675-4039-ab04-c7b181f0648d,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-ae7c601f-083b-4f3c-9cd9-4b3cf7f8c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-2fe4ad23-3de7-42f9-b798-3d333b89d4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-93011b9e-d5d5-442a-a4cc-bd96a21d4147,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-f50b8229-ee33-49d2-b0b1-47b27a520a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-6e373dc3-d02b-4c8b-8201-ba3a4ef9e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-008a589e-c16e-4b4d-a53e-77e9357e9f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-37d09a8e-2e51-47b8-a359-f59b5690d684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897453239-172.17.0.21-1597405098552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-64322a47-564e-4cb2-a6b9-5c987c690024,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-73cc459a-83d1-4794-b7c4-2713068a4452,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-f48dd5f3-6fea-4eab-a932-f46fc54facac,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-79aa241e-90fe-4223-88ff-68bc8d3ffee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-5400d909-ea9d-4bb7-9464-17869556c2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-7a768c22-ecaf-4002-96eb-4193ae5caab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-395b0594-ae87-42fb-9d19-59af4db2aab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-f03d9dbc-d452-408f-b502-ec76e767797b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897453239-172.17.0.21-1597405098552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-64322a47-564e-4cb2-a6b9-5c987c690024,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-73cc459a-83d1-4794-b7c4-2713068a4452,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-f48dd5f3-6fea-4eab-a932-f46fc54facac,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-79aa241e-90fe-4223-88ff-68bc8d3ffee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-5400d909-ea9d-4bb7-9464-17869556c2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-7a768c22-ecaf-4002-96eb-4193ae5caab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-395b0594-ae87-42fb-9d19-59af4db2aab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-f03d9dbc-d452-408f-b502-ec76e767797b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119039393-172.17.0.21-1597405168379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-bec9d74b-e38e-4ecc-90df-0ecc1d81e0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-9550c0d9-a117-4575-920c-fd7b2133b836,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-d64e05e8-deaf-45fb-be2c-c76f45d9a25b,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-6b2dae53-ebc5-4e58-a496-823f925ac3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-26e01143-27c6-44dd-9bba-37b62267da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-8716d547-4d47-4478-a29c-8b8503a8aff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-fb917821-dd32-4c20-82ef-4c6c492d963b,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-151a6e7a-7d64-4fe2-a001-297c0d7ee53f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119039393-172.17.0.21-1597405168379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-bec9d74b-e38e-4ecc-90df-0ecc1d81e0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-9550c0d9-a117-4575-920c-fd7b2133b836,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-d64e05e8-deaf-45fb-be2c-c76f45d9a25b,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-6b2dae53-ebc5-4e58-a496-823f925ac3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-26e01143-27c6-44dd-9bba-37b62267da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-8716d547-4d47-4478-a29c-8b8503a8aff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-fb917821-dd32-4c20-82ef-4c6c492d963b,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-151a6e7a-7d64-4fe2-a001-297c0d7ee53f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233534600-172.17.0.21-1597405599801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44564,DS-b143b4a8-d85d-4b78-be06-308020a4ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-2db558b5-374e-4961-b9d3-6fb349126170,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-8fe66a21-155b-461a-9cce-f9eb8f5cbe78,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-edc827ca-c8d4-4840-b346-4df67d899cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-6b51106d-94e4-486a-af3e-13f2c7b6b927,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-48c6e124-b676-4d2a-8035-28d2dbfdc380,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-7f7b07d3-d523-4982-8f76-776acb49b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-5ebe64e8-6482-475f-a3ad-b230f15211ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233534600-172.17.0.21-1597405599801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44564,DS-b143b4a8-d85d-4b78-be06-308020a4ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-2db558b5-374e-4961-b9d3-6fb349126170,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-8fe66a21-155b-461a-9cce-f9eb8f5cbe78,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-edc827ca-c8d4-4840-b346-4df67d899cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-6b51106d-94e4-486a-af3e-13f2c7b6b927,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-48c6e124-b676-4d2a-8035-28d2dbfdc380,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-7f7b07d3-d523-4982-8f76-776acb49b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-5ebe64e8-6482-475f-a3ad-b230f15211ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935214581-172.17.0.21-1597405670828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-d5bfdf1b-0b39-4ab1-a25c-33ab27073059,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-cfd8ef5c-e999-4219-b101-63bef9963945,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-b848df11-3427-4f52-8d60-576910cceb64,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-0f5d6de2-76ff-414b-8833-baeb83abe035,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-4089a93e-cdc1-4d73-9155-0bd2c78f58b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-fc81a660-2df7-40c9-84e7-32298d95c42c,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-ba326cdd-205c-4633-a11d-a2ece12b99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-c4c4e447-6e9f-4756-80ed-1f2cfc760970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935214581-172.17.0.21-1597405670828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-d5bfdf1b-0b39-4ab1-a25c-33ab27073059,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-cfd8ef5c-e999-4219-b101-63bef9963945,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-b848df11-3427-4f52-8d60-576910cceb64,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-0f5d6de2-76ff-414b-8833-baeb83abe035,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-4089a93e-cdc1-4d73-9155-0bd2c78f58b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-fc81a660-2df7-40c9-84e7-32298d95c42c,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-ba326cdd-205c-4633-a11d-a2ece12b99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-c4c4e447-6e9f-4756-80ed-1f2cfc760970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5423
