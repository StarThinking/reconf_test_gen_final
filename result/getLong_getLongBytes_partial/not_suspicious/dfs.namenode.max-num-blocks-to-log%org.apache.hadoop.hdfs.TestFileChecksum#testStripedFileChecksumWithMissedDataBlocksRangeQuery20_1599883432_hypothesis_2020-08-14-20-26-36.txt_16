reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767560213-172.17.0.3-1597436958814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33404,DS-c3d8bb4b-9a19-401a-949e-4a9d74213ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-e4200a1e-166b-49bf-a6bd-f69c2e3ee34c,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-40d16113-b7a2-42ab-a40c-074096803ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-5ae71af4-a44e-49bf-97d4-e4696a041588,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-cd13b586-4194-4180-addd-703a2c2bddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-f80186d5-1538-4e96-a536-5b627cc8c1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-6589aea3-ddff-47ca-a1b0-ef7ca7ea1044,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-8ecf602f-4863-4f03-831c-8e9ebf39021d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767560213-172.17.0.3-1597436958814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33404,DS-c3d8bb4b-9a19-401a-949e-4a9d74213ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-e4200a1e-166b-49bf-a6bd-f69c2e3ee34c,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-40d16113-b7a2-42ab-a40c-074096803ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-5ae71af4-a44e-49bf-97d4-e4696a041588,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-cd13b586-4194-4180-addd-703a2c2bddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-f80186d5-1538-4e96-a536-5b627cc8c1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-6589aea3-ddff-47ca-a1b0-ef7ca7ea1044,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-8ecf602f-4863-4f03-831c-8e9ebf39021d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084952314-172.17.0.3-1597437192772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41073,DS-2e056d04-1bd8-442f-aad5-5bb4531f44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-efab48ac-f403-4768-b83d-b9d9b3f07632,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-685258cc-d349-4349-9f93-21e364da571d,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-d420e884-7d71-4d7a-9583-e2f31bafc802,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-22f002d9-d214-4c8e-af35-7eb20800db12,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-bf59f622-3016-4c71-910f-8259731f276d,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-b665b16e-efa0-4bbb-b887-b57bd8fc556b,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-75d43a60-6cb9-414c-b9cb-7c46867e91cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084952314-172.17.0.3-1597437192772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41073,DS-2e056d04-1bd8-442f-aad5-5bb4531f44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-efab48ac-f403-4768-b83d-b9d9b3f07632,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-685258cc-d349-4349-9f93-21e364da571d,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-d420e884-7d71-4d7a-9583-e2f31bafc802,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-22f002d9-d214-4c8e-af35-7eb20800db12,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-bf59f622-3016-4c71-910f-8259731f276d,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-b665b16e-efa0-4bbb-b887-b57bd8fc556b,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-75d43a60-6cb9-414c-b9cb-7c46867e91cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609001211-172.17.0.3-1597437469215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46569,DS-76153843-b845-4914-b362-9a5039bffb03,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-526e2175-1879-4a49-a958-d862150207be,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-52dc20b4-f3dc-4a93-a6b5-883e3b5de9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-5664d8cf-9dfc-400f-aded-08b8a7408535,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-9656cb99-e8e7-4cf4-8425-119057292d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-334d0ea4-a4f3-41da-8a33-f44cdb8a27b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-c47a94d9-9061-4aad-9ca0-b9f3e665ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-6aed78e9-5d5b-48be-a60b-0e7a39ff736f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609001211-172.17.0.3-1597437469215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46569,DS-76153843-b845-4914-b362-9a5039bffb03,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-526e2175-1879-4a49-a958-d862150207be,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-52dc20b4-f3dc-4a93-a6b5-883e3b5de9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-5664d8cf-9dfc-400f-aded-08b8a7408535,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-9656cb99-e8e7-4cf4-8425-119057292d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-334d0ea4-a4f3-41da-8a33-f44cdb8a27b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-c47a94d9-9061-4aad-9ca0-b9f3e665ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-6aed78e9-5d5b-48be-a60b-0e7a39ff736f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459280584-172.17.0.3-1597437701035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36519,DS-ff66225e-9781-4b1b-b966-80e7c95e9d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-501b00c6-51ac-4aec-9640-30bfdf274f79,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-228908de-a169-4ada-8c68-9135e4d35b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-9ac56d0c-d4f2-4bbe-be4e-2f708f045417,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-77713625-b7b4-46d2-b827-555c03319837,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-bfe9e2a0-1805-475a-b60f-27104f04788a,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-a4283974-0349-468c-8d0e-4014bed94149,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-9d3cebac-043c-4daa-b1e5-8ed7b78fdea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459280584-172.17.0.3-1597437701035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36519,DS-ff66225e-9781-4b1b-b966-80e7c95e9d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-501b00c6-51ac-4aec-9640-30bfdf274f79,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-228908de-a169-4ada-8c68-9135e4d35b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-9ac56d0c-d4f2-4bbe-be4e-2f708f045417,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-77713625-b7b4-46d2-b827-555c03319837,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-bfe9e2a0-1805-475a-b60f-27104f04788a,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-a4283974-0349-468c-8d0e-4014bed94149,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-9d3cebac-043c-4daa-b1e5-8ed7b78fdea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123245972-172.17.0.3-1597438065513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42944,DS-a95d2043-0272-4592-b122-52c7989d5e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-6f6fda20-dca2-44a8-9b46-5a3e5bcfef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-ee3f1317-5eea-48bd-8dcb-301bd5b01831,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-46e6fdf2-a8e9-4604-be9b-546835ff1326,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-f167027d-2290-446c-abae-b360cc7e196c,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-fb853114-c90d-4b4d-a011-f571fc4417ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-ca13eb06-ae0c-4f7d-a347-ef208ee06e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-7a0fb53a-8566-40c4-9cea-1735f7168ef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123245972-172.17.0.3-1597438065513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42944,DS-a95d2043-0272-4592-b122-52c7989d5e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-6f6fda20-dca2-44a8-9b46-5a3e5bcfef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-ee3f1317-5eea-48bd-8dcb-301bd5b01831,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-46e6fdf2-a8e9-4604-be9b-546835ff1326,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-f167027d-2290-446c-abae-b360cc7e196c,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-fb853114-c90d-4b4d-a011-f571fc4417ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-ca13eb06-ae0c-4f7d-a347-ef208ee06e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-7a0fb53a-8566-40c4-9cea-1735f7168ef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611233758-172.17.0.3-1597438151495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40158,DS-1036e029-7a9f-4118-ae19-ff0e856a53e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-5a253d39-aa6b-4439-8739-802ffe4e1ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-369a4768-9bb5-4058-9cb4-39e3ba745e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-497115e7-b56a-40ec-b337-e063867039a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-e0417a29-1961-402d-a9f1-106c0ac8fda8,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-129c7d83-6f3c-45e9-a147-105a75bae47f,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-9987dc5a-5ff0-4474-b350-beee634775e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-af6085a1-be45-43c7-9716-390618a99f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611233758-172.17.0.3-1597438151495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40158,DS-1036e029-7a9f-4118-ae19-ff0e856a53e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-5a253d39-aa6b-4439-8739-802ffe4e1ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-369a4768-9bb5-4058-9cb4-39e3ba745e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-497115e7-b56a-40ec-b337-e063867039a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-e0417a29-1961-402d-a9f1-106c0ac8fda8,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-129c7d83-6f3c-45e9-a147-105a75bae47f,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-9987dc5a-5ff0-4474-b350-beee634775e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-af6085a1-be45-43c7-9716-390618a99f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085060144-172.17.0.3-1597439409457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44205,DS-948b5c16-a49b-4a49-a1d9-928eaa7559dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-c186ca88-cde1-4447-ae5a-6787ce936513,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-d7930e88-5d61-40ea-b73e-28890cff9aec,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-5fe0a423-2aa4-4074-bc63-e9e580749754,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-b57a3d5a-0c86-409e-863d-14a22d0323f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-3716e5cd-51a1-4e0c-9db7-aabf8b9532d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-ec05642c-0225-4a6a-a1df-c54de19cddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-77a971a2-fc56-42e0-a921-560de0ff6064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085060144-172.17.0.3-1597439409457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44205,DS-948b5c16-a49b-4a49-a1d9-928eaa7559dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-c186ca88-cde1-4447-ae5a-6787ce936513,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-d7930e88-5d61-40ea-b73e-28890cff9aec,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-5fe0a423-2aa4-4074-bc63-e9e580749754,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-b57a3d5a-0c86-409e-863d-14a22d0323f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-3716e5cd-51a1-4e0c-9db7-aabf8b9532d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-ec05642c-0225-4a6a-a1df-c54de19cddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-77a971a2-fc56-42e0-a921-560de0ff6064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883204761-172.17.0.3-1597439584523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-1eb908c2-6e88-4ff5-b05b-09c667e80b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-c8bd209c-9789-43dd-badb-4954512adab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-bee9dd6b-3dc4-4db2-86fc-b9045e36102e,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-d0c51e3d-1899-4470-a96a-e5df22543e56,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-fb22f22e-0d8d-4e7b-aec9-56b4b0cab59b,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-b33f5642-7d59-4f5e-8097-efe04af40fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-4f0dde85-9747-4014-8891-2408b2904646,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-678fdcac-8663-4312-9158-5a8a53ddf59e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883204761-172.17.0.3-1597439584523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-1eb908c2-6e88-4ff5-b05b-09c667e80b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-c8bd209c-9789-43dd-badb-4954512adab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-bee9dd6b-3dc4-4db2-86fc-b9045e36102e,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-d0c51e3d-1899-4470-a96a-e5df22543e56,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-fb22f22e-0d8d-4e7b-aec9-56b4b0cab59b,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-b33f5642-7d59-4f5e-8097-efe04af40fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-4f0dde85-9747-4014-8891-2408b2904646,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-678fdcac-8663-4312-9158-5a8a53ddf59e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352131902-172.17.0.3-1597440186307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-3bbe2c80-f464-49b0-a243-a94ff09de701,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-6acff01a-749b-44f0-b19f-286f68723079,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-25c45288-d86e-4c35-98d4-10ada8c889ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-4b9c4cf5-d13e-4c96-b834-7d475a54528d,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-7c24a304-8dbc-44f1-a1c0-4b9e283e4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-201b373e-be86-4e78-9fb2-68fd39f9c093,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-29f0d03e-84b1-4d86-b274-926cbd2d7acc,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-bfe7381e-6595-4d1c-a311-fbd62830a65f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352131902-172.17.0.3-1597440186307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-3bbe2c80-f464-49b0-a243-a94ff09de701,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-6acff01a-749b-44f0-b19f-286f68723079,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-25c45288-d86e-4c35-98d4-10ada8c889ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-4b9c4cf5-d13e-4c96-b834-7d475a54528d,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-7c24a304-8dbc-44f1-a1c0-4b9e283e4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-201b373e-be86-4e78-9fb2-68fd39f9c093,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-29f0d03e-84b1-4d86-b274-926cbd2d7acc,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-bfe7381e-6595-4d1c-a311-fbd62830a65f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036870541-172.17.0.3-1597440362371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34033,DS-aee213a5-a812-4431-8b37-dcc0a066895c,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-3e31f4ad-b974-4d18-853a-73db25083bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-2f793825-136c-4095-a97d-c8193989b73e,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-a26741e0-bfbe-4d09-a765-0524995478f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c196f86c-c4e5-4b14-bd4a-823da871d56e,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-1ae20d58-8ce1-40d4-bbe4-e2644e38b10d,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-bc103bea-80bf-4ac4-9fbb-ad250952bd62,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-e6087324-b433-47b4-92c4-6803286a0413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036870541-172.17.0.3-1597440362371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34033,DS-aee213a5-a812-4431-8b37-dcc0a066895c,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-3e31f4ad-b974-4d18-853a-73db25083bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-2f793825-136c-4095-a97d-c8193989b73e,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-a26741e0-bfbe-4d09-a765-0524995478f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c196f86c-c4e5-4b14-bd4a-823da871d56e,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-1ae20d58-8ce1-40d4-bbe4-e2644e38b10d,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-bc103bea-80bf-4ac4-9fbb-ad250952bd62,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-e6087324-b433-47b4-92c4-6803286a0413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372206852-172.17.0.3-1597440482009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-b9da7cfe-6e64-4885-9f3c-34ac39c81bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-a77291c2-e74c-43c4-8cee-2186a140b8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-7bbc8302-7266-4086-862d-fb2a9146a447,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-250b7573-bc3e-42ee-81b7-b9a48c3373a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-c44c9775-e137-4a14-a344-32899f9906f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-f747ed76-6e54-4569-9235-97c12da1274a,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-66eb02f2-db5f-4f3e-8bc8-3cf1dc61d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-6bf33129-4bf7-4d8b-a7e5-fcde0f34418f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372206852-172.17.0.3-1597440482009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-b9da7cfe-6e64-4885-9f3c-34ac39c81bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-a77291c2-e74c-43c4-8cee-2186a140b8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-7bbc8302-7266-4086-862d-fb2a9146a447,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-250b7573-bc3e-42ee-81b7-b9a48c3373a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-c44c9775-e137-4a14-a344-32899f9906f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-f747ed76-6e54-4569-9235-97c12da1274a,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-66eb02f2-db5f-4f3e-8bc8-3cf1dc61d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-6bf33129-4bf7-4d8b-a7e5-fcde0f34418f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699605777-172.17.0.3-1597440681434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-6dbed6b6-cf17-4f75-b404-e5d3e0d3e588,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-7f2f6480-934e-4c50-97dd-de5acbc3d528,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-56eb1fa2-d028-4dc0-ac23-81eab27ac9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-ca3df42f-1b73-4dd4-94d9-54b6a649b9be,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-e730edf2-da6a-4a31-8de8-28d38f52d818,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-ff57db71-0acc-4785-989d-ac2ce43f676f,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-f09ca13b-e577-4d16-ac8d-7442fc0956f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-ed7993a8-26f5-4fbd-8875-73499ce3d841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699605777-172.17.0.3-1597440681434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-6dbed6b6-cf17-4f75-b404-e5d3e0d3e588,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-7f2f6480-934e-4c50-97dd-de5acbc3d528,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-56eb1fa2-d028-4dc0-ac23-81eab27ac9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-ca3df42f-1b73-4dd4-94d9-54b6a649b9be,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-e730edf2-da6a-4a31-8de8-28d38f52d818,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-ff57db71-0acc-4785-989d-ac2ce43f676f,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-f09ca13b-e577-4d16-ac8d-7442fc0956f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-ed7993a8-26f5-4fbd-8875-73499ce3d841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005274195-172.17.0.3-1597441061727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44644,DS-14db3725-1751-4010-b829-fcc440115d89,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-985b9149-c184-46a4-95bc-3bb170783a16,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-88fe4614-ed79-4d85-96a2-c826f5e58f66,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-38d0350b-b7b6-4747-9c76-45a80da992f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-3b900bd2-707e-4296-9992-55e51ca4bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-3fdc351d-d32b-4c70-9e72-277067ab8540,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-b7595746-0634-47cc-a8c6-928a40bf0b10,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-2895a354-6a29-4d3d-ae4a-045f5436496d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005274195-172.17.0.3-1597441061727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44644,DS-14db3725-1751-4010-b829-fcc440115d89,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-985b9149-c184-46a4-95bc-3bb170783a16,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-88fe4614-ed79-4d85-96a2-c826f5e58f66,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-38d0350b-b7b6-4747-9c76-45a80da992f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-3b900bd2-707e-4296-9992-55e51ca4bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-3fdc351d-d32b-4c70-9e72-277067ab8540,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-b7595746-0634-47cc-a8c6-928a40bf0b10,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-2895a354-6a29-4d3d-ae4a-045f5436496d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490169120-172.17.0.3-1597441280018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-5126c7f2-c0e1-4fef-b292-b5bf7651cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-b26d054e-c055-4d09-b89f-71a4911beb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-447f3387-adf1-4f9f-89f8-7572240cc3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-b4410fc2-d882-47e0-b453-9401a5df1d17,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-1c1c46ab-eca8-4ec8-a4be-a8453b3b07dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-94d03512-84af-4e28-b01e-bc208ca14917,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-a5bd8211-e2cb-422c-9acf-5ad98937fb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-a1a5dc37-a71b-45be-acf9-d0afd37ddc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490169120-172.17.0.3-1597441280018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-5126c7f2-c0e1-4fef-b292-b5bf7651cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-b26d054e-c055-4d09-b89f-71a4911beb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-447f3387-adf1-4f9f-89f8-7572240cc3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-b4410fc2-d882-47e0-b453-9401a5df1d17,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-1c1c46ab-eca8-4ec8-a4be-a8453b3b07dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-94d03512-84af-4e28-b01e-bc208ca14917,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-a5bd8211-e2cb-422c-9acf-5ad98937fb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-a1a5dc37-a71b-45be-acf9-d0afd37ddc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367969067-172.17.0.3-1597441619663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-c8ff49d4-f7ec-43b8-9f7c-8e4b688a2d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-d1031333-be37-4ede-8646-b3c9c96e231e,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-ee45b65d-5b93-4339-9df3-44bbcd9f8d62,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-014e58f2-20e9-44d8-ae53-5d25a01724d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-6fa1abfa-ba1c-415c-bc1c-5d8441c455e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-0ed63edc-c554-40ce-b474-13c691144133,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-fe619d68-05c0-4116-87a6-0c106eb823f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-28f643ea-f9f4-496e-acc6-3df4baf766a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367969067-172.17.0.3-1597441619663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32909,DS-c8ff49d4-f7ec-43b8-9f7c-8e4b688a2d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-d1031333-be37-4ede-8646-b3c9c96e231e,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-ee45b65d-5b93-4339-9df3-44bbcd9f8d62,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-014e58f2-20e9-44d8-ae53-5d25a01724d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-6fa1abfa-ba1c-415c-bc1c-5d8441c455e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-0ed63edc-c554-40ce-b474-13c691144133,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-fe619d68-05c0-4116-87a6-0c106eb823f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-28f643ea-f9f4-496e-acc6-3df4baf766a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244623347-172.17.0.3-1597441815086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40016,DS-00b8dfb8-9c59-46b2-b5a8-2c998bd3312c,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-30c45d22-610f-4b30-94c5-091f2da111b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-45eee90e-49e0-4ac2-ba18-3b9f72a47d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-687ecbbe-3bc4-416a-adb7-6af1806500c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-5cdf2f57-531a-4bfa-913a-1955898eaed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-275ac1b7-9291-4962-ad5e-74c29eb580ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-f335dd60-17a7-47b3-9488-d71410071882,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-74e9af58-a4a1-473d-8491-2d3da39048d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244623347-172.17.0.3-1597441815086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40016,DS-00b8dfb8-9c59-46b2-b5a8-2c998bd3312c,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-30c45d22-610f-4b30-94c5-091f2da111b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-45eee90e-49e0-4ac2-ba18-3b9f72a47d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-687ecbbe-3bc4-416a-adb7-6af1806500c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-5cdf2f57-531a-4bfa-913a-1955898eaed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-275ac1b7-9291-4962-ad5e-74c29eb580ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-f335dd60-17a7-47b3-9488-d71410071882,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-74e9af58-a4a1-473d-8491-2d3da39048d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28813962-172.17.0.3-1597441859205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-cd4a0fe2-bac3-446a-8011-5f87870a54ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-184193e5-ba5d-4709-b66f-400cb33c6ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-b1087b91-4e5f-4a0f-92d5-c351464f9146,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-0a0c18a2-d00a-4ef8-b207-a720cbff6b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-26082174-4451-4502-bd14-5101b32b6a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-5a07cfc9-8cbf-4f45-a1c4-d9491f67b850,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-5f01df8e-10d9-4501-b1a2-dce4153dd63d,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-a7f8e6cd-083b-410f-8c8a-ce569a35de93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28813962-172.17.0.3-1597441859205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-cd4a0fe2-bac3-446a-8011-5f87870a54ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-184193e5-ba5d-4709-b66f-400cb33c6ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-b1087b91-4e5f-4a0f-92d5-c351464f9146,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-0a0c18a2-d00a-4ef8-b207-a720cbff6b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-26082174-4451-4502-bd14-5101b32b6a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-5a07cfc9-8cbf-4f45-a1c4-d9491f67b850,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-5f01df8e-10d9-4501-b1a2-dce4153dd63d,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-a7f8e6cd-083b-410f-8c8a-ce569a35de93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016788154-172.17.0.3-1597441964464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-a5ed8275-df43-4d4d-83ff-c15a5a378ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-d3b387ff-a920-4f72-ae5f-aa5f86c28939,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-9ab34abf-45df-416d-9cc1-af88379caad5,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-4b4b4fcd-e4ad-4d4b-9b5f-7ec52c19da0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-1b6af0e2-6e65-4ef6-bed8-5d3b92073f42,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-88d112b9-b8b7-4e8c-b844-bcfdfcb71226,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-68ef615c-9ca0-4bcb-bef1-e2e570db261d,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-4007e86a-da28-44fd-b5fa-37e024252778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016788154-172.17.0.3-1597441964464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-a5ed8275-df43-4d4d-83ff-c15a5a378ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-d3b387ff-a920-4f72-ae5f-aa5f86c28939,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-9ab34abf-45df-416d-9cc1-af88379caad5,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-4b4b4fcd-e4ad-4d4b-9b5f-7ec52c19da0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-1b6af0e2-6e65-4ef6-bed8-5d3b92073f42,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-88d112b9-b8b7-4e8c-b844-bcfdfcb71226,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-68ef615c-9ca0-4bcb-bef1-e2e570db261d,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-4007e86a-da28-44fd-b5fa-37e024252778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5181
