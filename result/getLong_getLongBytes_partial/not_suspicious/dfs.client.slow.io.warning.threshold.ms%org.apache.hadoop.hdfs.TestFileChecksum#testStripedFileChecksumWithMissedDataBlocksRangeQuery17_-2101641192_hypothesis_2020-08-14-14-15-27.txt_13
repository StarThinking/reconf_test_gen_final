reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27472999-172.17.0.5-1597415115042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41933,DS-624c388b-fac6-488a-a309-6db80c2b8ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-10008d2c-b3c1-452a-8070-d5f158763575,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-d15f58dd-983c-4262-9150-ba9bbc24e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-c46b59ad-6227-48fd-874d-e7d08a95bcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-aea349eb-f980-4ddc-809a-5d9a34b9e18b,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-2b04fad9-bed1-423e-aecd-64d5a2b46455,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-ab25701b-8d90-4898-9a62-0783611b733f,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-8bb8351d-5d22-400c-b323-ba7811d08061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27472999-172.17.0.5-1597415115042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41933,DS-624c388b-fac6-488a-a309-6db80c2b8ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-10008d2c-b3c1-452a-8070-d5f158763575,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-d15f58dd-983c-4262-9150-ba9bbc24e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-c46b59ad-6227-48fd-874d-e7d08a95bcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-aea349eb-f980-4ddc-809a-5d9a34b9e18b,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-2b04fad9-bed1-423e-aecd-64d5a2b46455,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-ab25701b-8d90-4898-9a62-0783611b733f,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-8bb8351d-5d22-400c-b323-ba7811d08061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293132508-172.17.0.5-1597415602434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-5d01797e-f807-4e1a-9c56-9d9d6af9e1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-508c775d-18a4-4032-8567-02b14300a424,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-583cde98-4271-4959-a7cc-08630a243198,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-fe3fd820-160f-4748-b3f9-1916a0bf6815,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-270815ae-fdcb-4905-a0a4-43fb3ae01f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-38469c8e-d169-42a1-b08c-2401986e5890,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-dfcf1155-a8fd-49cc-9457-a7010fe451bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-de22e388-6a68-422d-b981-99016823913a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293132508-172.17.0.5-1597415602434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-5d01797e-f807-4e1a-9c56-9d9d6af9e1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-508c775d-18a4-4032-8567-02b14300a424,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-583cde98-4271-4959-a7cc-08630a243198,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-fe3fd820-160f-4748-b3f9-1916a0bf6815,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-270815ae-fdcb-4905-a0a4-43fb3ae01f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-38469c8e-d169-42a1-b08c-2401986e5890,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-dfcf1155-a8fd-49cc-9457-a7010fe451bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-de22e388-6a68-422d-b981-99016823913a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797630547-172.17.0.5-1597415912314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-ec565fd9-3a5b-4f5e-9ef9-909e8aaf8c34,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-4bca7d5e-d389-46dd-8728-75b9ede04b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-79c14413-dbf2-4c3d-ae22-8d1cacf35b34,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-10382e2b-2e52-444c-ba57-f7b98e0c801f,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-2aa3688b-fe17-48a6-9d40-c8a4ad267ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-8071ad6e-0482-4a8d-8d5f-bd7b74332276,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-cd58b885-a4a7-4315-9b9e-c27b657cb5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-acd60ede-2790-4fe7-88df-89c49222ae8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797630547-172.17.0.5-1597415912314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-ec565fd9-3a5b-4f5e-9ef9-909e8aaf8c34,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-4bca7d5e-d389-46dd-8728-75b9ede04b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-79c14413-dbf2-4c3d-ae22-8d1cacf35b34,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-10382e2b-2e52-444c-ba57-f7b98e0c801f,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-2aa3688b-fe17-48a6-9d40-c8a4ad267ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-8071ad6e-0482-4a8d-8d5f-bd7b74332276,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-cd58b885-a4a7-4315-9b9e-c27b657cb5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-acd60ede-2790-4fe7-88df-89c49222ae8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671082907-172.17.0.5-1597416107633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44303,DS-4356ce9f-b371-4b54-9ae8-3a3c937bdfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-794c2c17-d9a4-4ec3-afcf-fe794c84d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-29e37f0f-472a-49c2-9504-f2ee1af0bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-7bca39f4-39a5-4306-8457-0214a8357add,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-9c7faf3d-f115-4839-8f83-93901da42c48,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-274ce08a-b928-4103-bd4f-40b95d539569,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-29c00113-4254-4c09-a691-38b1e87a6ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-8acc4814-44b4-4b52-b8d6-a9ea73d65633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671082907-172.17.0.5-1597416107633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44303,DS-4356ce9f-b371-4b54-9ae8-3a3c937bdfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-794c2c17-d9a4-4ec3-afcf-fe794c84d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-29e37f0f-472a-49c2-9504-f2ee1af0bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-7bca39f4-39a5-4306-8457-0214a8357add,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-9c7faf3d-f115-4839-8f83-93901da42c48,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-274ce08a-b928-4103-bd4f-40b95d539569,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-29c00113-4254-4c09-a691-38b1e87a6ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-8acc4814-44b4-4b52-b8d6-a9ea73d65633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510214322-172.17.0.5-1597416163739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37645,DS-f274d168-6f20-47b1-902d-359b40c1d3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-9a962e57-f264-42ce-9d67-30414a6bc4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-23ae8d95-92b6-4a19-b2c6-e24eac7bbff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-c2b5e9de-090e-4346-9765-019457c203a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-b820690d-55ee-4943-aba3-3b6dacbff59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-b86f36bc-0002-4aa2-b883-c77bdceab463,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-c0d9f904-bb07-4175-adeb-89b027142cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-9695a281-5998-4668-bb65-bc625e5fd8aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510214322-172.17.0.5-1597416163739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37645,DS-f274d168-6f20-47b1-902d-359b40c1d3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-9a962e57-f264-42ce-9d67-30414a6bc4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-23ae8d95-92b6-4a19-b2c6-e24eac7bbff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-c2b5e9de-090e-4346-9765-019457c203a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-b820690d-55ee-4943-aba3-3b6dacbff59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-b86f36bc-0002-4aa2-b883-c77bdceab463,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-c0d9f904-bb07-4175-adeb-89b027142cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-9695a281-5998-4668-bb65-bc625e5fd8aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102982239-172.17.0.5-1597418048372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35924,DS-a0854de5-e43e-4919-8dc8-cd43937d92ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-3148870b-5ba8-4db9-9907-bb4e76958c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-4b2e348d-3f57-451c-871f-9cd2179b3f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-8da66c32-ea68-4a43-8fe6-851ac60f4748,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-fd641b65-d6ca-4fda-bbdd-65aa62fe6f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-90e09ec8-f4be-4734-8d38-19f24775ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-224ace61-d748-4345-a562-4ff62994476e,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-4f1a7af3-9417-4be2-b8ae-4f8677aae9af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102982239-172.17.0.5-1597418048372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35924,DS-a0854de5-e43e-4919-8dc8-cd43937d92ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-3148870b-5ba8-4db9-9907-bb4e76958c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-4b2e348d-3f57-451c-871f-9cd2179b3f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-8da66c32-ea68-4a43-8fe6-851ac60f4748,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-fd641b65-d6ca-4fda-bbdd-65aa62fe6f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-90e09ec8-f4be-4734-8d38-19f24775ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-224ace61-d748-4345-a562-4ff62994476e,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-4f1a7af3-9417-4be2-b8ae-4f8677aae9af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018589468-172.17.0.5-1597418949340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34339,DS-e5769667-b95b-45b7-b28a-d989731715b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-1f3b814d-6cbb-4cc6-878f-807fba5f0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-66902933-7151-4e85-b968-880750bbc2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-34c4e861-9030-4d8e-823d-4adffb7e308e,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-e1bbda37-c42a-40f5-bacf-d59676149c97,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-5a6e08cd-308a-4d53-a077-1703cb954e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-1901524d-0b3d-43fe-ada1-dc5ca3fbbe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-20c67d59-807a-43cf-933e-b7806d4aee08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018589468-172.17.0.5-1597418949340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34339,DS-e5769667-b95b-45b7-b28a-d989731715b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-1f3b814d-6cbb-4cc6-878f-807fba5f0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-66902933-7151-4e85-b968-880750bbc2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-34c4e861-9030-4d8e-823d-4adffb7e308e,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-e1bbda37-c42a-40f5-bacf-d59676149c97,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-5a6e08cd-308a-4d53-a077-1703cb954e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-1901524d-0b3d-43fe-ada1-dc5ca3fbbe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-20c67d59-807a-43cf-933e-b7806d4aee08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981029173-172.17.0.5-1597419083274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-42dfd81d-c00d-42b5-b4ce-4aa3059fbdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-0193dbf0-fd78-4617-b472-c21482004847,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-e0b0651a-7e88-4348-9cca-14bff0afc470,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-3ac2fe36-a2b2-46b7-900c-05a41f71eeab,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-aebc4424-c8b6-4bc1-bcae-b21ab965304c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d6ffbf02-92d5-4006-85f3-e5389143db1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-1a4644d4-d28d-4b44-9d9e-40250f7831ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-9ede9da3-7392-439d-894e-9a7092d75bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981029173-172.17.0.5-1597419083274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-42dfd81d-c00d-42b5-b4ce-4aa3059fbdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-0193dbf0-fd78-4617-b472-c21482004847,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-e0b0651a-7e88-4348-9cca-14bff0afc470,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-3ac2fe36-a2b2-46b7-900c-05a41f71eeab,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-aebc4424-c8b6-4bc1-bcae-b21ab965304c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d6ffbf02-92d5-4006-85f3-e5389143db1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-1a4644d4-d28d-4b44-9d9e-40250f7831ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-9ede9da3-7392-439d-894e-9a7092d75bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968457884-172.17.0.5-1597419313200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-6c0355e4-d1cd-4ddd-91de-2401b90a99a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-639ce405-fea6-423f-9f2a-88a1fd98ef04,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-fc3c6ab3-796b-40a1-b427-7093d35055e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-9a524df4-5d8d-47e2-a2a7-ed6b8c830647,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-cb35cb24-4a3e-444f-a4f3-481b8fa89f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-06934857-5e10-4abb-8dc4-178d49200e10,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-e068a757-88b8-4a7f-971f-9116b538371a,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-51924238-9922-49f2-98fd-8534a228f347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968457884-172.17.0.5-1597419313200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-6c0355e4-d1cd-4ddd-91de-2401b90a99a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-639ce405-fea6-423f-9f2a-88a1fd98ef04,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-fc3c6ab3-796b-40a1-b427-7093d35055e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-9a524df4-5d8d-47e2-a2a7-ed6b8c830647,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-cb35cb24-4a3e-444f-a4f3-481b8fa89f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-06934857-5e10-4abb-8dc4-178d49200e10,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-e068a757-88b8-4a7f-971f-9116b538371a,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-51924238-9922-49f2-98fd-8534a228f347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603552945-172.17.0.5-1597419541005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33892,DS-c0c4f2e1-4615-473c-ae67-9c40af5f41c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-44976d26-4589-47f7-ac04-99a6d4e90adc,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-2047e620-eec5-4af3-bbab-300b1aaf791c,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-40b77495-dd8c-4562-b159-f46255cc54df,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-d1a9cb43-65f9-4b9d-aecd-31bdbca9f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-012c3476-f2a7-45a9-8724-b752fa1d243f,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-86ffab7a-1cd2-4cca-83ab-e6373c65dc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-8bcd5785-d70a-4094-a746-e872ec0ec9ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603552945-172.17.0.5-1597419541005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33892,DS-c0c4f2e1-4615-473c-ae67-9c40af5f41c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-44976d26-4589-47f7-ac04-99a6d4e90adc,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-2047e620-eec5-4af3-bbab-300b1aaf791c,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-40b77495-dd8c-4562-b159-f46255cc54df,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-d1a9cb43-65f9-4b9d-aecd-31bdbca9f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-012c3476-f2a7-45a9-8724-b752fa1d243f,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-86ffab7a-1cd2-4cca-83ab-e6373c65dc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-8bcd5785-d70a-4094-a746-e872ec0ec9ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944844865-172.17.0.5-1597420069747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46499,DS-172d0ea4-5c94-4ec0-a913-33a6f34fe9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-b9e13f6e-1ac0-4d92-b102-f2d1dfe1d9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-983e84ed-46ae-4d74-9930-92cdddda824d,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-9cec84ce-6600-4754-82ad-dc304a775c04,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-6235e596-a6fe-43b7-b255-a24c84705a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-9d58ba61-90fa-4149-8b6c-595c85f62ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-c0b0f640-e505-477c-a0b7-cfdff308bb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-28e43a9b-eadc-4ecd-983d-b47168300112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944844865-172.17.0.5-1597420069747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46499,DS-172d0ea4-5c94-4ec0-a913-33a6f34fe9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-b9e13f6e-1ac0-4d92-b102-f2d1dfe1d9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-983e84ed-46ae-4d74-9930-92cdddda824d,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-9cec84ce-6600-4754-82ad-dc304a775c04,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-6235e596-a6fe-43b7-b255-a24c84705a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-9d58ba61-90fa-4149-8b6c-595c85f62ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-c0b0f640-e505-477c-a0b7-cfdff308bb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-28e43a9b-eadc-4ecd-983d-b47168300112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574316444-172.17.0.5-1597420192496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-ba9c5ab6-f952-4b99-be3b-19c8914bae5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-1a0d3bce-34af-4318-bba0-b7219bc4ef16,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-f8cd1b7f-36ba-4776-98aa-d589d9372941,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-ba31a92d-7419-472c-a660-31a749efcc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-aaaf8b4b-2f0b-4b05-b91d-c44f4ab00120,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-7befdd58-b3a3-45a5-b2f4-b4f445c93f19,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-42d4a831-b7a9-4370-bf1b-51b01c4ab539,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-303c133d-a51a-4b8d-9817-48562ec20a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574316444-172.17.0.5-1597420192496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-ba9c5ab6-f952-4b99-be3b-19c8914bae5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-1a0d3bce-34af-4318-bba0-b7219bc4ef16,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-f8cd1b7f-36ba-4776-98aa-d589d9372941,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-ba31a92d-7419-472c-a660-31a749efcc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-aaaf8b4b-2f0b-4b05-b91d-c44f4ab00120,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-7befdd58-b3a3-45a5-b2f4-b4f445c93f19,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-42d4a831-b7a9-4370-bf1b-51b01c4ab539,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-303c133d-a51a-4b8d-9817-48562ec20a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457685447-172.17.0.5-1597420584318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-961b8a4d-3df1-4412-830a-e2b7f06e7e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-89bb4673-66e6-4cab-b392-0eca6e893cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-00bb7a92-0b22-4356-8e06-35a461735831,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-5dfc67f5-52e5-4359-9dd7-00c48961bae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-6097fd14-9e23-48f8-b128-71d92e86ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-27a7bd61-506d-4023-9a08-e9889f728d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-4318687f-c935-437f-af73-e0cc454c0805,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-17b8b771-1abe-43d9-96a1-7bf4032a86eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457685447-172.17.0.5-1597420584318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-961b8a4d-3df1-4412-830a-e2b7f06e7e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-89bb4673-66e6-4cab-b392-0eca6e893cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-00bb7a92-0b22-4356-8e06-35a461735831,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-5dfc67f5-52e5-4359-9dd7-00c48961bae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-6097fd14-9e23-48f8-b128-71d92e86ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-27a7bd61-506d-4023-9a08-e9889f728d12,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-4318687f-c935-437f-af73-e0cc454c0805,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-17b8b771-1abe-43d9-96a1-7bf4032a86eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255766143-172.17.0.5-1597421028512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39733,DS-0cd60de8-a900-4765-8dff-68abf318ba44,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-3f92bc11-385d-4df6-be2e-f4e20d1de4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-bd7a93ff-662e-4c80-8442-0e5ca13984dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-04749eb6-9364-4c97-9ca7-446a24deb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-772a9062-9e75-44e7-87b0-df9245e58b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-b35dc4c2-2d45-4e76-af61-c10398a8589a,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-8e0c1046-482a-4ce5-8b3d-a5123d1cb404,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-833d53e2-a209-4eb5-a676-38d9a926f106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255766143-172.17.0.5-1597421028512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39733,DS-0cd60de8-a900-4765-8dff-68abf318ba44,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-3f92bc11-385d-4df6-be2e-f4e20d1de4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-bd7a93ff-662e-4c80-8442-0e5ca13984dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-04749eb6-9364-4c97-9ca7-446a24deb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-772a9062-9e75-44e7-87b0-df9245e58b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-b35dc4c2-2d45-4e76-af61-c10398a8589a,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-8e0c1046-482a-4ce5-8b3d-a5123d1cb404,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-833d53e2-a209-4eb5-a676-38d9a926f106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341309527-172.17.0.5-1597421272458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-55a1c8ec-896f-4908-b00b-a623ae4d4f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-3c2bc8e5-1771-444a-b950-3fea4816d421,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-a8e31d66-9784-4351-af16-e1af35190c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-ffe0e9e6-d3c4-4cde-9aa5-8cc0f6619c15,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-cfb06f76-1a86-493a-aba6-35ccf5337f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-c800ad65-e73f-43e4-9dc4-14180fb2142f,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-4c453110-847f-4f8c-984e-9f8cc6e2e85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-c110f873-280f-42e3-b853-ef57e0e7441a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341309527-172.17.0.5-1597421272458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-55a1c8ec-896f-4908-b00b-a623ae4d4f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-3c2bc8e5-1771-444a-b950-3fea4816d421,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-a8e31d66-9784-4351-af16-e1af35190c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-ffe0e9e6-d3c4-4cde-9aa5-8cc0f6619c15,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-cfb06f76-1a86-493a-aba6-35ccf5337f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-c800ad65-e73f-43e4-9dc4-14180fb2142f,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-4c453110-847f-4f8c-984e-9f8cc6e2e85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-c110f873-280f-42e3-b853-ef57e0e7441a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145276027-172.17.0.5-1597421330032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-87830e87-7afa-45eb-a2dc-9da1404f3f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-ea58b262-9a46-450d-9296-1d87f99a19d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-b4e5d3d3-7505-477b-9198-e872843a4088,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-bcd7370f-6548-45f9-8087-28084052a88d,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-9978b6b7-a58c-42a7-825f-6d1ce39b2cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-330bac2f-fb26-4225-9dbf-b3a3d70b266c,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-e8396918-626a-40c9-9111-11446333c255,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-cb378680-7cdb-436d-bb9b-65e70abf8d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145276027-172.17.0.5-1597421330032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-87830e87-7afa-45eb-a2dc-9da1404f3f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-ea58b262-9a46-450d-9296-1d87f99a19d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-b4e5d3d3-7505-477b-9198-e872843a4088,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-bcd7370f-6548-45f9-8087-28084052a88d,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-9978b6b7-a58c-42a7-825f-6d1ce39b2cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-330bac2f-fb26-4225-9dbf-b3a3d70b266c,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-e8396918-626a-40c9-9111-11446333c255,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-cb378680-7cdb-436d-bb9b-65e70abf8d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6836
