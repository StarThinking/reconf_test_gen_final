reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429160893-172.17.0.4-1597288643370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-a9c07c15-b664-4288-a196-8f70d419cf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-2fe0d4ad-c074-468d-b0d4-8b9895ed41a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-36cdda64-9ab0-4f89-b03b-343586be07dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-21649fa2-703c-4c54-8b90-43533c011443,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-8dd448c8-1181-48eb-ae58-af7745f35584,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-25cc758c-6793-47d9-b41f-b7f71cca3fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-90081eac-3db7-4962-9032-3ab9de51b5af,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-5022b4b1-dd6a-4654-ae94-b69bb63dc670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429160893-172.17.0.4-1597288643370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-a9c07c15-b664-4288-a196-8f70d419cf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-2fe0d4ad-c074-468d-b0d4-8b9895ed41a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-36cdda64-9ab0-4f89-b03b-343586be07dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-21649fa2-703c-4c54-8b90-43533c011443,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-8dd448c8-1181-48eb-ae58-af7745f35584,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-25cc758c-6793-47d9-b41f-b7f71cca3fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-90081eac-3db7-4962-9032-3ab9de51b5af,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-5022b4b1-dd6a-4654-ae94-b69bb63dc670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046113992-172.17.0.4-1597288818305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-f3262195-d7d5-4c11-a3c1-0b4d34c36615,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-663f7a55-a3f0-4374-8592-706e49c46789,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-ac8dcd7f-10a1-4f37-9886-118609b0cbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-2da13f44-26f9-46cd-8c20-3b9540eda859,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-c9504ef4-0959-4a08-8a8e-6da99739887c,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-93ed2ddf-3e99-45c3-96af-24caa391abbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-63b526f6-44b7-441e-9904-57d0bf959d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-b2b19825-4c83-408d-b147-845e0da8a5bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046113992-172.17.0.4-1597288818305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-f3262195-d7d5-4c11-a3c1-0b4d34c36615,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-663f7a55-a3f0-4374-8592-706e49c46789,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-ac8dcd7f-10a1-4f37-9886-118609b0cbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-2da13f44-26f9-46cd-8c20-3b9540eda859,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-c9504ef4-0959-4a08-8a8e-6da99739887c,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-93ed2ddf-3e99-45c3-96af-24caa391abbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-63b526f6-44b7-441e-9904-57d0bf959d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-b2b19825-4c83-408d-b147-845e0da8a5bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811793964-172.17.0.4-1597289169843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-5dfa6ddf-a52e-4300-a5c8-48c94346cf35,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-93e648cb-a7fd-4bf2-8e81-dd0529416a92,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-1272c323-d025-4066-9a83-9e8643770233,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-3e14bebb-8b07-4d61-9292-c910176f086c,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-1bb97145-380d-48cd-8a5c-a0f96c26d263,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-c09f729e-6351-4351-8ec2-95d7dfb4a061,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-7b876718-1eb4-4b44-9230-97bb4e8da703,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-d7f3aeea-2fc3-4bac-a69d-6c605b1ac548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811793964-172.17.0.4-1597289169843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-5dfa6ddf-a52e-4300-a5c8-48c94346cf35,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-93e648cb-a7fd-4bf2-8e81-dd0529416a92,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-1272c323-d025-4066-9a83-9e8643770233,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-3e14bebb-8b07-4d61-9292-c910176f086c,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-1bb97145-380d-48cd-8a5c-a0f96c26d263,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-c09f729e-6351-4351-8ec2-95d7dfb4a061,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-7b876718-1eb4-4b44-9230-97bb4e8da703,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-d7f3aeea-2fc3-4bac-a69d-6c605b1ac548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795347994-172.17.0.4-1597289529126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34540,DS-79ac63b2-2fa0-4503-95d6-49e77e37477b,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-8b30617e-3935-44b9-8949-a152e84bcead,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-70a461b3-702c-49f2-a516-0b12d3325676,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-19dc2540-f7bc-455e-9e1d-d065614bc0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-65018cf1-498a-49ba-a74f-a43be04276f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-d9e8327a-0c0a-4f05-9afa-851cc3d63c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-f8c79ab7-c507-4d6e-82f2-9542024f0146,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-b033a945-4779-42ae-b2d5-3291b47cddde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795347994-172.17.0.4-1597289529126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34540,DS-79ac63b2-2fa0-4503-95d6-49e77e37477b,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-8b30617e-3935-44b9-8949-a152e84bcead,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-70a461b3-702c-49f2-a516-0b12d3325676,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-19dc2540-f7bc-455e-9e1d-d065614bc0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-65018cf1-498a-49ba-a74f-a43be04276f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-d9e8327a-0c0a-4f05-9afa-851cc3d63c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-f8c79ab7-c507-4d6e-82f2-9542024f0146,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-b033a945-4779-42ae-b2d5-3291b47cddde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467833420-172.17.0.4-1597289598466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43084,DS-bcc1954b-1d23-44ec-907b-b114751aea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-5c322ccb-ea1e-4826-a914-76e71fe18f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-1fa1913d-180a-4ed3-afd5-1ac93bc4e960,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-1111694f-f4ad-4e7b-8079-2573fbd1569e,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-2551a156-731b-4258-89c1-f62cd17671df,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-de5bf4ef-48cb-4c24-ba6d-3444bcfec675,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-de2d3ae2-2df0-4f6b-a4b5-8f3001e4dfde,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-5ff640dc-b45b-4693-902b-cc4d5a46bef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467833420-172.17.0.4-1597289598466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43084,DS-bcc1954b-1d23-44ec-907b-b114751aea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-5c322ccb-ea1e-4826-a914-76e71fe18f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-1fa1913d-180a-4ed3-afd5-1ac93bc4e960,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-1111694f-f4ad-4e7b-8079-2573fbd1569e,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-2551a156-731b-4258-89c1-f62cd17671df,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-de5bf4ef-48cb-4c24-ba6d-3444bcfec675,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-de2d3ae2-2df0-4f6b-a4b5-8f3001e4dfde,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-5ff640dc-b45b-4693-902b-cc4d5a46bef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086537778-172.17.0.4-1597290031027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-674f6049-e043-43b7-9d30-41a2acd719ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-e2c05035-16bc-47dd-800f-b7d01285fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-5dbb991e-3df9-4095-97fb-861ee8f2160b,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-0e9dd710-254e-40a0-8af4-f17c4fdd35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-5f42c7d6-7f83-4a0c-b474-1de641232e79,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-167ac85c-df39-4fe3-b665-976dc9fc302c,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-c27cd7e2-6d6b-4838-9069-ac87d27d2393,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-9ae3b33b-5e0a-4d28-a2fc-965ceb12f1a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086537778-172.17.0.4-1597290031027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-674f6049-e043-43b7-9d30-41a2acd719ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-e2c05035-16bc-47dd-800f-b7d01285fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-5dbb991e-3df9-4095-97fb-861ee8f2160b,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-0e9dd710-254e-40a0-8af4-f17c4fdd35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-5f42c7d6-7f83-4a0c-b474-1de641232e79,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-167ac85c-df39-4fe3-b665-976dc9fc302c,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-c27cd7e2-6d6b-4838-9069-ac87d27d2393,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-9ae3b33b-5e0a-4d28-a2fc-965ceb12f1a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826623283-172.17.0.4-1597290074906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39381,DS-b5dc8108-fd9d-498c-8f38-33b7438948f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-28aea79f-a534-40ea-b651-0ebbba8c25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-f242cdac-af86-4ddb-bee3-24b7e62cb8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-7d4bf4d6-9398-4de8-bd84-b0d408f7d8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-547f89dc-1087-494f-a38c-41023314c591,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-f77831e9-d6af-4712-911d-60188f290078,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-e3cfdd03-2862-4754-b508-5aee2eafd348,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-0483061d-2893-4bbd-a81d-7b7e222b3138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826623283-172.17.0.4-1597290074906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39381,DS-b5dc8108-fd9d-498c-8f38-33b7438948f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-28aea79f-a534-40ea-b651-0ebbba8c25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-f242cdac-af86-4ddb-bee3-24b7e62cb8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-7d4bf4d6-9398-4de8-bd84-b0d408f7d8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-547f89dc-1087-494f-a38c-41023314c591,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-f77831e9-d6af-4712-911d-60188f290078,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-e3cfdd03-2862-4754-b508-5aee2eafd348,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-0483061d-2893-4bbd-a81d-7b7e222b3138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636670106-172.17.0.4-1597290382190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-8d22f35d-04e8-46ce-935f-fbccca796d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-fbf6ce38-24f1-4b7a-938e-0998f4516d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-1a5b75b8-ff8b-47d9-8fd0-90450b19f66d,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-66b701c0-cf96-424f-976d-b7ee0f24e410,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-cc4b42ab-93d1-410c-9994-1154da9ea4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-e97125a4-f1ed-4d63-8921-b03d346a3de5,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-efa909a0-f574-40b9-a052-c9396427383a,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-23839802-63e6-4939-8012-1c5eab063441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636670106-172.17.0.4-1597290382190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-8d22f35d-04e8-46ce-935f-fbccca796d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-fbf6ce38-24f1-4b7a-938e-0998f4516d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-1a5b75b8-ff8b-47d9-8fd0-90450b19f66d,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-66b701c0-cf96-424f-976d-b7ee0f24e410,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-cc4b42ab-93d1-410c-9994-1154da9ea4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-e97125a4-f1ed-4d63-8921-b03d346a3de5,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-efa909a0-f574-40b9-a052-c9396427383a,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-23839802-63e6-4939-8012-1c5eab063441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572734856-172.17.0.4-1597290579043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-1d84a690-aa01-407e-be57-08966ea1e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-79a067a6-af47-48cc-98ee-6e7f08783b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-d9ffebe7-c702-49ee-a630-c69aa7c4b464,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-ae270147-7282-4e85-95ea-7ee17f856bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-b0919626-ebf9-4187-a543-47fc4c6be0be,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-d645519f-48ab-43f8-8ac1-54b51f824774,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-a371b108-cc8a-4443-9e61-2a95388c6740,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-3c1946e1-3a21-4a88-956c-9153f03ac3d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572734856-172.17.0.4-1597290579043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-1d84a690-aa01-407e-be57-08966ea1e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-79a067a6-af47-48cc-98ee-6e7f08783b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-d9ffebe7-c702-49ee-a630-c69aa7c4b464,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-ae270147-7282-4e85-95ea-7ee17f856bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-b0919626-ebf9-4187-a543-47fc4c6be0be,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-d645519f-48ab-43f8-8ac1-54b51f824774,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-a371b108-cc8a-4443-9e61-2a95388c6740,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-3c1946e1-3a21-4a88-956c-9153f03ac3d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942340821-172.17.0.4-1597291264486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-b9f45008-1656-4584-a856-fa3e9ea2605b,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-93e81caf-0311-4f19-a010-6551b864cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-0c29db52-84ef-4f01-8b90-84e16df5322c,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-a154b1a0-6c58-4243-8115-4765505eef47,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-0a012b8f-4516-4934-aaf2-203e1994ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-a89f3e18-ed13-475b-a989-5b513886e60f,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-8663a6b3-30bd-4fe6-b9af-f61fd36f173c,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-6f9f9a40-0d71-491b-853c-bb3ead37a67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942340821-172.17.0.4-1597291264486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-b9f45008-1656-4584-a856-fa3e9ea2605b,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-93e81caf-0311-4f19-a010-6551b864cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-0c29db52-84ef-4f01-8b90-84e16df5322c,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-a154b1a0-6c58-4243-8115-4765505eef47,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-0a012b8f-4516-4934-aaf2-203e1994ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-a89f3e18-ed13-475b-a989-5b513886e60f,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-8663a6b3-30bd-4fe6-b9af-f61fd36f173c,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-6f9f9a40-0d71-491b-853c-bb3ead37a67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882610897-172.17.0.4-1597291718092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-45e0ff8d-40e7-4265-bd49-d93097143bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-6e1880a6-c1b1-41dc-a08f-0d0015fabc21,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-edc38ff5-839b-479c-a084-315ac0513806,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-a9e51ddf-f537-4975-a63b-c6df9c35253a,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-c16b7a8f-92a0-4bdb-96de-0d59ca09eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-4d4e6ad8-7bc9-4484-9498-b5fc77e7784f,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-23f23ce6-dd6c-4b64-89d9-053b841dcf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-4b73df6a-b727-4f81-b416-bf5b581521e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882610897-172.17.0.4-1597291718092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-45e0ff8d-40e7-4265-bd49-d93097143bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-6e1880a6-c1b1-41dc-a08f-0d0015fabc21,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-edc38ff5-839b-479c-a084-315ac0513806,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-a9e51ddf-f537-4975-a63b-c6df9c35253a,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-c16b7a8f-92a0-4bdb-96de-0d59ca09eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-4d4e6ad8-7bc9-4484-9498-b5fc77e7784f,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-23f23ce6-dd6c-4b64-89d9-053b841dcf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-4b73df6a-b727-4f81-b416-bf5b581521e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134273592-172.17.0.4-1597291975380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-c8e9b2dd-88e6-4205-b453-010e2a05eff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-4c382fe0-cb09-4a2f-a12f-0f857b6e2706,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-b13f8dc2-7aae-49ce-a9f8-cf51073b9479,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-516969d9-33e2-480d-a21b-ccb7db6f0611,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-45b9e9a1-13ec-46da-9c64-ec0433e2585b,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-2708ce7f-4afd-4a1e-8472-04b324face5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-2cdeb770-d3ab-43ee-95b4-716d6a90035d,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-7421a680-a565-4461-b8e5-795d93f1738b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134273592-172.17.0.4-1597291975380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-c8e9b2dd-88e6-4205-b453-010e2a05eff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-4c382fe0-cb09-4a2f-a12f-0f857b6e2706,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-b13f8dc2-7aae-49ce-a9f8-cf51073b9479,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-516969d9-33e2-480d-a21b-ccb7db6f0611,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-45b9e9a1-13ec-46da-9c64-ec0433e2585b,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-2708ce7f-4afd-4a1e-8472-04b324face5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-2cdeb770-d3ab-43ee-95b4-716d6a90035d,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-7421a680-a565-4461-b8e5-795d93f1738b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054170927-172.17.0.4-1597292424504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43744,DS-4eecbb5e-8d20-4bd2-a046-981613f9cbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-f15d19b4-8c8d-492f-a686-e0b7a434c99c,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-9b20f320-3e10-41f3-9e2a-134b6cf99fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-8b336943-6be7-4c07-8d51-cac4f10e5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3c67e0d2-5ebb-4515-b692-628ffcbf0378,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-1634ab37-fef3-434d-96bc-e019f0be8fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-3aaefb5b-e1b1-4b49-a019-aa7130ed51ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-eab025ce-aeec-436a-aa46-08beca31ff14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054170927-172.17.0.4-1597292424504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43744,DS-4eecbb5e-8d20-4bd2-a046-981613f9cbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-f15d19b4-8c8d-492f-a686-e0b7a434c99c,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-9b20f320-3e10-41f3-9e2a-134b6cf99fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-8b336943-6be7-4c07-8d51-cac4f10e5dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3c67e0d2-5ebb-4515-b692-628ffcbf0378,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-1634ab37-fef3-434d-96bc-e019f0be8fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-3aaefb5b-e1b1-4b49-a019-aa7130ed51ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-eab025ce-aeec-436a-aa46-08beca31ff14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140646902-172.17.0.4-1597293025198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-6421bf79-b36d-40fc-a791-32689c5aba73,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-aeb123e2-2b6a-4c63-a7a3-be5c33687486,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-2db8f4e6-923a-4279-9cfc-1661108eac03,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-3f22b2ef-bdb3-43e6-960c-547e00cd9fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-88ee5b3c-f8a9-487a-a5e8-183f53f8f16c,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-30a2a991-2050-4920-b368-f1d83c8f3dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-6b5a57f7-d7ba-4bc9-b1d1-e0168cffa9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-57c67a07-c858-4804-bf15-49e33392066b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140646902-172.17.0.4-1597293025198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-6421bf79-b36d-40fc-a791-32689c5aba73,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-aeb123e2-2b6a-4c63-a7a3-be5c33687486,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-2db8f4e6-923a-4279-9cfc-1661108eac03,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-3f22b2ef-bdb3-43e6-960c-547e00cd9fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-88ee5b3c-f8a9-487a-a5e8-183f53f8f16c,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-30a2a991-2050-4920-b368-f1d83c8f3dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-6b5a57f7-d7ba-4bc9-b1d1-e0168cffa9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-57c67a07-c858-4804-bf15-49e33392066b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857579418-172.17.0.4-1597293176102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-9db87fdf-7f75-4c91-9da2-0131796e1653,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-79c5d95a-5931-4263-b580-f4230971dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-89d442bc-ee62-4f95-a430-1809b6a0036a,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-52f9fd69-5c11-4e39-8aab-3c0834e0a7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-f24f38a2-658e-4185-bee9-17cd7bc04d27,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-17d55b8a-a9ca-43b1-a7b1-9368027a86a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-ef131dd2-dbb0-4c6f-b04d-c3894547208b,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-2b7fcdc7-69f7-420b-ae5a-de4bb59383e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857579418-172.17.0.4-1597293176102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-9db87fdf-7f75-4c91-9da2-0131796e1653,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-79c5d95a-5931-4263-b580-f4230971dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-89d442bc-ee62-4f95-a430-1809b6a0036a,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-52f9fd69-5c11-4e39-8aab-3c0834e0a7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-f24f38a2-658e-4185-bee9-17cd7bc04d27,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-17d55b8a-a9ca-43b1-a7b1-9368027a86a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-ef131dd2-dbb0-4c6f-b04d-c3894547208b,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-2b7fcdc7-69f7-420b-ae5a-de4bb59383e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555982762-172.17.0.4-1597293211920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36235,DS-6eb000a5-dd54-4907-8999-bdfea118dd01,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-92cd8279-5ac7-4918-89e1-4083516fa601,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-3a852170-b4fc-478f-ae82-0fb7ee8b4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-27c2e40a-4d6f-42bf-b33f-ed9a5a15c412,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-5859e450-26a6-4a39-9fca-5220bb8329ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-b3b9a847-0a60-40e7-b54e-638bb10f47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-0863d03c-e874-4d84-90a9-ed5469a80d85,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-8842c57d-6d2f-4011-89ee-20f4db3bad19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555982762-172.17.0.4-1597293211920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36235,DS-6eb000a5-dd54-4907-8999-bdfea118dd01,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-92cd8279-5ac7-4918-89e1-4083516fa601,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-3a852170-b4fc-478f-ae82-0fb7ee8b4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-27c2e40a-4d6f-42bf-b33f-ed9a5a15c412,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-5859e450-26a6-4a39-9fca-5220bb8329ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-b3b9a847-0a60-40e7-b54e-638bb10f47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-0863d03c-e874-4d84-90a9-ed5469a80d85,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-8842c57d-6d2f-4011-89ee-20f4db3bad19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207137451-172.17.0.4-1597293796033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34342,DS-4c3ecc39-72e5-45f5-afda-1e35fde89c66,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-96c1f05f-ff54-47b7-bca2-9e9fc998372b,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-c526f817-5b8a-4bd4-aeca-498b3738ba6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-8f0544c8-ee08-4f96-b9ad-d0235cd29092,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-f82996fd-46d4-4c1b-8c38-345c3dcb9466,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-90ae77a7-378f-40c2-9bdd-6f1127d3baaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-2cf96e66-8ee2-4a2c-8063-6b636951dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-af01a7a1-534a-4e28-b201-570097f8922f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207137451-172.17.0.4-1597293796033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34342,DS-4c3ecc39-72e5-45f5-afda-1e35fde89c66,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-96c1f05f-ff54-47b7-bca2-9e9fc998372b,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-c526f817-5b8a-4bd4-aeca-498b3738ba6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-8f0544c8-ee08-4f96-b9ad-d0235cd29092,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-f82996fd-46d4-4c1b-8c38-345c3dcb9466,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-90ae77a7-378f-40c2-9bdd-6f1127d3baaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-2cf96e66-8ee2-4a2c-8063-6b636951dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-af01a7a1-534a-4e28-b201-570097f8922f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227256223-172.17.0.4-1597293988792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-13c1f6a4-582d-4d24-8ec6-1c14207890b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-cd1dfb2a-32bd-4b40-bfe3-88c5f7c35472,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-c8f08607-6798-43bf-856d-bd651b501299,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-c0820f00-2ca5-47ae-b347-b169484982ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-f2b56b23-a2f4-4b34-a71a-af055f4b8c34,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-98f551c8-9ed9-407d-801b-708a661d904b,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-dabdfaed-fdeb-45ca-b390-9af047740bec,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-b436532a-5b6c-4327-8243-7561aa29ae7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227256223-172.17.0.4-1597293988792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-13c1f6a4-582d-4d24-8ec6-1c14207890b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-cd1dfb2a-32bd-4b40-bfe3-88c5f7c35472,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-c8f08607-6798-43bf-856d-bd651b501299,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-c0820f00-2ca5-47ae-b347-b169484982ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-f2b56b23-a2f4-4b34-a71a-af055f4b8c34,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-98f551c8-9ed9-407d-801b-708a661d904b,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-dabdfaed-fdeb-45ca-b390-9af047740bec,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-b436532a-5b6c-4327-8243-7561aa29ae7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5716
