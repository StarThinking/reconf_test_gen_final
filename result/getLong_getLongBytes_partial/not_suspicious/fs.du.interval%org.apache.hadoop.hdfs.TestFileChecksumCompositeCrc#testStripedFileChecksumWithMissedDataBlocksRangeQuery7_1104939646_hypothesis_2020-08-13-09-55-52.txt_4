reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745022129-172.17.0.2-1597313042316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-da1ad6bd-6904-472b-aed3-f52a96de2824,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-60e314d7-9c02-4619-8c14-c07b6c59e0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-70569ec2-85ed-4296-8667-7ea8d38d2a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-262771ef-6397-4da6-931f-694a147f26ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-9425d59a-6fc8-488f-a524-0ebcdee726e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-5eea9900-89e1-4c56-8abb-d0bd878447ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-bbd4d1ff-7e39-4f8f-8a78-d2f960f120f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-16931a21-d38d-434c-861d-27d3644028d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745022129-172.17.0.2-1597313042316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-da1ad6bd-6904-472b-aed3-f52a96de2824,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-60e314d7-9c02-4619-8c14-c07b6c59e0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-70569ec2-85ed-4296-8667-7ea8d38d2a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-262771ef-6397-4da6-931f-694a147f26ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-9425d59a-6fc8-488f-a524-0ebcdee726e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-5eea9900-89e1-4c56-8abb-d0bd878447ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-bbd4d1ff-7e39-4f8f-8a78-d2f960f120f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-16931a21-d38d-434c-861d-27d3644028d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247787669-172.17.0.2-1597313080634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46373,DS-ab5f6248-3215-4544-a3e9-89c51ae6c407,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-b002dfb8-bb36-4633-868d-ea73b1447ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-8f4610ed-9e1b-4499-8557-6f7a501aa3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-e7b32c91-1b7b-4b1f-b847-e75edeacda55,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-e0eb1502-472c-4314-b605-eca88fd7ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-69772f26-c6e1-48d5-9e02-f7a86301bccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-f188f8ba-3dae-4313-880e-fea30e797c14,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-99d96168-bf80-4b17-855e-dbe41b7fecb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247787669-172.17.0.2-1597313080634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46373,DS-ab5f6248-3215-4544-a3e9-89c51ae6c407,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-b002dfb8-bb36-4633-868d-ea73b1447ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-8f4610ed-9e1b-4499-8557-6f7a501aa3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-e7b32c91-1b7b-4b1f-b847-e75edeacda55,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-e0eb1502-472c-4314-b605-eca88fd7ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-69772f26-c6e1-48d5-9e02-f7a86301bccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-f188f8ba-3dae-4313-880e-fea30e797c14,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-99d96168-bf80-4b17-855e-dbe41b7fecb6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138672383-172.17.0.2-1597314067001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39428,DS-15881797-abab-4307-b20b-a198ad03c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-7bb1ff53-18de-423e-b848-bc7f1c5663ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-2ac599af-5d49-4ae6-80dc-1ca480a408a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-22ce3898-e1e4-4cef-8f91-489c34a0ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-0af57657-f9de-40ef-9b2b-9c57ad9bc803,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-64d5bd95-7e3c-4417-850a-0422f27ae64b,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-a833b0df-40d9-4d20-9e13-cc66419fcf81,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-9efdfd82-f77d-46ea-9ec8-b4b222ec8c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138672383-172.17.0.2-1597314067001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39428,DS-15881797-abab-4307-b20b-a198ad03c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-7bb1ff53-18de-423e-b848-bc7f1c5663ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-2ac599af-5d49-4ae6-80dc-1ca480a408a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-22ce3898-e1e4-4cef-8f91-489c34a0ffae,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-0af57657-f9de-40ef-9b2b-9c57ad9bc803,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-64d5bd95-7e3c-4417-850a-0422f27ae64b,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-a833b0df-40d9-4d20-9e13-cc66419fcf81,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-9efdfd82-f77d-46ea-9ec8-b4b222ec8c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131031052-172.17.0.2-1597314106570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-d4e08d2d-4e26-4696-86e6-e4ed56a0d466,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-ccfc7326-7d66-41dc-9f70-0c730823e359,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-ae4b9280-4542-450f-b1d2-0895e1261b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-eae53236-d73c-425d-9661-7f7a610e3871,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-dc9f7025-1b74-4950-95c8-25dc75b2e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-960ada9f-de90-4955-9860-0312a60b536f,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-85bb4e2f-493b-4dc0-977b-4734a8d497d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-17291105-d51f-4f56-8bbb-d0433c288acd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131031052-172.17.0.2-1597314106570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-d4e08d2d-4e26-4696-86e6-e4ed56a0d466,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-ccfc7326-7d66-41dc-9f70-0c730823e359,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-ae4b9280-4542-450f-b1d2-0895e1261b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-eae53236-d73c-425d-9661-7f7a610e3871,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-dc9f7025-1b74-4950-95c8-25dc75b2e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-960ada9f-de90-4955-9860-0312a60b536f,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-85bb4e2f-493b-4dc0-977b-4734a8d497d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-17291105-d51f-4f56-8bbb-d0433c288acd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479228049-172.17.0.2-1597314142512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-e5d4785e-cd43-4891-a2ac-13a789b689ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-cdb838b7-28ee-4507-a1c3-133ecb5b32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-a45a232c-b061-4385-bcf0-078439e13535,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-61fb6b8b-358f-4ba6-8ebe-62f21604410b,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-d443a385-a289-4fc5-8458-243fccabee62,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-4dae70a4-a64b-4764-a32f-e300659ea939,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-286808b0-eb4e-4493-9b1f-85d7d556e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-b26ac2b1-ade1-4adf-8974-013827c7e45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479228049-172.17.0.2-1597314142512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-e5d4785e-cd43-4891-a2ac-13a789b689ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-cdb838b7-28ee-4507-a1c3-133ecb5b32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-a45a232c-b061-4385-bcf0-078439e13535,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-61fb6b8b-358f-4ba6-8ebe-62f21604410b,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-d443a385-a289-4fc5-8458-243fccabee62,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-4dae70a4-a64b-4764-a32f-e300659ea939,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-286808b0-eb4e-4493-9b1f-85d7d556e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-b26ac2b1-ade1-4adf-8974-013827c7e45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122990932-172.17.0.2-1597314511020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-9c523adc-7d25-46b7-a956-6580b10a7321,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-6cc819f2-52f6-488b-a25d-ad29ca2c3b64,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-35fdc637-cb6e-4fbc-b58f-87269571b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-17baa9be-fd55-487a-b2a6-c98b706f0419,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-4206874a-f317-4023-ae2b-1ae0267c4430,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-04c686b6-dec2-4b3f-bc4e-516631d7009d,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-6007a7bf-c56f-49d0-80e4-9b2f02a45f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-5c94906d-d949-4d83-a27a-621bb0e753ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122990932-172.17.0.2-1597314511020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-9c523adc-7d25-46b7-a956-6580b10a7321,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-6cc819f2-52f6-488b-a25d-ad29ca2c3b64,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-35fdc637-cb6e-4fbc-b58f-87269571b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-17baa9be-fd55-487a-b2a6-c98b706f0419,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-4206874a-f317-4023-ae2b-1ae0267c4430,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-04c686b6-dec2-4b3f-bc4e-516631d7009d,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-6007a7bf-c56f-49d0-80e4-9b2f02a45f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-5c94906d-d949-4d83-a27a-621bb0e753ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175986100-172.17.0.2-1597314544764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-1f146043-4450-4700-a192-d4eb7c12bd00,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-d4ce99de-1cd0-4268-a5c8-2fc8b60cee96,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-32f21ce3-fdad-49c8-a920-7681ac708751,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-20a3ec74-d48e-42ed-99df-489c069c327d,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-ae5af3dc-80dc-41d5-9253-b8fb8e967b78,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-bd00e38a-8727-4297-a4c4-5b47dd1b5171,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-660911ac-94f0-4d1a-92fe-4084a0792567,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-8c12e884-124f-401b-a2fd-f2236338925c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175986100-172.17.0.2-1597314544764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-1f146043-4450-4700-a192-d4eb7c12bd00,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-d4ce99de-1cd0-4268-a5c8-2fc8b60cee96,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-32f21ce3-fdad-49c8-a920-7681ac708751,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-20a3ec74-d48e-42ed-99df-489c069c327d,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-ae5af3dc-80dc-41d5-9253-b8fb8e967b78,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-bd00e38a-8727-4297-a4c4-5b47dd1b5171,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-660911ac-94f0-4d1a-92fe-4084a0792567,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-8c12e884-124f-401b-a2fd-f2236338925c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257887237-172.17.0.2-1597314582828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-a213aa11-e082-4803-ae5e-e5615ab4bd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-2dd4af25-0895-4b70-a16d-d3a74922e693,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-7ef0bff9-b8f1-4376-ba81-930f3e194579,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-512ebd93-f8ba-4c00-8faa-2278f7854b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-58e1d5c3-be2f-41a3-a469-893b9d00f15b,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-259e749d-224b-4586-9267-df706e82b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-5c253017-6dda-4973-acc2-7f056b2d13b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-754a7b57-d260-4cf4-bc67-65a319c61fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257887237-172.17.0.2-1597314582828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-a213aa11-e082-4803-ae5e-e5615ab4bd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-2dd4af25-0895-4b70-a16d-d3a74922e693,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-7ef0bff9-b8f1-4376-ba81-930f3e194579,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-512ebd93-f8ba-4c00-8faa-2278f7854b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-58e1d5c3-be2f-41a3-a469-893b9d00f15b,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-259e749d-224b-4586-9267-df706e82b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-5c253017-6dda-4973-acc2-7f056b2d13b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-754a7b57-d260-4cf4-bc67-65a319c61fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114960149-172.17.0.2-1597314746812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-127c3ac5-b60b-4dcf-b761-4b0a8b5498e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-dc820347-c5ca-4dac-901d-89cf6182fdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-934b4ba4-42f2-44c5-85eb-a20b95189b60,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-0a686cc0-d886-4fb5-8289-f73e8aecbd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-6f228d0f-df7a-4bf8-9a6f-8fc3bcc69bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-3998976e-ee0c-468f-9652-45787d918ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-8c4a1cec-1c34-4015-b78a-a0c5d4edfb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-f889b78e-876c-496b-b2c6-03e011fadb70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114960149-172.17.0.2-1597314746812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-127c3ac5-b60b-4dcf-b761-4b0a8b5498e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-dc820347-c5ca-4dac-901d-89cf6182fdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-934b4ba4-42f2-44c5-85eb-a20b95189b60,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-0a686cc0-d886-4fb5-8289-f73e8aecbd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-6f228d0f-df7a-4bf8-9a6f-8fc3bcc69bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-3998976e-ee0c-468f-9652-45787d918ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-8c4a1cec-1c34-4015-b78a-a0c5d4edfb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-f889b78e-876c-496b-b2c6-03e011fadb70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579291343-172.17.0.2-1597314904322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41497,DS-c25a5bdc-2749-469d-8660-fbfcfd3593c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-fa103175-c405-40a7-92e6-db7ff09ef603,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-e26b1956-e04a-481c-bb5c-5fadafff0564,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-98af2f09-fb3f-45af-9a53-144b3bcd7583,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-ceb2884c-5ce4-4e5b-90cc-c70470986972,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-36f4ca7b-261c-4cfb-960c-062804c13cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-9529a0f3-f953-4c85-a07f-d3dc12eb7f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-45396feb-6a79-4db5-b515-0302b611c823,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579291343-172.17.0.2-1597314904322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41497,DS-c25a5bdc-2749-469d-8660-fbfcfd3593c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-fa103175-c405-40a7-92e6-db7ff09ef603,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-e26b1956-e04a-481c-bb5c-5fadafff0564,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-98af2f09-fb3f-45af-9a53-144b3bcd7583,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-ceb2884c-5ce4-4e5b-90cc-c70470986972,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-36f4ca7b-261c-4cfb-960c-062804c13cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-9529a0f3-f953-4c85-a07f-d3dc12eb7f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-45396feb-6a79-4db5-b515-0302b611c823,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442000715-172.17.0.2-1597314989140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42720,DS-4fea83e4-f095-4bf1-afef-3cd29dbc0ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-92966986-18d7-4343-a5dc-5456bb914174,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-edd9a1d6-6ec8-4ff5-9c65-e24561ac3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-f74cf463-d282-4561-acec-a441b37a9af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-ed62db29-8045-4a46-8078-52f3e27c1105,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-af10a428-5b6a-45cc-b6c3-78e8ead773ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-c874371b-778c-4278-a4d7-2b1a98cd507e,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-2c6fc524-51e4-4a8d-9636-6946c300427e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442000715-172.17.0.2-1597314989140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42720,DS-4fea83e4-f095-4bf1-afef-3cd29dbc0ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-92966986-18d7-4343-a5dc-5456bb914174,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-edd9a1d6-6ec8-4ff5-9c65-e24561ac3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-f74cf463-d282-4561-acec-a441b37a9af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-ed62db29-8045-4a46-8078-52f3e27c1105,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-af10a428-5b6a-45cc-b6c3-78e8ead773ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-c874371b-778c-4278-a4d7-2b1a98cd507e,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-2c6fc524-51e4-4a8d-9636-6946c300427e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782233197-172.17.0.2-1597315303088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42880,DS-c58a7da7-6ba2-4039-ad91-db81a9bc9314,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-e90a16d7-bd34-47d4-ab77-ae66d60e363b,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-d6131ffe-9f6a-433a-b6ad-212fd664233a,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-6922363e-e9c6-4bca-b400-8617a48f8cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-85ef9518-f2f0-45eb-9a6f-b79935a97cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-6eebd6cf-c878-49eb-9335-6a2eb0937df5,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-d4d5bbc4-a6f9-4521-98db-4e73bdc21fce,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-71114536-8827-4416-8d25-de4ccb4dbc4c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782233197-172.17.0.2-1597315303088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42880,DS-c58a7da7-6ba2-4039-ad91-db81a9bc9314,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-e90a16d7-bd34-47d4-ab77-ae66d60e363b,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-d6131ffe-9f6a-433a-b6ad-212fd664233a,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-6922363e-e9c6-4bca-b400-8617a48f8cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-85ef9518-f2f0-45eb-9a6f-b79935a97cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-6eebd6cf-c878-49eb-9335-6a2eb0937df5,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-d4d5bbc4-a6f9-4521-98db-4e73bdc21fce,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-71114536-8827-4416-8d25-de4ccb4dbc4c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269685567-172.17.0.2-1597315542806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33147,DS-d2bb18d0-ce3e-47cf-b8b7-f03978d64c86,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-3e0a1af3-3c38-4fa9-a03b-a9e83202504a,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-8e16e939-71fe-43a0-89ac-b87650cfabac,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-627c4a5d-c089-4793-87aa-366347abf783,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-fe3a94b0-a744-4c0d-9833-e5135e969eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-b7c71af9-7f25-48e3-bb3c-9681e7c9d7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-66130570-0939-4514-b24a-129541a8d553,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-4bf0d6e9-0178-4ce5-b837-7f7f584d29cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269685567-172.17.0.2-1597315542806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33147,DS-d2bb18d0-ce3e-47cf-b8b7-f03978d64c86,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-3e0a1af3-3c38-4fa9-a03b-a9e83202504a,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-8e16e939-71fe-43a0-89ac-b87650cfabac,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-627c4a5d-c089-4793-87aa-366347abf783,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-fe3a94b0-a744-4c0d-9833-e5135e969eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-b7c71af9-7f25-48e3-bb3c-9681e7c9d7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-66130570-0939-4514-b24a-129541a8d553,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-4bf0d6e9-0178-4ce5-b837-7f7f584d29cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115250802-172.17.0.2-1597315615229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44478,DS-a6dea97a-99ee-4db1-a322-7235c297dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-eb718f3a-3645-4848-9af3-2e066d7514ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-19971091-c5d3-4b0a-a275-cbe2414e3d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-8d1c72d7-5bdb-46f7-9c11-5b7a08ef80f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-f71a404a-ac3d-4289-a397-e6d19389aab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-a9830344-a237-4d51-9efb-56cf0978f8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-6d6fbd53-a2b6-41d9-afe4-43ba7d35d4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-e055ba14-6da3-4b6c-8f3a-9739aafd10a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115250802-172.17.0.2-1597315615229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44478,DS-a6dea97a-99ee-4db1-a322-7235c297dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-eb718f3a-3645-4848-9af3-2e066d7514ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-19971091-c5d3-4b0a-a275-cbe2414e3d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-8d1c72d7-5bdb-46f7-9c11-5b7a08ef80f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-f71a404a-ac3d-4289-a397-e6d19389aab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-a9830344-a237-4d51-9efb-56cf0978f8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-6d6fbd53-a2b6-41d9-afe4-43ba7d35d4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-e055ba14-6da3-4b6c-8f3a-9739aafd10a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905375653-172.17.0.2-1597316202728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44793,DS-dac85c45-c03d-4ed2-9156-a55bc1d1a5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-cf4ae166-8dd5-4815-a955-aaf43a0f3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-df25dc46-fb40-4dab-9c52-15776d6b8673,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-23a7fe8c-07a7-4a3e-ab7d-8a764be8a849,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-5c2697d9-d1bb-485a-ba9a-d064ff7cd43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-8156876c-9347-4cba-b2f9-bf863a5ec0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-ac85eefa-6e87-4670-a9b6-c78b4095afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-a1444b87-a1ad-43d3-85fa-24c0341eb038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905375653-172.17.0.2-1597316202728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44793,DS-dac85c45-c03d-4ed2-9156-a55bc1d1a5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-cf4ae166-8dd5-4815-a955-aaf43a0f3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-df25dc46-fb40-4dab-9c52-15776d6b8673,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-23a7fe8c-07a7-4a3e-ab7d-8a764be8a849,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-5c2697d9-d1bb-485a-ba9a-d064ff7cd43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-8156876c-9347-4cba-b2f9-bf863a5ec0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-ac85eefa-6e87-4670-a9b6-c78b4095afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-a1444b87-a1ad-43d3-85fa-24c0341eb038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882195010-172.17.0.2-1597316280122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40073,DS-84632b81-ab04-4ab2-b7db-b01cf99cccc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-d9488317-7cff-4cf8-83aa-dcfb71aa99c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-c9978c41-ac40-43d4-b49b-d9ad01041f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-f4145c72-c1ae-44d9-b0d3-15fc7af1dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-46715cf3-0965-4578-82cc-60c1f402fca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-43871965-06de-4ad3-8466-e279406bdd29,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-a4ac9e7e-c8c6-48cc-ba99-3f586b9cf510,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-dfb857a3-5b46-47ea-aa4f-cc57e3830a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882195010-172.17.0.2-1597316280122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40073,DS-84632b81-ab04-4ab2-b7db-b01cf99cccc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-d9488317-7cff-4cf8-83aa-dcfb71aa99c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-c9978c41-ac40-43d4-b49b-d9ad01041f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-f4145c72-c1ae-44d9-b0d3-15fc7af1dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-46715cf3-0965-4578-82cc-60c1f402fca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-43871965-06de-4ad3-8466-e279406bdd29,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-a4ac9e7e-c8c6-48cc-ba99-3f586b9cf510,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-dfb857a3-5b46-47ea-aa4f-cc57e3830a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334810613-172.17.0.2-1597316432814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38419,DS-770a75d0-e337-41cc-9cc1-116a76886546,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-1dcfb74b-4279-4fd3-97ac-1b822275a647,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-cc842d77-0bce-466b-990e-adb564c767ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-d27080b9-bfc1-4fa7-9674-57200a4d9416,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-104b3f8b-de67-45ce-95d4-aaea36b4cfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-df444a4b-424f-4585-b065-f4bc4d9874f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-45b56fb2-820e-47ac-ba4c-1f645aaa0e11,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-6ad08886-1c50-4613-8864-7c21cd9fd41f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334810613-172.17.0.2-1597316432814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38419,DS-770a75d0-e337-41cc-9cc1-116a76886546,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-1dcfb74b-4279-4fd3-97ac-1b822275a647,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-cc842d77-0bce-466b-990e-adb564c767ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-d27080b9-bfc1-4fa7-9674-57200a4d9416,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-104b3f8b-de67-45ce-95d4-aaea36b4cfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-df444a4b-424f-4585-b065-f4bc4d9874f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-45b56fb2-820e-47ac-ba4c-1f645aaa0e11,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-6ad08886-1c50-4613-8864-7c21cd9fd41f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268051313-172.17.0.2-1597316587872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-3c38e9c7-7ffa-484b-bfc5-ba2d2ae64590,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-54ae6842-2520-46a7-a59d-02a206bf97ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ec5e3ec8-320e-484b-af24-2809f975f758,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-4827577c-8ed0-4141-8da5-c95a1d81e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-60b06dbf-19fe-40fb-8fb4-d0a91cbbe61e,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-f54e5994-b4b5-4006-b183-7e4d7cdf98c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-d7fb014c-a2ca-4c2a-9a18-f58e4b0cadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-136757f5-95cd-4ea1-bdbf-eaa4ba7a5255,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268051313-172.17.0.2-1597316587872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-3c38e9c7-7ffa-484b-bfc5-ba2d2ae64590,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-54ae6842-2520-46a7-a59d-02a206bf97ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ec5e3ec8-320e-484b-af24-2809f975f758,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-4827577c-8ed0-4141-8da5-c95a1d81e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-60b06dbf-19fe-40fb-8fb4-d0a91cbbe61e,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-f54e5994-b4b5-4006-b183-7e4d7cdf98c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-d7fb014c-a2ca-4c2a-9a18-f58e4b0cadf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-136757f5-95cd-4ea1-bdbf-eaa4ba7a5255,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653036093-172.17.0.2-1597316666335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36444,DS-3751c1cc-effe-44cf-9abb-8b6450bd8f96,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-d777f009-1e7c-4841-8029-62e0712ab677,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-cf4b2ca2-00f8-425f-a54c-4e9d99d54799,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-8b488958-6a7d-4759-9fc7-831663e1ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-b717b632-d392-4b17-b6d6-3dd2eff4c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-a6021150-6c36-45ca-a98c-dbbb2294c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-bf56e2ed-6baf-404e-8d66-58205496c7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-271d82a7-54cd-43e9-8c88-088fdf47ab60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653036093-172.17.0.2-1597316666335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36444,DS-3751c1cc-effe-44cf-9abb-8b6450bd8f96,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-d777f009-1e7c-4841-8029-62e0712ab677,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-cf4b2ca2-00f8-425f-a54c-4e9d99d54799,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-8b488958-6a7d-4759-9fc7-831663e1ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-b717b632-d392-4b17-b6d6-3dd2eff4c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-a6021150-6c36-45ca-a98c-dbbb2294c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-bf56e2ed-6baf-404e-8d66-58205496c7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-271d82a7-54cd-43e9-8c88-088fdf47ab60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320654899-172.17.0.2-1597316864952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-bb939ca3-b0ed-4192-a9df-d2880ac0ba6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-3fbf24a5-a182-454e-b2db-93cdfeedbdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-ba93e24e-04d8-4554-bc91-ac89e3e29101,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-2c711be7-8e3b-48c9-a06b-ec4192c7c859,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-17c396ce-8c6d-428c-8257-b9c860a2c858,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-fe673291-fc36-48f6-9fe5-26db43ffdd21,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-8e9dca1c-3ec6-4fa0-8452-23cc31a96ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-1541e790-f856-45ea-b295-826014316515,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320654899-172.17.0.2-1597316864952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-bb939ca3-b0ed-4192-a9df-d2880ac0ba6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-3fbf24a5-a182-454e-b2db-93cdfeedbdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-ba93e24e-04d8-4554-bc91-ac89e3e29101,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-2c711be7-8e3b-48c9-a06b-ec4192c7c859,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-17c396ce-8c6d-428c-8257-b9c860a2c858,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-fe673291-fc36-48f6-9fe5-26db43ffdd21,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-8e9dca1c-3ec6-4fa0-8452-23cc31a96ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-1541e790-f856-45ea-b295-826014316515,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040165711-172.17.0.2-1597317022393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-2c8717a1-13a9-44b9-a510-493745e18000,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-5718ed69-d19e-4c1a-9ab2-aaceec3dcd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-78ed3090-680c-4665-97fe-2fefd85daeae,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-1da242c6-6bc4-4b0f-ad95-d4f2313b8e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-e90e4436-118f-4490-8664-bd66ae39e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-3e1c47e7-20c1-4efc-8059-e77b8edb8708,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-1e2fe176-e19b-49fc-82a6-2c2e0880dc58,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-4c2cad7a-2a9a-47c6-ac72-0012f10d1acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040165711-172.17.0.2-1597317022393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-2c8717a1-13a9-44b9-a510-493745e18000,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-5718ed69-d19e-4c1a-9ab2-aaceec3dcd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-78ed3090-680c-4665-97fe-2fefd85daeae,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-1da242c6-6bc4-4b0f-ad95-d4f2313b8e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-e90e4436-118f-4490-8664-bd66ae39e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-3e1c47e7-20c1-4efc-8059-e77b8edb8708,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-1e2fe176-e19b-49fc-82a6-2c2e0880dc58,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-4c2cad7a-2a9a-47c6-ac72-0012f10d1acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181270778-172.17.0.2-1597317177987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39008,DS-27e277ac-1f69-4ef7-8587-eea645c828c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-0c99fe0e-4576-4b24-9872-8fe847f19409,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-323fe535-503d-4e3c-8940-6685ee500de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-d773f5e3-608b-4913-ab55-03b4818c3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-796778c8-0c11-43b5-860b-b1a5ea0f59c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-d17501d5-f17e-4bef-b6d8-21daa0643b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-939272ed-1567-43b9-b060-2fb992a66f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-d1649a74-928b-4467-88a7-ba6dcad345c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181270778-172.17.0.2-1597317177987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39008,DS-27e277ac-1f69-4ef7-8587-eea645c828c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-0c99fe0e-4576-4b24-9872-8fe847f19409,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-323fe535-503d-4e3c-8940-6685ee500de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-d773f5e3-608b-4913-ab55-03b4818c3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-796778c8-0c11-43b5-860b-b1a5ea0f59c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-d17501d5-f17e-4bef-b6d8-21daa0643b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-939272ed-1567-43b9-b060-2fb992a66f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-d1649a74-928b-4467-88a7-ba6dcad345c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894233066-172.17.0.2-1597317378609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37116,DS-c9b6e268-7012-40c5-b25e-5afe4a19a6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-1d8e13d9-aa9a-445f-8c79-3b4ba8ec3a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-d745a099-4b55-4897-876f-17802475dfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-ed6e2b22-843d-4efe-a905-dd8b2b245e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-6662724c-306d-4f5d-8117-0ea7c6eedd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-1658a7bb-607e-45bc-a729-58a9521b4b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-2b56186c-e5cf-4198-9078-d761d0f40244,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-7cadcb79-b423-47c9-abf1-fa25da9cfb0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894233066-172.17.0.2-1597317378609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37116,DS-c9b6e268-7012-40c5-b25e-5afe4a19a6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-1d8e13d9-aa9a-445f-8c79-3b4ba8ec3a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-d745a099-4b55-4897-876f-17802475dfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-ed6e2b22-843d-4efe-a905-dd8b2b245e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-6662724c-306d-4f5d-8117-0ea7c6eedd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-1658a7bb-607e-45bc-a729-58a9521b4b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-2b56186c-e5cf-4198-9078-d761d0f40244,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-7cadcb79-b423-47c9-abf1-fa25da9cfb0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879042070-172.17.0.2-1597317489182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41695,DS-5a56d966-c41b-4667-87ab-f6c6d28ccec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-459c034c-6329-400b-b03b-af904c0f3fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-7d3445f0-2b02-4baa-8b7c-5de9e37a5e46,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-a7fdcd04-1752-4cde-91ee-b78046cbc743,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-c1f75694-0af0-4e8e-ba80-67ca963cd2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-22c64e21-dfb8-4c4a-a99b-b4654b88c6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-cfbeb325-8764-4c57-abb5-4efbb32d4fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-63bf8d27-5509-4032-b81a-78552bae0299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879042070-172.17.0.2-1597317489182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41695,DS-5a56d966-c41b-4667-87ab-f6c6d28ccec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-459c034c-6329-400b-b03b-af904c0f3fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-7d3445f0-2b02-4baa-8b7c-5de9e37a5e46,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-a7fdcd04-1752-4cde-91ee-b78046cbc743,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-c1f75694-0af0-4e8e-ba80-67ca963cd2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-22c64e21-dfb8-4c4a-a99b-b4654b88c6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-cfbeb325-8764-4c57-abb5-4efbb32d4fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-63bf8d27-5509-4032-b81a-78552bae0299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894896269-172.17.0.2-1597317568510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-c4676ae2-c851-4da2-a212-c2de021d8f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-9cb50975-8d89-496f-85d7-ad0671b99c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bfbd5494-8e7b-4ce7-bd91-053961467f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-9ef9bf74-dbc8-489e-b976-041c757ed32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-17ac8c33-45ff-47ee-925f-2d55adb2291b,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-cbe56ade-7749-4bd0-810a-cb99e9416fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-e7dd153d-345f-4bd2-8393-73afc655712c,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-455ddda5-7cb6-48ed-b46b-44fb1e3c3348,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894896269-172.17.0.2-1597317568510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-c4676ae2-c851-4da2-a212-c2de021d8f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-9cb50975-8d89-496f-85d7-ad0671b99c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bfbd5494-8e7b-4ce7-bd91-053961467f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-9ef9bf74-dbc8-489e-b976-041c757ed32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-17ac8c33-45ff-47ee-925f-2d55adb2291b,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-cbe56ade-7749-4bd0-810a-cb99e9416fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-e7dd153d-345f-4bd2-8393-73afc655712c,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-455ddda5-7cb6-48ed-b46b-44fb1e3c3348,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773300292-172.17.0.2-1597317613086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-6231e525-63d5-41f2-9267-e37f70562b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-83292c01-7268-4aea-a2c3-9b6fc2b6b020,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-04568008-5403-46ea-9270-e0b88a2f7982,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-6eac9cef-a402-480c-a6a2-d4789a7b98df,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-7374745b-895e-421c-8664-f5885a620f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-14c84ff7-baf4-4683-a64f-2078c05bfe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-213e152d-b9a2-433d-9d0e-f356f0faa19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-991335b3-fd3d-43f2-a961-8f16ba0c6f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773300292-172.17.0.2-1597317613086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39662,DS-6231e525-63d5-41f2-9267-e37f70562b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-83292c01-7268-4aea-a2c3-9b6fc2b6b020,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-04568008-5403-46ea-9270-e0b88a2f7982,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-6eac9cef-a402-480c-a6a2-d4789a7b98df,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-7374745b-895e-421c-8664-f5885a620f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-14c84ff7-baf4-4683-a64f-2078c05bfe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-213e152d-b9a2-433d-9d0e-f356f0faa19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-991335b3-fd3d-43f2-a961-8f16ba0c6f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547142841-172.17.0.2-1597317871315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40057,DS-126b8da5-303e-4821-964e-42b57568c895,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-1c98be12-19fa-451e-b6d3-df4a21535cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-438db51f-9034-48d3-b668-bc7d362cb985,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-d9002e58-3989-4bd7-a8d9-7012372fa08e,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-1ba00a1d-a127-4828-8637-dfbfcf10488f,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-67d12031-a338-47a1-a98b-f927f7263de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-5fc1ff20-7054-4c2a-8c5e-58694e5da295,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-6a8ba6a5-ae60-420b-8f8e-828e6fd745b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547142841-172.17.0.2-1597317871315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40057,DS-126b8da5-303e-4821-964e-42b57568c895,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-1c98be12-19fa-451e-b6d3-df4a21535cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-438db51f-9034-48d3-b668-bc7d362cb985,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-d9002e58-3989-4bd7-a8d9-7012372fa08e,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-1ba00a1d-a127-4828-8637-dfbfcf10488f,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-67d12031-a338-47a1-a98b-f927f7263de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-5fc1ff20-7054-4c2a-8c5e-58694e5da295,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-6a8ba6a5-ae60-420b-8f8e-828e6fd745b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280317389-172.17.0.2-1597318263230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-fe752ad4-0990-43fd-ac01-d413c9363a83,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-61994173-e4e8-480d-a5d1-da7a1a19c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-79613f9a-d486-418e-92ae-56d56d6c175c,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-72d252cf-edee-4945-9d40-4cf41ddd0ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-b9d14e4b-174a-4755-8633-b2b3bc1ca738,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-65647f00-c53b-44f8-bbd3-ea40808d794e,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-3b79ce8a-aa10-431d-b9ec-c0d83e6098ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-cf0d083b-f826-42ff-a36b-a5d925ec3658,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280317389-172.17.0.2-1597318263230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-fe752ad4-0990-43fd-ac01-d413c9363a83,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-61994173-e4e8-480d-a5d1-da7a1a19c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-79613f9a-d486-418e-92ae-56d56d6c175c,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-72d252cf-edee-4945-9d40-4cf41ddd0ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-b9d14e4b-174a-4755-8633-b2b3bc1ca738,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-65647f00-c53b-44f8-bbd3-ea40808d794e,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-3b79ce8a-aa10-431d-b9ec-c0d83e6098ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-cf0d083b-f826-42ff-a36b-a5d925ec3658,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5802
