reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424225459-172.17.0.16-1597394430987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42280,DS-267f4c82-4d2b-4157-a957-3f6d80be6a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-cee1eb82-5735-47a3-915c-91b6c052d5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-d86b8f45-56c0-4de0-9eb7-d6ccb278b579,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-9220091c-8177-47c6-97db-0330ac11ca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-d466ebb5-479f-48e5-9030-bb9949718e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-e669851f-61ba-409a-a83b-250e28ae4848,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-d9f2d0fb-622a-4534-bcb0-879243e862fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-b7cca3ec-0472-432d-979f-3492d3682cbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424225459-172.17.0.16-1597394430987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42280,DS-267f4c82-4d2b-4157-a957-3f6d80be6a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-cee1eb82-5735-47a3-915c-91b6c052d5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-d86b8f45-56c0-4de0-9eb7-d6ccb278b579,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-9220091c-8177-47c6-97db-0330ac11ca4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-d466ebb5-479f-48e5-9030-bb9949718e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-e669851f-61ba-409a-a83b-250e28ae4848,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-d9f2d0fb-622a-4534-bcb0-879243e862fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-b7cca3ec-0472-432d-979f-3492d3682cbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328667105-172.17.0.16-1597394567278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42601,DS-2beb7924-1a56-40c8-bf4b-cd6a01de6885,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-3a9f3cb2-dde3-4255-b616-37142bceb781,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-7f778da3-7c13-4bed-bf7d-6014bf89a21a,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-4f2f4357-1182-4bab-8b13-c400faa4629b,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-5af0d210-21f0-4de1-9078-38a1fa307228,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-b1f5fd35-44ee-4f46-b24a-12daba27f221,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d6e1bb85-e2aa-4e4b-8d61-9c4993ba35ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-bc19eae2-e54c-40b0-b9f5-999d030f8794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328667105-172.17.0.16-1597394567278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42601,DS-2beb7924-1a56-40c8-bf4b-cd6a01de6885,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-3a9f3cb2-dde3-4255-b616-37142bceb781,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-7f778da3-7c13-4bed-bf7d-6014bf89a21a,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-4f2f4357-1182-4bab-8b13-c400faa4629b,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-5af0d210-21f0-4de1-9078-38a1fa307228,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-b1f5fd35-44ee-4f46-b24a-12daba27f221,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d6e1bb85-e2aa-4e4b-8d61-9c4993ba35ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-bc19eae2-e54c-40b0-b9f5-999d030f8794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158450681-172.17.0.16-1597394706293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-653827c5-fb8d-4e69-9282-932ad36dde59,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-97b8a356-ceac-4911-a693-5bb2c3003ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-ad5b3763-085d-40a2-96a6-cdd49edb69f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-6bdab939-a066-469e-a499-e508ef4cdf07,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-fc6a526f-1687-4dde-a734-3447af27be5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-46bdd413-b777-4b3c-b5ce-b509082749fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-3a527f9e-8d53-48c2-83eb-4767556e04f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-fefad0dc-6fbb-4d21-a39f-377f80008bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158450681-172.17.0.16-1597394706293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-653827c5-fb8d-4e69-9282-932ad36dde59,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-97b8a356-ceac-4911-a693-5bb2c3003ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-ad5b3763-085d-40a2-96a6-cdd49edb69f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-6bdab939-a066-469e-a499-e508ef4cdf07,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-fc6a526f-1687-4dde-a734-3447af27be5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-46bdd413-b777-4b3c-b5ce-b509082749fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-3a527f9e-8d53-48c2-83eb-4767556e04f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-fefad0dc-6fbb-4d21-a39f-377f80008bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251461960-172.17.0.16-1597394878635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37014,DS-bd1b22e5-f908-43f7-988c-4040ad8a0c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-e6109b34-2f1a-45db-bc5e-8a4ed144b164,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-29e0ad38-a988-4b82-913c-f7daf8d79cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-9953d014-c8a2-4b54-85ab-2326d0150974,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-951a5665-431f-49a6-9438-21daa785ea00,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-16e49627-62af-45c0-b804-07e1f67d330b,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-f5b12d28-0d59-4893-9b2b-362e33dc43e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-5b5f5a2c-89e9-41cc-bb3e-4893bf1f3fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251461960-172.17.0.16-1597394878635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37014,DS-bd1b22e5-f908-43f7-988c-4040ad8a0c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-e6109b34-2f1a-45db-bc5e-8a4ed144b164,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-29e0ad38-a988-4b82-913c-f7daf8d79cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-9953d014-c8a2-4b54-85ab-2326d0150974,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-951a5665-431f-49a6-9438-21daa785ea00,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-16e49627-62af-45c0-b804-07e1f67d330b,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-f5b12d28-0d59-4893-9b2b-362e33dc43e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-5b5f5a2c-89e9-41cc-bb3e-4893bf1f3fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057158089-172.17.0.16-1597395108697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-430f52da-b810-44ed-80e7-56ebab7c4ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-8f2f22ce-6df5-4bca-9744-c5ca0b236c28,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-c7e47fa4-ad3f-4576-bd7f-2400051650d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-4cbf1366-afa2-4b89-aff7-97e451fb7b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-bfde9080-3df9-4cea-add0-9b02c6c3deb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-e0745719-d81b-4aab-bde6-5817f890ed77,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-dff23127-a7f5-4fa0-b12b-6b0355c9d8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-c8bfc649-34dc-4518-b8b2-491d41ada3ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057158089-172.17.0.16-1597395108697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-430f52da-b810-44ed-80e7-56ebab7c4ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-8f2f22ce-6df5-4bca-9744-c5ca0b236c28,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-c7e47fa4-ad3f-4576-bd7f-2400051650d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-4cbf1366-afa2-4b89-aff7-97e451fb7b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-bfde9080-3df9-4cea-add0-9b02c6c3deb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-e0745719-d81b-4aab-bde6-5817f890ed77,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-dff23127-a7f5-4fa0-b12b-6b0355c9d8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-c8bfc649-34dc-4518-b8b2-491d41ada3ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235042349-172.17.0.16-1597395213664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43172,DS-a2dcba09-f0c0-412c-8e92-548b45f54796,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-1772825d-45fd-432e-97a0-70a370790899,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-2d48acc9-874e-4113-9750-05e536c1436e,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-7fdc63fd-a083-46f3-b2a1-78f544e85050,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-e1d45f9d-0ba1-4f1f-beec-3ab310d532ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-4a6df132-027e-420d-8a67-a96084e301df,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-1a858191-be1e-4872-9dff-3041f3722ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-51ced04f-991b-4ddf-905c-cf7d142f8fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235042349-172.17.0.16-1597395213664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43172,DS-a2dcba09-f0c0-412c-8e92-548b45f54796,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-1772825d-45fd-432e-97a0-70a370790899,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-2d48acc9-874e-4113-9750-05e536c1436e,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-7fdc63fd-a083-46f3-b2a1-78f544e85050,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-e1d45f9d-0ba1-4f1f-beec-3ab310d532ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-4a6df132-027e-420d-8a67-a96084e301df,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-1a858191-be1e-4872-9dff-3041f3722ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-51ced04f-991b-4ddf-905c-cf7d142f8fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948874974-172.17.0.16-1597395272485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-770de77d-5c44-4d28-a40b-f616c0bf5089,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-a3212b34-f6bc-4eb0-9bf9-e7dd47969c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-aca6383a-8d28-4961-a985-bd76af83b128,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-18c7f3bc-1c79-4fc8-9862-cf22fa472c12,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-2db3b740-1951-4eb3-83bb-d9f4db373508,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-4b08c55d-0ee4-4769-897e-80f525ee0fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-53db07c7-9c3c-405b-bdd7-0feb450dd29d,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-736baa05-8e39-48fd-a884-eea55fd07b3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948874974-172.17.0.16-1597395272485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-770de77d-5c44-4d28-a40b-f616c0bf5089,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-a3212b34-f6bc-4eb0-9bf9-e7dd47969c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-aca6383a-8d28-4961-a985-bd76af83b128,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-18c7f3bc-1c79-4fc8-9862-cf22fa472c12,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-2db3b740-1951-4eb3-83bb-d9f4db373508,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-4b08c55d-0ee4-4769-897e-80f525ee0fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-53db07c7-9c3c-405b-bdd7-0feb450dd29d,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-736baa05-8e39-48fd-a884-eea55fd07b3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177239983-172.17.0.16-1597395645400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43629,DS-d2b0b0cb-eea5-4dfa-9822-aa62c9fce0af,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-185cb4a0-ab62-40ab-8cfe-59c927359809,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-a3ac81ba-c751-4ec4-8c26-ce1faa47ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-39538b1f-abd8-4949-9be1-569dcd829917,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-e003cf07-6589-4a48-bad3-2e272e21821f,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-9b4b3776-a0fc-4153-a52f-063bb954469d,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-c45cf0f4-40d0-40df-9bd3-559610f05bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-7c4e1900-5e94-4f35-8a3c-f6cc9f5f2a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177239983-172.17.0.16-1597395645400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43629,DS-d2b0b0cb-eea5-4dfa-9822-aa62c9fce0af,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-185cb4a0-ab62-40ab-8cfe-59c927359809,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-a3ac81ba-c751-4ec4-8c26-ce1faa47ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-39538b1f-abd8-4949-9be1-569dcd829917,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-e003cf07-6589-4a48-bad3-2e272e21821f,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-9b4b3776-a0fc-4153-a52f-063bb954469d,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-c45cf0f4-40d0-40df-9bd3-559610f05bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-7c4e1900-5e94-4f35-8a3c-f6cc9f5f2a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37785661-172.17.0.16-1597396253990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46187,DS-7681c534-4ea6-4e37-86cd-8e91790526fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-b54f3b2d-1c85-45a1-9f69-7d9747c714b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-f2d37f40-12f1-4583-b3d1-17d997a2e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-1ef875ad-34d2-4aba-b363-1d70ec38d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-3534ce6f-a0ca-425a-9733-52e1737fd9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-778ebc86-50f0-4145-80b9-9f3f0ffb752e,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-4d085251-3118-4c1f-ae29-2233012f5b27,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-ea4b505b-7977-4e58-8424-874a749531f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37785661-172.17.0.16-1597396253990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46187,DS-7681c534-4ea6-4e37-86cd-8e91790526fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-b54f3b2d-1c85-45a1-9f69-7d9747c714b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-f2d37f40-12f1-4583-b3d1-17d997a2e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-1ef875ad-34d2-4aba-b363-1d70ec38d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-3534ce6f-a0ca-425a-9733-52e1737fd9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-778ebc86-50f0-4145-80b9-9f3f0ffb752e,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-4d085251-3118-4c1f-ae29-2233012f5b27,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-ea4b505b-7977-4e58-8424-874a749531f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622642698-172.17.0.16-1597396291255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35486,DS-93243a74-bbb0-40ec-b133-47e0e27ae098,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-5737bb95-4c19-4b60-9c29-b80c5bd38555,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-405fe824-42ef-4045-95f0-032c78523888,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-a5d4dcff-991b-46ce-963e-73e2bfa20a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-55203c09-61d5-4472-911c-6ab8a41b607d,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-70376920-c2db-4d6e-928b-e23187c99129,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-a9090625-8a5e-4f2e-9671-93186dfbd5af,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-85fafabe-0575-406d-82cd-4519af45c577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622642698-172.17.0.16-1597396291255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35486,DS-93243a74-bbb0-40ec-b133-47e0e27ae098,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-5737bb95-4c19-4b60-9c29-b80c5bd38555,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-405fe824-42ef-4045-95f0-032c78523888,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-a5d4dcff-991b-46ce-963e-73e2bfa20a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-55203c09-61d5-4472-911c-6ab8a41b607d,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-70376920-c2db-4d6e-928b-e23187c99129,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-a9090625-8a5e-4f2e-9671-93186dfbd5af,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-85fafabe-0575-406d-82cd-4519af45c577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701776472-172.17.0.16-1597396567108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34314,DS-75268145-50fc-43b4-80cd-c9a9992dbf85,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-6665c550-e310-475f-a3e6-0798b6581f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-18841d32-e9e8-43fc-9bb8-379c3efbb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-62a92f3b-614b-4006-a753-1e5ef24ea814,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-f3f62c3b-057b-476f-8f12-207dbc6b79a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-c8d0a099-d7c5-4b03-900c-614571e51aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-24d9b007-b080-4e43-9af6-8c6d27355058,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-dd6d000c-bd9b-49e2-8a8e-aa7c66895a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701776472-172.17.0.16-1597396567108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34314,DS-75268145-50fc-43b4-80cd-c9a9992dbf85,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-6665c550-e310-475f-a3e6-0798b6581f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-18841d32-e9e8-43fc-9bb8-379c3efbb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-62a92f3b-614b-4006-a753-1e5ef24ea814,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-f3f62c3b-057b-476f-8f12-207dbc6b79a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-c8d0a099-d7c5-4b03-900c-614571e51aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-24d9b007-b080-4e43-9af6-8c6d27355058,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-dd6d000c-bd9b-49e2-8a8e-aa7c66895a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512112937-172.17.0.16-1597396778277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-1a851ad3-cf1d-42bf-86a1-998c71043fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-0a02c306-565a-4e71-a2a3-a388daa53ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-534af2f5-062c-4cba-a84b-5bf74c022324,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-e60de4d0-c6e4-48e3-8985-81d3f99f51fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-98ac9556-c876-4ac0-bce6-33351a45978a,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-352ea2fe-76ca-4f5e-a8dc-fde17743c703,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-1bb9178c-8b92-4d6c-835f-66dd2e06bf80,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-56384bd2-4627-4725-9422-61958ee0184b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512112937-172.17.0.16-1597396778277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-1a851ad3-cf1d-42bf-86a1-998c71043fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-0a02c306-565a-4e71-a2a3-a388daa53ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-534af2f5-062c-4cba-a84b-5bf74c022324,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-e60de4d0-c6e4-48e3-8985-81d3f99f51fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-98ac9556-c876-4ac0-bce6-33351a45978a,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-352ea2fe-76ca-4f5e-a8dc-fde17743c703,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-1bb9178c-8b92-4d6c-835f-66dd2e06bf80,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-56384bd2-4627-4725-9422-61958ee0184b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229510657-172.17.0.16-1597396945419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37009,DS-8c13a0a7-d552-4a06-b3b2-541e3038a06a,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-9c343c06-913b-4544-ac91-5cdbba641f40,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-9a1e5cfd-d7dc-4971-8c25-7905e199147f,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-cc51c8ed-b5e4-4d33-a3d2-7e88394ca169,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-e72bcf9a-3851-4527-9584-ff275fd52126,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-87a601db-eb87-4b26-8cda-6cf5fed898fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-493f42a8-c5f9-433b-849f-fe491127b49c,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-c3ef06c1-481f-4e10-83da-7da6e4692886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229510657-172.17.0.16-1597396945419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37009,DS-8c13a0a7-d552-4a06-b3b2-541e3038a06a,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-9c343c06-913b-4544-ac91-5cdbba641f40,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-9a1e5cfd-d7dc-4971-8c25-7905e199147f,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-cc51c8ed-b5e4-4d33-a3d2-7e88394ca169,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-e72bcf9a-3851-4527-9584-ff275fd52126,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-87a601db-eb87-4b26-8cda-6cf5fed898fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-493f42a8-c5f9-433b-849f-fe491127b49c,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-c3ef06c1-481f-4e10-83da-7da6e4692886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231679115-172.17.0.16-1597397173173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36086,DS-df882718-1862-41c0-a9d6-db5e52513284,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-09776b4b-e2ef-40f6-9718-bc5b278b6359,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-421eba0b-8377-47b3-ac76-5bfe60b2166e,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-65fb780a-ad11-4b9b-b477-2939aac3c987,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-ee1e2173-a213-4b8d-8336-4c547b05ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-199ec73a-30ef-4191-b2e4-73d3122aa992,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-05966c53-650c-48f1-a083-01f35fc82e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-184603fd-80dd-453e-a61a-6a77786b7f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231679115-172.17.0.16-1597397173173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36086,DS-df882718-1862-41c0-a9d6-db5e52513284,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-09776b4b-e2ef-40f6-9718-bc5b278b6359,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-421eba0b-8377-47b3-ac76-5bfe60b2166e,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-65fb780a-ad11-4b9b-b477-2939aac3c987,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-ee1e2173-a213-4b8d-8336-4c547b05ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-199ec73a-30ef-4191-b2e4-73d3122aa992,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-05966c53-650c-48f1-a083-01f35fc82e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-184603fd-80dd-453e-a61a-6a77786b7f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178824191-172.17.0.16-1597397314667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38030,DS-4199682e-5dc2-415d-ad86-401de8a19e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-5b6f7bc7-a272-4491-b4c7-dd27cb904fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-d20952a6-1ab5-4f31-b08a-71a0148fd101,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-94d95d28-34fb-423f-bfed-642a3e3438cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-5ea7d4aa-c3e9-4f02-8479-69776456fc55,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-f0caa97d-b0ef-4c66-a622-a4369730a556,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-f0fd8885-6920-4cee-ae2d-9f0c588c6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-80d47729-339c-439d-b3d2-fa02427d1a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178824191-172.17.0.16-1597397314667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38030,DS-4199682e-5dc2-415d-ad86-401de8a19e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-5b6f7bc7-a272-4491-b4c7-dd27cb904fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-d20952a6-1ab5-4f31-b08a-71a0148fd101,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-94d95d28-34fb-423f-bfed-642a3e3438cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-5ea7d4aa-c3e9-4f02-8479-69776456fc55,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-f0caa97d-b0ef-4c66-a622-a4369730a556,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-f0fd8885-6920-4cee-ae2d-9f0c588c6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-80d47729-339c-439d-b3d2-fa02427d1a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745196262-172.17.0.16-1597398308530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-0f107f49-efab-4988-b551-d4ab152d91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-8ba442e7-b172-42c2-80f4-5688d4cabb68,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-84ce4cdd-51d7-4fa7-b59e-06a4a7f1d824,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-07d37fd6-5455-439f-b386-02c4ecc04b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-c0ed3481-b62b-4f92-a637-4c49ce15e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-070e7087-0c12-4d79-8213-a82baeb94491,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-4976a794-e67f-4357-912d-928a5d7f716b,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-7c283e0b-7eb0-4b12-b7ff-f66dbb03ece6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745196262-172.17.0.16-1597398308530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-0f107f49-efab-4988-b551-d4ab152d91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-8ba442e7-b172-42c2-80f4-5688d4cabb68,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-84ce4cdd-51d7-4fa7-b59e-06a4a7f1d824,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-07d37fd6-5455-439f-b386-02c4ecc04b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-c0ed3481-b62b-4f92-a637-4c49ce15e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-070e7087-0c12-4d79-8213-a82baeb94491,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-4976a794-e67f-4357-912d-928a5d7f716b,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-7c283e0b-7eb0-4b12-b7ff-f66dbb03ece6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176415357-172.17.0.16-1597398623834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-2650d74b-ba59-4189-a766-a740c2d97627,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d2255f9f-32b4-4fae-aeee-48c8227b1cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-a38f7288-6e8f-4f8a-b41b-d06d799c2619,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-01f2bf90-e93d-4dab-9d20-8c546c8f5d43,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-751bba0e-c591-413b-a2aa-2e0434857ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-dd579a86-371d-4ae8-9810-dce99740914c,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-5fa88daa-0c16-428b-8ee9-bd7169b799dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-e40be3cd-9df2-4fcd-82c6-7f3af4554299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176415357-172.17.0.16-1597398623834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-2650d74b-ba59-4189-a766-a740c2d97627,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d2255f9f-32b4-4fae-aeee-48c8227b1cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-a38f7288-6e8f-4f8a-b41b-d06d799c2619,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-01f2bf90-e93d-4dab-9d20-8c546c8f5d43,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-751bba0e-c591-413b-a2aa-2e0434857ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-dd579a86-371d-4ae8-9810-dce99740914c,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-5fa88daa-0c16-428b-8ee9-bd7169b799dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-e40be3cd-9df2-4fcd-82c6-7f3af4554299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358549534-172.17.0.16-1597399001991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40076,DS-5dbef2ed-00dc-406e-85c7-414e8b137d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-b7f42a1b-d188-44ca-b33f-c9e688ab7b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-3c965e74-7c00-40ff-8d69-7444b71fdb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-a99c461a-f6aa-4465-a57b-a0fe247afe29,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-19b591e3-1b6e-4f86-b0b6-1216e565e840,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-41154027-8d6f-4912-b26c-2c0ac85c4dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-0d4bd3fc-6a35-4ee4-835b-6754986f8d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-717fb86c-0334-4422-afd7-9db1fffe0db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358549534-172.17.0.16-1597399001991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40076,DS-5dbef2ed-00dc-406e-85c7-414e8b137d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-b7f42a1b-d188-44ca-b33f-c9e688ab7b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-3c965e74-7c00-40ff-8d69-7444b71fdb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-a99c461a-f6aa-4465-a57b-a0fe247afe29,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-19b591e3-1b6e-4f86-b0b6-1216e565e840,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-41154027-8d6f-4912-b26c-2c0ac85c4dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-0d4bd3fc-6a35-4ee4-835b-6754986f8d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-717fb86c-0334-4422-afd7-9db1fffe0db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998290073-172.17.0.16-1597399136429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42176,DS-ab1fd983-81d4-4032-a559-388498c88b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-ca94ed21-28b6-42dd-bfad-8008e61d88df,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-b3e13a2f-04c8-463f-8379-f12cdc718bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-c2d8b294-3632-4145-a958-7338a5efb07a,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-8bfe9802-7ff4-48c8-80f4-d6d8a6887e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-4815a83d-06b9-4d99-a7da-2c4784f8566d,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-b072ba6b-5422-4bb5-888c-5d278bd50b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-e0c0b9b2-c904-4e65-8cdc-1bcf572bc54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998290073-172.17.0.16-1597399136429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42176,DS-ab1fd983-81d4-4032-a559-388498c88b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-ca94ed21-28b6-42dd-bfad-8008e61d88df,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-b3e13a2f-04c8-463f-8379-f12cdc718bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-c2d8b294-3632-4145-a958-7338a5efb07a,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-8bfe9802-7ff4-48c8-80f4-d6d8a6887e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-4815a83d-06b9-4d99-a7da-2c4784f8566d,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-b072ba6b-5422-4bb5-888c-5d278bd50b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-e0c0b9b2-c904-4e65-8cdc-1bcf572bc54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5129
