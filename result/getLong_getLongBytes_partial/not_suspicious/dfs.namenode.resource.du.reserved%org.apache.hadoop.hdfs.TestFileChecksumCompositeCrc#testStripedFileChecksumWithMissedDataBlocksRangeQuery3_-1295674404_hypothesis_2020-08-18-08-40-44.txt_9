reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525504702-172.17.0.14-1597740407718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42230,DS-a12d7f79-4d47-46b6-bab0-123df8ef44fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-39440171-bcca-4605-bb3a-72df37ef6a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-e052315f-f35a-4ca8-a772-473ee9cd7479,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-6c0ceef9-1671-4688-a091-0d04fe0943cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-0c3e00f6-2f2b-45af-bfb9-3a05a8bb8219,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-435f1003-8dd1-4ce8-b690-a824f4ee0116,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-face396c-f27a-451f-9b29-2f0bbc801b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-02ddc307-8262-4666-bcc1-5f8d3871b168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525504702-172.17.0.14-1597740407718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42230,DS-a12d7f79-4d47-46b6-bab0-123df8ef44fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-39440171-bcca-4605-bb3a-72df37ef6a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-e052315f-f35a-4ca8-a772-473ee9cd7479,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-6c0ceef9-1671-4688-a091-0d04fe0943cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-0c3e00f6-2f2b-45af-bfb9-3a05a8bb8219,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-435f1003-8dd1-4ce8-b690-a824f4ee0116,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-face396c-f27a-451f-9b29-2f0bbc801b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-02ddc307-8262-4666-bcc1-5f8d3871b168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591067842-172.17.0.14-1597740593066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-53eaa8b6-09b9-4a0d-8b81-397c249f2274,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-d3eece43-09b8-44a2-8ecc-229af93118a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-11ed237b-2216-402a-901b-28b4b105bf72,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-133077f3-8428-461e-8c89-131d957aeea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-72e1cf5f-0cec-4efd-91c3-b515804f81bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-8ef648e8-35af-4a38-b9fb-48b34efa2632,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-4e362846-2982-45f2-9ec7-b72c7852f742,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-2840aafa-a1ad-493e-90a2-ff7a116ab5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591067842-172.17.0.14-1597740593066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-53eaa8b6-09b9-4a0d-8b81-397c249f2274,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-d3eece43-09b8-44a2-8ecc-229af93118a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-11ed237b-2216-402a-901b-28b4b105bf72,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-133077f3-8428-461e-8c89-131d957aeea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-72e1cf5f-0cec-4efd-91c3-b515804f81bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-8ef648e8-35af-4a38-b9fb-48b34efa2632,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-4e362846-2982-45f2-9ec7-b72c7852f742,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-2840aafa-a1ad-493e-90a2-ff7a116ab5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744151778-172.17.0.14-1597740630942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-c5e51a8e-726f-4940-853e-1afa443c3ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-febe016a-1467-4754-827a-a38e5d01f66d,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-3dd50fd8-ea7e-43cb-a4a4-ba8cf613c2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-f98f2175-fbcd-4c4f-a4dc-3c2c42a90a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-be30d624-a975-4497-9305-fce8c10a43c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-9df24981-1d32-4a15-a8e0-eb5578bb596f,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-eaef7939-360b-4602-b321-d75b40e5554f,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-37a11d1a-61fd-4333-a04c-d5da4f1b011f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744151778-172.17.0.14-1597740630942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46284,DS-c5e51a8e-726f-4940-853e-1afa443c3ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-febe016a-1467-4754-827a-a38e5d01f66d,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-3dd50fd8-ea7e-43cb-a4a4-ba8cf613c2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-f98f2175-fbcd-4c4f-a4dc-3c2c42a90a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-be30d624-a975-4497-9305-fce8c10a43c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-9df24981-1d32-4a15-a8e0-eb5578bb596f,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-eaef7939-360b-4602-b321-d75b40e5554f,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-37a11d1a-61fd-4333-a04c-d5da4f1b011f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046671901-172.17.0.14-1597740668588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-49988b6c-e3bd-4ef3-ace0-56fb93e9dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-c284bab5-7acc-40e2-96d9-4d302084e7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-7922f4b2-dc32-40a5-9527-c4cf838c9b76,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-54820b9f-c5ed-4411-955f-b02bd591c912,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-0ed3a859-4ead-479a-9b36-63176744dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-1456375e-c5c2-4fce-aef7-dec4c324fc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-b9d5318b-8e68-42ae-bf49-63767847fb84,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-19cf2807-cad9-4ede-b950-1ca92457a0d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046671901-172.17.0.14-1597740668588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-49988b6c-e3bd-4ef3-ace0-56fb93e9dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-c284bab5-7acc-40e2-96d9-4d302084e7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-7922f4b2-dc32-40a5-9527-c4cf838c9b76,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-54820b9f-c5ed-4411-955f-b02bd591c912,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-0ed3a859-4ead-479a-9b36-63176744dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-1456375e-c5c2-4fce-aef7-dec4c324fc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-b9d5318b-8e68-42ae-bf49-63767847fb84,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-19cf2807-cad9-4ede-b950-1ca92457a0d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097473970-172.17.0.14-1597740748337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-c1d7917e-da89-4a93-b9b6-595481a242b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-2b698aee-9120-4227-b1ab-5af01c664832,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-a0919fc7-0dfb-4f49-a99f-0e061ba87f70,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-b3f004cc-2cac-44c0-aafc-deeb3f541b49,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-a6e1d84b-f199-47e0-acf7-bf7be0c53b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-ecb089bf-bd5c-4cbd-a545-37f76f9f8147,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-f67e4547-79e9-44a5-9469-67ea858a25dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-d84b11dc-1c03-4702-ba08-c9ad0d2b1a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097473970-172.17.0.14-1597740748337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-c1d7917e-da89-4a93-b9b6-595481a242b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-2b698aee-9120-4227-b1ab-5af01c664832,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-a0919fc7-0dfb-4f49-a99f-0e061ba87f70,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-b3f004cc-2cac-44c0-aafc-deeb3f541b49,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-a6e1d84b-f199-47e0-acf7-bf7be0c53b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-ecb089bf-bd5c-4cbd-a545-37f76f9f8147,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-f67e4547-79e9-44a5-9469-67ea858a25dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-d84b11dc-1c03-4702-ba08-c9ad0d2b1a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612706076-172.17.0.14-1597740782670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-c674c913-d26f-45b9-8056-bf048b711cca,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-e43f87ce-f0a3-45d4-81a6-64162a4b6ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-28d664bb-622b-44c2-afb4-49b804c05da8,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-f3cfd5f9-a595-4256-8ac5-a87ee1afca93,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-60373341-fdd6-46d5-963d-35965337c5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-379bdfcf-f361-4bea-b2f2-2d52f1046e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-665c67b7-be7b-42fe-bbb7-eb0164d145a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-49abee47-e75f-4a66-a14b-3cf7c37f3536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612706076-172.17.0.14-1597740782670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-c674c913-d26f-45b9-8056-bf048b711cca,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-e43f87ce-f0a3-45d4-81a6-64162a4b6ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-28d664bb-622b-44c2-afb4-49b804c05da8,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-f3cfd5f9-a595-4256-8ac5-a87ee1afca93,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-60373341-fdd6-46d5-963d-35965337c5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-379bdfcf-f361-4bea-b2f2-2d52f1046e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-665c67b7-be7b-42fe-bbb7-eb0164d145a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-49abee47-e75f-4a66-a14b-3cf7c37f3536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7170959-172.17.0.14-1597741195308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-8c48aa54-1db4-4a37-ae7b-fe4d7fc417bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-0eaea0f7-0538-4f84-b19c-7cee2f93c9da,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-0a6ba2c3-b9e7-4b21-ad24-2c9735839378,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-579f46b0-fd20-48fb-831b-e5afa8b5865b,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-fb66701c-2be1-448e-8fc5-a362d5ba19c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4e87840e-06a3-43ef-b4b3-2864cfc26e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-d3e069ca-defa-4f28-9860-e4e01e41cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-3569de5d-c0c3-4657-bde6-3763b49adc34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7170959-172.17.0.14-1597741195308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-8c48aa54-1db4-4a37-ae7b-fe4d7fc417bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-0eaea0f7-0538-4f84-b19c-7cee2f93c9da,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-0a6ba2c3-b9e7-4b21-ad24-2c9735839378,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-579f46b0-fd20-48fb-831b-e5afa8b5865b,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-fb66701c-2be1-448e-8fc5-a362d5ba19c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4e87840e-06a3-43ef-b4b3-2864cfc26e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-d3e069ca-defa-4f28-9860-e4e01e41cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-3569de5d-c0c3-4657-bde6-3763b49adc34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2208205-172.17.0.14-1597741376635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46765,DS-d33f020a-4a9f-425f-8275-333efee383f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-b68bd774-136e-464c-9ada-cadd6615e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-b2454603-6d87-44fa-bca6-a167792f506c,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-1fbdf353-0859-4f57-9d59-420787e964ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-e3517d24-c376-4816-ad8c-f889641121aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-126ae532-5d00-4a7a-8c13-e763fb66dfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-bb4eb9d9-f1ee-4990-9bd4-ee757e0ab69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-f880fb51-344d-4f10-920c-a8fb897babe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2208205-172.17.0.14-1597741376635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46765,DS-d33f020a-4a9f-425f-8275-333efee383f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-b68bd774-136e-464c-9ada-cadd6615e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-b2454603-6d87-44fa-bca6-a167792f506c,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-1fbdf353-0859-4f57-9d59-420787e964ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-e3517d24-c376-4816-ad8c-f889641121aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-126ae532-5d00-4a7a-8c13-e763fb66dfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-bb4eb9d9-f1ee-4990-9bd4-ee757e0ab69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-f880fb51-344d-4f10-920c-a8fb897babe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549547577-172.17.0.14-1597741480764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-01eafb4e-51b3-474f-8f17-6b7b3fa2c2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-f206edc7-bee6-49cd-a87c-e5d679eba2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-aeb93c3b-1964-4281-9928-e79044a1c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-b7048ac9-a66c-4d8d-95b0-0b892f0b94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-b853080e-49f0-494f-804c-fe2798715f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-01439d3b-5621-4570-89b5-274a4f173964,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-65f83323-481e-4b01-992b-1acbcdc01547,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-24d4f82b-6ba9-4688-8de9-df9651b6195e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549547577-172.17.0.14-1597741480764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-01eafb4e-51b3-474f-8f17-6b7b3fa2c2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-f206edc7-bee6-49cd-a87c-e5d679eba2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-aeb93c3b-1964-4281-9928-e79044a1c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-b7048ac9-a66c-4d8d-95b0-0b892f0b94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-b853080e-49f0-494f-804c-fe2798715f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-01439d3b-5621-4570-89b5-274a4f173964,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-65f83323-481e-4b01-992b-1acbcdc01547,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-24d4f82b-6ba9-4688-8de9-df9651b6195e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765943697-172.17.0.14-1597741510326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-d958a0f3-f588-4513-9289-a70054605e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-e629ceeb-8409-4425-866c-01f317f06aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-3a65d25d-be29-4245-b5f3-d7aabe99733c,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-a7cca18a-eddd-4d58-8bca-67e8959941d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-07860008-c26d-4428-ada6-b91294bfe56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-13ddb589-4e7c-41be-a7fb-0be15a9a45c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-a28accfd-daa0-4a2f-bc74-af74ee87b2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-c76725fd-cf13-422d-96b3-f1f06c5fce75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765943697-172.17.0.14-1597741510326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-d958a0f3-f588-4513-9289-a70054605e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-e629ceeb-8409-4425-866c-01f317f06aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-3a65d25d-be29-4245-b5f3-d7aabe99733c,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-a7cca18a-eddd-4d58-8bca-67e8959941d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-07860008-c26d-4428-ada6-b91294bfe56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-13ddb589-4e7c-41be-a7fb-0be15a9a45c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-a28accfd-daa0-4a2f-bc74-af74ee87b2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-c76725fd-cf13-422d-96b3-f1f06c5fce75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424390428-172.17.0.14-1597742059811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-043e6c60-1a16-4aab-9ea5-70afdee575ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-8f07b7d9-62e3-49c1-9405-d3abefcef164,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-e0e7e10a-c9a6-41f6-a0c5-0b1ad0b2891e,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-e76783c5-48d1-4eee-a363-1f5d5d0fd34c,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-f0ed1105-d8b4-48c8-b07a-320e499720e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-dc6b2405-dff5-4521-a530-b0e785253a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-94d7decf-def8-464d-86aa-abd0768aaf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-ceaf3557-3f35-4e63-9ee7-e2c11d317035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424390428-172.17.0.14-1597742059811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-043e6c60-1a16-4aab-9ea5-70afdee575ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-8f07b7d9-62e3-49c1-9405-d3abefcef164,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-e0e7e10a-c9a6-41f6-a0c5-0b1ad0b2891e,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-e76783c5-48d1-4eee-a363-1f5d5d0fd34c,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-f0ed1105-d8b4-48c8-b07a-320e499720e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-dc6b2405-dff5-4521-a530-b0e785253a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-94d7decf-def8-464d-86aa-abd0768aaf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-ceaf3557-3f35-4e63-9ee7-e2c11d317035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831630030-172.17.0.14-1597742333729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-2f9f4342-c122-4794-ab64-0ea364b9f237,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-2183014d-bf65-49c6-ba74-a713cfdbf3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-922a1373-cce8-46bc-b692-3527df521fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-ab4f66dd-a10a-4a30-992b-a37acd8b6d71,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-84b636a7-a24e-437e-a55b-5cd7ce558007,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-3edc410d-671f-4e5e-bcf1-8054d64b9a23,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-521a0fa8-c589-41a7-9898-a67fe6e10a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-2bf7a466-6f84-471f-95bc-a5f3ff668a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831630030-172.17.0.14-1597742333729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39173,DS-2f9f4342-c122-4794-ab64-0ea364b9f237,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-2183014d-bf65-49c6-ba74-a713cfdbf3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-922a1373-cce8-46bc-b692-3527df521fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-ab4f66dd-a10a-4a30-992b-a37acd8b6d71,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-84b636a7-a24e-437e-a55b-5cd7ce558007,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-3edc410d-671f-4e5e-bcf1-8054d64b9a23,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-521a0fa8-c589-41a7-9898-a67fe6e10a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-2bf7a466-6f84-471f-95bc-a5f3ff668a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625045267-172.17.0.14-1597742755082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-28617145-d9e7-49b1-b643-2bf8d8357227,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-df230f0d-fd59-4680-a7bf-f1dc8f152114,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-8c59e97d-3725-4848-ad39-c91e0bb5884f,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-c53ba65c-6a33-41d1-8dc6-f8818d0bd14f,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-98e9b360-7cab-4988-813d-e558078f2e79,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-c15e3e9e-312c-435c-9909-e651c7ce8130,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-bee1e220-7e95-49ca-bdde-2c2c8b423383,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-3af6b7c4-d689-45f5-b850-d51f0db28ac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625045267-172.17.0.14-1597742755082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-28617145-d9e7-49b1-b643-2bf8d8357227,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-df230f0d-fd59-4680-a7bf-f1dc8f152114,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-8c59e97d-3725-4848-ad39-c91e0bb5884f,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-c53ba65c-6a33-41d1-8dc6-f8818d0bd14f,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-98e9b360-7cab-4988-813d-e558078f2e79,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-c15e3e9e-312c-435c-9909-e651c7ce8130,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-bee1e220-7e95-49ca-bdde-2c2c8b423383,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-3af6b7c4-d689-45f5-b850-d51f0db28ac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-116297893-172.17.0.14-1597743649456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39429,DS-a6619fc9-4d93-4b6f-82b9-d5af76c1eb87,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-3c80bef9-b1eb-47e4-931e-0068de77b9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-ae12ab65-943a-47e9-a3f9-8143cd3379ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-177b31f4-a4e1-4a8c-92a3-c24ed5ee4b36,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-3c3c233f-8bd8-4bdb-96e3-a762f14b92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-685013d7-5895-4a0d-b0ab-69fe9f954b51,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-267848c9-4204-44ba-bc70-41bb5b0b0b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-049086bd-8c7e-4fd7-8b44-73b0b9e8d302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-116297893-172.17.0.14-1597743649456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39429,DS-a6619fc9-4d93-4b6f-82b9-d5af76c1eb87,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-3c80bef9-b1eb-47e4-931e-0068de77b9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-ae12ab65-943a-47e9-a3f9-8143cd3379ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-177b31f4-a4e1-4a8c-92a3-c24ed5ee4b36,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-3c3c233f-8bd8-4bdb-96e3-a762f14b92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-685013d7-5895-4a0d-b0ab-69fe9f954b51,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-267848c9-4204-44ba-bc70-41bb5b0b0b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-049086bd-8c7e-4fd7-8b44-73b0b9e8d302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545331840-172.17.0.14-1597743918406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34033,DS-9c050f78-c2c2-42ca-9dc2-6e6e29226fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-361b1817-da87-4d81-9d0c-606d9bc12311,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-d83633da-00bc-49ae-9a6a-125fcbff042c,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-985c362a-749e-4a8c-bb99-7201b77018b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-7c01c380-5813-4feb-a1bf-50c31a079779,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-6daa0098-749f-4a71-ac21-6fd8f1f54e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-969b037c-1c3a-4ad6-93db-688793d311d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-fb104ca6-a3ba-4d57-bc1a-fb3f4945cdc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545331840-172.17.0.14-1597743918406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34033,DS-9c050f78-c2c2-42ca-9dc2-6e6e29226fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-361b1817-da87-4d81-9d0c-606d9bc12311,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-d83633da-00bc-49ae-9a6a-125fcbff042c,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-985c362a-749e-4a8c-bb99-7201b77018b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-7c01c380-5813-4feb-a1bf-50c31a079779,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-6daa0098-749f-4a71-ac21-6fd8f1f54e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-969b037c-1c3a-4ad6-93db-688793d311d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-fb104ca6-a3ba-4d57-bc1a-fb3f4945cdc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021279005-172.17.0.14-1597744439428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-7f55d4b0-8d7b-4e46-80f6-b4e0ce9066fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-6ec8bbf2-8c52-41ef-a660-32a9918a6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-7624cc37-de87-4913-9bf4-7644bb945452,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-30c20e4f-a842-4120-8c0f-f5e67b3acbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-d80d09dd-7418-4253-af33-f8d6ba624999,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-6db394af-182b-44a1-b4a6-b9b8963c9b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-5c6078df-8c5a-47ed-b49a-7cba8ce0535c,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-a88e85f5-cbfb-438d-85fb-dff42ab27d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021279005-172.17.0.14-1597744439428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-7f55d4b0-8d7b-4e46-80f6-b4e0ce9066fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-6ec8bbf2-8c52-41ef-a660-32a9918a6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-7624cc37-de87-4913-9bf4-7644bb945452,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-30c20e4f-a842-4120-8c0f-f5e67b3acbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-d80d09dd-7418-4253-af33-f8d6ba624999,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-6db394af-182b-44a1-b4a6-b9b8963c9b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-5c6078df-8c5a-47ed-b49a-7cba8ce0535c,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-a88e85f5-cbfb-438d-85fb-dff42ab27d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943677095-172.17.0.14-1597744593845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-143f2ae5-8155-46e1-b3fa-c9b8f922c642,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-1def4dfd-485a-4037-9641-886fe30d1e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-98f0b7d2-94f5-4f81-9b7c-14cb997362ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-bbbb5d48-0015-4b30-91c6-811462b39a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-6ebbda5f-4de4-4dd8-a42d-be8ff9d3a34c,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-36e8c0e2-0aee-4d6e-83b2-77fd1398e01e,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-268b39df-8e29-4d79-8587-320af1254af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-ffa74f58-e246-4063-b95d-d86b77aa643b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943677095-172.17.0.14-1597744593845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-143f2ae5-8155-46e1-b3fa-c9b8f922c642,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-1def4dfd-485a-4037-9641-886fe30d1e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-98f0b7d2-94f5-4f81-9b7c-14cb997362ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-bbbb5d48-0015-4b30-91c6-811462b39a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-6ebbda5f-4de4-4dd8-a42d-be8ff9d3a34c,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-36e8c0e2-0aee-4d6e-83b2-77fd1398e01e,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-268b39df-8e29-4d79-8587-320af1254af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-ffa74f58-e246-4063-b95d-d86b77aa643b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986397233-172.17.0.14-1597744663958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38340,DS-6c33d77d-cae3-4148-807b-8a599483938c,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-a5d282ef-1483-4904-a586-f2929567d869,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-5ad64c65-65b7-4943-b1ca-8d7eb1a66e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-c61cddb4-4c2e-4c08-82b6-b194a4355d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-4a471424-0fb1-490e-aaa0-fd679227e311,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-96dbc7f7-0a86-4a5e-be6a-60e4d18a090d,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-00bb7c0e-91ab-4b2a-b33f-ba3f9d922639,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-65639d5f-07da-490f-9994-f9b3af9d40b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986397233-172.17.0.14-1597744663958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38340,DS-6c33d77d-cae3-4148-807b-8a599483938c,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-a5d282ef-1483-4904-a586-f2929567d869,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-5ad64c65-65b7-4943-b1ca-8d7eb1a66e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-c61cddb4-4c2e-4c08-82b6-b194a4355d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-4a471424-0fb1-490e-aaa0-fd679227e311,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-96dbc7f7-0a86-4a5e-be6a-60e4d18a090d,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-00bb7c0e-91ab-4b2a-b33f-ba3f9d922639,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-65639d5f-07da-490f-9994-f9b3af9d40b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327682445-172.17.0.14-1597745576325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39833,DS-765bbd12-100b-46aa-8c48-b4330aaf0c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-85df4a08-3153-49c3-9939-68c83a92c501,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-2657ee11-3a60-4cdb-a2bf-dc7f3ef293a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-3844af9e-bc04-43da-a815-b810858ec858,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-c5e91126-8953-4823-a237-b98688709cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-6caadd5a-1b5e-4730-83fe-dd546c0bea59,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-6b2c376f-70c9-4f61-aa75-744028cc2a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-83ce5f22-f77d-4bee-b68a-47f1daa75a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327682445-172.17.0.14-1597745576325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39833,DS-765bbd12-100b-46aa-8c48-b4330aaf0c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-85df4a08-3153-49c3-9939-68c83a92c501,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-2657ee11-3a60-4cdb-a2bf-dc7f3ef293a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-3844af9e-bc04-43da-a815-b810858ec858,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-c5e91126-8953-4823-a237-b98688709cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-6caadd5a-1b5e-4730-83fe-dd546c0bea59,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-6b2c376f-70c9-4f61-aa75-744028cc2a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-83ce5f22-f77d-4bee-b68a-47f1daa75a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 16384
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058745952-172.17.0.14-1597745654435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46463,DS-72d23815-63fb-4f60-b327-aedff87b66ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-8fcb9f11-73df-49ac-a041-04e9a70807b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-96a9d32f-f4c1-49a4-8356-4cd351520f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-56dc5799-146a-48de-ab04-a98aea2c05ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-3b3d2e8e-f34e-424a-8449-647ea205e722,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-a4beeac1-ebfb-4eba-9045-ea40a02e9808,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-fc03ffc8-c57e-48b2-a539-6ee9fb9622a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-a6d93daa-8ee9-4c9d-8310-049cdfd0c920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058745952-172.17.0.14-1597745654435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46463,DS-72d23815-63fb-4f60-b327-aedff87b66ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-8fcb9f11-73df-49ac-a041-04e9a70807b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-96a9d32f-f4c1-49a4-8356-4cd351520f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-56dc5799-146a-48de-ab04-a98aea2c05ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-3b3d2e8e-f34e-424a-8449-647ea205e722,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-a4beeac1-ebfb-4eba-9045-ea40a02e9808,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-fc03ffc8-c57e-48b2-a539-6ee9fb9622a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-a6d93daa-8ee9-4c9d-8310-049cdfd0c920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5678
