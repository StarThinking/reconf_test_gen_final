reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168126065-172.17.0.9-1597496092627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-2a13f965-3c68-407e-b9df-cb1e26bdb7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-5db41fbc-6872-4041-b982-ad709324c47c,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-a9561ef5-90b5-455a-b9e1-eb1dcc933272,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-0fcaeec2-2068-46ab-9dda-7747647b44cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-ffe75bf7-e850-4ddc-b1ed-f4fc7e275acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-b975fdb9-f0bc-4c46-a379-37cfe76862a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-45d8f882-7487-49df-944a-6d1a4206978c,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-4fed079c-0088-41d3-a73e-96c187c830a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168126065-172.17.0.9-1597496092627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-2a13f965-3c68-407e-b9df-cb1e26bdb7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-5db41fbc-6872-4041-b982-ad709324c47c,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-a9561ef5-90b5-455a-b9e1-eb1dcc933272,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-0fcaeec2-2068-46ab-9dda-7747647b44cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-ffe75bf7-e850-4ddc-b1ed-f4fc7e275acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-b975fdb9-f0bc-4c46-a379-37cfe76862a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-45d8f882-7487-49df-944a-6d1a4206978c,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-4fed079c-0088-41d3-a73e-96c187c830a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359903311-172.17.0.9-1597496130519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-32473957-2b55-4f6a-8f6c-8c18e79d7c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-de61c557-fb34-4965-b9f7-9ac9975cb30d,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-225c45d4-e3d7-4d19-a1a9-ad03b200137c,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-94283e5f-57c5-433f-b5aa-52162c9983e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-871acf4f-ddbc-4797-8ff0-2ff3ad6434dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-309ddd1a-97a7-44ef-8878-55419c903fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-8005743f-5f32-4af5-98f3-7712e07cd2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-bf18046f-e96c-459a-a251-091e810892a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359903311-172.17.0.9-1597496130519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-32473957-2b55-4f6a-8f6c-8c18e79d7c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-de61c557-fb34-4965-b9f7-9ac9975cb30d,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-225c45d4-e3d7-4d19-a1a9-ad03b200137c,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-94283e5f-57c5-433f-b5aa-52162c9983e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-871acf4f-ddbc-4797-8ff0-2ff3ad6434dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-309ddd1a-97a7-44ef-8878-55419c903fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-8005743f-5f32-4af5-98f3-7712e07cd2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-bf18046f-e96c-459a-a251-091e810892a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097770269-172.17.0.9-1597496622721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33569,DS-4c24b81f-6325-4633-8ed6-6bde570ab1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-1c97e77f-1191-4b08-883e-b400bc1cf824,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-37f39e75-7872-4515-bae9-6c694e9dc8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-957c5e04-c5b7-42c6-8bb4-23d4917a5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-2a725d6c-5c58-4df1-ba39-afdef301ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-7d69fabb-50a7-4043-afe7-1dcd26e5325c,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-b528efd2-53a7-408a-a96e-8e4dd4e44d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-7d731a64-1c32-4be9-ab88-fe77bba70544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097770269-172.17.0.9-1597496622721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33569,DS-4c24b81f-6325-4633-8ed6-6bde570ab1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-1c97e77f-1191-4b08-883e-b400bc1cf824,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-37f39e75-7872-4515-bae9-6c694e9dc8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-957c5e04-c5b7-42c6-8bb4-23d4917a5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-2a725d6c-5c58-4df1-ba39-afdef301ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-7d69fabb-50a7-4043-afe7-1dcd26e5325c,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-b528efd2-53a7-408a-a96e-8e4dd4e44d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-7d731a64-1c32-4be9-ab88-fe77bba70544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241106322-172.17.0.9-1597497224124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-7f0e64e8-325f-4c73-ab2c-5e81be7f2a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-4f22dbf5-74bb-4370-92ff-c0cb0553a838,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-c7f47bab-7ccc-427d-8241-39dee7d6689d,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-07c0e2ef-6282-4a8a-afc5-c248422da87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-51b6e621-71a1-48e5-a97e-6955f4b248e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-65c0e4f1-ce88-4223-90a1-429e920a2c21,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-0a77fde5-a38d-48bc-a95d-a287eab983e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-c5f2b28b-7237-478d-b329-bb2b4c5d44a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241106322-172.17.0.9-1597497224124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33832,DS-7f0e64e8-325f-4c73-ab2c-5e81be7f2a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-4f22dbf5-74bb-4370-92ff-c0cb0553a838,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-c7f47bab-7ccc-427d-8241-39dee7d6689d,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-07c0e2ef-6282-4a8a-afc5-c248422da87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-51b6e621-71a1-48e5-a97e-6955f4b248e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-65c0e4f1-ce88-4223-90a1-429e920a2c21,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-0a77fde5-a38d-48bc-a95d-a287eab983e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-c5f2b28b-7237-478d-b329-bb2b4c5d44a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525654292-172.17.0.9-1597497458789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40337,DS-894bf0bf-448e-4770-9b0a-8fefbee3ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-a40e6d17-0b71-494f-b82f-dead42a03dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-eb271387-f599-4310-b52c-098beb699268,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-cf815885-128d-4c0c-acf1-0b4982e7a0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-09e2a723-1b75-4613-b476-39253ce883c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-06607b2b-a78c-4e3b-b98b-278c96f34911,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-50969985-2293-4cf9-a8ad-15f01cb389c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-d269c7ff-5109-40ab-a268-d1b37be952ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525654292-172.17.0.9-1597497458789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40337,DS-894bf0bf-448e-4770-9b0a-8fefbee3ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-a40e6d17-0b71-494f-b82f-dead42a03dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-eb271387-f599-4310-b52c-098beb699268,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-cf815885-128d-4c0c-acf1-0b4982e7a0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-09e2a723-1b75-4613-b476-39253ce883c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-06607b2b-a78c-4e3b-b98b-278c96f34911,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-50969985-2293-4cf9-a8ad-15f01cb389c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-d269c7ff-5109-40ab-a268-d1b37be952ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619268504-172.17.0.9-1597498464764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41118,DS-88bda36a-88db-4267-b730-8ee395712c00,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-a8d9ed6b-154b-4d9f-a239-daf6813981b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-0d5a314b-0f6f-4606-928c-7c9c75a8119d,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-58b431bc-6df5-49b4-9d9c-93572642c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-44fa0204-df92-4cfa-8aef-9c98835cedbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-06c9af1f-6569-46e5-9b96-40f2cfb3ebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-c3804ba8-a006-482e-8e42-825f58e613c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-4db9a093-043f-462b-8a05-7bf0363ff320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619268504-172.17.0.9-1597498464764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41118,DS-88bda36a-88db-4267-b730-8ee395712c00,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-a8d9ed6b-154b-4d9f-a239-daf6813981b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-0d5a314b-0f6f-4606-928c-7c9c75a8119d,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-58b431bc-6df5-49b4-9d9c-93572642c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-44fa0204-df92-4cfa-8aef-9c98835cedbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-06c9af1f-6569-46e5-9b96-40f2cfb3ebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-c3804ba8-a006-482e-8e42-825f58e613c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-4db9a093-043f-462b-8a05-7bf0363ff320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532402016-172.17.0.9-1597498613838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-f1489807-6cea-4d23-b1d0-551124e9bb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-84c246d5-bb56-4c8d-97f3-a7cc0631e772,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-750103b4-6817-40d4-9755-aded2fd21f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-1c066884-ee81-4e17-ac36-bf3b60803de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-ac33c5f8-8916-485f-8554-8a5959705a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-0cf6886e-43f2-468a-b1e7-9a8205607135,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-941a6a2c-fe6f-44a7-a4fc-895675e691d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-72aa9418-2476-4b5a-9c2e-04c633fba12f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532402016-172.17.0.9-1597498613838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-f1489807-6cea-4d23-b1d0-551124e9bb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-84c246d5-bb56-4c8d-97f3-a7cc0631e772,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-750103b4-6817-40d4-9755-aded2fd21f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-1c066884-ee81-4e17-ac36-bf3b60803de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-ac33c5f8-8916-485f-8554-8a5959705a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-0cf6886e-43f2-468a-b1e7-9a8205607135,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-941a6a2c-fe6f-44a7-a4fc-895675e691d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-72aa9418-2476-4b5a-9c2e-04c633fba12f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9013336-172.17.0.9-1597499121804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38970,DS-fec69f90-533a-4fdd-8432-7c6f7ffd089e,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-20e9fd99-b1f0-4e80-bcd1-e82df5637db2,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-df3c7927-448f-4d5e-944a-a4e7dbaafa89,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-f80ea0dc-b990-4a38-ae2d-b4d35fb99a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-42897a16-ea1d-49b7-8542-0fe88bdc5548,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-33e5d04f-6137-4d62-a687-0402600d572a,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-60d61e60-1f5a-4eb9-b168-9b981cae9015,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-20559791-bf1d-4147-b92d-48facae1b821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9013336-172.17.0.9-1597499121804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38970,DS-fec69f90-533a-4fdd-8432-7c6f7ffd089e,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-20e9fd99-b1f0-4e80-bcd1-e82df5637db2,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-df3c7927-448f-4d5e-944a-a4e7dbaafa89,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-f80ea0dc-b990-4a38-ae2d-b4d35fb99a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-42897a16-ea1d-49b7-8542-0fe88bdc5548,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-33e5d04f-6137-4d62-a687-0402600d572a,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-60d61e60-1f5a-4eb9-b168-9b981cae9015,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-20559791-bf1d-4147-b92d-48facae1b821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304579214-172.17.0.9-1597499841472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-28641cbb-f690-4be5-ad48-c9b5e2404971,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-b48f7fd0-b303-4f1e-a7b8-80d432684e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-d8b7c5f6-e870-4747-bd61-9eef27a4e26b,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-c3539411-90e8-4e5d-aa6c-02abf68b5f43,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-051f435a-b080-476f-84fe-187760aa8bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-ef883461-bf6c-46e2-8637-1fa644f70f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-049a8e33-b2e7-497e-807a-1f03b1ceb387,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-84474c0b-5885-4823-a5b4-9738e5264105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304579214-172.17.0.9-1597499841472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-28641cbb-f690-4be5-ad48-c9b5e2404971,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-b48f7fd0-b303-4f1e-a7b8-80d432684e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-d8b7c5f6-e870-4747-bd61-9eef27a4e26b,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-c3539411-90e8-4e5d-aa6c-02abf68b5f43,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-051f435a-b080-476f-84fe-187760aa8bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-ef883461-bf6c-46e2-8637-1fa644f70f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-049a8e33-b2e7-497e-807a-1f03b1ceb387,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-84474c0b-5885-4823-a5b4-9738e5264105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721070434-172.17.0.9-1597500255223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38905,DS-f3016265-9607-44c3-8cb9-1a5eec4b130b,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-ba39854f-0cee-4a07-a99d-f07da272d54b,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-a2c42d40-b844-4e3e-af42-01f13e25f794,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-5eb2bae3-0b1a-4229-8495-d8a22945fac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-8888c67d-2eb5-4c08-bfcf-ec529a4f353a,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-59a14a49-f48a-49d6-a5a1-5c1653a4921c,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-70fafa6a-3d05-49f4-b9f2-cb35a78082b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-a5160138-88c1-4f29-8929-e7e2068bd039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721070434-172.17.0.9-1597500255223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38905,DS-f3016265-9607-44c3-8cb9-1a5eec4b130b,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-ba39854f-0cee-4a07-a99d-f07da272d54b,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-a2c42d40-b844-4e3e-af42-01f13e25f794,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-5eb2bae3-0b1a-4229-8495-d8a22945fac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-8888c67d-2eb5-4c08-bfcf-ec529a4f353a,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-59a14a49-f48a-49d6-a5a1-5c1653a4921c,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-70fafa6a-3d05-49f4-b9f2-cb35a78082b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-a5160138-88c1-4f29-8929-e7e2068bd039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080521791-172.17.0.9-1597500484264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34901,DS-f32b30b9-cb58-4bdf-b4f0-db1a88a4e907,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-5a7d1537-d93a-4751-9253-da69e50f113f,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-3a83d103-f59b-4c75-b81c-5dbabf433cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-2ee97ddd-3ef9-4221-b486-5c4bcf3fa8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-8bfcafad-f34e-4abe-ac68-f103e3543211,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-b2302299-eee0-47ed-8f46-b37ef771ff0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-e79f263c-aeba-4e52-8324-c47198531681,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-dd350d2e-3908-416f-b180-cebe8938a65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080521791-172.17.0.9-1597500484264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34901,DS-f32b30b9-cb58-4bdf-b4f0-db1a88a4e907,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-5a7d1537-d93a-4751-9253-da69e50f113f,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-3a83d103-f59b-4c75-b81c-5dbabf433cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-2ee97ddd-3ef9-4221-b486-5c4bcf3fa8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-8bfcafad-f34e-4abe-ac68-f103e3543211,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-b2302299-eee0-47ed-8f46-b37ef771ff0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-e79f263c-aeba-4e52-8324-c47198531681,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-dd350d2e-3908-416f-b180-cebe8938a65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043483063-172.17.0.9-1597500874593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34369,DS-0b8c91e4-7561-4b91-9792-b3fcaa97d4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-26ac1e95-fd1e-480c-979c-4f0159e90917,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-dbfe8836-14d3-4716-924b-ca4fbe15c3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-66333107-9721-4b58-98bd-0f320638b076,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-1e96191b-7f15-47aa-88da-1c8c6d7feaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-3ce24d4c-7fff-49d6-a05b-9abc1cbc3639,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-08fb16b9-ed8d-4347-9075-96a074c45ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-74b5acc5-a83d-42a8-ba6a-ff9ddbacf35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043483063-172.17.0.9-1597500874593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34369,DS-0b8c91e4-7561-4b91-9792-b3fcaa97d4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-26ac1e95-fd1e-480c-979c-4f0159e90917,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-dbfe8836-14d3-4716-924b-ca4fbe15c3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-66333107-9721-4b58-98bd-0f320638b076,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-1e96191b-7f15-47aa-88da-1c8c6d7feaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-3ce24d4c-7fff-49d6-a05b-9abc1cbc3639,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-08fb16b9-ed8d-4347-9075-96a074c45ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-74b5acc5-a83d-42a8-ba6a-ff9ddbacf35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638148582-172.17.0.9-1597500911611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40291,DS-962a8cd9-1e7b-43d8-9f3b-2f3a5f81e641,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-fc121c9a-aeae-4d6b-8ad3-b10a4f654edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-90d510d4-702b-4642-a8f8-4c33da172957,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-518c451f-7eed-45d6-bada-7d3cfcad31f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-8580d040-e134-4e13-a031-4ca8d397b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-6a6be822-68e1-4e7b-9ffc-d758da8c96f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-b05a856b-7ed9-4176-a056-d5e9842661b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-ddebe882-6053-4b03-a8ec-0172541dae07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638148582-172.17.0.9-1597500911611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40291,DS-962a8cd9-1e7b-43d8-9f3b-2f3a5f81e641,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-fc121c9a-aeae-4d6b-8ad3-b10a4f654edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-90d510d4-702b-4642-a8f8-4c33da172957,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-518c451f-7eed-45d6-bada-7d3cfcad31f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-8580d040-e134-4e13-a031-4ca8d397b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-6a6be822-68e1-4e7b-9ffc-d758da8c96f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-b05a856b-7ed9-4176-a056-d5e9842661b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-ddebe882-6053-4b03-a8ec-0172541dae07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323176990-172.17.0.9-1597501281050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-ac955c68-94d5-4ce1-baf3-d882bf4911e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-431ec2e6-0ea0-4df6-9ab9-3b3cb3f80b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-df37a60d-668b-4401-bf14-c92739d33631,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-99f294e9-6eba-40fb-8163-9a24c66c1478,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-15e42f3e-4ed0-45df-97e8-9e036a08ab47,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-0df89bdb-5bd3-4059-b655-cc5f058e7942,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-59a76e55-5229-493a-869d-85489135bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-d872d69d-0dc3-490f-935e-3c72cefc09b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323176990-172.17.0.9-1597501281050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-ac955c68-94d5-4ce1-baf3-d882bf4911e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-431ec2e6-0ea0-4df6-9ab9-3b3cb3f80b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-df37a60d-668b-4401-bf14-c92739d33631,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-99f294e9-6eba-40fb-8163-9a24c66c1478,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-15e42f3e-4ed0-45df-97e8-9e036a08ab47,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-0df89bdb-5bd3-4059-b655-cc5f058e7942,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-59a76e55-5229-493a-869d-85489135bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-d872d69d-0dc3-490f-935e-3c72cefc09b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753387372-172.17.0.9-1597501322549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-b39080f5-837d-4ab4-87fd-67d3287babfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-a77ad255-06cb-4915-867d-f59a9fcc47c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-9cf9babf-d15b-4406-9c9f-fd68b3d65a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-bddfd0ae-d1b6-4dd4-8c56-7d4d08553bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-12e0c6b8-b878-42fc-9c4a-55bf218d2a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-12cd4f1a-b16a-4f83-8f11-52eedd8c2e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-f35f9fec-3199-48f9-a068-acf42ea7b841,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-2b0b1ed9-db26-41e2-86e3-84b0dfdc1952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753387372-172.17.0.9-1597501322549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-b39080f5-837d-4ab4-87fd-67d3287babfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-a77ad255-06cb-4915-867d-f59a9fcc47c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-9cf9babf-d15b-4406-9c9f-fd68b3d65a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-bddfd0ae-d1b6-4dd4-8c56-7d4d08553bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-12e0c6b8-b878-42fc-9c4a-55bf218d2a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-12cd4f1a-b16a-4f83-8f11-52eedd8c2e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-f35f9fec-3199-48f9-a068-acf42ea7b841,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-2b0b1ed9-db26-41e2-86e3-84b0dfdc1952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416993460-172.17.0.9-1597501398025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-4d8b3207-54b8-435f-a600-ef6539657fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-8fce8c54-98ec-4d7b-818f-de920c5888e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-f65e894d-8288-40e6-9305-8f04dfb6a10c,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-19111d43-b321-4e2e-8dc8-b1ef0acec5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-b3ead873-5174-4315-8248-c98635a3b568,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-03cb6cc3-8508-40e6-a00b-092ca52a0cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-487059cc-8587-4e35-ba9c-c67642f4e908,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-a4b7bfa5-6160-4871-83d0-2415e001a413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416993460-172.17.0.9-1597501398025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-4d8b3207-54b8-435f-a600-ef6539657fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-8fce8c54-98ec-4d7b-818f-de920c5888e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-f65e894d-8288-40e6-9305-8f04dfb6a10c,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-19111d43-b321-4e2e-8dc8-b1ef0acec5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-b3ead873-5174-4315-8248-c98635a3b568,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-03cb6cc3-8508-40e6-a00b-092ca52a0cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-487059cc-8587-4e35-ba9c-c67642f4e908,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-a4b7bfa5-6160-4871-83d0-2415e001a413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69836642-172.17.0.9-1597501477919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-661b22d4-dde1-44d7-8cd7-d8df407904e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-1ef605d3-f82e-43b0-b8a9-623159c78680,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-1397c752-0b3b-4e54-90ab-4e3ade6f88d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-fe61bd2e-a6c6-4c77-8c33-282f45ff54f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-6123c2c3-8ead-4769-91e3-e3dcd5aa50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-f298308e-7f64-45f0-9db0-95345a4b95b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-bb4ce5fe-2e5d-4764-b3de-2089b0ebf699,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-cb6262f5-3fd0-4dc4-b205-cd2ec065b082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69836642-172.17.0.9-1597501477919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-661b22d4-dde1-44d7-8cd7-d8df407904e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-1ef605d3-f82e-43b0-b8a9-623159c78680,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-1397c752-0b3b-4e54-90ab-4e3ade6f88d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-fe61bd2e-a6c6-4c77-8c33-282f45ff54f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-6123c2c3-8ead-4769-91e3-e3dcd5aa50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-f298308e-7f64-45f0-9db0-95345a4b95b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-bb4ce5fe-2e5d-4764-b3de-2089b0ebf699,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-cb6262f5-3fd0-4dc4-b205-cd2ec065b082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5595
