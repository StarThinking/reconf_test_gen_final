reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342499997-172.17.0.15-1597398451655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43588,DS-7949564a-b53b-4a0b-b8bc-1285fb479f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-c59c4ded-4837-4afe-8847-a2867ff9e9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-7031c426-5068-4907-b1fa-0405e812cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-2098b625-85f6-42b3-970c-ad6981826091,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-b07ea69d-d20f-481d-a283-c98913054a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-c85528e8-0785-4f56-a197-99b645c281d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-861475e8-fc7c-4646-b77d-d76059afe692,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-350d1e85-f5fb-4dac-b950-23fdf3451241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342499997-172.17.0.15-1597398451655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43588,DS-7949564a-b53b-4a0b-b8bc-1285fb479f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-c59c4ded-4837-4afe-8847-a2867ff9e9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-7031c426-5068-4907-b1fa-0405e812cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-2098b625-85f6-42b3-970c-ad6981826091,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-b07ea69d-d20f-481d-a283-c98913054a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-c85528e8-0785-4f56-a197-99b645c281d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-861475e8-fc7c-4646-b77d-d76059afe692,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-350d1e85-f5fb-4dac-b950-23fdf3451241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840907650-172.17.0.15-1597398842824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-4f2edf2b-84d0-4e3c-8165-f8ecbca5b099,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-367b3753-f308-4d65-9314-57525b10f8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-efd8b111-87b5-4ca5-b11f-8fb07e2a87f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-bedab2fd-ef6d-441b-af5d-a291040e1b55,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-a614496d-ca44-4ef8-b605-dcc52792ad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-f0305c4e-1f74-4ddd-979e-3cc6c4deb8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-fd2f37c5-f029-4c18-bd9c-ba7b648418a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-0ed96439-83c1-49c5-b7b9-f96bfccb93ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840907650-172.17.0.15-1597398842824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-4f2edf2b-84d0-4e3c-8165-f8ecbca5b099,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-367b3753-f308-4d65-9314-57525b10f8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-efd8b111-87b5-4ca5-b11f-8fb07e2a87f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-bedab2fd-ef6d-441b-af5d-a291040e1b55,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-a614496d-ca44-4ef8-b605-dcc52792ad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-f0305c4e-1f74-4ddd-979e-3cc6c4deb8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-fd2f37c5-f029-4c18-bd9c-ba7b648418a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-0ed96439-83c1-49c5-b7b9-f96bfccb93ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145073430-172.17.0.15-1597398924524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-655b187a-fa56-473c-a4ed-2ebe1caae3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-7edbcbd8-8e17-4895-ae96-b31cbb33305f,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-78ee7589-fff8-43af-9e6c-066325f6bc12,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-54ae78cc-e5af-4c64-a9b4-11cdd32c344f,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-a9fc32b5-703d-4a5c-a482-7981c03e94bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-a734bb02-be93-4956-a7f8-21d30f0a2699,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-16ad8196-8490-40f6-9f94-bc6e02a4f2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-57b6eacd-251e-4d15-b85a-d217b6ff01e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145073430-172.17.0.15-1597398924524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-655b187a-fa56-473c-a4ed-2ebe1caae3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-7edbcbd8-8e17-4895-ae96-b31cbb33305f,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-78ee7589-fff8-43af-9e6c-066325f6bc12,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-54ae78cc-e5af-4c64-a9b4-11cdd32c344f,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-a9fc32b5-703d-4a5c-a482-7981c03e94bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-a734bb02-be93-4956-a7f8-21d30f0a2699,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-16ad8196-8490-40f6-9f94-bc6e02a4f2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-57b6eacd-251e-4d15-b85a-d217b6ff01e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085421913-172.17.0.15-1597399059468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-6104fd5b-dd41-4e17-b398-8c6afea0f887,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-07268c4f-8d5e-4e68-8932-35878bc7bb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-e4c776da-84a6-4e67-91a1-8f5f1b2697ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-983f8c46-a908-4c62-b7b3-43887fb7aa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-e3128f3e-1a4d-4e30-a515-502798886951,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-235de853-de5c-4a2e-acac-57af0e54c714,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-cbdca8bd-be63-4228-b967-94f855cba605,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-0c54953c-3b08-4e2d-bfca-26fa9890bcef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085421913-172.17.0.15-1597399059468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-6104fd5b-dd41-4e17-b398-8c6afea0f887,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-07268c4f-8d5e-4e68-8932-35878bc7bb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-e4c776da-84a6-4e67-91a1-8f5f1b2697ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-983f8c46-a908-4c62-b7b3-43887fb7aa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-e3128f3e-1a4d-4e30-a515-502798886951,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-235de853-de5c-4a2e-acac-57af0e54c714,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-cbdca8bd-be63-4228-b967-94f855cba605,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-0c54953c-3b08-4e2d-bfca-26fa9890bcef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866666177-172.17.0.15-1597399270627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44209,DS-bbaa3561-6804-4c40-bd0e-cc3114ba9a93,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-cf3e6b70-7b63-4b71-bb73-c6268407df2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-809b7f30-b5d5-4eea-9e45-a3f1eb05060c,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-3d0092c9-d406-4d92-b9fb-e6aeda69de77,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-ddd27227-68e4-4c2e-bb58-5c790cf7a4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-807af10c-69fc-412d-93f6-af46f17bb368,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-0a7d064f-1f5e-4edb-911c-a0f91af4a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-ede73e8d-a195-4bad-ad86-c23afec3e151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866666177-172.17.0.15-1597399270627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44209,DS-bbaa3561-6804-4c40-bd0e-cc3114ba9a93,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-cf3e6b70-7b63-4b71-bb73-c6268407df2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-809b7f30-b5d5-4eea-9e45-a3f1eb05060c,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-3d0092c9-d406-4d92-b9fb-e6aeda69de77,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-ddd27227-68e4-4c2e-bb58-5c790cf7a4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-807af10c-69fc-412d-93f6-af46f17bb368,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-0a7d064f-1f5e-4edb-911c-a0f91af4a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-ede73e8d-a195-4bad-ad86-c23afec3e151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253361981-172.17.0.15-1597399412641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-21ea669d-6fec-43cc-9ce3-a32c9fc3d7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-0a4b33c8-65aa-4f94-af2b-b44aa1296048,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-93124d5f-9a9b-40a2-8b40-4c36ffeba7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-03503fe9-ae03-41fc-bde6-3a16c6b460a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-ea5e4b4b-5f66-4553-9fab-5b41277c5584,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-3fb784f0-2c11-4bc0-b194-eb0c78a4a1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-377deeae-9193-4cd9-bc7a-f5bbd0571f84,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-aac07f2c-419c-41f3-ba6d-89c13d88b84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253361981-172.17.0.15-1597399412641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43191,DS-21ea669d-6fec-43cc-9ce3-a32c9fc3d7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-0a4b33c8-65aa-4f94-af2b-b44aa1296048,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-93124d5f-9a9b-40a2-8b40-4c36ffeba7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-03503fe9-ae03-41fc-bde6-3a16c6b460a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-ea5e4b4b-5f66-4553-9fab-5b41277c5584,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-3fb784f0-2c11-4bc0-b194-eb0c78a4a1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-377deeae-9193-4cd9-bc7a-f5bbd0571f84,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-aac07f2c-419c-41f3-ba6d-89c13d88b84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251893290-172.17.0.15-1597399824229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42627,DS-e1864b2d-f1eb-403c-b172-aa0109bf6561,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-d4929eb6-0e4e-4583-837a-662fa84a065c,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-345ea860-9643-40a0-bf24-37b18a75efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-1558f47f-84e6-4209-9126-577dbd890672,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-6858cefa-2abe-4326-9249-815c4bb40303,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-8dc9cdb0-2dd4-4f61-a376-1e0fe8251ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-a6f75f80-c5a8-4466-b262-170d27eff618,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-a0a76274-c465-4292-a1db-1a4aae908206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251893290-172.17.0.15-1597399824229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42627,DS-e1864b2d-f1eb-403c-b172-aa0109bf6561,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-d4929eb6-0e4e-4583-837a-662fa84a065c,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-345ea860-9643-40a0-bf24-37b18a75efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-1558f47f-84e6-4209-9126-577dbd890672,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-6858cefa-2abe-4326-9249-815c4bb40303,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-8dc9cdb0-2dd4-4f61-a376-1e0fe8251ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-a6f75f80-c5a8-4466-b262-170d27eff618,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-a0a76274-c465-4292-a1db-1a4aae908206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338156344-172.17.0.15-1597401144346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42573,DS-0d8a5008-66e8-4d40-84d6-ea6c9135e301,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-067fed82-c2a2-4c6a-bf99-4d52e532a08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-3e1ce807-2fa0-4fb1-919f-f79e81e2aa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-b4b6e8d2-ef23-4a4a-a7b1-79a4d1ab8b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-b1f8165f-80af-4d83-ac75-a4510c33d90d,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-3e8b4e21-52b7-4f90-8b35-b78b79be2b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-fab77899-1595-4e2f-8300-eba9274ee6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-547e199f-c663-462b-9d26-72c20a82f4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338156344-172.17.0.15-1597401144346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42573,DS-0d8a5008-66e8-4d40-84d6-ea6c9135e301,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-067fed82-c2a2-4c6a-bf99-4d52e532a08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-3e1ce807-2fa0-4fb1-919f-f79e81e2aa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-b4b6e8d2-ef23-4a4a-a7b1-79a4d1ab8b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-b1f8165f-80af-4d83-ac75-a4510c33d90d,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-3e8b4e21-52b7-4f90-8b35-b78b79be2b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-fab77899-1595-4e2f-8300-eba9274ee6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-547e199f-c663-462b-9d26-72c20a82f4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344166752-172.17.0.15-1597401435334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-31a1f3da-d3b8-4b5e-83be-dc3f00cd0026,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-4500f473-b7fe-41be-9604-8d8af55aef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-569a29cb-c025-40be-96df-1df7472aad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-96c711bb-1dbf-4535-afbc-8ba7481862c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-6689e5f9-0804-4694-b76f-5a5cf452413d,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-9e3aad55-881b-458f-9a38-d4ae4a60b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-e16b0583-0f3a-4271-a341-e71da5f541a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-5c7be5e6-375a-4a43-a7df-9df0058b1bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344166752-172.17.0.15-1597401435334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-31a1f3da-d3b8-4b5e-83be-dc3f00cd0026,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-4500f473-b7fe-41be-9604-8d8af55aef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-569a29cb-c025-40be-96df-1df7472aad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-96c711bb-1dbf-4535-afbc-8ba7481862c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-6689e5f9-0804-4694-b76f-5a5cf452413d,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-9e3aad55-881b-458f-9a38-d4ae4a60b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-e16b0583-0f3a-4271-a341-e71da5f541a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-5c7be5e6-375a-4a43-a7df-9df0058b1bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447367766-172.17.0.15-1597401605757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-5a5f1a04-9801-42aa-8d66-74838faf460f,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-b9c7cbcb-fa0e-4625-8d1c-db52e6fa55e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-8f474393-3fd8-4d4f-9553-f2b83ef18c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-25c018d8-9def-4a7a-ab69-5cf13ac4ad92,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-f9c9750c-bcfe-427a-ac6c-f559d321180d,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-b893175a-f16f-427a-a10e-9d7cac5faa67,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-ca05afa7-adc5-4e34-a083-d31f27bcceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-65a88f21-b476-401a-be23-e805a62b3f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447367766-172.17.0.15-1597401605757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35039,DS-5a5f1a04-9801-42aa-8d66-74838faf460f,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-b9c7cbcb-fa0e-4625-8d1c-db52e6fa55e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-8f474393-3fd8-4d4f-9553-f2b83ef18c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-25c018d8-9def-4a7a-ab69-5cf13ac4ad92,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-f9c9750c-bcfe-427a-ac6c-f559d321180d,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-b893175a-f16f-427a-a10e-9d7cac5faa67,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-ca05afa7-adc5-4e34-a083-d31f27bcceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-65a88f21-b476-401a-be23-e805a62b3f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186815921-172.17.0.15-1597401946808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37439,DS-e1d9ea91-7910-459d-ae17-720d431a5d61,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-462a08a7-4b6f-426b-a0fb-40507d1eff00,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-0b68ca3c-069c-41d4-af3c-3f33324e7897,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-9aa9aeae-9322-4823-ae32-179d645ee42c,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-a7fbe427-73b0-4592-b753-13360522f8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-bedef951-2ec9-4e40-ab5d-eb54e0f97631,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-34edcb49-c461-41f2-aa8a-67d7ad3ee03e,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-b6e4cd8f-afc5-429e-9832-96bf5dfd1184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186815921-172.17.0.15-1597401946808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37439,DS-e1d9ea91-7910-459d-ae17-720d431a5d61,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-462a08a7-4b6f-426b-a0fb-40507d1eff00,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-0b68ca3c-069c-41d4-af3c-3f33324e7897,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-9aa9aeae-9322-4823-ae32-179d645ee42c,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-a7fbe427-73b0-4592-b753-13360522f8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-bedef951-2ec9-4e40-ab5d-eb54e0f97631,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-34edcb49-c461-41f2-aa8a-67d7ad3ee03e,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-b6e4cd8f-afc5-429e-9832-96bf5dfd1184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061677372-172.17.0.15-1597402135957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-dada6dc9-aee6-491b-ae63-17c5b57b17f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-6480a0bf-831e-4ca3-86a7-06a782ee0412,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-d963dcd8-02de-4055-9c20-2cc41be4df3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-fd7d9baa-8a64-4f9c-9838-712fadcbf642,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-d9190727-53df-465a-85d5-eb12dacf7edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-a6e02aee-6f5b-4c21-bd6c-3a9f09082eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-efb4ee1f-01b8-4f26-a43c-c44cfa283625,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-610a0c38-dd03-4e33-8a3e-297fdd8307df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061677372-172.17.0.15-1597402135957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-dada6dc9-aee6-491b-ae63-17c5b57b17f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-6480a0bf-831e-4ca3-86a7-06a782ee0412,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-d963dcd8-02de-4055-9c20-2cc41be4df3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-fd7d9baa-8a64-4f9c-9838-712fadcbf642,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-d9190727-53df-465a-85d5-eb12dacf7edd,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-a6e02aee-6f5b-4c21-bd6c-3a9f09082eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-efb4ee1f-01b8-4f26-a43c-c44cfa283625,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-610a0c38-dd03-4e33-8a3e-297fdd8307df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953580056-172.17.0.15-1597402437836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-37dfc1e4-5bbc-4bbc-a286-e9bb11929d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-51e20dff-8495-4f71-88e9-7c12ee869c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-f2c53ead-9611-437f-9c8f-588e22f4335c,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-43610d6c-1af5-4ccf-9235-f80799d5b319,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-0d2279df-68b8-454a-a7b1-c231735b353b,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-9bbb673c-c998-44cd-9b07-1d01543ebbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-f166577d-7281-43a1-9cbb-4b3774fb0c50,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-2b8ca76a-e11c-43dc-9412-55c8533b248f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953580056-172.17.0.15-1597402437836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-37dfc1e4-5bbc-4bbc-a286-e9bb11929d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-51e20dff-8495-4f71-88e9-7c12ee869c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-f2c53ead-9611-437f-9c8f-588e22f4335c,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-43610d6c-1af5-4ccf-9235-f80799d5b319,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-0d2279df-68b8-454a-a7b1-c231735b353b,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-9bbb673c-c998-44cd-9b07-1d01543ebbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-f166577d-7281-43a1-9cbb-4b3774fb0c50,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-2b8ca76a-e11c-43dc-9412-55c8533b248f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626947816-172.17.0.15-1597402568318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-54990879-1b79-44d4-af22-2221e0caa935,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-0793068e-e29d-46b0-8409-b211db43f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-2b27ee16-32e1-4e59-94fc-bbc8c6bd9e35,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-81132f90-96b2-4774-9b90-7acf93cdbf13,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-95ef1482-6e37-4e7e-9ed3-b6da21a8949f,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-4ebd09f3-74a6-4deb-83f0-0c0680a9ec98,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-e11025b5-324d-478d-afe5-d91801f279bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a8a4f406-9e44-42cf-b66f-1fbd473b2e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626947816-172.17.0.15-1597402568318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44193,DS-54990879-1b79-44d4-af22-2221e0caa935,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-0793068e-e29d-46b0-8409-b211db43f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-2b27ee16-32e1-4e59-94fc-bbc8c6bd9e35,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-81132f90-96b2-4774-9b90-7acf93cdbf13,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-95ef1482-6e37-4e7e-9ed3-b6da21a8949f,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-4ebd09f3-74a6-4deb-83f0-0c0680a9ec98,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-e11025b5-324d-478d-afe5-d91801f279bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a8a4f406-9e44-42cf-b66f-1fbd473b2e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868865658-172.17.0.15-1597402614036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-32a2645e-95b5-415f-934a-cc87e8ce406e,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-e8442c41-2309-44aa-a5e2-a780b26eb2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-415b65fe-2dd1-47fe-9d70-c6dc6e0d6a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-3d67a642-3d47-4793-b8e0-1cdf1622c194,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-879aeb47-416a-4436-a098-4b9754a47c43,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-1f0c59c4-f913-449a-955d-776ea091839e,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-2bec79d2-c118-46d9-96ae-152760dd59de,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-092dfd5c-ed67-4674-a4af-5988032f5198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868865658-172.17.0.15-1597402614036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-32a2645e-95b5-415f-934a-cc87e8ce406e,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-e8442c41-2309-44aa-a5e2-a780b26eb2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-415b65fe-2dd1-47fe-9d70-c6dc6e0d6a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-3d67a642-3d47-4793-b8e0-1cdf1622c194,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-879aeb47-416a-4436-a098-4b9754a47c43,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-1f0c59c4-f913-449a-955d-776ea091839e,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-2bec79d2-c118-46d9-96ae-152760dd59de,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-092dfd5c-ed67-4674-a4af-5988032f5198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566813803-172.17.0.15-1597402862473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41692,DS-2c0b3e4f-54b6-4e25-89d6-1edd1ecf904f,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-068db483-bbbc-4339-ace7-e822d7ec8fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-28dd350e-1a67-4c2b-8b16-7e7c7f931369,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-caf0b25f-7771-41fc-8d96-b0e1afcce87e,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-f553d304-a61f-4a4f-85cd-53caf6c02dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-955109b4-f4f7-46d1-b3b8-291cb6241a68,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-255f3795-dd74-4e18-929b-ac8d737cf757,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-8e8406d5-269e-42aa-8858-57ba64687bd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566813803-172.17.0.15-1597402862473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41692,DS-2c0b3e4f-54b6-4e25-89d6-1edd1ecf904f,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-068db483-bbbc-4339-ace7-e822d7ec8fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-28dd350e-1a67-4c2b-8b16-7e7c7f931369,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-caf0b25f-7771-41fc-8d96-b0e1afcce87e,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-f553d304-a61f-4a4f-85cd-53caf6c02dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-955109b4-f4f7-46d1-b3b8-291cb6241a68,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-255f3795-dd74-4e18-929b-ac8d737cf757,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-8e8406d5-269e-42aa-8858-57ba64687bd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131541433-172.17.0.15-1597403455198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43362,DS-77ed48eb-c445-4c9c-ae31-97f5d3049991,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-e91f6953-d5e9-4c5d-ad2b-bffb12dd3ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-5e724864-8b09-436d-a2e5-6969f8fc2c25,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-a91fd0dc-eb45-4fb6-9bac-237fc7b2d062,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-7bd2fcd9-ccd2-4f54-9154-aae4c5e9e714,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-13ba6899-d974-4222-b05a-45bcd73ffe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-4b8dc6f1-967f-4139-a3fa-893c42e13cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-0048eef1-247c-4ce5-87ef-904c6e001d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131541433-172.17.0.15-1597403455198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43362,DS-77ed48eb-c445-4c9c-ae31-97f5d3049991,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-e91f6953-d5e9-4c5d-ad2b-bffb12dd3ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-5e724864-8b09-436d-a2e5-6969f8fc2c25,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-a91fd0dc-eb45-4fb6-9bac-237fc7b2d062,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-7bd2fcd9-ccd2-4f54-9154-aae4c5e9e714,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-13ba6899-d974-4222-b05a-45bcd73ffe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-4b8dc6f1-967f-4139-a3fa-893c42e13cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-0048eef1-247c-4ce5-87ef-904c6e001d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327359964-172.17.0.15-1597404251806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-5da7e3be-8203-4eeb-b68e-26002021e60b,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-5ecf8e6d-6f46-484c-b3be-d0d6b4608fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-b6888828-dbeb-424f-b796-aff1a3818aac,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-1a1f28ce-2104-483c-a626-934c7558d178,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-9b4902d1-c904-4adc-8f10-4955fe0668da,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-4b13bd9b-a1e0-4ce0-88a4-96af1622fcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-179199ff-ffff-4502-8773-429a822606e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-9aaa80aa-396a-47d3-b2e7-cc73b8ee2495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327359964-172.17.0.15-1597404251806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-5da7e3be-8203-4eeb-b68e-26002021e60b,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-5ecf8e6d-6f46-484c-b3be-d0d6b4608fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-b6888828-dbeb-424f-b796-aff1a3818aac,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-1a1f28ce-2104-483c-a626-934c7558d178,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-9b4902d1-c904-4adc-8f10-4955fe0668da,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-4b13bd9b-a1e0-4ce0-88a4-96af1622fcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-179199ff-ffff-4502-8773-429a822606e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-9aaa80aa-396a-47d3-b2e7-cc73b8ee2495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116363194-172.17.0.15-1597405035049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43733,DS-effadc3b-9543-4ecd-ae1e-a797a9d250ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-dfc7119e-bcf7-4090-9992-6d537375fd60,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-b9ceef96-a433-4598-8c46-1998fa4216ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-20ed5de6-db23-44ab-8f64-2cdbdea9036f,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-1d376aa1-1d8a-4052-8ab1-cec310cd563b,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-d846cce7-cb71-4999-8a44-9fc261aecec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-5d567311-22e7-4623-99d6-872086720c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-e7d617a0-8e3c-4784-8ecf-896df7fd695b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116363194-172.17.0.15-1597405035049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43733,DS-effadc3b-9543-4ecd-ae1e-a797a9d250ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-dfc7119e-bcf7-4090-9992-6d537375fd60,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-b9ceef96-a433-4598-8c46-1998fa4216ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-20ed5de6-db23-44ab-8f64-2cdbdea9036f,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-1d376aa1-1d8a-4052-8ab1-cec310cd563b,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-d846cce7-cb71-4999-8a44-9fc261aecec9,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-5d567311-22e7-4623-99d6-872086720c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-e7d617a0-8e3c-4784-8ecf-896df7fd695b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6769
