reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765248863-172.17.0.8-1597683409394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-034efc2d-e7d8-40c9-9c2d-a77552c3f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-f160fb90-b2f4-4537-bbf6-6e6fe0505128,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-4d460dae-7c52-40e8-941d-d10d24ae00d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-8807befa-c86f-4217-8bcf-c9bef5d0aa69,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-4c6afc50-3997-4074-9ec8-160baa9a98aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-19a3237c-35f2-43ee-9bc7-1fe654e20c51,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-3580cd32-fa4b-4759-abbc-e468a657f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-ecbffa9b-ea5b-4471-b837-d4dafae08fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765248863-172.17.0.8-1597683409394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-034efc2d-e7d8-40c9-9c2d-a77552c3f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-f160fb90-b2f4-4537-bbf6-6e6fe0505128,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-4d460dae-7c52-40e8-941d-d10d24ae00d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-8807befa-c86f-4217-8bcf-c9bef5d0aa69,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-4c6afc50-3997-4074-9ec8-160baa9a98aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-19a3237c-35f2-43ee-9bc7-1fe654e20c51,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-3580cd32-fa4b-4759-abbc-e468a657f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-ecbffa9b-ea5b-4471-b837-d4dafae08fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025769237-172.17.0.8-1597683877353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-4a1379f0-6ff3-4778-8d06-908ab072c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-cb94e6fa-05e9-49e2-8a03-3a5f34e33d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-1acd79cb-0bbd-425c-946c-6118711acb54,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-2bee4ccf-e355-438c-a3f4-3fab1ed7ed94,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-ceae52cf-00a6-4bd1-b666-b88ccfc43d46,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-7f01fddf-c205-467c-a943-b58272ccdd08,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-6fcf143d-368d-4f74-9b42-9ae201727120,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-070a5565-d83b-4806-98e7-aeb98f8f5e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025769237-172.17.0.8-1597683877353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-4a1379f0-6ff3-4778-8d06-908ab072c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-cb94e6fa-05e9-49e2-8a03-3a5f34e33d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-1acd79cb-0bbd-425c-946c-6118711acb54,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-2bee4ccf-e355-438c-a3f4-3fab1ed7ed94,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-ceae52cf-00a6-4bd1-b666-b88ccfc43d46,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-7f01fddf-c205-467c-a943-b58272ccdd08,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-6fcf143d-368d-4f74-9b42-9ae201727120,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-070a5565-d83b-4806-98e7-aeb98f8f5e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2013360802-172.17.0.8-1597684273906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45074,DS-56f32ea7-59c7-4c86-8715-028a86f6120c,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-fb1e2d22-1915-48e8-aa9c-72c46662a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-5fc06197-2b35-4451-a4df-7867215339e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-3dc813a5-11c1-42ef-80c4-7cded41af807,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-ec16f1e4-44a8-4400-8154-b1608c36efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-81053223-6f33-48d4-b1f1-e3211cc52ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-d33e97a7-717b-4892-b709-8d593d49ac10,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-0dccf529-2e2e-4261-870f-3492e0bf282b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2013360802-172.17.0.8-1597684273906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45074,DS-56f32ea7-59c7-4c86-8715-028a86f6120c,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-fb1e2d22-1915-48e8-aa9c-72c46662a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-5fc06197-2b35-4451-a4df-7867215339e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-3dc813a5-11c1-42ef-80c4-7cded41af807,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-ec16f1e4-44a8-4400-8154-b1608c36efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-81053223-6f33-48d4-b1f1-e3211cc52ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-d33e97a7-717b-4892-b709-8d593d49ac10,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-0dccf529-2e2e-4261-870f-3492e0bf282b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481125497-172.17.0.8-1597684435652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-529db027-66df-4e74-95f3-fa402fb738e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-8ff67ecb-e31f-47b1-9e15-3bd6c21d6fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-8e24f622-1547-434d-aca3-31248ed3d456,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-a61584aa-d8cd-4878-8e8b-a8b157d0a5de,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-0ab778cf-d699-4017-86fe-10e492b783bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-6c2e81c6-f93e-4ed3-8437-022f523ef2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-155b6799-ae5f-4888-856e-34bbffe8b183,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-3d6d5751-65ae-4a3e-9395-387c0a9e0cfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481125497-172.17.0.8-1597684435652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-529db027-66df-4e74-95f3-fa402fb738e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-8ff67ecb-e31f-47b1-9e15-3bd6c21d6fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-8e24f622-1547-434d-aca3-31248ed3d456,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-a61584aa-d8cd-4878-8e8b-a8b157d0a5de,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-0ab778cf-d699-4017-86fe-10e492b783bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-6c2e81c6-f93e-4ed3-8437-022f523ef2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-155b6799-ae5f-4888-856e-34bbffe8b183,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-3d6d5751-65ae-4a3e-9395-387c0a9e0cfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196109819-172.17.0.8-1597684667739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39076,DS-ef100006-7f72-4c28-b7a8-c8685058f035,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-0ec2f7a8-8a10-4adc-ae0e-cf2f73c9adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-1f92fbb3-72af-40a8-8e57-bff546f87bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-a2198f8f-3e8a-4e18-bfe2-40119ac7c625,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-23bbada2-2112-4a80-ac1d-dba5db1b8e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-0ca3445a-db2b-44b2-bc84-f0fab71d7a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-0dc990e5-7a2b-42c4-8104-a8b6bf1e0149,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-b908685e-78fd-49d2-b54f-d85bfde982f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196109819-172.17.0.8-1597684667739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39076,DS-ef100006-7f72-4c28-b7a8-c8685058f035,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-0ec2f7a8-8a10-4adc-ae0e-cf2f73c9adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-1f92fbb3-72af-40a8-8e57-bff546f87bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-a2198f8f-3e8a-4e18-bfe2-40119ac7c625,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-23bbada2-2112-4a80-ac1d-dba5db1b8e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-0ca3445a-db2b-44b2-bc84-f0fab71d7a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-0dc990e5-7a2b-42c4-8104-a8b6bf1e0149,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-b908685e-78fd-49d2-b54f-d85bfde982f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377286463-172.17.0.8-1597684865697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-2290c990-87c3-4e0f-8328-fa218901e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-6a16c7b3-0912-4709-91ea-3b04412e7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-888e765f-7255-4d0f-8f8c-1dc124ba9a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-edaccfd7-2f4c-498a-a59f-dddb2fc4c690,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-eaf08f0a-650b-4605-9069-5da551250cba,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-a501e67d-6e98-4645-a7ad-dcaa4322c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-b2e4ade7-b303-4dd0-bf68-b41a229b1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-e5285e05-ffd4-4945-815e-634a62d7a432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377286463-172.17.0.8-1597684865697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-2290c990-87c3-4e0f-8328-fa218901e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-6a16c7b3-0912-4709-91ea-3b04412e7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-888e765f-7255-4d0f-8f8c-1dc124ba9a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-edaccfd7-2f4c-498a-a59f-dddb2fc4c690,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-eaf08f0a-650b-4605-9069-5da551250cba,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-a501e67d-6e98-4645-a7ad-dcaa4322c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-b2e4ade7-b303-4dd0-bf68-b41a229b1a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-e5285e05-ffd4-4945-815e-634a62d7a432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006523336-172.17.0.8-1597685384544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-703a77df-25a8-462b-9704-f17204a24324,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-f8e7a75a-1f45-4b1a-a92f-9feef3f3d37f,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-91b66393-5eb6-4a4a-9396-4a090f3a18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-14aab418-74ca-48b9-abda-f56ed4559f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-b0eda9fd-6722-4a5a-838d-939651b05a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-3b9c0b54-3b6d-4a75-b619-5b116e51b357,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-2a4ffd54-9b90-41ed-892e-3631ea8ab2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-15684362-79f6-4447-bb5d-63f923f81abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006523336-172.17.0.8-1597685384544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-703a77df-25a8-462b-9704-f17204a24324,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-f8e7a75a-1f45-4b1a-a92f-9feef3f3d37f,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-91b66393-5eb6-4a4a-9396-4a090f3a18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-14aab418-74ca-48b9-abda-f56ed4559f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-b0eda9fd-6722-4a5a-838d-939651b05a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-3b9c0b54-3b6d-4a75-b619-5b116e51b357,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-2a4ffd54-9b90-41ed-892e-3631ea8ab2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-15684362-79f6-4447-bb5d-63f923f81abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994941588-172.17.0.8-1597686530690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-2199820b-484d-48b7-a16b-423515a52c40,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-838de992-bb92-4fb3-a8cb-63809aa99a92,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-58a0d51d-d464-46a8-9b61-d60d3a40bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-5ad5da12-8059-43d0-b625-f7dc9d6cb379,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-b73dd038-f96e-4a1f-9b01-fd6a0b3b4214,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-9a1ccab4-aa1f-4677-91e0-b8df203e7864,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-177b1bac-6357-48d6-b0a7-cd918bb77937,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-d7f5fecc-1a68-476d-a706-f5d4bf469317,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994941588-172.17.0.8-1597686530690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-2199820b-484d-48b7-a16b-423515a52c40,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-838de992-bb92-4fb3-a8cb-63809aa99a92,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-58a0d51d-d464-46a8-9b61-d60d3a40bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-5ad5da12-8059-43d0-b625-f7dc9d6cb379,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-b73dd038-f96e-4a1f-9b01-fd6a0b3b4214,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-9a1ccab4-aa1f-4677-91e0-b8df203e7864,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-177b1bac-6357-48d6-b0a7-cd918bb77937,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-d7f5fecc-1a68-476d-a706-f5d4bf469317,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823657288-172.17.0.8-1597686727253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40565,DS-1d4eb1c5-2a34-4da4-85d2-6a5b510d490d,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-c194b7f0-88db-4fb9-8c56-45bb1faccb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-663dc4cd-da88-4dd3-b15c-a90a60b89c84,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-aa68e29a-0dda-4e65-a533-a908f5d93336,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-8851cccd-c430-4b3f-943a-0fab9f4a80e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-28b3b223-5f69-430c-84c3-426f08ad11f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-a6f6a5f8-6a59-41bd-a8e9-22ba3ef288d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-35206e7b-da31-4a56-84cb-7473df56be17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823657288-172.17.0.8-1597686727253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40565,DS-1d4eb1c5-2a34-4da4-85d2-6a5b510d490d,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-c194b7f0-88db-4fb9-8c56-45bb1faccb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-663dc4cd-da88-4dd3-b15c-a90a60b89c84,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-aa68e29a-0dda-4e65-a533-a908f5d93336,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-8851cccd-c430-4b3f-943a-0fab9f4a80e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-28b3b223-5f69-430c-84c3-426f08ad11f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-a6f6a5f8-6a59-41bd-a8e9-22ba3ef288d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-35206e7b-da31-4a56-84cb-7473df56be17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109847435-172.17.0.8-1597686801924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-df4b934a-c452-467e-b239-ed6d7e0e112d,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-f245b9ee-5ca3-4311-8b3a-5d9848572a56,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-50d48af5-a3ed-422c-9863-1434ff24e250,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-d159a31d-dbd1-4d62-a1c2-03b2680ce780,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-d9cc1a0c-8b1a-4037-9e68-35f6d1770293,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-835f601c-6ad6-4913-8397-49614fa59b86,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-4063e468-d129-4f7c-a6b8-d619380f4814,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-cdd043a3-6ad6-4b0d-8d43-15f248de439d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109847435-172.17.0.8-1597686801924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-df4b934a-c452-467e-b239-ed6d7e0e112d,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-f245b9ee-5ca3-4311-8b3a-5d9848572a56,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-50d48af5-a3ed-422c-9863-1434ff24e250,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-d159a31d-dbd1-4d62-a1c2-03b2680ce780,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-d9cc1a0c-8b1a-4037-9e68-35f6d1770293,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-835f601c-6ad6-4913-8397-49614fa59b86,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-4063e468-d129-4f7c-a6b8-d619380f4814,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-cdd043a3-6ad6-4b0d-8d43-15f248de439d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203877631-172.17.0.8-1597686958926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33642,DS-6732e59e-88dc-4689-bf93-4a2980235868,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-f3f3d370-c66a-40b0-83ad-7039ffb992eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-579e6151-324f-4019-a33e-c619539d65f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-663759df-8785-4945-a04d-924b1d2614c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-0d1d00f2-9d6f-4ebf-9b6d-076cc0255f53,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-b7fdf5ea-80c6-4b77-85e1-f5f818208811,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-fe1afcd8-08c2-4133-863f-0c9c015b4a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-63202b00-594e-49d4-964d-d7c55134daa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203877631-172.17.0.8-1597686958926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33642,DS-6732e59e-88dc-4689-bf93-4a2980235868,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-f3f3d370-c66a-40b0-83ad-7039ffb992eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-579e6151-324f-4019-a33e-c619539d65f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-663759df-8785-4945-a04d-924b1d2614c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-0d1d00f2-9d6f-4ebf-9b6d-076cc0255f53,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-b7fdf5ea-80c6-4b77-85e1-f5f818208811,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-fe1afcd8-08c2-4133-863f-0c9c015b4a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-63202b00-594e-49d4-964d-d7c55134daa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773273857-172.17.0.8-1597687543132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-5572ee33-67b7-4079-90e3-5a5dd0187c86,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-bd2793ca-7913-4d6a-a55c-ade95897fb46,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-edae767b-57c9-48d7-9968-305611448e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-8bbe80ca-4d1b-433a-acda-93acc59fbce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-dd8c2dd0-c8bb-4559-ad88-5c3eb99d7b53,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-c9b0d3f0-98bb-409c-a394-58e27440ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-584e129a-511c-4d5f-acb5-8af74f7d66d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-ec988fb3-cdc3-4b71-a7c9-5d470cc2f673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773273857-172.17.0.8-1597687543132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-5572ee33-67b7-4079-90e3-5a5dd0187c86,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-bd2793ca-7913-4d6a-a55c-ade95897fb46,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-edae767b-57c9-48d7-9968-305611448e79,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-8bbe80ca-4d1b-433a-acda-93acc59fbce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-dd8c2dd0-c8bb-4559-ad88-5c3eb99d7b53,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-c9b0d3f0-98bb-409c-a394-58e27440ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-584e129a-511c-4d5f-acb5-8af74f7d66d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-ec988fb3-cdc3-4b71-a7c9-5d470cc2f673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5694
