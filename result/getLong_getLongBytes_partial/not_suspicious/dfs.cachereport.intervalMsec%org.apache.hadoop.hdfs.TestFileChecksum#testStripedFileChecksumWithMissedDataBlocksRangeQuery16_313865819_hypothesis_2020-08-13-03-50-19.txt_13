reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663310254-172.17.0.13-1597290674639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-d2340031-cb72-48df-b6b9-2d68fa205bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-677457f3-21d3-4c52-b54e-74ef939986ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-005ec93c-55bf-46f5-8510-e5074fb70ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-6a677c2e-5996-4925-b5de-14814fd1104a,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-342a36b8-874f-4058-afd2-f6e98340987d,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-1ec1defe-edf2-44a2-902a-e15ae73de64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-eecd1188-99e5-4434-90c2-6062050b2bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-96de74a0-e3fd-4b8a-a0fc-6c67b0ed7417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663310254-172.17.0.13-1597290674639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-d2340031-cb72-48df-b6b9-2d68fa205bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-677457f3-21d3-4c52-b54e-74ef939986ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-005ec93c-55bf-46f5-8510-e5074fb70ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-6a677c2e-5996-4925-b5de-14814fd1104a,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-342a36b8-874f-4058-afd2-f6e98340987d,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-1ec1defe-edf2-44a2-902a-e15ae73de64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-eecd1188-99e5-4434-90c2-6062050b2bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-96de74a0-e3fd-4b8a-a0fc-6c67b0ed7417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525533354-172.17.0.13-1597291054053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-ff6b7ced-bd5e-469a-a0c1-6ae8d245fced,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-d366dda3-9950-4357-8d6c-7afa15762170,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-5bba1060-7e6b-4188-bde3-9f61e36a4ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-242c5d2a-b3e6-4b05-af5b-e01fd24b664b,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-959de13d-8314-4c15-9c43-c83811b2ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-3c1bd55b-3c9e-4263-8f1c-94d82bd508e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-69e468ca-8c83-4146-9f35-3c50592ad633,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-9aad64e8-1785-4d9f-ae55-b3f88c0d2e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525533354-172.17.0.13-1597291054053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-ff6b7ced-bd5e-469a-a0c1-6ae8d245fced,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-d366dda3-9950-4357-8d6c-7afa15762170,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-5bba1060-7e6b-4188-bde3-9f61e36a4ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-242c5d2a-b3e6-4b05-af5b-e01fd24b664b,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-959de13d-8314-4c15-9c43-c83811b2ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-3c1bd55b-3c9e-4263-8f1c-94d82bd508e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-69e468ca-8c83-4146-9f35-3c50592ad633,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-9aad64e8-1785-4d9f-ae55-b3f88c0d2e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549701039-172.17.0.13-1597291180016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37940,DS-4eb74d08-de45-4516-8f03-305def892245,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-b78b7300-352a-4b8e-a410-c92a3c8fbab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-3ef86268-1e41-4bd9-9d6c-09b324ffabcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-7f37b40c-fd2f-4a4a-b728-dc5d73017196,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-bf6453d5-6183-4d45-b3ee-29f170535d65,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-e8f15b00-fec9-482e-ab8d-6202bf4eae3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-19588e03-fa4f-40dc-8fb4-c470676b6b80,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-6353c261-31d5-4a1b-a46a-1673db9de063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549701039-172.17.0.13-1597291180016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37940,DS-4eb74d08-de45-4516-8f03-305def892245,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-b78b7300-352a-4b8e-a410-c92a3c8fbab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-3ef86268-1e41-4bd9-9d6c-09b324ffabcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-7f37b40c-fd2f-4a4a-b728-dc5d73017196,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-bf6453d5-6183-4d45-b3ee-29f170535d65,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-e8f15b00-fec9-482e-ab8d-6202bf4eae3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-19588e03-fa4f-40dc-8fb4-c470676b6b80,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-6353c261-31d5-4a1b-a46a-1673db9de063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110056194-172.17.0.13-1597291219141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-2f2b380e-6612-43fa-aad1-bed71438988b,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-3da30a37-4cb9-46f6-8cbb-22e635a25813,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-840ba31c-b7a5-4d43-8976-7e3a4c928531,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-e43415c1-314a-4ea2-a3ca-1ddbe60367f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-c2fbf4b9-b50f-4419-b316-e1a98da78022,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-62e8b252-4ca4-4eb5-a4dd-d33545fdb142,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-5051898e-a3cb-44cf-b86f-79dc95bd47bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-17b835d8-340a-4cc2-b56b-47dda86d7383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110056194-172.17.0.13-1597291219141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-2f2b380e-6612-43fa-aad1-bed71438988b,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-3da30a37-4cb9-46f6-8cbb-22e635a25813,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-840ba31c-b7a5-4d43-8976-7e3a4c928531,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-e43415c1-314a-4ea2-a3ca-1ddbe60367f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-c2fbf4b9-b50f-4419-b316-e1a98da78022,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-62e8b252-4ca4-4eb5-a4dd-d33545fdb142,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-5051898e-a3cb-44cf-b86f-79dc95bd47bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-17b835d8-340a-4cc2-b56b-47dda86d7383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641249167-172.17.0.13-1597292255274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44533,DS-4c87f0d7-9cf7-4ce9-9195-125d64bb4716,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-2accd788-1f4e-48ac-8170-156bc1cb637b,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-bd4f61a4-2d3b-4ac6-bcab-94cef404daf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-692d5fc1-9765-4a0e-8480-921750fe3aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-c9337f09-21dd-4aa3-80d7-1bf445c2e964,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-7969c256-37fa-448d-92f5-d05a018190b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-bb5ff6fe-eac0-40d3-9bc7-0b409979eb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-e200df8e-8c35-43b3-8315-f378668e1d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641249167-172.17.0.13-1597292255274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44533,DS-4c87f0d7-9cf7-4ce9-9195-125d64bb4716,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-2accd788-1f4e-48ac-8170-156bc1cb637b,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-bd4f61a4-2d3b-4ac6-bcab-94cef404daf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-692d5fc1-9765-4a0e-8480-921750fe3aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-c9337f09-21dd-4aa3-80d7-1bf445c2e964,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-7969c256-37fa-448d-92f5-d05a018190b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-bb5ff6fe-eac0-40d3-9bc7-0b409979eb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-e200df8e-8c35-43b3-8315-f378668e1d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615215649-172.17.0.13-1597292450562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38275,DS-a8f483a7-a9eb-4f78-b216-d1cc47a98650,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-95e652a5-7f1e-4cf0-9ae9-e4e9158aed53,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-545b73cf-55d5-46bb-b0fe-710d3d6654d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-e6e39369-76f9-43a6-bfaf-a83577abc25d,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-f0e8f34a-c658-4bdf-8020-375494a06358,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-afc987c5-bd71-4779-a3df-bf350d19daa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-aaa4d74a-b16f-469a-8e77-5ff06b58a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-1846ae7e-fe8c-403e-9a54-173f1ec30f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615215649-172.17.0.13-1597292450562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38275,DS-a8f483a7-a9eb-4f78-b216-d1cc47a98650,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-95e652a5-7f1e-4cf0-9ae9-e4e9158aed53,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-545b73cf-55d5-46bb-b0fe-710d3d6654d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-e6e39369-76f9-43a6-bfaf-a83577abc25d,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-f0e8f34a-c658-4bdf-8020-375494a06358,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-afc987c5-bd71-4779-a3df-bf350d19daa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-aaa4d74a-b16f-469a-8e77-5ff06b58a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-1846ae7e-fe8c-403e-9a54-173f1ec30f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103148952-172.17.0.13-1597292492138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42251,DS-cc1f1800-c2c3-4a91-ab62-d373a34d604f,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-620cefac-aa07-442b-b1e0-f52f10ffb0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-4a60e568-aa82-4b19-8e3c-35cf9ddb91a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-653aee77-dfcb-4066-ad53-d72489579465,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-908e45fb-cc85-41f0-850d-14ffbd1ab557,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-f2476720-55f1-4fe8-bd32-6c70ecbf418b,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-289d481f-971c-4811-8cee-9dc1b9772992,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-138de370-4463-4a85-8c5c-660eb2096c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103148952-172.17.0.13-1597292492138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42251,DS-cc1f1800-c2c3-4a91-ab62-d373a34d604f,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-620cefac-aa07-442b-b1e0-f52f10ffb0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-4a60e568-aa82-4b19-8e3c-35cf9ddb91a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-653aee77-dfcb-4066-ad53-d72489579465,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-908e45fb-cc85-41f0-850d-14ffbd1ab557,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-f2476720-55f1-4fe8-bd32-6c70ecbf418b,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-289d481f-971c-4811-8cee-9dc1b9772992,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-138de370-4463-4a85-8c5c-660eb2096c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247789743-172.17.0.13-1597292925622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-a8d4d22f-476b-40d5-9ae9-4136959da609,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-bdae8f0e-f528-4b6b-a450-1fca0d4bd65e,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-2567d62b-24aa-4fec-b994-85d30c379f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-fa815af9-d47b-4d0d-a299-77fd33eaacfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-f54a0e62-b7fb-432f-afe9-f4a5deb21455,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-e0903fe5-8417-4fca-9e04-e09185a26a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-f3aac2cd-144e-4fca-8cbc-d04610358136,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-56d76186-553d-4b33-9c09-8acd1d671a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247789743-172.17.0.13-1597292925622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-a8d4d22f-476b-40d5-9ae9-4136959da609,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-bdae8f0e-f528-4b6b-a450-1fca0d4bd65e,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-2567d62b-24aa-4fec-b994-85d30c379f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-fa815af9-d47b-4d0d-a299-77fd33eaacfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-f54a0e62-b7fb-432f-afe9-f4a5deb21455,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-e0903fe5-8417-4fca-9e04-e09185a26a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-f3aac2cd-144e-4fca-8cbc-d04610358136,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-56d76186-553d-4b33-9c09-8acd1d671a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504364916-172.17.0.13-1597293011605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-e651c68b-1d0b-4d1c-86fa-91f07cb59e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-65867212-38b3-45a6-be51-690b9c7063c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-00e428c7-7c1c-4ef6-a5b3-79d209c9475e,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-7af41291-d9f0-4d07-bf7b-12ff76ac76d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-0125a513-8766-48fb-9fe7-682572199787,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-8f9418aa-7c0b-4a11-96d8-df2418909a73,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-21fa7d0b-1859-4cb6-91fe-f2cdd265026d,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-51c08cb4-b3fc-4ee6-bc5f-5d772d841e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504364916-172.17.0.13-1597293011605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-e651c68b-1d0b-4d1c-86fa-91f07cb59e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-65867212-38b3-45a6-be51-690b9c7063c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-00e428c7-7c1c-4ef6-a5b3-79d209c9475e,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-7af41291-d9f0-4d07-bf7b-12ff76ac76d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-0125a513-8766-48fb-9fe7-682572199787,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-8f9418aa-7c0b-4a11-96d8-df2418909a73,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-21fa7d0b-1859-4cb6-91fe-f2cdd265026d,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-51c08cb4-b3fc-4ee6-bc5f-5d772d841e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265075014-172.17.0.13-1597293049927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-67e5924e-c2c7-4fe5-ba43-a91f3f2932f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-235908fb-7dca-45fb-b712-44cd67951bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-8a9d3206-8b3d-41de-ac47-b8932aec87e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-c7002a44-417d-4d78-b79f-d05b072cc9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-31ca99e9-d3c3-4c50-9031-7c9f82bc0ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-c76e8065-ab24-41af-bc1a-d2d175793b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-61fa8b57-0021-4db2-96e6-fdfdcbfe5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-6a9295bb-ca41-446c-94de-3a2e7bc4cc02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265075014-172.17.0.13-1597293049927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-67e5924e-c2c7-4fe5-ba43-a91f3f2932f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-235908fb-7dca-45fb-b712-44cd67951bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-8a9d3206-8b3d-41de-ac47-b8932aec87e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-c7002a44-417d-4d78-b79f-d05b072cc9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-31ca99e9-d3c3-4c50-9031-7c9f82bc0ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-c76e8065-ab24-41af-bc1a-d2d175793b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-61fa8b57-0021-4db2-96e6-fdfdcbfe5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-6a9295bb-ca41-446c-94de-3a2e7bc4cc02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603089686-172.17.0.13-1597293133533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38935,DS-72e32c23-85b9-4136-b70d-00bb2566ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-ec714e23-3ec1-4775-83e7-3f5963ffb0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-a27cb710-2fe6-4eb4-b35a-ee26103d6db4,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-a8d12ae9-261b-493e-9e18-cca6503cf78a,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-f2d80c47-4290-4c8c-b71d-2b355e353792,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-d90980e6-420f-4c9b-b6c3-aac9a38b0b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-f28d184e-736f-424a-a42e-1af8e829268d,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-d61a14a0-6aa0-4935-bc4e-40fc8c7c0aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603089686-172.17.0.13-1597293133533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38935,DS-72e32c23-85b9-4136-b70d-00bb2566ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-ec714e23-3ec1-4775-83e7-3f5963ffb0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-a27cb710-2fe6-4eb4-b35a-ee26103d6db4,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-a8d12ae9-261b-493e-9e18-cca6503cf78a,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-f2d80c47-4290-4c8c-b71d-2b355e353792,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-d90980e6-420f-4c9b-b6c3-aac9a38b0b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-f28d184e-736f-424a-a42e-1af8e829268d,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-d61a14a0-6aa0-4935-bc4e-40fc8c7c0aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538352106-172.17.0.13-1597293364654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-91f97ff1-a70c-48ed-b9aa-e582643163e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-d64f1841-96dc-4e40-9311-dfc702beebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-80e93976-23df-42d2-9346-72d19e52e0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-7af61a22-b65e-4f89-ade6-19f5e24b97c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-fa675012-377c-4512-8277-8f785dbcd9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-996d7a59-9cef-43ca-98dd-0a270027d157,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-6e6a547d-c2c7-4cc3-8032-d7bd64d0fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-f2643229-f90e-425d-b87a-c7959b9bedf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538352106-172.17.0.13-1597293364654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46275,DS-91f97ff1-a70c-48ed-b9aa-e582643163e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-d64f1841-96dc-4e40-9311-dfc702beebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-80e93976-23df-42d2-9346-72d19e52e0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-7af61a22-b65e-4f89-ade6-19f5e24b97c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-fa675012-377c-4512-8277-8f785dbcd9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-996d7a59-9cef-43ca-98dd-0a270027d157,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-6e6a547d-c2c7-4cc3-8032-d7bd64d0fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-f2643229-f90e-425d-b87a-c7959b9bedf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331630847-172.17.0.13-1597293759660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45236,DS-bf058a85-ba45-4112-9485-41717bde39d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-e0335c2d-5c54-4e30-ae87-70e0f2812728,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-193276c8-a372-4070-8772-0f90aa438ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-10048367-dd8c-4cfd-b978-acdf1e0b26d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-7c3a9d1c-95a8-4b54-bccf-b0712fb44b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-f8122744-4176-4777-99ee-0e633786bc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f97b7ef8-8c49-4da7-8e79-5329dcbab18c,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-9aafed30-1f76-435d-855e-ec0e19b9262d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331630847-172.17.0.13-1597293759660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45236,DS-bf058a85-ba45-4112-9485-41717bde39d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-e0335c2d-5c54-4e30-ae87-70e0f2812728,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-193276c8-a372-4070-8772-0f90aa438ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-10048367-dd8c-4cfd-b978-acdf1e0b26d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-7c3a9d1c-95a8-4b54-bccf-b0712fb44b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-f8122744-4176-4777-99ee-0e633786bc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f97b7ef8-8c49-4da7-8e79-5329dcbab18c,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-9aafed30-1f76-435d-855e-ec0e19b9262d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80129614-172.17.0.13-1597293792472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42685,DS-273bd505-ab37-41f9-9fca-0867d6e50dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-6281a983-c41e-498d-87a7-d756c3cbd4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-1f0001f1-ba0d-4277-b2a0-47c5adfeb2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-dfc3f19e-da24-4f6f-a93d-0c5fc123c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-22283585-cecc-4bfe-b4f3-4278cf548df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-2badd1c6-3dc1-4b88-a3d6-3de5f4d1b93d,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-491a340b-4a9f-4a58-8874-1c272744aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-70555a50-1f1c-42d4-a6dc-7efc640769a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80129614-172.17.0.13-1597293792472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42685,DS-273bd505-ab37-41f9-9fca-0867d6e50dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-6281a983-c41e-498d-87a7-d756c3cbd4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-1f0001f1-ba0d-4277-b2a0-47c5adfeb2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-dfc3f19e-da24-4f6f-a93d-0c5fc123c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-22283585-cecc-4bfe-b4f3-4278cf548df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-2badd1c6-3dc1-4b88-a3d6-3de5f4d1b93d,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-491a340b-4a9f-4a58-8874-1c272744aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-70555a50-1f1c-42d4-a6dc-7efc640769a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801635546-172.17.0.13-1597294749165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37923,DS-4bda311a-5706-4cfa-85df-7272621da92a,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-b9d0f8e3-fabb-4d6f-9d9c-6b22b253a7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-df6c443e-a3b8-43bc-8a8f-59b316d30a23,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-528674c2-052a-4088-a50c-d80e61b1bc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-ac0d501e-6124-4f90-9d10-6bf60d3ba873,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-a643d695-b743-4b1a-8177-fec9eeeceab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-71bade19-bb30-4ed6-adc2-108ab1fd3ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-4ece4211-3603-4525-b74d-f50f7bdc5ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801635546-172.17.0.13-1597294749165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37923,DS-4bda311a-5706-4cfa-85df-7272621da92a,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-b9d0f8e3-fabb-4d6f-9d9c-6b22b253a7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-df6c443e-a3b8-43bc-8a8f-59b316d30a23,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-528674c2-052a-4088-a50c-d80e61b1bc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-ac0d501e-6124-4f90-9d10-6bf60d3ba873,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-a643d695-b743-4b1a-8177-fec9eeeceab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-71bade19-bb30-4ed6-adc2-108ab1fd3ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-4ece4211-3603-4525-b74d-f50f7bdc5ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254809929-172.17.0.13-1597295133914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45700,DS-01516648-65e8-4288-88e9-dfb004f11c17,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-2a670d61-7474-45cd-a05a-2db4f0b48316,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-93d1ff3c-465e-4a37-b295-f2b6d197fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-900f4fc2-3c48-4669-b0e0-47fe3c8f78fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-0d7d3e8c-a8e2-4523-b403-1e00a2327274,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-bda4f14b-f6c5-4be9-94c6-9e49b6027ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-6e121467-3ca7-46d2-9e53-cb0641c46791,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-0a13e924-c966-4f0b-80ce-b90f0622859f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254809929-172.17.0.13-1597295133914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45700,DS-01516648-65e8-4288-88e9-dfb004f11c17,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-2a670d61-7474-45cd-a05a-2db4f0b48316,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-93d1ff3c-465e-4a37-b295-f2b6d197fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-900f4fc2-3c48-4669-b0e0-47fe3c8f78fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-0d7d3e8c-a8e2-4523-b403-1e00a2327274,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-bda4f14b-f6c5-4be9-94c6-9e49b6027ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-6e121467-3ca7-46d2-9e53-cb0641c46791,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-0a13e924-c966-4f0b-80ce-b90f0622859f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608972506-172.17.0.13-1597296171219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-02ebd033-8948-4e6e-9373-d708081af559,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-b499ff1a-cd22-474b-ab43-93dcb1a1db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-c28489e6-1f6c-4f2c-b6ac-c4826067af0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-cc3f9fd7-e884-40fd-b026-c5396bd94014,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-99377767-8beb-4223-a955-a18e5cfd3358,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-e1eb6215-9c37-4cfa-b861-5273a6909578,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-e5fe59a1-8e62-44da-947d-bc26cbfe75dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-d16d434f-469b-4183-b666-636f9d82d466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608972506-172.17.0.13-1597296171219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-02ebd033-8948-4e6e-9373-d708081af559,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-b499ff1a-cd22-474b-ab43-93dcb1a1db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-c28489e6-1f6c-4f2c-b6ac-c4826067af0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-cc3f9fd7-e884-40fd-b026-c5396bd94014,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-99377767-8beb-4223-a955-a18e5cfd3358,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-e1eb6215-9c37-4cfa-b861-5273a6909578,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-e5fe59a1-8e62-44da-947d-bc26cbfe75dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-d16d434f-469b-4183-b666-636f9d82d466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018258501-172.17.0.13-1597296282916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41980,DS-eba7257f-1ab3-4496-b0f8-2636b94fd16a,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-58388ba9-b6c2-49b0-8b92-67bd7c655db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-79ad85bc-7eed-4689-bff9-e25e93963731,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-b059d846-8274-41f5-83a9-168d3d3b735a,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-a994f756-7c6f-427e-84bb-e2b0aa410beb,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-dfc40d3d-462b-464d-89af-577510658440,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-9dc47bea-4ed1-4f7f-aa5c-cba03c2b1399,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-a3edae31-0810-4102-bf7f-bdcef14e3a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018258501-172.17.0.13-1597296282916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41980,DS-eba7257f-1ab3-4496-b0f8-2636b94fd16a,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-58388ba9-b6c2-49b0-8b92-67bd7c655db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-79ad85bc-7eed-4689-bff9-e25e93963731,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-b059d846-8274-41f5-83a9-168d3d3b735a,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-a994f756-7c6f-427e-84bb-e2b0aa410beb,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-dfc40d3d-462b-464d-89af-577510658440,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-9dc47bea-4ed1-4f7f-aa5c-cba03c2b1399,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-a3edae31-0810-4102-bf7f-bdcef14e3a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5869
