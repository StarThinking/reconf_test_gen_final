reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866041797-172.17.0.19-1597366373521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-e4b0377e-6632-49a4-88b5-d21255f084c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-28c1d4c7-0bf8-4e71-8487-2c03966abbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-9b246d24-1f37-4d84-9bdf-16a62f8853a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-e97a6348-942a-4a43-bd53-e897c1357a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-a1e6cd9a-9357-4244-a580-f51ca9ae53e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-b1fb722b-5f6b-4bb5-894b-dd01eadad769,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-6dc400ef-b9fa-4c0a-9e43-d8b3a0a93356,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-a0d44dde-530e-4662-bc24-6f2986529478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866041797-172.17.0.19-1597366373521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-e4b0377e-6632-49a4-88b5-d21255f084c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-28c1d4c7-0bf8-4e71-8487-2c03966abbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-9b246d24-1f37-4d84-9bdf-16a62f8853a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-e97a6348-942a-4a43-bd53-e897c1357a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-a1e6cd9a-9357-4244-a580-f51ca9ae53e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-b1fb722b-5f6b-4bb5-894b-dd01eadad769,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-6dc400ef-b9fa-4c0a-9e43-d8b3a0a93356,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-a0d44dde-530e-4662-bc24-6f2986529478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743382634-172.17.0.19-1597367027910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-9194204c-5196-4b93-b22c-1d7e6de4a8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-31a1e7c3-fd88-46ae-ad07-36cb49bf0911,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-20d1f212-3816-494b-a2d9-6113f2929994,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-7d15d314-6bfa-4be3-be05-626067a421b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-f389a672-415d-4a6f-8892-8c522b5c88e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-727d6bbe-4948-4b3f-81e9-c2e5f59d6301,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-596d15da-83b3-463e-8acc-74752b35285b,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-d9dab8ae-9c60-4414-a723-4962d9c88205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743382634-172.17.0.19-1597367027910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40100,DS-9194204c-5196-4b93-b22c-1d7e6de4a8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-31a1e7c3-fd88-46ae-ad07-36cb49bf0911,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-20d1f212-3816-494b-a2d9-6113f2929994,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-7d15d314-6bfa-4be3-be05-626067a421b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-f389a672-415d-4a6f-8892-8c522b5c88e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-727d6bbe-4948-4b3f-81e9-c2e5f59d6301,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-596d15da-83b3-463e-8acc-74752b35285b,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-d9dab8ae-9c60-4414-a723-4962d9c88205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918529835-172.17.0.19-1597367139994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46481,DS-fb124b75-5a74-4082-96b0-ee50757cc1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-19481137-05e4-4b09-a43e-f91fafb9f2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-28c64cab-8bbb-4237-bb2c-9b17af2b1a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-68841faf-e1db-4c0c-8c59-e3a481d279b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-168dee6c-ddee-4629-b74c-0174a62c609a,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-c4e7c672-94e9-4f19-a166-b706bf75106b,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-bbec4348-4265-40d5-a7b4-22145b157fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-ddb7ba3a-e1f9-4c79-a258-cfa7f9f015c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918529835-172.17.0.19-1597367139994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46481,DS-fb124b75-5a74-4082-96b0-ee50757cc1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-19481137-05e4-4b09-a43e-f91fafb9f2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-28c64cab-8bbb-4237-bb2c-9b17af2b1a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-68841faf-e1db-4c0c-8c59-e3a481d279b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-168dee6c-ddee-4629-b74c-0174a62c609a,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-c4e7c672-94e9-4f19-a166-b706bf75106b,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-bbec4348-4265-40d5-a7b4-22145b157fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-ddb7ba3a-e1f9-4c79-a258-cfa7f9f015c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110371178-172.17.0.19-1597367345641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-49726209-bf90-41ee-ac79-fb7ead1562f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-eccf860f-9400-4b6d-a17c-ee37eaf626fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-172d08a3-967b-489b-b2cd-335b675c103e,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-3bb5ac2e-1bb8-42d8-bfae-b4d6092f6c88,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-627b11a7-53d4-4296-a58e-97179d83e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-1827e23f-a5f5-45b4-8098-d0db1207ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-30210b07-f7e7-4d19-bd43-c8792c4aa305,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-ca5f1cde-f041-40a4-8884-d736fbf2635a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110371178-172.17.0.19-1597367345641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-49726209-bf90-41ee-ac79-fb7ead1562f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-eccf860f-9400-4b6d-a17c-ee37eaf626fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-172d08a3-967b-489b-b2cd-335b675c103e,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-3bb5ac2e-1bb8-42d8-bfae-b4d6092f6c88,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-627b11a7-53d4-4296-a58e-97179d83e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-1827e23f-a5f5-45b4-8098-d0db1207ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-30210b07-f7e7-4d19-bd43-c8792c4aa305,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-ca5f1cde-f041-40a4-8884-d736fbf2635a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925282750-172.17.0.19-1597367392964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44716,DS-90ee99c3-b58f-4dbf-a932-7d6457545c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-a29502a1-da51-4b34-942a-7c874f012afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-41f7116a-9ddd-4c5e-ae4b-c94aff5c52ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-d32bc6b6-d698-4cd5-807a-ea956f391ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-5ea0a540-3bb8-4767-bf13-933471e3ad8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-a6555561-bcd6-4614-8cd3-044ccd1608d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-86eb7bb6-d6d6-45e9-b873-4654cb5fb5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-d21d0459-0da5-4e69-901d-fbd567ada765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925282750-172.17.0.19-1597367392964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44716,DS-90ee99c3-b58f-4dbf-a932-7d6457545c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-a29502a1-da51-4b34-942a-7c874f012afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-41f7116a-9ddd-4c5e-ae4b-c94aff5c52ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-d32bc6b6-d698-4cd5-807a-ea956f391ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-5ea0a540-3bb8-4767-bf13-933471e3ad8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-a6555561-bcd6-4614-8cd3-044ccd1608d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-86eb7bb6-d6d6-45e9-b873-4654cb5fb5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-d21d0459-0da5-4e69-901d-fbd567ada765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461799900-172.17.0.19-1597367940822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44281,DS-6cc9037f-9cb4-4ec4-9123-22da187ecc14,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-dec949fb-64f8-4c02-8fa2-0d305702cbff,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-599ef823-15fa-41c6-911d-30a2ec55ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-557e5da6-1e29-4023-b695-ccb2557c409f,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-04ee334d-436a-4364-8fca-1f7cbdc896a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-7f42f1b1-e0ed-4721-8e45-9db24cee5439,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-e01b4782-2eec-42bc-a3d6-cef710b12303,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-a87860e8-1654-4333-bc16-4adff05b5bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461799900-172.17.0.19-1597367940822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44281,DS-6cc9037f-9cb4-4ec4-9123-22da187ecc14,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-dec949fb-64f8-4c02-8fa2-0d305702cbff,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-599ef823-15fa-41c6-911d-30a2ec55ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-557e5da6-1e29-4023-b695-ccb2557c409f,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-04ee334d-436a-4364-8fca-1f7cbdc896a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-7f42f1b1-e0ed-4721-8e45-9db24cee5439,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-e01b4782-2eec-42bc-a3d6-cef710b12303,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-a87860e8-1654-4333-bc16-4adff05b5bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544485811-172.17.0.19-1597368055406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37623,DS-0d0d0262-503a-4379-9baa-680807ae0723,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-dc9d2580-813c-434e-aa55-bd6ceceaea11,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-398b3f7c-b655-4137-8d9b-d279ba372522,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-7a7c4158-a2fe-4495-a0d3-dca8c38ebe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-c20de77d-b580-4641-aee4-c601ad7825bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-152c1607-0536-4415-bf2b-ffd2f282bed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-8b349fe0-6794-40d3-a256-8d4cc958a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-e192e7a0-b812-4bcb-9d97-2f5440672575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544485811-172.17.0.19-1597368055406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37623,DS-0d0d0262-503a-4379-9baa-680807ae0723,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-dc9d2580-813c-434e-aa55-bd6ceceaea11,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-398b3f7c-b655-4137-8d9b-d279ba372522,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-7a7c4158-a2fe-4495-a0d3-dca8c38ebe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-c20de77d-b580-4641-aee4-c601ad7825bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-152c1607-0536-4415-bf2b-ffd2f282bed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-8b349fe0-6794-40d3-a256-8d4cc958a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-e192e7a0-b812-4bcb-9d97-2f5440672575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620158870-172.17.0.19-1597368290639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-4c1f007e-7156-470c-8ae4-25a37167f760,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-cb5527c1-36f0-4403-899d-9303f447bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-a0f3fe8f-0649-4116-958e-1feb3327423f,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-f70439a4-ccb5-4bec-aa80-bdc6a270e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-2ee518f5-276e-43a4-9b70-c73d2d2dc9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-28816457-b925-46e8-90c5-e7aeb6eb6d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-bd22aed9-d5d3-4dd3-95c1-033f277afc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-a1e58c66-d082-43ab-a446-a1a225377b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620158870-172.17.0.19-1597368290639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-4c1f007e-7156-470c-8ae4-25a37167f760,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-cb5527c1-36f0-4403-899d-9303f447bc34,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-a0f3fe8f-0649-4116-958e-1feb3327423f,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-f70439a4-ccb5-4bec-aa80-bdc6a270e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-2ee518f5-276e-43a4-9b70-c73d2d2dc9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-28816457-b925-46e8-90c5-e7aeb6eb6d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-bd22aed9-d5d3-4dd3-95c1-033f277afc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-a1e58c66-d082-43ab-a446-a1a225377b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056561450-172.17.0.19-1597368369520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37344,DS-fc926b5f-b4ba-4653-a8bf-021d6901847d,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-2a276c29-09be-4970-8e35-b643f592ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-13e85eb0-aa04-4ca4-88bc-03fe73ca5881,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-343cbb37-da59-466a-a626-c8032e637c49,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-3396e768-5570-4bc1-8bef-7cecd583605c,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-c9db3868-ee99-40d1-9b84-266d75e72dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-6a0ba42a-5d5a-4898-8315-ef534839f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-1ca1117c-e181-4706-8371-8a027c0f055d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056561450-172.17.0.19-1597368369520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37344,DS-fc926b5f-b4ba-4653-a8bf-021d6901847d,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-2a276c29-09be-4970-8e35-b643f592ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-13e85eb0-aa04-4ca4-88bc-03fe73ca5881,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-343cbb37-da59-466a-a626-c8032e637c49,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-3396e768-5570-4bc1-8bef-7cecd583605c,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-c9db3868-ee99-40d1-9b84-266d75e72dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-6a0ba42a-5d5a-4898-8315-ef534839f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-1ca1117c-e181-4706-8371-8a027c0f055d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942253739-172.17.0.19-1597369333928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-0129c918-60e2-41f7-8f59-94cbc3a6f4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-0aaa79da-40da-474f-b270-cdc68d72032a,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-f41a1270-3464-40ba-aa5b-7e1eb9bc1d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-b2c578e4-0ea8-498f-bfc8-6ee7db839245,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-1f4accb5-3224-418a-996b-4d06bf44e241,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-f8e73f0a-e93f-4315-9ff0-56510d3259e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-71aa2e76-7486-4d5f-85f4-732acfde16d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-de491719-4868-4d4a-8d42-70a6f6ab9932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942253739-172.17.0.19-1597369333928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-0129c918-60e2-41f7-8f59-94cbc3a6f4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-0aaa79da-40da-474f-b270-cdc68d72032a,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-f41a1270-3464-40ba-aa5b-7e1eb9bc1d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-b2c578e4-0ea8-498f-bfc8-6ee7db839245,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-1f4accb5-3224-418a-996b-4d06bf44e241,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-f8e73f0a-e93f-4315-9ff0-56510d3259e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-71aa2e76-7486-4d5f-85f4-732acfde16d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-de491719-4868-4d4a-8d42-70a6f6ab9932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296955270-172.17.0.19-1597369630533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37469,DS-9951cc18-1022-461f-a05d-b02820c397b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-019ecac2-cd97-49b1-8ffb-ad38a1abc50a,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-b555d22b-9d5e-4573-ab35-8107f4d08a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-b1f8ff38-49d4-4271-b8ca-41e8cb10853e,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-51e684a3-1da1-4a62-8000-511b2370a763,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-a1003495-04d2-4320-927c-cbd06d1d61b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-7d273219-fd6b-4fd0-8091-0c9945f889d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-fe5abc8b-2a38-45ea-9ed6-e65ec6cf24d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296955270-172.17.0.19-1597369630533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37469,DS-9951cc18-1022-461f-a05d-b02820c397b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-019ecac2-cd97-49b1-8ffb-ad38a1abc50a,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-b555d22b-9d5e-4573-ab35-8107f4d08a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-b1f8ff38-49d4-4271-b8ca-41e8cb10853e,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-51e684a3-1da1-4a62-8000-511b2370a763,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-a1003495-04d2-4320-927c-cbd06d1d61b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-7d273219-fd6b-4fd0-8091-0c9945f889d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-fe5abc8b-2a38-45ea-9ed6-e65ec6cf24d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983891082-172.17.0.19-1597369958149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-282d62fa-d9be-4567-b2f8-cb9ff0930183,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-7dd4bb04-36a2-41b6-9fb7-739e17f3baed,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-128c297a-aa65-47cd-bc84-a044d88b1b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-9b39ebde-322d-4d4f-8e1e-20118e534df6,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-14e9f68a-b064-40d7-a0cd-1f7350d19491,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-c1f9fc4d-ee37-493b-8b98-a18b04d7ced9,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-8828e588-bd19-4f42-84f4-a35d1d5c2b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-9432fbe9-8fce-482c-9455-02b0e2a2150f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983891082-172.17.0.19-1597369958149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-282d62fa-d9be-4567-b2f8-cb9ff0930183,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-7dd4bb04-36a2-41b6-9fb7-739e17f3baed,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-128c297a-aa65-47cd-bc84-a044d88b1b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-9b39ebde-322d-4d4f-8e1e-20118e534df6,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-14e9f68a-b064-40d7-a0cd-1f7350d19491,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-c1f9fc4d-ee37-493b-8b98-a18b04d7ced9,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-8828e588-bd19-4f42-84f4-a35d1d5c2b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-9432fbe9-8fce-482c-9455-02b0e2a2150f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195248594-172.17.0.19-1597370000731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46008,DS-b83feb69-c48c-420b-9051-0f9787492bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-8cfa997e-e9d7-4472-b0bf-2689b43cb6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-5dab02c2-9b92-45d3-b669-7d5d0546a691,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-c2689d6e-68f8-45fe-bc63-46ccc4f5fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-ea214235-c039-4a96-9a33-6f8b302bf0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-b469290a-c651-4160-bbad-c7141ea19bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-db2b6d43-665d-4595-9e85-abc8d9ac3b79,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-ebdc6ec1-558f-45cd-adb5-afd4146dfea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195248594-172.17.0.19-1597370000731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46008,DS-b83feb69-c48c-420b-9051-0f9787492bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-8cfa997e-e9d7-4472-b0bf-2689b43cb6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-5dab02c2-9b92-45d3-b669-7d5d0546a691,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-c2689d6e-68f8-45fe-bc63-46ccc4f5fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-ea214235-c039-4a96-9a33-6f8b302bf0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-b469290a-c651-4160-bbad-c7141ea19bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-db2b6d43-665d-4595-9e85-abc8d9ac3b79,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-ebdc6ec1-558f-45cd-adb5-afd4146dfea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822331768-172.17.0.19-1597370037164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-37380570-184f-4392-ba1d-8528d977f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-7337d72d-7994-497d-968b-c053ddff100c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-149ee94a-b6a7-47ff-b8ee-89e61459cc56,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-e1d7db13-83f6-44ae-ac88-8565318f4bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-023a3c2b-0cbb-46c0-b7c5-648ce05651d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-b394935f-490d-4740-a582-9876cdf24467,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-b88d7040-7aee-40c9-aec3-da3f261a6d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-1d5f7208-4722-40d0-b83f-d801ce783fd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822331768-172.17.0.19-1597370037164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-37380570-184f-4392-ba1d-8528d977f9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-7337d72d-7994-497d-968b-c053ddff100c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-149ee94a-b6a7-47ff-b8ee-89e61459cc56,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-e1d7db13-83f6-44ae-ac88-8565318f4bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-023a3c2b-0cbb-46c0-b7c5-648ce05651d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-b394935f-490d-4740-a582-9876cdf24467,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-b88d7040-7aee-40c9-aec3-da3f261a6d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-1d5f7208-4722-40d0-b83f-d801ce783fd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428308989-172.17.0.19-1597370267022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-c70edba9-8c3a-4fec-ab94-66e95916a8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-5c2f2e42-8109-49c6-9c58-0c0b65743606,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-0772ff1a-795e-4c8e-a301-4a25c6f99130,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-a682d881-5ff9-4f63-b013-fa4e7c63f213,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-00c8edee-abef-483b-9b9f-f5db43ce7f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-1027ff24-2544-4b12-9419-29fb0e7725d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-86fb498e-5004-4571-a2a2-4e75f743bc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-5eebe9fa-efca-44fe-964e-640b49a903e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428308989-172.17.0.19-1597370267022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-c70edba9-8c3a-4fec-ab94-66e95916a8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-5c2f2e42-8109-49c6-9c58-0c0b65743606,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-0772ff1a-795e-4c8e-a301-4a25c6f99130,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-a682d881-5ff9-4f63-b013-fa4e7c63f213,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-00c8edee-abef-483b-9b9f-f5db43ce7f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-1027ff24-2544-4b12-9419-29fb0e7725d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-86fb498e-5004-4571-a2a2-4e75f743bc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-5eebe9fa-efca-44fe-964e-640b49a903e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880158383-172.17.0.19-1597370650389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42408,DS-1f1a396f-9721-454e-a668-21166d167619,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-e51c8554-3460-4685-bff9-95685df33c19,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-5cb9431c-02a3-484c-9713-dd919eab6c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-9e4f140b-0648-4e2a-9ba4-bc6a21195d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-e8ef16ff-dbe9-4795-856c-847bebee2731,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-f9fcbe48-f436-4c67-b1b8-13a9f51ebb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-2c6908a5-779e-45a8-8aed-04a88a8b628a,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-a64848e7-8a53-4377-882d-f806fd33760f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880158383-172.17.0.19-1597370650389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42408,DS-1f1a396f-9721-454e-a668-21166d167619,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-e51c8554-3460-4685-bff9-95685df33c19,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-5cb9431c-02a3-484c-9713-dd919eab6c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-9e4f140b-0648-4e2a-9ba4-bc6a21195d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-e8ef16ff-dbe9-4795-856c-847bebee2731,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-f9fcbe48-f436-4c67-b1b8-13a9f51ebb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-2c6908a5-779e-45a8-8aed-04a88a8b628a,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-a64848e7-8a53-4377-882d-f806fd33760f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5774
