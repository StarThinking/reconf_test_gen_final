reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104344587-172.17.0.7-1597746359602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44992,DS-29a01f70-839c-45b1-91e9-0bb6eba55e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-69886565-5c62-4c15-85c5-7d7010b1a033,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-f2313043-0869-4847-8556-835e872aaee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-cce577f9-5aed-4c5b-8975-922d64946642,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-d877775f-8051-4ca1-9794-d6aeb8f4df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-79c81d0d-7427-47da-8f35-05f8bac48495,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-dcbf863f-ec50-45cc-a9ab-5e08dd0f686d,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-83a13932-9f9f-4363-82c0-ed81c2c7841a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104344587-172.17.0.7-1597746359602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44992,DS-29a01f70-839c-45b1-91e9-0bb6eba55e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-69886565-5c62-4c15-85c5-7d7010b1a033,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-f2313043-0869-4847-8556-835e872aaee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-cce577f9-5aed-4c5b-8975-922d64946642,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-d877775f-8051-4ca1-9794-d6aeb8f4df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-79c81d0d-7427-47da-8f35-05f8bac48495,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-dcbf863f-ec50-45cc-a9ab-5e08dd0f686d,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-83a13932-9f9f-4363-82c0-ed81c2c7841a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729402923-172.17.0.7-1597746936512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39710,DS-94a93bed-b118-46d1-bded-ef9df2f08e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-28a4e874-3e91-4180-a2e7-d94db99fd51a,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-1e8608f5-e687-426b-8baa-5f2ad24308b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-1dcd4203-3999-4250-b953-9b7c52694936,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-ce06b538-f97d-46bc-9447-e01cdf20ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-02ba87d5-2b03-4524-8ea7-aeec848f090c,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-2a023201-58db-4aa5-a414-4fce51bf1f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-b48c8173-50a8-4c2a-83c7-9a84501812c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729402923-172.17.0.7-1597746936512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39710,DS-94a93bed-b118-46d1-bded-ef9df2f08e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-28a4e874-3e91-4180-a2e7-d94db99fd51a,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-1e8608f5-e687-426b-8baa-5f2ad24308b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-1dcd4203-3999-4250-b953-9b7c52694936,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-ce06b538-f97d-46bc-9447-e01cdf20ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-02ba87d5-2b03-4524-8ea7-aeec848f090c,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-2a023201-58db-4aa5-a414-4fce51bf1f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-b48c8173-50a8-4c2a-83c7-9a84501812c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863619052-172.17.0.7-1597747052928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-7a6534c0-a298-4e05-8268-731b1dd1c456,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-30538298-a17d-489b-b2b7-597b91b5d3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-38e2afec-2d93-4ca3-9218-9b10ba1ed637,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-633f445c-b406-4981-9897-5a01492f9c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-0132fbdd-4a81-4f99-af74-0f27ffac921b,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-a46cd2e5-28d4-44a2-b65f-9fd3aed00d63,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-67a70bc0-908d-4b2b-8139-3d82704b79af,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-375637f6-a1a9-4699-ba2a-367b33f123bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863619052-172.17.0.7-1597747052928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-7a6534c0-a298-4e05-8268-731b1dd1c456,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-30538298-a17d-489b-b2b7-597b91b5d3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-38e2afec-2d93-4ca3-9218-9b10ba1ed637,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-633f445c-b406-4981-9897-5a01492f9c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-0132fbdd-4a81-4f99-af74-0f27ffac921b,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-a46cd2e5-28d4-44a2-b65f-9fd3aed00d63,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-67a70bc0-908d-4b2b-8139-3d82704b79af,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-375637f6-a1a9-4699-ba2a-367b33f123bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283942187-172.17.0.7-1597747327526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45654,DS-9e75747c-fedd-478a-a695-409c490e8d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-8ba83407-102c-4e13-9244-4732ac3e5930,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-0e38b3f3-dcba-410a-9c11-189cdffeab74,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-316f851c-ecfc-4a57-b072-77d307f978aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-15d1cba8-a47a-454f-bf76-69ac7bd953d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-f16edb26-e9c5-4e03-8a78-04a02a5c650c,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-c7cf495a-1b98-4303-8b68-857ab359324b,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-269def8b-f6ae-47ac-81c3-351cad45ae2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283942187-172.17.0.7-1597747327526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45654,DS-9e75747c-fedd-478a-a695-409c490e8d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-8ba83407-102c-4e13-9244-4732ac3e5930,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-0e38b3f3-dcba-410a-9c11-189cdffeab74,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-316f851c-ecfc-4a57-b072-77d307f978aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-15d1cba8-a47a-454f-bf76-69ac7bd953d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-f16edb26-e9c5-4e03-8a78-04a02a5c650c,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-c7cf495a-1b98-4303-8b68-857ab359324b,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-269def8b-f6ae-47ac-81c3-351cad45ae2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510432726-172.17.0.7-1597747614159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-dc447a8a-dc9e-448b-af05-aeea1134bef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-509361ae-233b-4236-af2c-51e482927820,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-ee9f0468-5a62-4adf-abbe-e65d079053c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-0beb1a3d-5062-4d49-996e-07b81fca442b,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-26597fbf-d89e-47a6-978e-c5ad1a7f49f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-b9aa297d-3c5b-49d4-bc6c-a3813419feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-0773c362-0d87-431b-9930-ce8f667490a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-087ea15f-3b89-493d-bfff-6d390b37ffdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510432726-172.17.0.7-1597747614159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-dc447a8a-dc9e-448b-af05-aeea1134bef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-509361ae-233b-4236-af2c-51e482927820,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-ee9f0468-5a62-4adf-abbe-e65d079053c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-0beb1a3d-5062-4d49-996e-07b81fca442b,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-26597fbf-d89e-47a6-978e-c5ad1a7f49f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-b9aa297d-3c5b-49d4-bc6c-a3813419feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-0773c362-0d87-431b-9930-ce8f667490a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-087ea15f-3b89-493d-bfff-6d390b37ffdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274967167-172.17.0.7-1597748059073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35382,DS-243cded1-b9bd-455b-a0fd-1ef6c4082549,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-92e3e229-124b-4bf3-a6b9-4849c88e47cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-d566661d-0768-428b-91f1-5d9260fbf825,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-07c7da71-219e-4aef-87fb-a01d9e01a9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-ea88666a-0c77-4c90-8a05-4ae030eacd56,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-8fd96f90-0a82-4772-821d-3077770c856a,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-ed21ca8c-34b8-4d76-b366-ac771929f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-88fba2e9-6851-4d2f-8948-2ad1f1f4a756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274967167-172.17.0.7-1597748059073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35382,DS-243cded1-b9bd-455b-a0fd-1ef6c4082549,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-92e3e229-124b-4bf3-a6b9-4849c88e47cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-d566661d-0768-428b-91f1-5d9260fbf825,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-07c7da71-219e-4aef-87fb-a01d9e01a9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-ea88666a-0c77-4c90-8a05-4ae030eacd56,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-8fd96f90-0a82-4772-821d-3077770c856a,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-ed21ca8c-34b8-4d76-b366-ac771929f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-88fba2e9-6851-4d2f-8948-2ad1f1f4a756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538389395-172.17.0.7-1597748211850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-aa0de3e4-480c-41c0-aa07-6bb2b4a31589,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-ce5e0a92-657c-496d-97e5-2b3a5eea5d03,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-aa0003f3-d43a-4adc-9b6c-de7b04b871c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f3293f23-9dee-4deb-a45b-8a03db087136,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-c4b1f93f-6c2f-4bb4-8ca2-0b49b7fdf60b,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-46306c76-da43-40f3-802b-ad79403262d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-ebf160ae-70f1-45a5-bfdd-315456d94278,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-a36ae963-c0c5-47ec-b858-99ee6b1a60c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538389395-172.17.0.7-1597748211850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-aa0de3e4-480c-41c0-aa07-6bb2b4a31589,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-ce5e0a92-657c-496d-97e5-2b3a5eea5d03,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-aa0003f3-d43a-4adc-9b6c-de7b04b871c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f3293f23-9dee-4deb-a45b-8a03db087136,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-c4b1f93f-6c2f-4bb4-8ca2-0b49b7fdf60b,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-46306c76-da43-40f3-802b-ad79403262d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-ebf160ae-70f1-45a5-bfdd-315456d94278,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-a36ae963-c0c5-47ec-b858-99ee6b1a60c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129856907-172.17.0.7-1597748598216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46457,DS-878ef048-bd1d-4293-8337-be519751c0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-b40627cd-ce87-4d44-8b1c-55329bf3ed43,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-6ddb6533-552d-44b0-99da-33dec5412fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-0ee0ae97-2a97-435c-a596-f0accd8dbd77,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-28e373c1-5cd9-4ef2-981f-7ce2fc0b05fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-5d30986b-2b8b-4e81-bbbc-36d0dd7b6575,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-2fe8a226-c027-45e3-9c27-d0354568e457,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-a842f28c-a7c0-4421-b0f3-4d55a35a2caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129856907-172.17.0.7-1597748598216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46457,DS-878ef048-bd1d-4293-8337-be519751c0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-b40627cd-ce87-4d44-8b1c-55329bf3ed43,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-6ddb6533-552d-44b0-99da-33dec5412fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-0ee0ae97-2a97-435c-a596-f0accd8dbd77,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-28e373c1-5cd9-4ef2-981f-7ce2fc0b05fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-5d30986b-2b8b-4e81-bbbc-36d0dd7b6575,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-2fe8a226-c027-45e3-9c27-d0354568e457,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-a842f28c-a7c0-4421-b0f3-4d55a35a2caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480144665-172.17.0.7-1597749121468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-537100f9-f17c-4121-b22b-88546d62b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-2098f005-def8-4aef-8a32-d892f88970bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-b3a2580d-c228-4f33-884f-d5a0388f5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-8c005111-5e32-4509-ba60-2fb49e521695,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-286117cc-6478-4d78-9bbb-86ac650746b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-9d0d20a0-3d77-4d12-abee-990ee02d3b01,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-a14b8581-a5c0-4b92-ad47-7dbdec1008f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-c431559f-64e7-4e1b-aa44-0fcb1f31e7b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480144665-172.17.0.7-1597749121468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-537100f9-f17c-4121-b22b-88546d62b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-2098f005-def8-4aef-8a32-d892f88970bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-b3a2580d-c228-4f33-884f-d5a0388f5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-8c005111-5e32-4509-ba60-2fb49e521695,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-286117cc-6478-4d78-9bbb-86ac650746b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-9d0d20a0-3d77-4d12-abee-990ee02d3b01,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-a14b8581-a5c0-4b92-ad47-7dbdec1008f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-c431559f-64e7-4e1b-aa44-0fcb1f31e7b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031705991-172.17.0.7-1597749642106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-8bd06df3-0fd8-4625-b6fc-648aef9e9967,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-dd2e0c24-5d46-4b29-8234-a4a2c682363f,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-5f278f6c-e124-4953-9b52-a52180a4cf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-ddb9e912-f1df-4e99-b81d-d047ca831f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-679b4f29-a24d-474a-8208-e2177782cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-11ea62b7-e970-47c9-bbd7-2249cd9db9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-53dd5531-cbec-46a5-9e1c-58bdc0a0bb09,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-6530219c-1ff5-4012-a530-132aaa12fb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031705991-172.17.0.7-1597749642106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-8bd06df3-0fd8-4625-b6fc-648aef9e9967,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-dd2e0c24-5d46-4b29-8234-a4a2c682363f,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-5f278f6c-e124-4953-9b52-a52180a4cf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-ddb9e912-f1df-4e99-b81d-d047ca831f22,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-679b4f29-a24d-474a-8208-e2177782cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-11ea62b7-e970-47c9-bbd7-2249cd9db9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-53dd5531-cbec-46a5-9e1c-58bdc0a0bb09,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-6530219c-1ff5-4012-a530-132aaa12fb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752452209-172.17.0.7-1597749997135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-bbe5d823-56f1-41cc-8d04-e2cd2fd039eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-612ee887-8dc2-42ff-b186-867c49395312,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-48bcf016-4469-4e37-8e92-5d9a745f4b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-106dbcbd-4693-42fd-97f9-580778ae7583,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-cc11257d-6df7-4811-b552-6830b98b40eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-e27698e9-6883-4208-8b29-b38c32b02687,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-6c2a3e59-3012-4f2c-a171-f8958c2a393a,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-ae3c8fe9-c5b6-49f0-bd8d-9517e8b3c3c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752452209-172.17.0.7-1597749997135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-bbe5d823-56f1-41cc-8d04-e2cd2fd039eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-612ee887-8dc2-42ff-b186-867c49395312,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-48bcf016-4469-4e37-8e92-5d9a745f4b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-106dbcbd-4693-42fd-97f9-580778ae7583,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-cc11257d-6df7-4811-b552-6830b98b40eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-e27698e9-6883-4208-8b29-b38c32b02687,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-6c2a3e59-3012-4f2c-a171-f8958c2a393a,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-ae3c8fe9-c5b6-49f0-bd8d-9517e8b3c3c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749936706-172.17.0.7-1597750146074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39830,DS-ec9f1479-eaad-433a-847b-db216c96b89e,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-db5264d9-4fd1-4b05-a4e0-455443e1f2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-69fa9b48-0869-4939-8445-b310457144c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-de803078-3cc2-4d21-a1d5-94cf4a0bfab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-4b012bd1-b45c-4395-b78f-163ed4a0d0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-f68f2470-6ee5-4ffe-9288-a77a16afb34e,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-0ae2ec22-820a-4c44-b023-4a8855dc35fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-c8982ed0-d9a9-45b2-8199-0aea77366b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749936706-172.17.0.7-1597750146074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39830,DS-ec9f1479-eaad-433a-847b-db216c96b89e,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-db5264d9-4fd1-4b05-a4e0-455443e1f2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-69fa9b48-0869-4939-8445-b310457144c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-de803078-3cc2-4d21-a1d5-94cf4a0bfab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-4b012bd1-b45c-4395-b78f-163ed4a0d0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-f68f2470-6ee5-4ffe-9288-a77a16afb34e,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-0ae2ec22-820a-4c44-b023-4a8855dc35fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-c8982ed0-d9a9-45b2-8199-0aea77366b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530940270-172.17.0.7-1597750214735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44367,DS-8eb3339e-91f3-42d0-9545-1ad45db5eabf,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-bffd1c84-70df-4fe2-9628-a82e2ebce3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-7d04dd7a-018c-4965-b4b6-cc7ea6dc0617,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-de32b884-6ad5-4bf4-b1b1-a344825332c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-0f4b19d3-95e3-48db-9568-f7ef4ef31971,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-2d87f960-b76c-4b25-85a0-9c15b9ae1366,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-7e59d6dc-2fed-46ac-9da7-b2f3089ad8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-a4fad29e-9023-48e5-990b-6a12485a9bb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530940270-172.17.0.7-1597750214735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44367,DS-8eb3339e-91f3-42d0-9545-1ad45db5eabf,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-bffd1c84-70df-4fe2-9628-a82e2ebce3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-7d04dd7a-018c-4965-b4b6-cc7ea6dc0617,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-de32b884-6ad5-4bf4-b1b1-a344825332c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-0f4b19d3-95e3-48db-9568-f7ef4ef31971,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-2d87f960-b76c-4b25-85a0-9c15b9ae1366,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-7e59d6dc-2fed-46ac-9da7-b2f3089ad8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-a4fad29e-9023-48e5-990b-6a12485a9bb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370032786-172.17.0.7-1597750425963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-587cc657-2f09-4f53-ab46-7880c1664fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-7ee8df15-1529-4070-9fb9-6f68a3fe88da,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-9d30c1e4-8f47-4624-ba49-6e46d2cda4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-4e4facd5-645f-46fe-90ac-bd07dba97fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-c92fcb4c-0f6f-4cbc-bdd4-f5056ecd59b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-81038b7c-9823-451c-8762-03f6fd0664ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-1f843178-aa1e-4b30-8fe7-fc7a7d1abab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-baf5bb83-71a3-43a1-9c5d-9a6388457e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370032786-172.17.0.7-1597750425963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-587cc657-2f09-4f53-ab46-7880c1664fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-7ee8df15-1529-4070-9fb9-6f68a3fe88da,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-9d30c1e4-8f47-4624-ba49-6e46d2cda4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-4e4facd5-645f-46fe-90ac-bd07dba97fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-c92fcb4c-0f6f-4cbc-bdd4-f5056ecd59b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-81038b7c-9823-451c-8762-03f6fd0664ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-1f843178-aa1e-4b30-8fe7-fc7a7d1abab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-baf5bb83-71a3-43a1-9c5d-9a6388457e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288171215-172.17.0.7-1597750463045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44653,DS-a363797c-c969-4474-a70f-f862560c590c,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-2b05dd21-410b-490e-bc64-9749450e08c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-ed628a6d-1e0e-418f-a9e0-1787656e2f68,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-7a2195cc-3dfd-495d-8c9f-673ae8448245,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-6959c5e8-a600-450d-999c-64e462fb6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-b7a3f112-3380-4907-9163-d56aa47be966,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-5cdeb935-00e6-4d52-860a-54c4eae0eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-5fa786f9-8a45-40a7-be8b-5c895220479a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288171215-172.17.0.7-1597750463045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44653,DS-a363797c-c969-4474-a70f-f862560c590c,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-2b05dd21-410b-490e-bc64-9749450e08c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-ed628a6d-1e0e-418f-a9e0-1787656e2f68,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-7a2195cc-3dfd-495d-8c9f-673ae8448245,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-6959c5e8-a600-450d-999c-64e462fb6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-b7a3f112-3380-4907-9163-d56aa47be966,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-5cdeb935-00e6-4d52-860a-54c4eae0eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-5fa786f9-8a45-40a7-be8b-5c895220479a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61005966-172.17.0.7-1597751555957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43730,DS-445a9e94-9353-4cd9-b6e0-0c385179e578,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-fb5185e7-1eff-4da7-a11a-de56f9668319,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-5e006cac-b022-4b0b-b10a-4bbaf11148c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-72eeb562-cbbd-42be-8fb8-67d051dd97b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-15f39eca-2af0-46a8-921a-c61de94176a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-92f87e92-6b43-4fa8-aec8-f66aea21bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-ae112a08-3627-46e7-a40b-8e91a02f5112,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-0e5345af-fcc6-475a-b5ed-8efae004968a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61005966-172.17.0.7-1597751555957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43730,DS-445a9e94-9353-4cd9-b6e0-0c385179e578,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-fb5185e7-1eff-4da7-a11a-de56f9668319,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-5e006cac-b022-4b0b-b10a-4bbaf11148c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-72eeb562-cbbd-42be-8fb8-67d051dd97b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-15f39eca-2af0-46a8-921a-c61de94176a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-92f87e92-6b43-4fa8-aec8-f66aea21bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-ae112a08-3627-46e7-a40b-8e91a02f5112,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-0e5345af-fcc6-475a-b5ed-8efae004968a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502230294-172.17.0.7-1597751852058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-228afbd5-ccf8-402f-9709-aed5f9c9416f,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-32be3f7d-bb8c-4e45-9cff-2875c53654c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-2b51c8f0-3cab-4e95-b64b-4abb2cd7f490,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-1c4b989e-4f69-4219-92d6-dda11c20857d,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-afa59c6b-6181-4049-a783-550fa158cece,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-45f8ffbd-4b98-4bb0-9aa5-22457323a17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-e216b606-3375-4702-9ff7-845ef7e8bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-99d8b64e-9a73-4ea2-94d1-e95d6fa3639a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502230294-172.17.0.7-1597751852058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-228afbd5-ccf8-402f-9709-aed5f9c9416f,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-32be3f7d-bb8c-4e45-9cff-2875c53654c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-2b51c8f0-3cab-4e95-b64b-4abb2cd7f490,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-1c4b989e-4f69-4219-92d6-dda11c20857d,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-afa59c6b-6181-4049-a783-550fa158cece,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-45f8ffbd-4b98-4bb0-9aa5-22457323a17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-e216b606-3375-4702-9ff7-845ef7e8bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-99d8b64e-9a73-4ea2-94d1-e95d6fa3639a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5574
