reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624951344-172.17.0.15-1597427767386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35593,DS-1d13ee13-b2e1-448c-b1bc-35aede24e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-681f6895-612b-4ec2-b94d-b2bc1166025f,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-e960ad7c-fba1-42e0-9668-43aab652ee3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-e57fb421-0252-4981-9ff3-7bf727f41aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-64a4caf7-79c3-46f7-a70b-7bb3987066d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-c9f8f93e-af37-4478-95d7-5c1c04739e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-246bf828-4eba-49b2-94ca-838774c691e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-2a63dfb4-387a-49e8-9e39-4730db5f3e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624951344-172.17.0.15-1597427767386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35593,DS-1d13ee13-b2e1-448c-b1bc-35aede24e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-681f6895-612b-4ec2-b94d-b2bc1166025f,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-e960ad7c-fba1-42e0-9668-43aab652ee3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-e57fb421-0252-4981-9ff3-7bf727f41aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-64a4caf7-79c3-46f7-a70b-7bb3987066d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-c9f8f93e-af37-4478-95d7-5c1c04739e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-246bf828-4eba-49b2-94ca-838774c691e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-2a63dfb4-387a-49e8-9e39-4730db5f3e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8450486-172.17.0.15-1597428310472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41571,DS-97dfea04-51bf-490a-99cf-9d2372061193,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-3cc89d06-e64a-422d-9ca1-0c498697af33,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-b5870bf0-10d8-4f8d-a0d5-5b108d5f860a,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-8f1d018e-fa31-4d93-b9e3-3332c334f45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-a0b14cf7-1d1d-4967-abda-ccd84f1e306d,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-fbb8deb5-401d-4683-8784-ade5379f9586,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-3031dbec-8ecf-4509-96c8-1833543f2af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-94f32b0c-d54f-490b-9414-775b537d7b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8450486-172.17.0.15-1597428310472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41571,DS-97dfea04-51bf-490a-99cf-9d2372061193,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-3cc89d06-e64a-422d-9ca1-0c498697af33,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-b5870bf0-10d8-4f8d-a0d5-5b108d5f860a,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-8f1d018e-fa31-4d93-b9e3-3332c334f45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-a0b14cf7-1d1d-4967-abda-ccd84f1e306d,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-fbb8deb5-401d-4683-8784-ade5379f9586,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-3031dbec-8ecf-4509-96c8-1833543f2af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-94f32b0c-d54f-490b-9414-775b537d7b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925909302-172.17.0.15-1597428433198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-82e0b469-b8c9-443d-9c30-9bdbe36e07cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-7a3783b0-6d11-4e61-a566-4135802175d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-4e6bb353-04ed-4f30-b5d6-baf84a32d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-7f003f8f-bde5-470a-a8b7-0ed7e8164a55,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-ff106809-fca2-4f52-91d6-714dcde01862,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-465f65b2-a759-40a2-91e7-714e8eda611d,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-493e852d-e598-4f20-8e64-ae1572bb97f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-83b354bf-04ce-44bc-b665-358be9e8969b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925909302-172.17.0.15-1597428433198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-82e0b469-b8c9-443d-9c30-9bdbe36e07cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-7a3783b0-6d11-4e61-a566-4135802175d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-4e6bb353-04ed-4f30-b5d6-baf84a32d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-7f003f8f-bde5-470a-a8b7-0ed7e8164a55,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-ff106809-fca2-4f52-91d6-714dcde01862,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-465f65b2-a759-40a2-91e7-714e8eda611d,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-493e852d-e598-4f20-8e64-ae1572bb97f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-83b354bf-04ce-44bc-b665-358be9e8969b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170504523-172.17.0.15-1597429288062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-89375633-5dd5-4676-af3d-e07a29d5d926,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-e192ae66-8700-4b06-81af-d8d7f3f9d765,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-321b491c-994b-4fe0-a545-85c6db21a471,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-192fa852-8bca-476e-a120-4d87a9062a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-81e41cc2-49bf-42a6-8757-425021708269,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-1ae12a63-392f-4077-9796-24ae441b89c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-997a5f07-1907-4328-9697-b4f250e56d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-c2960555-6cce-40d2-b0c3-58e12ec2fe7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170504523-172.17.0.15-1597429288062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-89375633-5dd5-4676-af3d-e07a29d5d926,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-e192ae66-8700-4b06-81af-d8d7f3f9d765,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-321b491c-994b-4fe0-a545-85c6db21a471,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-192fa852-8bca-476e-a120-4d87a9062a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-81e41cc2-49bf-42a6-8757-425021708269,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-1ae12a63-392f-4077-9796-24ae441b89c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-997a5f07-1907-4328-9697-b4f250e56d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-c2960555-6cce-40d2-b0c3-58e12ec2fe7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262626032-172.17.0.15-1597429545169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40427,DS-117c604d-270a-49e9-a48b-72144daff4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-cd8e82fa-b1ec-4c04-95e0-691b1470267e,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-e603f4de-335e-43ed-8ece-b7f315d71541,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-390f2332-fe17-4e22-af85-60abf9230b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-5a5916a5-147b-480c-a596-32fe6c0431ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-1c3ce51c-378e-48a3-9d1b-26239d0ebb95,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-f17dcdd4-308f-4dd8-bde5-f4dbb3bf3525,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-3b0c7ea0-8f17-48b7-bfd1-1148ba70ff85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262626032-172.17.0.15-1597429545169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40427,DS-117c604d-270a-49e9-a48b-72144daff4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-cd8e82fa-b1ec-4c04-95e0-691b1470267e,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-e603f4de-335e-43ed-8ece-b7f315d71541,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-390f2332-fe17-4e22-af85-60abf9230b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-5a5916a5-147b-480c-a596-32fe6c0431ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-1c3ce51c-378e-48a3-9d1b-26239d0ebb95,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-f17dcdd4-308f-4dd8-bde5-f4dbb3bf3525,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-3b0c7ea0-8f17-48b7-bfd1-1148ba70ff85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980561994-172.17.0.15-1597429670751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34818,DS-e2fbce4f-cd1a-45fd-8da1-9754a3f23c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-979e66be-6c52-4323-a7e9-fefa16a7641b,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-5d396014-f0ba-4192-8286-9652059c7b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-ec9e5405-019b-4563-9ac3-527231778f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-e69c516b-8bf8-4fdb-9526-e00fee2f20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-cf277e43-ec00-44f0-b88a-8e7c8d490b08,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-f48ce80a-c962-4ed8-a617-d4e885f6f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-dff8334a-6b11-4a9f-ae20-7125cace5047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980561994-172.17.0.15-1597429670751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34818,DS-e2fbce4f-cd1a-45fd-8da1-9754a3f23c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-979e66be-6c52-4323-a7e9-fefa16a7641b,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-5d396014-f0ba-4192-8286-9652059c7b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-ec9e5405-019b-4563-9ac3-527231778f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-e69c516b-8bf8-4fdb-9526-e00fee2f20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-cf277e43-ec00-44f0-b88a-8e7c8d490b08,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-f48ce80a-c962-4ed8-a617-d4e885f6f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-dff8334a-6b11-4a9f-ae20-7125cace5047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075450048-172.17.0.15-1597430165402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33026,DS-bd1ff6d0-e4e6-46b3-8ea6-1c90dc2782c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-b656fd47-923f-44c9-9aa0-41a2e5b2e386,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-fe9841cc-25f0-4c7d-9391-c97f830e4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-99c968a5-3f8d-4953-b32b-5122ac50d139,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-56a6b660-719b-4ccb-bfdb-5fcd2a371c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-fb416820-ba1f-4753-96db-00562310bbad,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-c362b964-ab64-4cbc-aa61-517629ca8a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-df4b9ac0-c81c-4cec-a275-0bb44976196a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075450048-172.17.0.15-1597430165402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33026,DS-bd1ff6d0-e4e6-46b3-8ea6-1c90dc2782c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-b656fd47-923f-44c9-9aa0-41a2e5b2e386,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-fe9841cc-25f0-4c7d-9391-c97f830e4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-99c968a5-3f8d-4953-b32b-5122ac50d139,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-56a6b660-719b-4ccb-bfdb-5fcd2a371c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-fb416820-ba1f-4753-96db-00562310bbad,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-c362b964-ab64-4cbc-aa61-517629ca8a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-df4b9ac0-c81c-4cec-a275-0bb44976196a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958724397-172.17.0.15-1597430328187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45345,DS-d1b921d1-1983-4228-8073-53d398b47503,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-6b73a359-90bc-4029-baad-b1f89840189c,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-48f08d47-ee9b-46eb-b2e2-40d5b1693887,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-1ed1a64e-afe1-4472-b03d-f93a3b8f2ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-9441a34e-8b83-43f2-a827-402e247a419e,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-036be357-e869-4ce2-9985-60b6141891c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-832fb6ff-af1a-4fd6-bd8d-34046910986b,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-daad7c03-4eed-4f6e-bd34-b8b229f01efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958724397-172.17.0.15-1597430328187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45345,DS-d1b921d1-1983-4228-8073-53d398b47503,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-6b73a359-90bc-4029-baad-b1f89840189c,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-48f08d47-ee9b-46eb-b2e2-40d5b1693887,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-1ed1a64e-afe1-4472-b03d-f93a3b8f2ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-9441a34e-8b83-43f2-a827-402e247a419e,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-036be357-e869-4ce2-9985-60b6141891c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-832fb6ff-af1a-4fd6-bd8d-34046910986b,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-daad7c03-4eed-4f6e-bd34-b8b229f01efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857791106-172.17.0.15-1597430611525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37640,DS-0065cdda-0108-47b8-9be9-c3ff4c67514e,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-1d88af13-aa00-4967-84cc-28a41c45f0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-35ed4f90-90ea-41b0-80ed-539905d4e738,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-8c859e59-7208-40af-ae1b-7a2370006fee,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-0249b16b-6106-49f8-b765-b53fdaf9b1da,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-d1272460-ddf2-4f40-96b2-52c2a13b4cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-9c6f06af-c254-4c69-9cd3-cedf74fe8c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-c9a1dca2-2d1d-4d2f-885a-a3eb4719ff64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857791106-172.17.0.15-1597430611525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37640,DS-0065cdda-0108-47b8-9be9-c3ff4c67514e,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-1d88af13-aa00-4967-84cc-28a41c45f0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-35ed4f90-90ea-41b0-80ed-539905d4e738,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-8c859e59-7208-40af-ae1b-7a2370006fee,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-0249b16b-6106-49f8-b765-b53fdaf9b1da,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-d1272460-ddf2-4f40-96b2-52c2a13b4cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-9c6f06af-c254-4c69-9cd3-cedf74fe8c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-c9a1dca2-2d1d-4d2f-885a-a3eb4719ff64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219065689-172.17.0.15-1597430835018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34627,DS-653b3f42-30e4-4ada-a268-411bd7aa6b46,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-13f1d5f8-1812-471b-9394-90724267be45,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-d322850c-1c82-48c6-93fa-d395c2c94fff,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-a7d0254f-aa58-4983-a667-2f0b35837eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-4634abb3-f8a2-4890-922b-f419b70a2b80,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-21ae36b7-cc84-4bbd-8439-73de9140ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-fb1db68d-0c1d-4b68-b630-65eb02e00e88,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-88cb56c5-c6fb-4574-8099-e32749b65818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219065689-172.17.0.15-1597430835018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34627,DS-653b3f42-30e4-4ada-a268-411bd7aa6b46,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-13f1d5f8-1812-471b-9394-90724267be45,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-d322850c-1c82-48c6-93fa-d395c2c94fff,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-a7d0254f-aa58-4983-a667-2f0b35837eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-4634abb3-f8a2-4890-922b-f419b70a2b80,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-21ae36b7-cc84-4bbd-8439-73de9140ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-fb1db68d-0c1d-4b68-b630-65eb02e00e88,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-88cb56c5-c6fb-4574-8099-e32749b65818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161114267-172.17.0.15-1597430976507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-0fbf4bdc-fa15-4639-a9c0-7c6c4b5c0b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-ec9daf37-72b4-4bc6-86ea-57f8b13b8937,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-b27b7cc8-e347-4693-8e95-72bc7c432501,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-4acf3590-760c-47d9-9129-9ed8a3e49fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-c9015a08-2d94-4305-8f3b-c9a66ac54db1,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-fe981a77-c3a9-46b9-b967-631eb19d4213,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-ed36c300-ca6b-4786-a1e4-b868b6d8b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-2b6e76a2-d147-4ea1-8401-42738b9d9d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161114267-172.17.0.15-1597430976507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-0fbf4bdc-fa15-4639-a9c0-7c6c4b5c0b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-ec9daf37-72b4-4bc6-86ea-57f8b13b8937,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-b27b7cc8-e347-4693-8e95-72bc7c432501,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-4acf3590-760c-47d9-9129-9ed8a3e49fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-c9015a08-2d94-4305-8f3b-c9a66ac54db1,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-fe981a77-c3a9-46b9-b967-631eb19d4213,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-ed36c300-ca6b-4786-a1e4-b868b6d8b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-2b6e76a2-d147-4ea1-8401-42738b9d9d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814408417-172.17.0.15-1597431086634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35304,DS-9437e867-5d4e-445b-b604-dbef5a955a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-7a178300-0f92-4e0c-9066-5c21f848423f,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-e1d48195-892c-4bab-8f91-2ec19c6d60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-ff3ac575-721b-4c54-9ee2-696a631fb96e,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-2fd708e1-9938-4fd1-9e7b-f7fbc15aae73,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-080184e7-8425-488b-9e8a-6b363e936d34,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-cee94789-1f04-4bb1-94c0-43cb939deb77,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-88918cc0-3a85-4047-8c0c-024c3170a657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814408417-172.17.0.15-1597431086634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35304,DS-9437e867-5d4e-445b-b604-dbef5a955a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-7a178300-0f92-4e0c-9066-5c21f848423f,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-e1d48195-892c-4bab-8f91-2ec19c6d60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-ff3ac575-721b-4c54-9ee2-696a631fb96e,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-2fd708e1-9938-4fd1-9e7b-f7fbc15aae73,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-080184e7-8425-488b-9e8a-6b363e936d34,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-cee94789-1f04-4bb1-94c0-43cb939deb77,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-88918cc0-3a85-4047-8c0c-024c3170a657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572759733-172.17.0.15-1597431686592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43642,DS-993095e2-d757-4171-9d90-461f4ab08a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-08ff84e6-4a95-4cf4-a50b-a5937ba4347d,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-d141de62-be2f-4f88-8608-4717fdcfa516,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-fe7b4fbd-d294-4b5e-b38a-856ab02a266c,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-c2455304-300e-455d-b00a-6baf42781d39,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-c55b5bbd-8f9a-460b-abe1-7b24fb3e43bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-a0995186-9b81-45f9-bdd5-eb23d3ee69d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-319e9e2d-1274-42a0-8034-1f5beb1a2437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572759733-172.17.0.15-1597431686592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43642,DS-993095e2-d757-4171-9d90-461f4ab08a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-08ff84e6-4a95-4cf4-a50b-a5937ba4347d,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-d141de62-be2f-4f88-8608-4717fdcfa516,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-fe7b4fbd-d294-4b5e-b38a-856ab02a266c,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-c2455304-300e-455d-b00a-6baf42781d39,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-c55b5bbd-8f9a-460b-abe1-7b24fb3e43bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-a0995186-9b81-45f9-bdd5-eb23d3ee69d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-319e9e2d-1274-42a0-8034-1f5beb1a2437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4252
