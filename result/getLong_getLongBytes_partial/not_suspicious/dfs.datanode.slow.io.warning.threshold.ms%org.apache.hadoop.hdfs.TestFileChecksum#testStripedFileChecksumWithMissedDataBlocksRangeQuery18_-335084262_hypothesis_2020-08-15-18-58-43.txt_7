reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626889399-172.17.0.2-1597518403940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-9c7cc98f-8a4e-4114-9335-2c3677c87cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-3cf2aa1b-9fe3-47b6-ae5c-cca9f85e6016,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-7498659e-9e4f-401a-ac92-e2265b50baaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-b96d7ec7-cfc7-4ce5-81de-ae7bbd827e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-426b1166-515f-44b0-ae14-2ad5d3691312,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-ba3b6684-26ab-49cf-a60f-cdcec48dd82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-175b0d28-8624-44f3-84aa-412757b4a06b,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-0e6260ae-60be-46dd-9f27-97556497df63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626889399-172.17.0.2-1597518403940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-9c7cc98f-8a4e-4114-9335-2c3677c87cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-3cf2aa1b-9fe3-47b6-ae5c-cca9f85e6016,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-7498659e-9e4f-401a-ac92-e2265b50baaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-b96d7ec7-cfc7-4ce5-81de-ae7bbd827e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-426b1166-515f-44b0-ae14-2ad5d3691312,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-ba3b6684-26ab-49cf-a60f-cdcec48dd82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-175b0d28-8624-44f3-84aa-412757b4a06b,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-0e6260ae-60be-46dd-9f27-97556497df63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359429864-172.17.0.2-1597519861070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-2a6a883f-a50a-4b2f-9d8d-02a207d368eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-de743204-2eb2-4782-a584-110024d00745,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-f947c6af-1899-4c56-ac50-56eb0fa7ae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-1282c59d-0ddf-477b-adce-aa2d9506fb87,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-1bdb0927-13b2-4b0b-8179-0f9350395f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-24fdf7e6-841c-4a5a-8b6b-badbbf33f220,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-e1fe6d6a-1da7-4ba1-8517-864210d1cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-2b37af56-b243-446a-9f36-2980559116c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359429864-172.17.0.2-1597519861070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-2a6a883f-a50a-4b2f-9d8d-02a207d368eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-de743204-2eb2-4782-a584-110024d00745,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-f947c6af-1899-4c56-ac50-56eb0fa7ae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-1282c59d-0ddf-477b-adce-aa2d9506fb87,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-1bdb0927-13b2-4b0b-8179-0f9350395f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-24fdf7e6-841c-4a5a-8b6b-badbbf33f220,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-e1fe6d6a-1da7-4ba1-8517-864210d1cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-2b37af56-b243-446a-9f36-2980559116c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841989127-172.17.0.2-1597519902559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-d0cf63f2-35d8-4977-8297-8be33a385af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-0106390f-83c9-4697-971e-f84143da8297,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-91360948-05d2-4cd2-8cbf-fb0b30853179,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-d436710d-d4b4-4053-8c2b-813c32193409,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-d6ab899f-32d8-466d-aa0f-8bf0ae0e4c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-b1eeedd4-df98-49eb-a4a1-e1ed7e04ca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-15b79213-b6de-4cc7-9359-4441fca38c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-c6202d95-3819-485e-83d3-5495abd9ed62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841989127-172.17.0.2-1597519902559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-d0cf63f2-35d8-4977-8297-8be33a385af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-0106390f-83c9-4697-971e-f84143da8297,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-91360948-05d2-4cd2-8cbf-fb0b30853179,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-d436710d-d4b4-4053-8c2b-813c32193409,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-d6ab899f-32d8-466d-aa0f-8bf0ae0e4c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-b1eeedd4-df98-49eb-a4a1-e1ed7e04ca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-15b79213-b6de-4cc7-9359-4441fca38c68,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-c6202d95-3819-485e-83d3-5495abd9ed62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113271156-172.17.0.2-1597520165888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-b1af431b-2870-4f1d-8b71-bbb0b650b83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-933ba93f-b7dd-4b8e-8702-a97be208a12e,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-8c693552-9797-4f12-8db3-cbe9675e883b,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-964ace62-e771-4b00-9ab8-d945428ca64d,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-5f3be596-43f8-400d-b074-6c9dcd4284a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-6b2e5a7f-a569-419a-a96c-216993adfc59,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-73caff92-d44a-4011-854f-8fcdfba154c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-b0c33f39-4add-4504-a715-d644c6d955d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113271156-172.17.0.2-1597520165888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-b1af431b-2870-4f1d-8b71-bbb0b650b83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-933ba93f-b7dd-4b8e-8702-a97be208a12e,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-8c693552-9797-4f12-8db3-cbe9675e883b,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-964ace62-e771-4b00-9ab8-d945428ca64d,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-5f3be596-43f8-400d-b074-6c9dcd4284a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-6b2e5a7f-a569-419a-a96c-216993adfc59,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-73caff92-d44a-4011-854f-8fcdfba154c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-b0c33f39-4add-4504-a715-d644c6d955d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958225935-172.17.0.2-1597520422055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-b683b3c5-0893-4ef2-a510-ebfea027db97,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-62401740-b9d5-4d19-a605-6337375b54e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-0e672064-9ddf-4f0f-bf7a-6af584717119,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-07cbbec2-5498-4b48-ac47-0f5c67bdea65,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-78ada7d3-ba16-4997-9bc8-c42abae2d024,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-b231d0f3-f8f3-455e-b7aa-91b2169fe80c,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-c8774803-6d46-46b4-b57e-c43227e402d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-5978bbc5-e1e4-4c72-8709-4e282928a04b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958225935-172.17.0.2-1597520422055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-b683b3c5-0893-4ef2-a510-ebfea027db97,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-62401740-b9d5-4d19-a605-6337375b54e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-0e672064-9ddf-4f0f-bf7a-6af584717119,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-07cbbec2-5498-4b48-ac47-0f5c67bdea65,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-78ada7d3-ba16-4997-9bc8-c42abae2d024,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-b231d0f3-f8f3-455e-b7aa-91b2169fe80c,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-c8774803-6d46-46b4-b57e-c43227e402d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-5978bbc5-e1e4-4c72-8709-4e282928a04b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033071573-172.17.0.2-1597521611477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-7fffa08f-fc13-48ee-9a69-2a9c349b4215,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-0d0ecd1b-3bbf-4c10-ab69-c0d4c9b52302,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-b02c9177-c9d7-4cd8-9553-9d5551a9d3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-485f9d53-cad4-45bc-8e95-55c7abae0f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-d397ef60-78ae-4820-9bbf-b5b297b51646,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-f6d8043a-a7e8-48eb-bf62-db651a4a71e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-c1ed799a-f95e-43be-b1af-9bf3ce94ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-9ec3e2fa-4d47-404c-b845-6008f985b4b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033071573-172.17.0.2-1597521611477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33996,DS-7fffa08f-fc13-48ee-9a69-2a9c349b4215,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-0d0ecd1b-3bbf-4c10-ab69-c0d4c9b52302,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-b02c9177-c9d7-4cd8-9553-9d5551a9d3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-485f9d53-cad4-45bc-8e95-55c7abae0f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-d397ef60-78ae-4820-9bbf-b5b297b51646,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-f6d8043a-a7e8-48eb-bf62-db651a4a71e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-c1ed799a-f95e-43be-b1af-9bf3ce94ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-9ec3e2fa-4d47-404c-b845-6008f985b4b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197542201-172.17.0.2-1597522152350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41458,DS-06b9424c-48ad-4540-a99d-12e11c4d7294,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-77c0868c-4f76-422d-acf2-641ab323e2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-d067fab4-c76b-4f8c-94c2-11c40c311586,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-b42b8ad9-ce39-429b-8065-247b6d1387c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-ca2d73b2-6de4-43d4-9975-5e04a223aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-8e7f4f03-7f6d-4f0f-95f8-fcb1fd4fb098,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-a5a06671-5364-4966-92c7-da6769202444,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-b8680ead-b038-484e-a9a8-e01c37c2b32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197542201-172.17.0.2-1597522152350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41458,DS-06b9424c-48ad-4540-a99d-12e11c4d7294,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-77c0868c-4f76-422d-acf2-641ab323e2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-d067fab4-c76b-4f8c-94c2-11c40c311586,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-b42b8ad9-ce39-429b-8065-247b6d1387c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-ca2d73b2-6de4-43d4-9975-5e04a223aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-8e7f4f03-7f6d-4f0f-95f8-fcb1fd4fb098,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-a5a06671-5364-4966-92c7-da6769202444,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-b8680ead-b038-484e-a9a8-e01c37c2b32f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346400266-172.17.0.2-1597522899001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-1a6cb578-3a36-4917-9d7a-96a9f02c3d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-1ed12cae-324c-490e-811b-435283a2c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-6f0fac8e-83cc-4ac6-ab28-106516ecdb85,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-790ff7b7-e345-497c-8970-18c73dedf683,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-df30a308-ee24-43e9-b11b-c0dbc74a260a,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-69e58003-3c84-4b34-b778-589e35453ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-7bbbf9cd-1d7b-4ee1-8640-f88e3e2e3503,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-e80f7165-ea8e-4485-a556-1e50d8668cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346400266-172.17.0.2-1597522899001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-1a6cb578-3a36-4917-9d7a-96a9f02c3d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-1ed12cae-324c-490e-811b-435283a2c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-6f0fac8e-83cc-4ac6-ab28-106516ecdb85,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-790ff7b7-e345-497c-8970-18c73dedf683,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-df30a308-ee24-43e9-b11b-c0dbc74a260a,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-69e58003-3c84-4b34-b778-589e35453ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-7bbbf9cd-1d7b-4ee1-8640-f88e3e2e3503,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-e80f7165-ea8e-4485-a556-1e50d8668cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-259574801-172.17.0.2-1597522941298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-f1da125f-3e8c-47ca-bbaa-1396c9f1f766,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-70865caf-4af8-47ad-96f8-2f9cf3ac5f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-1d39927e-8179-4bc3-b6e9-be0b20326523,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-afc07ac2-d3d0-46ab-a852-edd9ace51042,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-52028146-866a-4583-a17f-f74f5db87cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-250a5f52-1aca-4f9c-840d-8e8c0033954a,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-5f588980-2094-4568-993b-989bc2600839,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-9db1be30-9368-43c0-97c0-54ee6a3f485f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-259574801-172.17.0.2-1597522941298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-f1da125f-3e8c-47ca-bbaa-1396c9f1f766,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-70865caf-4af8-47ad-96f8-2f9cf3ac5f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-1d39927e-8179-4bc3-b6e9-be0b20326523,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-afc07ac2-d3d0-46ab-a852-edd9ace51042,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-52028146-866a-4583-a17f-f74f5db87cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-250a5f52-1aca-4f9c-840d-8e8c0033954a,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-5f588980-2094-4568-993b-989bc2600839,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-9db1be30-9368-43c0-97c0-54ee6a3f485f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56126837-172.17.0.2-1597523258978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42219,DS-662e587e-926e-4f27-a50e-d19a3fc52300,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-3453a2c0-cd54-48bc-ad88-93c34e74d395,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-ae8bd288-9740-4e6f-87f2-38ac2933ddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-aeffd860-34cf-4e8b-bbf4-90e31e8b595f,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-0c158c5c-8b6e-4d68-88e7-364c9dacc306,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-58c36419-f7df-4810-a085-71ebb785d752,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-50487873-535c-4f5c-be74-5156ca375e16,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-638e98f1-b278-4c6a-a687-ea6ef06f8f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56126837-172.17.0.2-1597523258978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42219,DS-662e587e-926e-4f27-a50e-d19a3fc52300,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-3453a2c0-cd54-48bc-ad88-93c34e74d395,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-ae8bd288-9740-4e6f-87f2-38ac2933ddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-aeffd860-34cf-4e8b-bbf4-90e31e8b595f,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-0c158c5c-8b6e-4d68-88e7-364c9dacc306,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-58c36419-f7df-4810-a085-71ebb785d752,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-50487873-535c-4f5c-be74-5156ca375e16,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-638e98f1-b278-4c6a-a687-ea6ef06f8f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907642450-172.17.0.2-1597524109900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35036,DS-9a20ed1b-85df-4cd4-9a9e-75a4a27a2f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-b9316c77-6ae1-4f36-981d-ae430dc73e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-5fe43e61-4e82-4e30-b2a3-6cb5c81d260d,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-0c3d461a-b935-4b1a-a8c1-c51db68618cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-4cc171ed-88e4-4339-b5d8-0cbfa479cf00,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-4255dada-2f63-473a-8216-4f28ce81fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ef12a663-190f-4e56-b135-6f386ead8556,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-8becd3c2-0a85-47c6-b2a0-a8192427a9fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907642450-172.17.0.2-1597524109900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35036,DS-9a20ed1b-85df-4cd4-9a9e-75a4a27a2f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-b9316c77-6ae1-4f36-981d-ae430dc73e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-5fe43e61-4e82-4e30-b2a3-6cb5c81d260d,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-0c3d461a-b935-4b1a-a8c1-c51db68618cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-4cc171ed-88e4-4339-b5d8-0cbfa479cf00,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-4255dada-2f63-473a-8216-4f28ce81fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ef12a663-190f-4e56-b135-6f386ead8556,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-8becd3c2-0a85-47c6-b2a0-a8192427a9fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6784
