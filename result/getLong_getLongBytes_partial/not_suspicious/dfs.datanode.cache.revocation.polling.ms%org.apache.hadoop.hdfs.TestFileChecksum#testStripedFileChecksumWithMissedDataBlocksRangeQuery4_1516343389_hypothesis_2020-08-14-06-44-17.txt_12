reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63098467-172.17.0.19-1597387995178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32857,DS-48899bac-d179-4adf-b465-efb138054435,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-3c8fb48c-7584-465e-a506-ecc694d2f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-fdf10d0e-cb51-42c2-8f4b-7f34ea9928e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-42289358-ccb2-4aab-a904-3bc805a983a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-8fec24bf-8a8e-49e0-83b3-4918f4d34d88,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-7fa7d299-3ab0-420c-8ef2-36edbbc28d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-93329254-5498-4098-84c7-aaf24875d710,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-bd0a2091-6254-441a-8167-ef4e5c293c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63098467-172.17.0.19-1597387995178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32857,DS-48899bac-d179-4adf-b465-efb138054435,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-3c8fb48c-7584-465e-a506-ecc694d2f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-fdf10d0e-cb51-42c2-8f4b-7f34ea9928e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-42289358-ccb2-4aab-a904-3bc805a983a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-8fec24bf-8a8e-49e0-83b3-4918f4d34d88,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-7fa7d299-3ab0-420c-8ef2-36edbbc28d20,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-93329254-5498-4098-84c7-aaf24875d710,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-bd0a2091-6254-441a-8167-ef4e5c293c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297997243-172.17.0.19-1597388172806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37331,DS-d953bfb2-5cf1-47d9-8e2c-fd87b0f7569f,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-732d1df3-c48f-43de-8194-50863958c00d,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-66ac178a-fa82-4118-aa7c-e605e6959175,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-c2d1f251-81c7-48e4-8d76-2e68e07a3c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-7bf29323-4d9a-4a19-98ff-4f74c1c66586,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-500a00ee-1a88-45d5-a2b9-c8208a4dc338,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-9c4aba59-9ecf-4690-a8c8-2967ddc3db2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-cf728fee-629d-4d60-99de-0f224e9589c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297997243-172.17.0.19-1597388172806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37331,DS-d953bfb2-5cf1-47d9-8e2c-fd87b0f7569f,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-732d1df3-c48f-43de-8194-50863958c00d,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-66ac178a-fa82-4118-aa7c-e605e6959175,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-c2d1f251-81c7-48e4-8d76-2e68e07a3c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-7bf29323-4d9a-4a19-98ff-4f74c1c66586,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-500a00ee-1a88-45d5-a2b9-c8208a4dc338,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-9c4aba59-9ecf-4690-a8c8-2967ddc3db2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-cf728fee-629d-4d60-99de-0f224e9589c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782728157-172.17.0.19-1597388261892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33879,DS-fbf8ea5d-4ab1-4167-b711-8aa11a90be71,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-39199fff-cb3e-48d7-8288-16cc5bc6f39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-03b411ac-1e2c-41cd-a8b6-11158b5ce58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-68bc7c8d-f445-49c4-af4d-c6f07fee43f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-81b21bc6-5c0d-4583-820b-84d0e165e800,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-fbe4583a-38cc-4341-9cbd-9f7625410331,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-effb156e-c0c7-49fd-859b-f3b4335af55e,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-577cf5fa-e93c-4da8-88f6-059584d89263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782728157-172.17.0.19-1597388261892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33879,DS-fbf8ea5d-4ab1-4167-b711-8aa11a90be71,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-39199fff-cb3e-48d7-8288-16cc5bc6f39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-03b411ac-1e2c-41cd-a8b6-11158b5ce58e,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-68bc7c8d-f445-49c4-af4d-c6f07fee43f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-81b21bc6-5c0d-4583-820b-84d0e165e800,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-fbe4583a-38cc-4341-9cbd-9f7625410331,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-effb156e-c0c7-49fd-859b-f3b4335af55e,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-577cf5fa-e93c-4da8-88f6-059584d89263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703820482-172.17.0.19-1597388788190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43393,DS-4d814358-d5d7-4a09-b661-508a7790b706,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-88d3b660-b323-486d-8d14-89b589926490,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-c2c5998f-d8e7-4dd5-abf1-7e95b39d2f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-1cc074e5-81d8-464e-9d60-35df3d725be4,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-e0a017a9-2180-4860-9223-173925ec15cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-110b9bfb-ebb6-4f7e-8b40-869830aa9531,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-8dd152c5-f722-449c-9fca-ce18b09522d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-ba0c6392-dbb6-4bfe-b947-e8cb1ba0f75b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703820482-172.17.0.19-1597388788190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43393,DS-4d814358-d5d7-4a09-b661-508a7790b706,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-88d3b660-b323-486d-8d14-89b589926490,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-c2c5998f-d8e7-4dd5-abf1-7e95b39d2f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-1cc074e5-81d8-464e-9d60-35df3d725be4,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-e0a017a9-2180-4860-9223-173925ec15cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-110b9bfb-ebb6-4f7e-8b40-869830aa9531,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-8dd152c5-f722-449c-9fca-ce18b09522d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-ba0c6392-dbb6-4bfe-b947-e8cb1ba0f75b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822622680-172.17.0.19-1597389296969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-bb5bca1f-0c2a-4da2-850a-6dc2a5bff773,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-758717e8-0680-474d-b9f2-9fcbb09f0a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-5056a6a9-166e-4dbf-8ee1-36d01032522c,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-792bb668-2624-4e83-9113-575b1846097f,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-f9ee3fee-c88d-4edb-a47a-c414a5411426,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-72677d9b-4512-4256-b30d-c77341be1294,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-99ab4243-f022-427a-bff4-838d6e797353,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-cc9571ae-d139-4fea-abaf-b5e56da570a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822622680-172.17.0.19-1597389296969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-bb5bca1f-0c2a-4da2-850a-6dc2a5bff773,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-758717e8-0680-474d-b9f2-9fcbb09f0a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-5056a6a9-166e-4dbf-8ee1-36d01032522c,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-792bb668-2624-4e83-9113-575b1846097f,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-f9ee3fee-c88d-4edb-a47a-c414a5411426,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-72677d9b-4512-4256-b30d-c77341be1294,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-99ab4243-f022-427a-bff4-838d6e797353,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-cc9571ae-d139-4fea-abaf-b5e56da570a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532947401-172.17.0.19-1597390614772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37426,DS-163728c1-4293-40a1-ae03-b494e872bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-1fdb964f-5a28-4c9a-a937-b7733150f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-370b5b66-2333-48c3-b8ec-1295da982631,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-1715dfd7-b9c0-464d-9e67-ee1065fdadb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-fbb849f6-8b63-45cf-9af1-8fd93176d50f,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-20104dad-74f7-43e9-b61d-4766be8a6365,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-47fbe796-b2bd-469d-9f43-8ff194909b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-0ab7e398-0eb5-491e-925f-323bd1377afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532947401-172.17.0.19-1597390614772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37426,DS-163728c1-4293-40a1-ae03-b494e872bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-1fdb964f-5a28-4c9a-a937-b7733150f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-370b5b66-2333-48c3-b8ec-1295da982631,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-1715dfd7-b9c0-464d-9e67-ee1065fdadb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-fbb849f6-8b63-45cf-9af1-8fd93176d50f,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-20104dad-74f7-43e9-b61d-4766be8a6365,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-47fbe796-b2bd-469d-9f43-8ff194909b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-0ab7e398-0eb5-491e-925f-323bd1377afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290092368-172.17.0.19-1597390753907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-6226c745-b407-4d38-a9a4-d38ae12e44bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-84f71158-25e5-48e7-a66f-fa609a8768ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-cba05355-af6d-409d-9053-453285f04fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-c1ba9105-3162-4bed-8f2e-e74704b56b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-1429897e-cbbc-4903-99ac-eadeb5f34941,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-19074fa6-202d-4265-9296-d7ee95debb41,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-0dee1ba7-4cd7-41b5-97de-e9c64e44d0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-4f3b3ce4-de9b-4441-accb-91b6332454e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290092368-172.17.0.19-1597390753907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-6226c745-b407-4d38-a9a4-d38ae12e44bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-84f71158-25e5-48e7-a66f-fa609a8768ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-cba05355-af6d-409d-9053-453285f04fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-c1ba9105-3162-4bed-8f2e-e74704b56b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-1429897e-cbbc-4903-99ac-eadeb5f34941,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-19074fa6-202d-4265-9296-d7ee95debb41,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-0dee1ba7-4cd7-41b5-97de-e9c64e44d0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-4f3b3ce4-de9b-4441-accb-91b6332454e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145666930-172.17.0.19-1597391677953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44310,DS-1168fb8e-8f1a-482b-848b-a66875204e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-a4accd6e-dd93-4ac6-8871-66c085441b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-f53cc8c3-debb-48c5-9817-18f06ee81f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-838773b7-4fe6-485e-bd7f-14b0c191bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-e1851cae-1282-40be-b465-f3a3b2ab82cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-1baa78bc-05a1-4448-9bfe-15cee26c2e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-ed75b296-eb40-41d6-aac8-f7155cd3b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-b63f0684-ac86-45c1-aaf9-f1e0395aee36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145666930-172.17.0.19-1597391677953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44310,DS-1168fb8e-8f1a-482b-848b-a66875204e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-a4accd6e-dd93-4ac6-8871-66c085441b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-f53cc8c3-debb-48c5-9817-18f06ee81f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-838773b7-4fe6-485e-bd7f-14b0c191bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-e1851cae-1282-40be-b465-f3a3b2ab82cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-1baa78bc-05a1-4448-9bfe-15cee26c2e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-ed75b296-eb40-41d6-aac8-f7155cd3b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-b63f0684-ac86-45c1-aaf9-f1e0395aee36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897165712-172.17.0.19-1597392372388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-c6ccefb6-e555-4252-bc73-997e39b677b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-afb7fab2-c471-4f75-bf6f-0ceb19e54f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-ed41ec48-87bb-4f70-9cae-ba69486638bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-d3527556-b37c-4909-881e-7363ed225920,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-2b41b75b-5c77-495b-8a7c-cca8d9d1b368,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-b219db49-3ead-4164-8c9d-659594f97867,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-b1e2b7e0-91f3-4e65-a8aa-29648eb6142c,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-e3ed189f-4e21-456c-9a0e-9214bc04e7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897165712-172.17.0.19-1597392372388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-c6ccefb6-e555-4252-bc73-997e39b677b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-afb7fab2-c471-4f75-bf6f-0ceb19e54f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-ed41ec48-87bb-4f70-9cae-ba69486638bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-d3527556-b37c-4909-881e-7363ed225920,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-2b41b75b-5c77-495b-8a7c-cca8d9d1b368,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-b219db49-3ead-4164-8c9d-659594f97867,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-b1e2b7e0-91f3-4e65-a8aa-29648eb6142c,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-e3ed189f-4e21-456c-9a0e-9214bc04e7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121855197-172.17.0.19-1597392617544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-c6460ab2-00cf-4326-80bc-6b78ec2a65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-01d753d5-92ee-4ab5-ad33-0d04e986b311,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-3b7bd5cf-2542-446d-81d6-ebeea2b3fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-50d3dbc6-96b7-42dc-92ff-93fa7dda9ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-af4bd70d-e949-4f1f-846e-15126bbec4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-628fe7f6-4179-4d87-9e5f-4719b90a5fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-4fda9144-5f00-4609-afb8-16ac7252b38e,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-6249fc2a-9c77-4f21-9f3c-2d2faca07a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121855197-172.17.0.19-1597392617544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-c6460ab2-00cf-4326-80bc-6b78ec2a65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-01d753d5-92ee-4ab5-ad33-0d04e986b311,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-3b7bd5cf-2542-446d-81d6-ebeea2b3fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-50d3dbc6-96b7-42dc-92ff-93fa7dda9ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-af4bd70d-e949-4f1f-846e-15126bbec4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-628fe7f6-4179-4d87-9e5f-4719b90a5fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-4fda9144-5f00-4609-afb8-16ac7252b38e,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-6249fc2a-9c77-4f21-9f3c-2d2faca07a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592370064-172.17.0.19-1597392791680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-22c60292-aaac-45cd-8e40-78e2908080d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-840e64fc-92c4-4d26-b7da-75be4086b4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-da3aa42d-5e85-40e3-bb3b-492883bb987c,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-afb540b1-7294-4dca-bcc7-218766aae6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-40b8fe83-80ee-4a9f-8a46-9304cb173871,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-205ccad2-f83d-435e-ad98-83d4fdfaa0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-e36a4762-ac1f-4557-bd50-5f6c18a86062,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-4ed7a176-933f-4486-9453-74e53286d06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592370064-172.17.0.19-1597392791680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-22c60292-aaac-45cd-8e40-78e2908080d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-840e64fc-92c4-4d26-b7da-75be4086b4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-da3aa42d-5e85-40e3-bb3b-492883bb987c,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-afb540b1-7294-4dca-bcc7-218766aae6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-40b8fe83-80ee-4a9f-8a46-9304cb173871,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-205ccad2-f83d-435e-ad98-83d4fdfaa0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-e36a4762-ac1f-4557-bd50-5f6c18a86062,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-4ed7a176-933f-4486-9453-74e53286d06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942680145-172.17.0.19-1597393425755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-91660bb4-518c-42a0-a10b-2fb66e135185,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-8c944de8-62dd-4eed-9add-4b7ff844e345,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-e7f98ea5-2770-48cd-a8b5-38e598ef686a,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-a9b66207-b016-495a-846b-8192a7d9d1df,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-0b7943e8-42d0-4875-ba25-bc8709d4dd59,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-ce00774f-4106-4b40-a68c-32e5a013f42b,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-bed88275-013f-4d0d-802b-bce4e8380587,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-13e14055-b2ca-424c-9f69-6e256c8a835c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942680145-172.17.0.19-1597393425755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-91660bb4-518c-42a0-a10b-2fb66e135185,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-8c944de8-62dd-4eed-9add-4b7ff844e345,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-e7f98ea5-2770-48cd-a8b5-38e598ef686a,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-a9b66207-b016-495a-846b-8192a7d9d1df,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-0b7943e8-42d0-4875-ba25-bc8709d4dd59,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-ce00774f-4106-4b40-a68c-32e5a013f42b,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-bed88275-013f-4d0d-802b-bce4e8380587,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-13e14055-b2ca-424c-9f69-6e256c8a835c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167289023-172.17.0.19-1597393656919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-dc04f3db-be74-49f8-8685-17be4a86f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-39fdf301-dcef-47dd-af0a-841c706aff51,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-0c4c96f2-d3a7-45fa-97f6-9f5708cd6aca,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-7384ab13-cc16-4f1d-acd6-ddf68c8e78c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-843a7ae9-450c-4e75-8773-0815efb88e48,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-e371e3dd-0308-4418-af37-89238ff0dfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-30bf80f5-30c7-4b09-b8fd-8624d70e80ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-aa9a6335-709f-40f3-96dc-6a20903dd50c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167289023-172.17.0.19-1597393656919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-dc04f3db-be74-49f8-8685-17be4a86f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-39fdf301-dcef-47dd-af0a-841c706aff51,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-0c4c96f2-d3a7-45fa-97f6-9f5708cd6aca,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-7384ab13-cc16-4f1d-acd6-ddf68c8e78c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-843a7ae9-450c-4e75-8773-0815efb88e48,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-e371e3dd-0308-4418-af37-89238ff0dfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-30bf80f5-30c7-4b09-b8fd-8624d70e80ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-aa9a6335-709f-40f3-96dc-6a20903dd50c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073553147-172.17.0.19-1597393905154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-ecc502e9-371d-499c-b374-d7a4196ed220,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-e8e58c09-cfa9-4033-a497-2e3f1ceefba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-77ff2659-a38e-415a-9823-b0495e03a84a,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-9d757fc9-880b-4911-8b3f-39a88607fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-0cff371a-a7f1-4896-bc3c-be5e1d8ab16c,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-af0aeafc-9b44-4459-90fb-6d663ef161dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-ff1252ac-1178-40ae-b134-8ab7422e7643,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-42a3afd7-1bb7-46be-9421-fba1938e207f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073553147-172.17.0.19-1597393905154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-ecc502e9-371d-499c-b374-d7a4196ed220,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-e8e58c09-cfa9-4033-a497-2e3f1ceefba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-77ff2659-a38e-415a-9823-b0495e03a84a,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-9d757fc9-880b-4911-8b3f-39a88607fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-0cff371a-a7f1-4896-bc3c-be5e1d8ab16c,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-af0aeafc-9b44-4459-90fb-6d663ef161dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-ff1252ac-1178-40ae-b134-8ab7422e7643,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-42a3afd7-1bb7-46be-9421-fba1938e207f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902104506-172.17.0.19-1597394214204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-89c61300-88a9-43af-a005-67d31c37166e,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-c9a34b61-a0ef-451f-96a9-bf037449798e,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-fba432fb-66f9-4003-82b4-ea289a5e7459,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-56197590-7c3b-42d1-a8e0-a99fe4b89295,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-e05b4351-3402-41e8-9223-f1404ac6c543,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-c34ed823-e733-4fdd-be51-78f7c35064a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-2c3eeb1f-f1e9-4d0d-bd81-79717e388aac,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-ea333373-f2b0-445a-93b2-536b1efc0af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902104506-172.17.0.19-1597394214204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-89c61300-88a9-43af-a005-67d31c37166e,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-c9a34b61-a0ef-451f-96a9-bf037449798e,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-fba432fb-66f9-4003-82b4-ea289a5e7459,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-56197590-7c3b-42d1-a8e0-a99fe4b89295,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-e05b4351-3402-41e8-9223-f1404ac6c543,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-c34ed823-e733-4fdd-be51-78f7c35064a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-2c3eeb1f-f1e9-4d0d-bd81-79717e388aac,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-ea333373-f2b0-445a-93b2-536b1efc0af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149261893-172.17.0.19-1597394267358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-e394eebb-0c81-4bf7-8b77-35ec654bfc71,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-e370464b-9d8c-403b-999c-4d99d9b90f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-267ef0c2-dc91-4ed2-b925-10705de0f617,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1a6cc4f4-5d4d-4be1-b1c8-05afe2a5d9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-ffe6028c-eba2-46ac-ac2e-601a037eed48,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-1efc2d93-0475-4731-92b4-f2b4742c208b,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-5e85ec06-902e-4720-bca2-9b4dd21b7f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-7d9a11b2-b592-43aa-80df-9a2f68f00470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149261893-172.17.0.19-1597394267358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-e394eebb-0c81-4bf7-8b77-35ec654bfc71,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-e370464b-9d8c-403b-999c-4d99d9b90f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-267ef0c2-dc91-4ed2-b925-10705de0f617,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1a6cc4f4-5d4d-4be1-b1c8-05afe2a5d9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-ffe6028c-eba2-46ac-ac2e-601a037eed48,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-1efc2d93-0475-4731-92b4-f2b4742c208b,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-5e85ec06-902e-4720-bca2-9b4dd21b7f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-7d9a11b2-b592-43aa-80df-9a2f68f00470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6969
