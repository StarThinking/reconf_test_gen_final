reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486764004-172.17.0.7-1597643850986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-d0b0e6b6-4e4e-440c-aa5f-67a51520d3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-2a33ef47-5e96-4489-ac96-f9c3e8de1966,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-f926c0c9-733f-41d9-ba29-b903c3d302dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-1f6b229f-7307-4fbd-9021-0142f2439edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-1df9937c-822b-450d-82be-887f5d173ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-2418fda3-b4bf-4907-a11f-62c61c8b23d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-f041a63b-4fa1-4d75-ba82-83cdeef86f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-29469669-c7ea-4de1-b896-dcf8798a5ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486764004-172.17.0.7-1597643850986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-d0b0e6b6-4e4e-440c-aa5f-67a51520d3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-2a33ef47-5e96-4489-ac96-f9c3e8de1966,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-f926c0c9-733f-41d9-ba29-b903c3d302dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-1f6b229f-7307-4fbd-9021-0142f2439edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-1df9937c-822b-450d-82be-887f5d173ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-2418fda3-b4bf-4907-a11f-62c61c8b23d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-f041a63b-4fa1-4d75-ba82-83cdeef86f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-29469669-c7ea-4de1-b896-dcf8798a5ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566937827-172.17.0.7-1597645044949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-4b986f3f-bdaf-437b-8853-21b4ad588d50,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-3609217b-fa66-4020-9247-3ba744923b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-0a36170b-f2ed-44b4-ad90-7dc321351682,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-b1793d1c-1b17-489b-9e3f-4144b85e8c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-73ff1eea-29a9-491b-8e69-bb2c6ad88ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-57ec7f59-1c59-429d-88d3-8f13e50b2ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-a7d39dae-7088-4e5a-b3cf-4f0609f0351f,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-c1f71d14-5cdc-4847-aa4c-0c2c7c949ee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566937827-172.17.0.7-1597645044949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-4b986f3f-bdaf-437b-8853-21b4ad588d50,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-3609217b-fa66-4020-9247-3ba744923b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-0a36170b-f2ed-44b4-ad90-7dc321351682,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-b1793d1c-1b17-489b-9e3f-4144b85e8c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-73ff1eea-29a9-491b-8e69-bb2c6ad88ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-57ec7f59-1c59-429d-88d3-8f13e50b2ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-a7d39dae-7088-4e5a-b3cf-4f0609f0351f,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-c1f71d14-5cdc-4847-aa4c-0c2c7c949ee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083786416-172.17.0.7-1597645782435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35247,DS-c6df8564-2964-4e21-b855-76af8dfb72d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-3c388207-7eff-4cde-95e1-7b4117b4d46f,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-863af0a5-c6b5-4e41-a434-66c04f4925bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-86ed3e89-cd17-4e9e-862f-daf8e5c0b3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-21758c85-38da-4bae-b5e9-95b37f85158a,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-15c089a0-c3d3-404f-939a-5e6b830b9c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-cbc88d64-d6eb-4f32-a19d-10b28c160540,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-9409dd97-d98d-4dde-8769-4de0c59f1cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083786416-172.17.0.7-1597645782435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35247,DS-c6df8564-2964-4e21-b855-76af8dfb72d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-3c388207-7eff-4cde-95e1-7b4117b4d46f,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-863af0a5-c6b5-4e41-a434-66c04f4925bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-86ed3e89-cd17-4e9e-862f-daf8e5c0b3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-21758c85-38da-4bae-b5e9-95b37f85158a,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-15c089a0-c3d3-404f-939a-5e6b830b9c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-cbc88d64-d6eb-4f32-a19d-10b28c160540,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-9409dd97-d98d-4dde-8769-4de0c59f1cf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996050058-172.17.0.7-1597645920193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38040,DS-75e7915b-6bad-46e8-ae5d-f7c56e91b8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-cbfea93b-153b-444f-8c7e-fef7abad53c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-e0b8ec6e-1e38-4f9c-b02e-1a76abc251c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-700126a2-05aa-4241-9d36-e853c5a2a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-2943694c-ae9b-4fcb-ba44-99751618dda7,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-a075b35d-0f9a-4c2f-8c4d-764976c962ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-3e8b8c82-bae3-42ce-bb03-541343fa3290,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-af6c55db-e16a-4514-8ad3-9b3e5af9e23a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996050058-172.17.0.7-1597645920193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38040,DS-75e7915b-6bad-46e8-ae5d-f7c56e91b8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-cbfea93b-153b-444f-8c7e-fef7abad53c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-e0b8ec6e-1e38-4f9c-b02e-1a76abc251c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-700126a2-05aa-4241-9d36-e853c5a2a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-2943694c-ae9b-4fcb-ba44-99751618dda7,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-a075b35d-0f9a-4c2f-8c4d-764976c962ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-3e8b8c82-bae3-42ce-bb03-541343fa3290,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-af6c55db-e16a-4514-8ad3-9b3e5af9e23a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266844783-172.17.0.7-1597646385827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-18eb5596-03ad-40d0-b372-f9f747abe711,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-f0533a97-b7c5-422d-8b83-7662a0b3d6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-b7cc79b6-8b6a-4af1-8eac-81c800776491,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-e539496e-f2ab-4772-8bf3-ac8295ad553c,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-cf10be7b-0b84-4bc6-9909-024599be8274,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-b57cdc9b-6b9c-4d5b-af7c-78c069e1c5da,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-06a4cf80-9e08-4253-a7f1-e115219a9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-47ae05b5-b918-437e-bdb0-eff3e5414e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266844783-172.17.0.7-1597646385827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-18eb5596-03ad-40d0-b372-f9f747abe711,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-f0533a97-b7c5-422d-8b83-7662a0b3d6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-b7cc79b6-8b6a-4af1-8eac-81c800776491,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-e539496e-f2ab-4772-8bf3-ac8295ad553c,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-cf10be7b-0b84-4bc6-9909-024599be8274,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-b57cdc9b-6b9c-4d5b-af7c-78c069e1c5da,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-06a4cf80-9e08-4253-a7f1-e115219a9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-47ae05b5-b918-437e-bdb0-eff3e5414e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88403696-172.17.0.7-1597646427199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-db1ef583-1aaa-455a-b013-8666723af54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-0b4f4dbc-1f55-46b7-8ab1-a794355c24b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-0b3628d9-092f-43fb-903e-ed0a17ba8bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-7eea8c53-705c-4070-9841-cd2007e713e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-661dece6-7a8f-40e4-a37f-4765ccbe1efa,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-30ed3f1f-e0c2-4e7d-bb73-5365c3344dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-587b13d1-c458-4900-8bcc-43448c6a1468,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-74b3553e-55d9-43d0-b6e2-8726696fad31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88403696-172.17.0.7-1597646427199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-db1ef583-1aaa-455a-b013-8666723af54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-0b4f4dbc-1f55-46b7-8ab1-a794355c24b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-0b3628d9-092f-43fb-903e-ed0a17ba8bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-7eea8c53-705c-4070-9841-cd2007e713e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-661dece6-7a8f-40e4-a37f-4765ccbe1efa,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-30ed3f1f-e0c2-4e7d-bb73-5365c3344dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-587b13d1-c458-4900-8bcc-43448c6a1468,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-74b3553e-55d9-43d0-b6e2-8726696fad31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429603154-172.17.0.7-1597647499268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39340,DS-ccb6a380-4d99-41ef-8ce6-8a96a15cc688,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-00891e80-8961-4016-b3d8-a7f53e98c608,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-49d329b4-4502-4766-a094-1e5395ce7718,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-e8f75e29-a01b-447b-88d7-35f76300aca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-b4038e9c-4559-4710-a7ea-9a5756a7024f,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-83a08d51-2df1-4bbf-8529-32ecb78debc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-56423f83-cba1-4df7-af55-a3d1279b6172,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-85b7f59e-0bef-4b27-8bbb-c67f8df93bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429603154-172.17.0.7-1597647499268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39340,DS-ccb6a380-4d99-41ef-8ce6-8a96a15cc688,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-00891e80-8961-4016-b3d8-a7f53e98c608,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-49d329b4-4502-4766-a094-1e5395ce7718,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-e8f75e29-a01b-447b-88d7-35f76300aca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-b4038e9c-4559-4710-a7ea-9a5756a7024f,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-83a08d51-2df1-4bbf-8529-32ecb78debc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-56423f83-cba1-4df7-af55-a3d1279b6172,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-85b7f59e-0bef-4b27-8bbb-c67f8df93bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735740258-172.17.0.7-1597647868167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-e37be55b-2d9b-4618-9534-91248b803cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-2e5c366c-6a2d-4a97-92e4-dbcdc314e6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-bf648f65-7797-453a-a8d7-cb0a88b41334,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-71204222-bfec-4810-92f1-5456382a259c,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-2c60df57-bdd4-4f7d-b746-7d7fb4aa54d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-471a0396-5fa9-4179-aac0-33ac7dec3052,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-a423a5e0-098e-47c5-9d5b-c7697452f8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-92a9fc26-c6d0-4565-b926-d4a32f2b6b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735740258-172.17.0.7-1597647868167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-e37be55b-2d9b-4618-9534-91248b803cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-2e5c366c-6a2d-4a97-92e4-dbcdc314e6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-bf648f65-7797-453a-a8d7-cb0a88b41334,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-71204222-bfec-4810-92f1-5456382a259c,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-2c60df57-bdd4-4f7d-b746-7d7fb4aa54d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-471a0396-5fa9-4179-aac0-33ac7dec3052,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-a423a5e0-098e-47c5-9d5b-c7697452f8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-92a9fc26-c6d0-4565-b926-d4a32f2b6b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762212448-172.17.0.7-1597648805701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41677,DS-52c42bc0-7287-4ad7-afe5-fd50acf48517,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-bd010ea4-51b0-464c-af19-e9de6511a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-099c061f-c43e-4ca2-b489-1858bcce36ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-95678e28-52d1-4347-97a9-16845f5675c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-361d5ef8-8bb0-4bd0-9fe5-1159897a56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-1f0c587f-f2be-467e-af27-0870c85bfa18,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-1d5b9f7c-2f94-4777-85c0-5cbe2f6e12b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-2c1d837b-76a6-4a79-8771-8393c0327b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762212448-172.17.0.7-1597648805701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41677,DS-52c42bc0-7287-4ad7-afe5-fd50acf48517,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-bd010ea4-51b0-464c-af19-e9de6511a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-099c061f-c43e-4ca2-b489-1858bcce36ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-95678e28-52d1-4347-97a9-16845f5675c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-361d5ef8-8bb0-4bd0-9fe5-1159897a56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-1f0c587f-f2be-467e-af27-0870c85bfa18,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-1d5b9f7c-2f94-4777-85c0-5cbe2f6e12b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-2c1d837b-76a6-4a79-8771-8393c0327b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723846444-172.17.0.7-1597649041504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-10f5411e-c8b4-4210-84ab-862f92d3b33f,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-b692e235-2aca-4909-bd0c-9b57733e2789,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-5fb50979-c3cb-40a5-abb7-70951e276b13,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-c056357b-44b3-4245-9b75-6738e09609f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-5c7ad921-03a8-492a-948f-bd24e608be3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-6beda583-9e91-45aa-8a4a-ebf81515f89b,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-85362aa9-ffd0-4c5d-b19c-84203553f12d,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-07d4f1e3-4db2-4a13-88e7-d6613f3ce62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723846444-172.17.0.7-1597649041504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-10f5411e-c8b4-4210-84ab-862f92d3b33f,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-b692e235-2aca-4909-bd0c-9b57733e2789,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-5fb50979-c3cb-40a5-abb7-70951e276b13,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-c056357b-44b3-4245-9b75-6738e09609f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-5c7ad921-03a8-492a-948f-bd24e608be3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-6beda583-9e91-45aa-8a4a-ebf81515f89b,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-85362aa9-ffd0-4c5d-b19c-84203553f12d,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-07d4f1e3-4db2-4a13-88e7-d6613f3ce62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92780411-172.17.0.7-1597649130172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-4c0b4af4-d901-4bd7-a054-0945f03c96e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-58516d48-bb11-4eab-87ce-7170ce88df29,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-aa57badf-ddd1-4fdd-b3d6-71a41d4fe6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-b37bde4b-1b20-4f61-bc4c-bcbc53e84660,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-3759ce0d-eb4b-44c4-bedf-20768175ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-63d64167-19c7-4249-a932-75994510f00f,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-39f6d97a-a256-4214-b109-7a838e8ec03d,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-e5b918e2-d067-4cd1-b8fd-aae833eb6750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92780411-172.17.0.7-1597649130172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-4c0b4af4-d901-4bd7-a054-0945f03c96e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-58516d48-bb11-4eab-87ce-7170ce88df29,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-aa57badf-ddd1-4fdd-b3d6-71a41d4fe6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-b37bde4b-1b20-4f61-bc4c-bcbc53e84660,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-3759ce0d-eb4b-44c4-bedf-20768175ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-63d64167-19c7-4249-a932-75994510f00f,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-39f6d97a-a256-4214-b109-7a838e8ec03d,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-e5b918e2-d067-4cd1-b8fd-aae833eb6750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801800173-172.17.0.7-1597649252743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34683,DS-6ad5fabe-f7dc-4a7f-86fe-fbbd03dd008f,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-a4aec4bb-4ab0-4ed1-94bc-1c3b7037382f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-410ceb38-039a-41b5-b1d6-0660c2d79d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-d923ff47-6865-4e54-9230-4fc48ae7f291,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-a4656c27-556f-4af4-ba1f-7c08b2a78657,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-24d1305b-98c2-44a9-afd7-8e0b577d04ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-f615f639-80e0-4e63-909e-176971a5bd48,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-dfb7cfa0-6e86-4fa5-ae0c-f7b818b48156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801800173-172.17.0.7-1597649252743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34683,DS-6ad5fabe-f7dc-4a7f-86fe-fbbd03dd008f,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-a4aec4bb-4ab0-4ed1-94bc-1c3b7037382f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-410ceb38-039a-41b5-b1d6-0660c2d79d70,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-d923ff47-6865-4e54-9230-4fc48ae7f291,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-a4656c27-556f-4af4-ba1f-7c08b2a78657,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-24d1305b-98c2-44a9-afd7-8e0b577d04ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-f615f639-80e0-4e63-909e-176971a5bd48,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-dfb7cfa0-6e86-4fa5-ae0c-f7b818b48156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 7078
