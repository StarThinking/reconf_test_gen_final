reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528079168-172.17.0.7-1597665657318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-250b4888-c23e-480b-ab75-d15d09fb0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-3ae8d4ed-863b-4b45-8e85-4d21c6aba105,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-fc03b248-2f45-4532-9337-bf96fcf12359,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-9217bd8a-2a31-4391-b159-4de22f709b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-33cf0f81-b3b1-4540-97f3-02b1c7389839,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-a02b8bb9-541f-4a4a-a296-51cc84c81dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-478995ed-75eb-4510-9a9f-b8e7ec0913b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-4746ab7b-c7ec-4f94-aba3-dfc030b1c428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528079168-172.17.0.7-1597665657318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-250b4888-c23e-480b-ab75-d15d09fb0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-3ae8d4ed-863b-4b45-8e85-4d21c6aba105,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-fc03b248-2f45-4532-9337-bf96fcf12359,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-9217bd8a-2a31-4391-b159-4de22f709b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-33cf0f81-b3b1-4540-97f3-02b1c7389839,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-a02b8bb9-541f-4a4a-a296-51cc84c81dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-478995ed-75eb-4510-9a9f-b8e7ec0913b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-4746ab7b-c7ec-4f94-aba3-dfc030b1c428,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837035023-172.17.0.7-1597665688082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35028,DS-634a8981-6cf0-4b2e-84b7-c66d14d66cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-fd9e7792-80f1-4ae8-83d2-c3ce10d09901,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-298e6677-66c8-4686-a3e8-ed9daf0879c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-eb517de4-936b-45ba-95ab-0b66f567c360,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-be405ee9-c78e-43a5-9ffb-f14b123745fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-48f630b5-82b0-4dc2-acad-f62d6870bad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-fd1fb2e7-4678-43ac-bffb-245d014890ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-d3d3e995-d9db-423b-b8d5-88c4ab16967b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837035023-172.17.0.7-1597665688082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35028,DS-634a8981-6cf0-4b2e-84b7-c66d14d66cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-fd9e7792-80f1-4ae8-83d2-c3ce10d09901,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-298e6677-66c8-4686-a3e8-ed9daf0879c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-eb517de4-936b-45ba-95ab-0b66f567c360,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-be405ee9-c78e-43a5-9ffb-f14b123745fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-48f630b5-82b0-4dc2-acad-f62d6870bad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-fd1fb2e7-4678-43ac-bffb-245d014890ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-d3d3e995-d9db-423b-b8d5-88c4ab16967b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238261166-172.17.0.7-1597665770393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-1c1c6477-c6dc-4eaa-a67d-1990a4f481c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-6eea289c-7d35-439c-b33f-52ce5ba454ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-e183abaa-5b8d-45dd-9094-4a1075c53383,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-855cf58f-be11-49f9-a055-5465cd1820d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-ee666059-9a89-4a07-9543-3821daf7d690,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-cd88ba7f-bc87-4819-88e7-60271a22f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-6ee84f11-5c54-4fb2-b7e3-8731e45f84f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-3412b4c5-0fd2-4aa1-a030-14e60e16f341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238261166-172.17.0.7-1597665770393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-1c1c6477-c6dc-4eaa-a67d-1990a4f481c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-6eea289c-7d35-439c-b33f-52ce5ba454ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-e183abaa-5b8d-45dd-9094-4a1075c53383,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-855cf58f-be11-49f9-a055-5465cd1820d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-ee666059-9a89-4a07-9543-3821daf7d690,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-cd88ba7f-bc87-4819-88e7-60271a22f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-6ee84f11-5c54-4fb2-b7e3-8731e45f84f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-3412b4c5-0fd2-4aa1-a030-14e60e16f341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845962235-172.17.0.7-1597666038724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43385,DS-c1579134-0633-4efd-9318-0faf625594ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-ec6c3636-1658-4e42-8a40-fbb83af19ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-41253b3b-fe8c-48f9-8981-ba2c11379a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-51cfc6e9-240b-4450-9edd-652aa88547dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-2116b683-1357-4af9-afbd-47839537a899,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-32e99404-4c37-4574-99e6-56442bffea04,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-e0ebc16a-9362-4339-846e-ab6cc88a2817,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-00f302bc-c31d-40d6-aded-6fdac1b92368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845962235-172.17.0.7-1597666038724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43385,DS-c1579134-0633-4efd-9318-0faf625594ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-ec6c3636-1658-4e42-8a40-fbb83af19ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-41253b3b-fe8c-48f9-8981-ba2c11379a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-51cfc6e9-240b-4450-9edd-652aa88547dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-2116b683-1357-4af9-afbd-47839537a899,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-32e99404-4c37-4574-99e6-56442bffea04,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-e0ebc16a-9362-4339-846e-ab6cc88a2817,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-00f302bc-c31d-40d6-aded-6fdac1b92368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866692097-172.17.0.7-1597666082076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44591,DS-37721ff3-641d-4692-af57-8768dfe69b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-2ceb8d26-764b-4427-b59e-3d142bdfcc30,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-da4388b5-a6e3-4a50-9f95-cd8fed49a96c,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-d15933ba-90ee-444e-b3be-308491ba5235,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-0e6bc88e-9ee3-4b5b-bab1-d8f902c9891a,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-70fa1f63-c31e-49a4-a709-71c4a96350a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-4963f220-27fd-4d4d-9a82-0cebd680d02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-9e9b72b3-3d8b-450d-8145-398d563857fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866692097-172.17.0.7-1597666082076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44591,DS-37721ff3-641d-4692-af57-8768dfe69b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-2ceb8d26-764b-4427-b59e-3d142bdfcc30,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-da4388b5-a6e3-4a50-9f95-cd8fed49a96c,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-d15933ba-90ee-444e-b3be-308491ba5235,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-0e6bc88e-9ee3-4b5b-bab1-d8f902c9891a,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-70fa1f63-c31e-49a4-a709-71c4a96350a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-4963f220-27fd-4d4d-9a82-0cebd680d02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-9e9b72b3-3d8b-450d-8145-398d563857fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057772685-172.17.0.7-1597666198852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39100,DS-a23d20c4-c579-47b2-8d26-5a518dada88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-57f7e114-c76a-4064-96d3-6bd119702e73,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-2b8cbb91-e60d-4725-a657-2204d23c61bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-2cb68131-1c69-4794-9475-6f7ae30af379,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-f49e0fa1-76b3-4f7f-a6b6-e82d0e65ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-0550d8ce-3f2b-433f-9266-6c6845934e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-022034a1-feea-46fb-9cf2-9f4c809c9c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-e0ef4bde-7aa2-471e-82bb-98886f411ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057772685-172.17.0.7-1597666198852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39100,DS-a23d20c4-c579-47b2-8d26-5a518dada88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-57f7e114-c76a-4064-96d3-6bd119702e73,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-2b8cbb91-e60d-4725-a657-2204d23c61bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-2cb68131-1c69-4794-9475-6f7ae30af379,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-f49e0fa1-76b3-4f7f-a6b6-e82d0e65ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-0550d8ce-3f2b-433f-9266-6c6845934e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-022034a1-feea-46fb-9cf2-9f4c809c9c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-e0ef4bde-7aa2-471e-82bb-98886f411ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324969247-172.17.0.7-1597666293742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32964,DS-b21e5857-de76-4ce3-85e5-30023cf4a007,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-2475ed18-e372-4e6a-8980-278a554b882f,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-5d8d0131-120a-44d3-ad47-7da52be08dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-457287df-eaf0-4de2-a104-335240a14109,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-48af6484-7ae8-4ec0-9706-5bb3dc8a768e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-1b4ce7df-a013-4bfe-a370-cbb7ff36d752,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-c68d7f7c-b17a-4e33-86f8-855134295139,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-5f3c13a3-77fe-4d07-b42e-c780db9faadf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324969247-172.17.0.7-1597666293742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32964,DS-b21e5857-de76-4ce3-85e5-30023cf4a007,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-2475ed18-e372-4e6a-8980-278a554b882f,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-5d8d0131-120a-44d3-ad47-7da52be08dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-457287df-eaf0-4de2-a104-335240a14109,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-48af6484-7ae8-4ec0-9706-5bb3dc8a768e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-1b4ce7df-a013-4bfe-a370-cbb7ff36d752,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-c68d7f7c-b17a-4e33-86f8-855134295139,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-5f3c13a3-77fe-4d07-b42e-c780db9faadf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729704675-172.17.0.7-1597667401287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-b11c16d7-9534-42a2-9053-b58cf00f8207,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-3b76429e-5995-4ca5-8580-f113b04e7fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-bacde94d-e69f-4c52-aeb0-2c6ba260337f,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-009583fe-082a-4efa-b21c-706215d34f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-d45f3985-d17b-47f3-8448-7c136c673974,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-2ebd5b1d-0eef-4cd1-b5f5-b1c283834281,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-7035f161-e262-418e-be34-2df530fe575d,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-9a15f391-44e2-495a-84a8-27918e764d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729704675-172.17.0.7-1597667401287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-b11c16d7-9534-42a2-9053-b58cf00f8207,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-3b76429e-5995-4ca5-8580-f113b04e7fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-bacde94d-e69f-4c52-aeb0-2c6ba260337f,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-009583fe-082a-4efa-b21c-706215d34f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-d45f3985-d17b-47f3-8448-7c136c673974,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-2ebd5b1d-0eef-4cd1-b5f5-b1c283834281,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-7035f161-e262-418e-be34-2df530fe575d,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-9a15f391-44e2-495a-84a8-27918e764d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311770723-172.17.0.7-1597667479432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-8d268379-e479-4733-8a1a-87d7fa3b750e,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-94ce086f-6365-4d9f-b936-ccdeaecf4797,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-01ff9062-c39f-4201-9771-8b00353ba1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-bbbd67b7-5a01-4d96-b1b7-b80b8ef6da80,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-98247d73-1ac2-427f-b95c-3ea52347500a,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-cb026533-9369-410b-ad93-a7fc961d8861,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-8e63abd2-fb20-4b4d-8135-4d77627f0509,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-0e19f2d0-12bf-4d68-9a7f-39bcab1385da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311770723-172.17.0.7-1597667479432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-8d268379-e479-4733-8a1a-87d7fa3b750e,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-94ce086f-6365-4d9f-b936-ccdeaecf4797,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-01ff9062-c39f-4201-9771-8b00353ba1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-bbbd67b7-5a01-4d96-b1b7-b80b8ef6da80,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-98247d73-1ac2-427f-b95c-3ea52347500a,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-cb026533-9369-410b-ad93-a7fc961d8861,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-8e63abd2-fb20-4b4d-8135-4d77627f0509,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-0e19f2d0-12bf-4d68-9a7f-39bcab1385da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327943243-172.17.0.7-1597667558491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-35ab7e0b-7d26-4c49-b734-1d2202fd5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-42fe277d-fb51-4039-b173-16c357687277,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-65617107-523e-46e5-a086-735b12b3e739,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-d0029d9b-d385-40c2-a005-47d6d47b16e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-da8643ae-a975-479b-a05a-05a559d6551c,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-9a9ad4b9-a6cb-4d16-8e04-a9920a295a00,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-4da7a8c8-52b1-4902-9c42-538545f196ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-3854b71d-421f-4dd5-a79c-263e7170fa4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327943243-172.17.0.7-1597667558491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-35ab7e0b-7d26-4c49-b734-1d2202fd5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-42fe277d-fb51-4039-b173-16c357687277,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-65617107-523e-46e5-a086-735b12b3e739,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-d0029d9b-d385-40c2-a005-47d6d47b16e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-da8643ae-a975-479b-a05a-05a559d6551c,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-9a9ad4b9-a6cb-4d16-8e04-a9920a295a00,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-4da7a8c8-52b1-4902-9c42-538545f196ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-3854b71d-421f-4dd5-a79c-263e7170fa4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212218114-172.17.0.7-1597668141484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32808,DS-3e7c6060-9d0d-4c7e-9d52-b11079eb79e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-9288f241-6806-4680-a52b-2bdaf327498c,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-cccc783f-bda6-4a07-addb-5d46724a37ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-120e3c96-ea3c-45f2-a1fb-d7ad5f5623fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-1b93d0c4-aedc-47f7-b9f4-5b9982b78625,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-ba4f28ad-c50a-43f5-82fc-fd66d72c1f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-588d941f-0c9f-425f-bcc7-9688d30c9ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-cbcef701-9906-43ce-8a5f-7c536d859de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212218114-172.17.0.7-1597668141484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32808,DS-3e7c6060-9d0d-4c7e-9d52-b11079eb79e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-9288f241-6806-4680-a52b-2bdaf327498c,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-cccc783f-bda6-4a07-addb-5d46724a37ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-120e3c96-ea3c-45f2-a1fb-d7ad5f5623fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-1b93d0c4-aedc-47f7-b9f4-5b9982b78625,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-ba4f28ad-c50a-43f5-82fc-fd66d72c1f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-588d941f-0c9f-425f-bcc7-9688d30c9ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-cbcef701-9906-43ce-8a5f-7c536d859de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199518574-172.17.0.7-1597668763795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-ec52cfea-c57e-484f-ba48-deacceecd52d,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-b63afb13-2524-4fc9-81ed-67c6d4424a78,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-89a482af-7715-4d05-8153-5bf0aa89fe26,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-4fdedd3d-7404-43aa-91f3-5733c14cccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-b099ce26-39ad-4f95-a0ec-0983b4530107,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-b6ce3c5f-5ba5-49fd-89e4-23a1f91254f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-f21ff776-0210-4e06-8084-e1075cded76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-623ce0ae-e5d8-408e-a6a6-c9d4259c8a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199518574-172.17.0.7-1597668763795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-ec52cfea-c57e-484f-ba48-deacceecd52d,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-b63afb13-2524-4fc9-81ed-67c6d4424a78,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-89a482af-7715-4d05-8153-5bf0aa89fe26,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-4fdedd3d-7404-43aa-91f3-5733c14cccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-b099ce26-39ad-4f95-a0ec-0983b4530107,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-b6ce3c5f-5ba5-49fd-89e4-23a1f91254f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-f21ff776-0210-4e06-8084-e1075cded76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-623ce0ae-e5d8-408e-a6a6-c9d4259c8a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509616027-172.17.0.7-1597670150858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37677,DS-772ed04f-b35c-4d66-9802-364c91e85aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-a9aba2fc-9902-48c2-81d2-0e03b1998cee,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-6db0a5a7-e548-4940-ad6b-df3b33ba7eab,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-a52b3aa6-b18f-4f2f-b215-e873b76e8e72,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-5d6700f9-e4aa-44f2-ade6-6cb50a428f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-37fe7434-3baf-4516-b4a0-4775478cedb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-d9af7a59-8ed5-44e0-8c88-5694d00ee7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-c02001d6-2cb2-463a-bd0a-eb689f7d7756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509616027-172.17.0.7-1597670150858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37677,DS-772ed04f-b35c-4d66-9802-364c91e85aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-a9aba2fc-9902-48c2-81d2-0e03b1998cee,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-6db0a5a7-e548-4940-ad6b-df3b33ba7eab,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-a52b3aa6-b18f-4f2f-b215-e873b76e8e72,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-5d6700f9-e4aa-44f2-ade6-6cb50a428f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-37fe7434-3baf-4516-b4a0-4775478cedb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-d9af7a59-8ed5-44e0-8c88-5694d00ee7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-c02001d6-2cb2-463a-bd0a-eb689f7d7756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651229047-172.17.0.7-1597670270503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43846,DS-a49b42b0-751a-45b1-9501-83b523257912,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-0a152461-5e64-4ae5-b545-a3b4f73a37e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-0c8ec8d9-e590-4101-ade0-6aa35e9b3257,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-7c76b4b7-f9c7-4e27-89a2-909a532b1bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-2377e990-0eb2-4a46-aeb2-30bc14d62964,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-f311f638-1307-4ad5-b5c7-6f3b320d1b12,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-189c5505-2b8f-4f9d-9c8c-b0348ab18426,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-dcaf38b5-6804-45ce-8f77-cab2a36c92eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651229047-172.17.0.7-1597670270503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43846,DS-a49b42b0-751a-45b1-9501-83b523257912,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-0a152461-5e64-4ae5-b545-a3b4f73a37e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-0c8ec8d9-e590-4101-ade0-6aa35e9b3257,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-7c76b4b7-f9c7-4e27-89a2-909a532b1bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-2377e990-0eb2-4a46-aeb2-30bc14d62964,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-f311f638-1307-4ad5-b5c7-6f3b320d1b12,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-189c5505-2b8f-4f9d-9c8c-b0348ab18426,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-dcaf38b5-6804-45ce-8f77-cab2a36c92eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985309939-172.17.0.7-1597670344876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39556,DS-1e36fab2-bcdb-4c27-9ba4-f75c72c4b756,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-a60639ac-285f-4d39-8518-9d5fb2de1db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-7f09dd21-15f4-4d57-bd62-61e06e19c370,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-2ff24429-4ae8-4a61-a413-b29466fcb36d,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-25784cf3-3478-4002-b988-1a4e6775a14b,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-b0bfb70d-e2b7-49a3-866b-c610b51686df,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-49191263-a961-433d-bb01-f84fa7d3fc18,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-83d1b5a2-3b49-417b-87a4-751aebbe1098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985309939-172.17.0.7-1597670344876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39556,DS-1e36fab2-bcdb-4c27-9ba4-f75c72c4b756,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-a60639ac-285f-4d39-8518-9d5fb2de1db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-7f09dd21-15f4-4d57-bd62-61e06e19c370,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-2ff24429-4ae8-4a61-a413-b29466fcb36d,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-25784cf3-3478-4002-b988-1a4e6775a14b,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-b0bfb70d-e2b7-49a3-866b-c610b51686df,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-49191263-a961-433d-bb01-f84fa7d3fc18,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-83d1b5a2-3b49-417b-87a4-751aebbe1098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324736234-172.17.0.7-1597670519399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35099,DS-abd1021f-9ee2-4cec-8b14-2eeeebc4029e,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-9d12db43-172a-449a-b0b9-4e4ed972d565,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-965920b2-f9d5-4b9e-98b7-33696cc4a875,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-946f5561-a1bb-4cb9-b683-0b95ce9909a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-1a485b59-ac84-47b5-91cb-43bcfd495f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-b74131ce-946b-417a-a723-6b24fba4b30c,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-ef8e012f-0e98-410c-8190-ec3bc2656a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-6c76fdc7-a3a0-4925-9ade-1cef199c915a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324736234-172.17.0.7-1597670519399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35099,DS-abd1021f-9ee2-4cec-8b14-2eeeebc4029e,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-9d12db43-172a-449a-b0b9-4e4ed972d565,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-965920b2-f9d5-4b9e-98b7-33696cc4a875,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-946f5561-a1bb-4cb9-b683-0b95ce9909a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-1a485b59-ac84-47b5-91cb-43bcfd495f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-b74131ce-946b-417a-a723-6b24fba4b30c,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-ef8e012f-0e98-410c-8190-ec3bc2656a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-6c76fdc7-a3a0-4925-9ade-1cef199c915a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346893672-172.17.0.7-1597671015991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33050,DS-370ce93a-c265-4da2-a40e-e29cf33ad7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-da38fd5a-4810-4142-9dab-f416292d6bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-9849fc73-e37a-4e9f-be8a-7823db9da3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-e0762513-2a83-4ad5-848b-3d9ef3a2646e,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-701ef549-c01c-4a4c-9955-83baef6d3682,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-8937ca09-5cef-477a-9656-5649eaccc7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-abd96808-54a5-47a7-89e0-3beeefad5198,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-2a7fbdb8-02ea-499a-a779-56bdb22a1c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346893672-172.17.0.7-1597671015991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33050,DS-370ce93a-c265-4da2-a40e-e29cf33ad7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-da38fd5a-4810-4142-9dab-f416292d6bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-9849fc73-e37a-4e9f-be8a-7823db9da3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-e0762513-2a83-4ad5-848b-3d9ef3a2646e,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-701ef549-c01c-4a4c-9955-83baef6d3682,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-8937ca09-5cef-477a-9656-5649eaccc7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-abd96808-54a5-47a7-89e0-3beeefad5198,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-2a7fbdb8-02ea-499a-a779-56bdb22a1c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666981379-172.17.0.7-1597671252577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40164,DS-99abbae6-a334-4d0d-a7cd-6889904d272b,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-b9eb04d2-0600-416a-8e3b-f67c8cb7caf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-2395f100-814c-4c24-b722-a999ff79fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-55685107-3df1-4263-b237-a60e6175db53,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-f7ff015f-26ea-410b-bec1-27943201cb65,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-904b2d5a-7b8e-49db-b209-dd1a1245488c,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-bb05fa44-204f-40b2-8e71-c464d3e28816,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-bef60e84-a654-4af2-b68c-573f0a6185cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666981379-172.17.0.7-1597671252577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40164,DS-99abbae6-a334-4d0d-a7cd-6889904d272b,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-b9eb04d2-0600-416a-8e3b-f67c8cb7caf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-2395f100-814c-4c24-b722-a999ff79fe2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-55685107-3df1-4263-b237-a60e6175db53,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-f7ff015f-26ea-410b-bec1-27943201cb65,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-904b2d5a-7b8e-49db-b209-dd1a1245488c,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-bb05fa44-204f-40b2-8e71-c464d3e28816,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-bef60e84-a654-4af2-b68c-573f0a6185cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6027
