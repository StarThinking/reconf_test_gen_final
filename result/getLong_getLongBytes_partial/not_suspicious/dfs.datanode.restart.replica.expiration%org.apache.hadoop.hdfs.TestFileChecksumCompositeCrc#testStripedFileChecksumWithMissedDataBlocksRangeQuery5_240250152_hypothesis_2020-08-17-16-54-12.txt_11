reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571790010-172.17.0.9-1597683508706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41910,DS-a293d56c-60a8-4b1c-b942-8ec48b3de165,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-37399782-e090-4d09-8583-25d848d83cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-7bf60a5c-b045-4a18-b5dc-afbf55651518,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-314bbefc-7ae4-4808-bc3e-445ee17db180,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-57ecb9bb-0578-469e-ab45-797633126075,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-74de1dab-a43d-41b0-9b9f-4ac474f78d77,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-d6a03168-8b75-49f9-a84a-a33384a88ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-bb40815d-960d-4f6b-b52d-d81c5a867424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571790010-172.17.0.9-1597683508706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41910,DS-a293d56c-60a8-4b1c-b942-8ec48b3de165,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-37399782-e090-4d09-8583-25d848d83cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-7bf60a5c-b045-4a18-b5dc-afbf55651518,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-314bbefc-7ae4-4808-bc3e-445ee17db180,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-57ecb9bb-0578-469e-ab45-797633126075,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-74de1dab-a43d-41b0-9b9f-4ac474f78d77,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-d6a03168-8b75-49f9-a84a-a33384a88ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-bb40815d-960d-4f6b-b52d-d81c5a867424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280057329-172.17.0.9-1597683622160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37410,DS-8715e397-8560-4ee8-b22b-2b8475b591f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-efecc458-2afa-4268-9939-f1584422d3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-65d0ec33-58ed-4ed7-b336-65b7b12d1445,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-8c874a69-1fc9-4dc2-9057-5cf7b4d70fae,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-fb541159-34a6-4f71-a44a-a3f1d1c67a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-0a24a269-f0bd-45f9-86ca-4fb1c6bc942f,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-526a2e8d-e1e8-4866-9d63-efd23fa93ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-7f0591a3-69e9-4c65-878f-7351ed122bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280057329-172.17.0.9-1597683622160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37410,DS-8715e397-8560-4ee8-b22b-2b8475b591f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-efecc458-2afa-4268-9939-f1584422d3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-65d0ec33-58ed-4ed7-b336-65b7b12d1445,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-8c874a69-1fc9-4dc2-9057-5cf7b4d70fae,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-fb541159-34a6-4f71-a44a-a3f1d1c67a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-0a24a269-f0bd-45f9-86ca-4fb1c6bc942f,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-526a2e8d-e1e8-4866-9d63-efd23fa93ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-7f0591a3-69e9-4c65-878f-7351ed122bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202865954-172.17.0.9-1597683885018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-1b7e057d-fa48-4b14-8f1f-ca4c8334adf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-de7c7ab8-1deb-4fab-9a29-b8aef4717968,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-995dd212-6162-4dea-b3fd-3d9607970468,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-998ee421-82bc-4e1f-bcd3-0da9e1f4e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-33c330ec-ee2a-44b0-a68f-84ef25bdc51b,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-cd32cd49-999c-4b20-9898-8efa5d51ed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-7d49f454-1e81-4705-819d-a6e52b2d2016,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-a69aa6ee-0284-479e-91a9-a6461bc90312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202865954-172.17.0.9-1597683885018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-1b7e057d-fa48-4b14-8f1f-ca4c8334adf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-de7c7ab8-1deb-4fab-9a29-b8aef4717968,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-995dd212-6162-4dea-b3fd-3d9607970468,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-998ee421-82bc-4e1f-bcd3-0da9e1f4e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-33c330ec-ee2a-44b0-a68f-84ef25bdc51b,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-cd32cd49-999c-4b20-9898-8efa5d51ed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-7d49f454-1e81-4705-819d-a6e52b2d2016,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-a69aa6ee-0284-479e-91a9-a6461bc90312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589973182-172.17.0.9-1597683992813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44447,DS-a0895085-4df0-4882-80c2-b681dbfd1349,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-4b9901ea-efcc-47c5-bcc2-84b822cf0b46,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-f09558c8-90c0-4bc1-83d0-47ebd6ac706b,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-e182f5b1-e47b-4e49-bfd8-7c0663cf0d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-bc1b4054-6898-405f-837b-df2bd84f53d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-84324c2c-c41f-4dc0-9005-3ecc570fcb90,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-a0e6ff7f-60fc-43f7-9fa1-f5f6e9dc528c,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-a0540383-51a9-4d60-b40e-faac4b1cfdc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589973182-172.17.0.9-1597683992813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44447,DS-a0895085-4df0-4882-80c2-b681dbfd1349,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-4b9901ea-efcc-47c5-bcc2-84b822cf0b46,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-f09558c8-90c0-4bc1-83d0-47ebd6ac706b,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-e182f5b1-e47b-4e49-bfd8-7c0663cf0d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-bc1b4054-6898-405f-837b-df2bd84f53d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-84324c2c-c41f-4dc0-9005-3ecc570fcb90,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-a0e6ff7f-60fc-43f7-9fa1-f5f6e9dc528c,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-a0540383-51a9-4d60-b40e-faac4b1cfdc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860848597-172.17.0.9-1597684460364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44140,DS-6d198e80-9350-4844-83cb-30fa6eba3936,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-5053dd09-3b3c-46dd-b314-d1ae2b5be8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-81bb0b9f-c121-45de-b824-b1d26c3d2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-940b17a0-3705-466f-b7e9-a6524e73cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-f3e5d95f-df72-412e-a418-24686de003ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-56a3cda1-d712-441f-8feb-da56a0b7c160,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-40dd642c-fee6-41b1-acb1-e583d8c99ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-6d2d2062-a092-4baa-a5c9-b00ce739bc2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860848597-172.17.0.9-1597684460364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44140,DS-6d198e80-9350-4844-83cb-30fa6eba3936,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-5053dd09-3b3c-46dd-b314-d1ae2b5be8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-81bb0b9f-c121-45de-b824-b1d26c3d2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-940b17a0-3705-466f-b7e9-a6524e73cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-f3e5d95f-df72-412e-a418-24686de003ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-56a3cda1-d712-441f-8feb-da56a0b7c160,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-40dd642c-fee6-41b1-acb1-e583d8c99ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-6d2d2062-a092-4baa-a5c9-b00ce739bc2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533584521-172.17.0.9-1597684608590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-22fbd96a-bc67-467d-868e-89e14e48d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-ec4652bb-9bb1-45b1-9cbc-cbd15dfdd46c,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-c7e278d4-1265-4243-bdff-27c4c92d296a,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-a9aaf9de-e9f8-47bf-a7cb-348c8677efc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-b82d0e81-9015-4f10-8b3e-f8e265d84e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-c0be36a0-5737-44e4-b065-7b9a0d9b5518,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-e025ca89-b781-4a26-8c72-a84bc92721db,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-b207f76c-80db-420e-96eb-9be7ea4d49bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533584521-172.17.0.9-1597684608590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-22fbd96a-bc67-467d-868e-89e14e48d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-ec4652bb-9bb1-45b1-9cbc-cbd15dfdd46c,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-c7e278d4-1265-4243-bdff-27c4c92d296a,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-a9aaf9de-e9f8-47bf-a7cb-348c8677efc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-b82d0e81-9015-4f10-8b3e-f8e265d84e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-c0be36a0-5737-44e4-b065-7b9a0d9b5518,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-e025ca89-b781-4a26-8c72-a84bc92721db,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-b207f76c-80db-420e-96eb-9be7ea4d49bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274560562-172.17.0.9-1597684985071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-2f75f25a-37df-4bde-9bf8-0cf27f4c2f28,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-67ff7ff2-3e21-484a-a4cd-f62ab51fd056,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-ef053384-61e2-4d27-b963-970db68357cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-d640a433-e154-4535-bc56-cdc32ae16f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-1a771683-bd7f-448a-81e8-0ba17f0c2013,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-f5699d77-b113-4ed8-8ad8-6955acc44b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-ba8f8e83-4f76-41ec-9686-8fcdf207daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-3526b8b5-b247-47c3-8529-131b71db1577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274560562-172.17.0.9-1597684985071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42650,DS-2f75f25a-37df-4bde-9bf8-0cf27f4c2f28,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-67ff7ff2-3e21-484a-a4cd-f62ab51fd056,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-ef053384-61e2-4d27-b963-970db68357cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-d640a433-e154-4535-bc56-cdc32ae16f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-1a771683-bd7f-448a-81e8-0ba17f0c2013,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-f5699d77-b113-4ed8-8ad8-6955acc44b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-ba8f8e83-4f76-41ec-9686-8fcdf207daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-3526b8b5-b247-47c3-8529-131b71db1577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148876115-172.17.0.9-1597685054790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-be64e2f7-161b-4d7e-a706-90a7c0924ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-82664862-2811-4424-8c46-9bcc9e99dfef,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-e699932b-eb12-4748-8383-c1dcf267a768,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-2bc35193-db34-4ef4-8c62-e3b46aa9a036,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-b415f46c-883f-4706-976f-65a1b9e0a857,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-e9d20986-4940-4d38-9a32-fbdab19073c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-d4009f9d-b50f-4035-a115-80bf155ecfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-2bbba776-dbd9-444d-9562-13931205627c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148876115-172.17.0.9-1597685054790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-be64e2f7-161b-4d7e-a706-90a7c0924ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-82664862-2811-4424-8c46-9bcc9e99dfef,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-e699932b-eb12-4748-8383-c1dcf267a768,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-2bc35193-db34-4ef4-8c62-e3b46aa9a036,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-b415f46c-883f-4706-976f-65a1b9e0a857,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-e9d20986-4940-4d38-9a32-fbdab19073c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-d4009f9d-b50f-4035-a115-80bf155ecfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-2bbba776-dbd9-444d-9562-13931205627c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99941647-172.17.0.9-1597685529737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41421,DS-894f63ae-b8c0-4871-b385-b7c8f925c030,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-8ed3ebdb-4f02-4346-a433-ee2b5ac0c7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-cfa063b4-e0c5-4a5e-b8ac-a9b98ef6d997,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-3f3e0a1b-3639-4f8f-a4f1-c3c8793f56a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-71d2bb92-8fb5-4489-9e75-7079ddf1d864,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-0a0d1c28-8ef1-4106-b4b7-a69facce488f,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-3a16b115-3514-4ea2-8ea4-673e02fe053a,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-e84a2832-88bf-4bb2-9021-246768ebd679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99941647-172.17.0.9-1597685529737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41421,DS-894f63ae-b8c0-4871-b385-b7c8f925c030,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-8ed3ebdb-4f02-4346-a433-ee2b5ac0c7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-cfa063b4-e0c5-4a5e-b8ac-a9b98ef6d997,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-3f3e0a1b-3639-4f8f-a4f1-c3c8793f56a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-71d2bb92-8fb5-4489-9e75-7079ddf1d864,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-0a0d1c28-8ef1-4106-b4b7-a69facce488f,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-3a16b115-3514-4ea2-8ea4-673e02fe053a,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-e84a2832-88bf-4bb2-9021-246768ebd679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483307474-172.17.0.9-1597685876149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-23690ef7-18ce-41f4-a649-3938496612dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-244b0abf-39e3-41cc-89d7-168e5777aa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-c96a98d9-cd04-472b-a245-9f15971a502d,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-586b181a-92e5-4a4e-8255-5a0eda79e7db,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-835930a7-28c5-452a-a645-b0655e172563,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-bcf0870c-c17e-4726-93bb-4b9c8c4b304e,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-9dad96b2-01a8-4af3-9cd1-027bb9a79330,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-17652624-87e4-4fa6-a775-33c597be8c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483307474-172.17.0.9-1597685876149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-23690ef7-18ce-41f4-a649-3938496612dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-244b0abf-39e3-41cc-89d7-168e5777aa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-c96a98d9-cd04-472b-a245-9f15971a502d,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-586b181a-92e5-4a4e-8255-5a0eda79e7db,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-835930a7-28c5-452a-a645-b0655e172563,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-bcf0870c-c17e-4726-93bb-4b9c8c4b304e,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-9dad96b2-01a8-4af3-9cd1-027bb9a79330,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-17652624-87e4-4fa6-a775-33c597be8c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013363752-172.17.0.9-1597686057536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-aef37d6e-4f28-40d7-92c6-a4e8f73861da,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-cac2a733-a9f3-4c92-b89d-7bd75298adc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-0a152e6e-44e2-4f95-a41a-bf251b0c3ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-81c60f84-4fd3-434b-9d40-c3ad1073bb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-7a0097c8-aaf1-4ed9-a3d1-8ec797a054f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-95f300af-823c-4f78-8f77-7e1e3eb77f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-78df4022-ffe6-4d6c-a6ac-5ffdcd42417a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-ff3feae7-0dae-4392-b288-85e6e135c6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013363752-172.17.0.9-1597686057536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-aef37d6e-4f28-40d7-92c6-a4e8f73861da,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-cac2a733-a9f3-4c92-b89d-7bd75298adc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-0a152e6e-44e2-4f95-a41a-bf251b0c3ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-81c60f84-4fd3-434b-9d40-c3ad1073bb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-7a0097c8-aaf1-4ed9-a3d1-8ec797a054f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-95f300af-823c-4f78-8f77-7e1e3eb77f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-78df4022-ffe6-4d6c-a6ac-5ffdcd42417a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-ff3feae7-0dae-4392-b288-85e6e135c6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160641921-172.17.0.9-1597687434567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-492e92e3-6766-4267-9a0e-692da35db9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-4705aed2-937a-470a-a8ff-346229ae75d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-f397458a-34ca-47f2-9c9c-ed6d9d7925ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-fe7ed06f-2656-4147-bcb4-4a5d5ede03e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-f3233af9-61f2-4e4a-a63d-8d9f7432fa80,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-aabf131f-7442-4e95-a7c8-4a0fe6450290,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-d727e3f8-ee73-49c8-a659-1c026d9ef68f,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-4bbdfc86-2030-4595-a2b7-4360f5c85d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160641921-172.17.0.9-1597687434567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-492e92e3-6766-4267-9a0e-692da35db9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-4705aed2-937a-470a-a8ff-346229ae75d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-f397458a-34ca-47f2-9c9c-ed6d9d7925ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-fe7ed06f-2656-4147-bcb4-4a5d5ede03e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-f3233af9-61f2-4e4a-a63d-8d9f7432fa80,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-aabf131f-7442-4e95-a7c8-4a0fe6450290,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-d727e3f8-ee73-49c8-a659-1c026d9ef68f,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-4bbdfc86-2030-4595-a2b7-4360f5c85d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5524
