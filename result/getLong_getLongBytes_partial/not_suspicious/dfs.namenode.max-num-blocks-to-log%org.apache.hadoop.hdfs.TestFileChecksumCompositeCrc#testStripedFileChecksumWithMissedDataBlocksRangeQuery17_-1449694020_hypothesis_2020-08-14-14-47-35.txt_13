reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417897576-172.17.0.17-1597417245578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35617,DS-6c1f9bed-c5f3-4afe-bd15-ad924389b7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-935f93d8-e90b-4865-b8cd-7743257c1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-7aae4727-48b4-432c-b49e-3aed142af4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-cfd74dd6-82fd-4e09-afe6-61e33c93e676,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-2b068f1c-319e-4b75-9a5b-01721c76c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-88e6c498-8193-4e15-a1fb-63e10707d815,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-8fe2b271-37e4-4573-86ee-fd36f1deec65,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-bdb2c00c-ddc2-472a-8611-0b04f01088d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417897576-172.17.0.17-1597417245578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35617,DS-6c1f9bed-c5f3-4afe-bd15-ad924389b7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-935f93d8-e90b-4865-b8cd-7743257c1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-7aae4727-48b4-432c-b49e-3aed142af4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-cfd74dd6-82fd-4e09-afe6-61e33c93e676,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-2b068f1c-319e-4b75-9a5b-01721c76c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-88e6c498-8193-4e15-a1fb-63e10707d815,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-8fe2b271-37e4-4573-86ee-fd36f1deec65,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-bdb2c00c-ddc2-472a-8611-0b04f01088d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803908754-172.17.0.17-1597417369995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38039,DS-95ae9a9f-1bc8-4d04-8c03-fd1e82361953,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-30b2f53b-ed29-4369-8f0f-4bdf05f6d957,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-f9997b02-36ff-4b3e-bbf3-1c5abb893de5,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-63d3db5a-4b91-4062-86d5-1298ce468e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-ff46825f-9a23-42e3-94c3-cc33471aa035,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-5917bc62-0ad0-443c-8214-7ca80df00828,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-30b59261-2dda-4705-bd29-911675593741,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-a1651928-b6c1-40cf-8ade-e5eaac30c046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803908754-172.17.0.17-1597417369995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38039,DS-95ae9a9f-1bc8-4d04-8c03-fd1e82361953,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-30b2f53b-ed29-4369-8f0f-4bdf05f6d957,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-f9997b02-36ff-4b3e-bbf3-1c5abb893de5,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-63d3db5a-4b91-4062-86d5-1298ce468e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-ff46825f-9a23-42e3-94c3-cc33471aa035,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-5917bc62-0ad0-443c-8214-7ca80df00828,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-30b59261-2dda-4705-bd29-911675593741,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-a1651928-b6c1-40cf-8ade-e5eaac30c046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637246600-172.17.0.17-1597418090418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-99bd86f4-ba78-4e8e-8376-35bb4c26afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-7fec0bae-49a4-4dc0-b30d-71527ce51243,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-560fdad7-a9eb-491e-acdf-f9a4b337dc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-07437f45-7617-4746-8710-f8f39c37d132,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-d7a3ada8-a54c-4369-8dbb-3156c687d0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-1252988c-62d0-4e53-a8d1-9eb62def41ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-90fe3efb-a744-42cb-b0c3-b1deac9c5695,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-8a9d84bc-7d7e-42f1-a0b6-9da55d0cbde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637246600-172.17.0.17-1597418090418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37282,DS-99bd86f4-ba78-4e8e-8376-35bb4c26afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-7fec0bae-49a4-4dc0-b30d-71527ce51243,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-560fdad7-a9eb-491e-acdf-f9a4b337dc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-07437f45-7617-4746-8710-f8f39c37d132,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-d7a3ada8-a54c-4369-8dbb-3156c687d0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-1252988c-62d0-4e53-a8d1-9eb62def41ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-90fe3efb-a744-42cb-b0c3-b1deac9c5695,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-8a9d84bc-7d7e-42f1-a0b6-9da55d0cbde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687775234-172.17.0.17-1597418558243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36312,DS-aa8c40e6-9d24-4bb0-9700-c739b630d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-92389ade-d481-42d5-8da6-e2a4bf7bcfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-dd56803f-232a-4616-8a1e-d70e7bed7a43,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-544e4b43-046a-4e6d-ae7a-b6b725cfabc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-dd99808b-8f3f-4774-99d4-c92a41e32f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-a818f2b7-e635-4146-be4a-a9f739b1dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-2de6f4ab-60d9-41c8-8d07-4073da30cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-b31b76ae-37df-4ab9-b92a-e8ebf805ab4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687775234-172.17.0.17-1597418558243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36312,DS-aa8c40e6-9d24-4bb0-9700-c739b630d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-92389ade-d481-42d5-8da6-e2a4bf7bcfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-dd56803f-232a-4616-8a1e-d70e7bed7a43,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-544e4b43-046a-4e6d-ae7a-b6b725cfabc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-dd99808b-8f3f-4774-99d4-c92a41e32f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-a818f2b7-e635-4146-be4a-a9f739b1dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-2de6f4ab-60d9-41c8-8d07-4073da30cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-b31b76ae-37df-4ab9-b92a-e8ebf805ab4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972350292-172.17.0.17-1597418860129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-dc71fcc9-8b85-42d0-875c-40735e29d81e,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-51a97e35-75eb-45f3-9b5e-54717266161a,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-1c2ae9b1-75dd-4a97-b401-d10cfe5c9720,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-3fc5c1d6-cc3f-46e3-945f-1aac25747c43,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-551b0f3a-ca2f-48a6-b480-a92a4598c188,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-52d62cb3-e66d-45e3-81db-2f253689fa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-6cfd61a7-1b0f-4b94-99a1-6a01147b62c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-791b8144-271d-4394-a404-e54b961cdcdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972350292-172.17.0.17-1597418860129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-dc71fcc9-8b85-42d0-875c-40735e29d81e,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-51a97e35-75eb-45f3-9b5e-54717266161a,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-1c2ae9b1-75dd-4a97-b401-d10cfe5c9720,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-3fc5c1d6-cc3f-46e3-945f-1aac25747c43,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-551b0f3a-ca2f-48a6-b480-a92a4598c188,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-52d62cb3-e66d-45e3-81db-2f253689fa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-6cfd61a7-1b0f-4b94-99a1-6a01147b62c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-791b8144-271d-4394-a404-e54b961cdcdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709790780-172.17.0.17-1597418924743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42524,DS-08c60918-eafe-4fb8-a205-75f3accb092c,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-40d5a441-e8f0-4dcf-97b6-e2e44fa312bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-a9bcdde5-a925-454b-a87a-7ab1d9fbe9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-bdfb1b96-5e5f-4dcc-aefd-0d230866482a,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-aa51c288-eff8-40de-8f6d-aa2db5e63edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-24279caf-79e4-4232-9320-ad16d96e558f,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-02b5d651-b881-452c-b75b-52510dce4921,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-48b7490b-ee25-4dcd-9d49-434c69d7d301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709790780-172.17.0.17-1597418924743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42524,DS-08c60918-eafe-4fb8-a205-75f3accb092c,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-40d5a441-e8f0-4dcf-97b6-e2e44fa312bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-a9bcdde5-a925-454b-a87a-7ab1d9fbe9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-bdfb1b96-5e5f-4dcc-aefd-0d230866482a,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-aa51c288-eff8-40de-8f6d-aa2db5e63edb,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-24279caf-79e4-4232-9320-ad16d96e558f,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-02b5d651-b881-452c-b75b-52510dce4921,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-48b7490b-ee25-4dcd-9d49-434c69d7d301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123548710-172.17.0.17-1597419272702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-8584a75e-32ea-4ee9-9d7e-10dd829acd49,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-99ba92b1-ced3-4319-908f-dab730a57c38,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-47441006-bdd3-4d6c-840f-9ab23352052c,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-f070064e-a0cc-498c-84aa-88f6bed7dc94,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e398f0d0-601e-440b-93f0-e801da5e5ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-daa02883-4214-42fe-93f0-b8c2be5fc0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-48b12ada-e0dc-42de-b15b-dcc4697d2d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-0a2f2d0a-8758-44c4-92d0-384630ae6038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123548710-172.17.0.17-1597419272702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-8584a75e-32ea-4ee9-9d7e-10dd829acd49,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-99ba92b1-ced3-4319-908f-dab730a57c38,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-47441006-bdd3-4d6c-840f-9ab23352052c,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-f070064e-a0cc-498c-84aa-88f6bed7dc94,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e398f0d0-601e-440b-93f0-e801da5e5ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-daa02883-4214-42fe-93f0-b8c2be5fc0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-48b12ada-e0dc-42de-b15b-dcc4697d2d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-0a2f2d0a-8758-44c4-92d0-384630ae6038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722042971-172.17.0.17-1597419851243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-99f8d2a1-900b-4798-8fe9-369385f96368,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-03b82341-c128-44dd-8685-a6a1083f1a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-39e302d5-c99f-4e1e-a08d-8c62bdd21acf,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-9e6fdbbb-baca-41d8-81f7-3496111703c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-f91641d9-c48f-4448-98b4-b50fd452131f,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-a3b6faf0-4b9a-418a-a4f9-bda7d7d223f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-a09a7685-0445-4e5d-80d5-9c31340d6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-f63d7c92-7d7e-4cc7-9fe1-a47db0459a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722042971-172.17.0.17-1597419851243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40557,DS-99f8d2a1-900b-4798-8fe9-369385f96368,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-03b82341-c128-44dd-8685-a6a1083f1a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-39e302d5-c99f-4e1e-a08d-8c62bdd21acf,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-9e6fdbbb-baca-41d8-81f7-3496111703c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-f91641d9-c48f-4448-98b4-b50fd452131f,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-a3b6faf0-4b9a-418a-a4f9-bda7d7d223f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-a09a7685-0445-4e5d-80d5-9c31340d6adb,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-f63d7c92-7d7e-4cc7-9fe1-a47db0459a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541163936-172.17.0.17-1597420077472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37698,DS-ae51df4e-daf9-49e2-b7e9-87d8d06b8bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-c7e73d12-5779-4ca9-a486-d26163d370f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-cec13643-9053-4307-b1de-2714f2d59934,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-b13eca91-e73c-4f2f-a4e6-5b4f44acaa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-5bf75e3f-916a-4baf-871d-c1b126877939,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-3d80d1e9-4adf-4ed8-9b85-f98441e3bdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-7ecf98ac-1e9d-4caa-98ae-3f8adf15b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-3a9f3dc8-94af-4723-b1bc-86e6156f9710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541163936-172.17.0.17-1597420077472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37698,DS-ae51df4e-daf9-49e2-b7e9-87d8d06b8bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-c7e73d12-5779-4ca9-a486-d26163d370f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-cec13643-9053-4307-b1de-2714f2d59934,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-b13eca91-e73c-4f2f-a4e6-5b4f44acaa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-5bf75e3f-916a-4baf-871d-c1b126877939,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-3d80d1e9-4adf-4ed8-9b85-f98441e3bdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-7ecf98ac-1e9d-4caa-98ae-3f8adf15b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-3a9f3dc8-94af-4723-b1bc-86e6156f9710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853008676-172.17.0.17-1597420619731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-1c145d0a-2d9f-4bbe-a10a-b3220d059940,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-288a93ef-d340-4762-acb7-3851ac57f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-3bdb7661-350f-4a28-9239-c0731dcacb19,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-e847a070-6427-431a-bcf2-987fad1a7fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-ac92d77f-a4d8-4b03-8463-bea80a471e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-cc2737be-e03f-4107-82ec-655549998cad,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-9304c362-910d-4302-bfab-dd7f063f57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-d3eac3f6-b564-4988-846e-d3dd6aba064a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853008676-172.17.0.17-1597420619731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-1c145d0a-2d9f-4bbe-a10a-b3220d059940,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-288a93ef-d340-4762-acb7-3851ac57f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-3bdb7661-350f-4a28-9239-c0731dcacb19,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-e847a070-6427-431a-bcf2-987fad1a7fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-ac92d77f-a4d8-4b03-8463-bea80a471e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-cc2737be-e03f-4107-82ec-655549998cad,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-9304c362-910d-4302-bfab-dd7f063f57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-d3eac3f6-b564-4988-846e-d3dd6aba064a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124591425-172.17.0.17-1597420825792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-1f950075-0d36-49b3-9a51-49c9452d509b,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-b822f9a7-2a52-4940-a962-5f5c58d7e0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-2e62075f-03f3-4c45-9218-a949531f7423,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-de8ac567-9a13-4fb3-abbc-80e4890327d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-768a80e2-d025-4b58-981c-cda28bc2fc67,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-0144df8e-1ca6-4dbb-a533-9d5d38d783b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-e79c6ce8-f7e6-49c8-9d3c-de42a47a88e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-5bbfbd71-0e1b-40bb-8f86-9766f6266248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124591425-172.17.0.17-1597420825792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-1f950075-0d36-49b3-9a51-49c9452d509b,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-b822f9a7-2a52-4940-a962-5f5c58d7e0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-2e62075f-03f3-4c45-9218-a949531f7423,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-de8ac567-9a13-4fb3-abbc-80e4890327d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-768a80e2-d025-4b58-981c-cda28bc2fc67,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-0144df8e-1ca6-4dbb-a533-9d5d38d783b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-e79c6ce8-f7e6-49c8-9d3c-de42a47a88e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-5bbfbd71-0e1b-40bb-8f86-9766f6266248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777617380-172.17.0.17-1597421239421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40906,DS-670f9ca1-495e-4202-a668-82738afdc9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-7562a8f1-def6-43ef-aa02-d3419bf11b13,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-05256674-bc53-4918-85c4-3db060e8f39d,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-6a4b5dc5-20e5-4398-84c9-66d430681073,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-3c7f2866-2445-4b18-a3ab-e501030b2523,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-8352bc4e-525b-49b4-8c95-cc713cc00503,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-e664b768-3469-422f-b081-d7c615540fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-260be65a-f91e-450d-b392-28b89a971d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777617380-172.17.0.17-1597421239421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40906,DS-670f9ca1-495e-4202-a668-82738afdc9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-7562a8f1-def6-43ef-aa02-d3419bf11b13,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-05256674-bc53-4918-85c4-3db060e8f39d,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-6a4b5dc5-20e5-4398-84c9-66d430681073,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-3c7f2866-2445-4b18-a3ab-e501030b2523,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-8352bc4e-525b-49b4-8c95-cc713cc00503,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-e664b768-3469-422f-b081-d7c615540fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-260be65a-f91e-450d-b392-28b89a971d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980256072-172.17.0.17-1597421270164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-8167b592-0601-41eb-833a-b02e8fd00212,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-fe969d8a-7334-48f4-9063-c1340b69037f,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-7f8aa870-73b4-484c-94c4-0c51b162a711,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-61ffdd42-7954-4e63-8511-1a56c5e1bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-e8a34644-6f19-48ab-923e-878d3dceedca,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-d0b588d4-826e-4fbf-a496-07da397864a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-eae2a132-0bd7-4173-9709-96885081d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-d36fa8f0-c86c-45c5-b415-02d6f2d3d707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980256072-172.17.0.17-1597421270164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-8167b592-0601-41eb-833a-b02e8fd00212,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-fe969d8a-7334-48f4-9063-c1340b69037f,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-7f8aa870-73b4-484c-94c4-0c51b162a711,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-61ffdd42-7954-4e63-8511-1a56c5e1bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-e8a34644-6f19-48ab-923e-878d3dceedca,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-d0b588d4-826e-4fbf-a496-07da397864a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-eae2a132-0bd7-4173-9709-96885081d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-d36fa8f0-c86c-45c5-b415-02d6f2d3d707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4940
