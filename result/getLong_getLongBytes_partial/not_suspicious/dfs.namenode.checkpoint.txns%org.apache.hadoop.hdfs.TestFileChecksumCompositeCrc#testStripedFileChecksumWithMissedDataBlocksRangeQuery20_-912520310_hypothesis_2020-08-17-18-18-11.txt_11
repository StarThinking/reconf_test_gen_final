reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842594170-172.17.0.2-1597688305890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-4e6f2a32-1565-4594-9d60-dbff623fa3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-72669d7e-1a4c-4454-8b9d-e46a96fc330b,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-0d0a6658-c9b9-4314-9825-1a427d4033a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-e8f487e5-d89d-4af9-90ab-035a3d822053,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-90fa522f-c7d1-46bc-a968-dc501b96984a,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-d88ab9bc-91d1-4633-8dc8-96a28213667c,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-c36925b5-125b-45d1-9dd3-d02418803681,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-8af58d91-71bb-4b2e-8782-bc31331ec94c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842594170-172.17.0.2-1597688305890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-4e6f2a32-1565-4594-9d60-dbff623fa3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-72669d7e-1a4c-4454-8b9d-e46a96fc330b,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-0d0a6658-c9b9-4314-9825-1a427d4033a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-e8f487e5-d89d-4af9-90ab-035a3d822053,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-90fa522f-c7d1-46bc-a968-dc501b96984a,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-d88ab9bc-91d1-4633-8dc8-96a28213667c,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-c36925b5-125b-45d1-9dd3-d02418803681,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-8af58d91-71bb-4b2e-8782-bc31331ec94c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928378217-172.17.0.2-1597688582176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-40e5cd2f-3172-4fcc-ab14-f280f0f3fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-9a287d2e-5db2-4ff9-a257-ddedbbcba9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-43fbaf41-ec58-4628-b365-da0b9e9ed66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-6fd20c9e-8f1e-4b4d-91b5-5d2c9ffc5956,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-df99c245-e3cb-4a27-bd0a-04032706179f,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-b4b74cc6-7ea7-489c-9fe7-a3146e7bba33,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-146aafc6-ea6a-4716-9e00-5825e0de95b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-304e9626-f647-4954-9835-962f6933e855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928378217-172.17.0.2-1597688582176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-40e5cd2f-3172-4fcc-ab14-f280f0f3fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-9a287d2e-5db2-4ff9-a257-ddedbbcba9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-43fbaf41-ec58-4628-b365-da0b9e9ed66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-6fd20c9e-8f1e-4b4d-91b5-5d2c9ffc5956,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-df99c245-e3cb-4a27-bd0a-04032706179f,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-b4b74cc6-7ea7-489c-9fe7-a3146e7bba33,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-146aafc6-ea6a-4716-9e00-5825e0de95b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-304e9626-f647-4954-9835-962f6933e855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012912342-172.17.0.2-1597689160144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39330,DS-f1bd9e5c-7661-48fa-9684-5e25d6e8b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-9b9b4486-1c92-4f3f-91fc-3eb4e06c95c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-49ff4187-f6a0-4753-88d0-33d02b2d26cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-b5a798e8-6a38-4f73-9127-007abe9fb93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-dc7351ff-dbef-4e9a-9e42-06c7fdcba21f,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-d29e97cb-9e08-484b-b5bf-89c243695d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-487e9b7b-50b0-4d1e-af0b-1d669f513996,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-2191237a-ab38-4ab1-9dec-bb8a680d1ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012912342-172.17.0.2-1597689160144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39330,DS-f1bd9e5c-7661-48fa-9684-5e25d6e8b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-9b9b4486-1c92-4f3f-91fc-3eb4e06c95c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-49ff4187-f6a0-4753-88d0-33d02b2d26cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-b5a798e8-6a38-4f73-9127-007abe9fb93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-dc7351ff-dbef-4e9a-9e42-06c7fdcba21f,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-d29e97cb-9e08-484b-b5bf-89c243695d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-487e9b7b-50b0-4d1e-af0b-1d669f513996,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-2191237a-ab38-4ab1-9dec-bb8a680d1ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900721517-172.17.0.2-1597689321042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37985,DS-be9191fa-9f75-4c81-b5e7-acd39aaef786,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-5e82ee13-780b-4607-a2fa-8e931e5b61f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-540dba2c-5d16-4aeb-b0d2-ddf1fbe302c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-3219eb11-a259-4e81-9924-59c63e525a80,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-8d1c62b3-0595-4ad4-9904-76bfc565d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-627bf73a-27b6-4e1b-b313-ab70ed5cdfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-1f6fca78-dd8e-477b-923d-855cad4e2966,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-00ee2684-34b0-46a1-a43c-c21e3d685a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900721517-172.17.0.2-1597689321042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37985,DS-be9191fa-9f75-4c81-b5e7-acd39aaef786,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-5e82ee13-780b-4607-a2fa-8e931e5b61f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-540dba2c-5d16-4aeb-b0d2-ddf1fbe302c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-3219eb11-a259-4e81-9924-59c63e525a80,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-8d1c62b3-0595-4ad4-9904-76bfc565d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-627bf73a-27b6-4e1b-b313-ab70ed5cdfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-1f6fca78-dd8e-477b-923d-855cad4e2966,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-00ee2684-34b0-46a1-a43c-c21e3d685a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402266214-172.17.0.2-1597689816703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34366,DS-ef206346-68f5-4549-96e0-00cde9171f30,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-3143223a-23b3-4b9d-abec-f59a9ad8fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-caf9007c-3f8a-40fb-84f5-cd73aaed4b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-741f9a0d-9fad-4715-aa18-9bbe7da4b967,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-3c3a519b-6b53-417b-9bd6-8ee66d1aec09,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-78a7fac1-ec04-43b4-8986-8817aab3930c,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-06fb00c6-6461-4b6f-aa4c-93f77c0de05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-5ee59492-a45a-44f8-a318-ef021aac6bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402266214-172.17.0.2-1597689816703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34366,DS-ef206346-68f5-4549-96e0-00cde9171f30,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-3143223a-23b3-4b9d-abec-f59a9ad8fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-caf9007c-3f8a-40fb-84f5-cd73aaed4b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-741f9a0d-9fad-4715-aa18-9bbe7da4b967,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-3c3a519b-6b53-417b-9bd6-8ee66d1aec09,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-78a7fac1-ec04-43b4-8986-8817aab3930c,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-06fb00c6-6461-4b6f-aa4c-93f77c0de05c,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-5ee59492-a45a-44f8-a318-ef021aac6bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750199393-172.17.0.2-1597689853971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37295,DS-fdda6cff-4035-4fa4-9a73-68439d2768ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-b680aa61-2d0a-4b65-a5a0-5832537bb55d,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-b7f80191-1f46-481c-858d-a93589ecf9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-ef2148ff-2f18-4089-a8e8-dbfceb1257f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-18dab036-a5ab-4e83-ac92-e7fee5005bed,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-228cabed-6a93-450a-b9a9-28ba016b6102,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-0c111f72-c288-4726-8893-7d95406d360c,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-65fea13d-59a9-42ab-b0c0-457acbc2def7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750199393-172.17.0.2-1597689853971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37295,DS-fdda6cff-4035-4fa4-9a73-68439d2768ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-b680aa61-2d0a-4b65-a5a0-5832537bb55d,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-b7f80191-1f46-481c-858d-a93589ecf9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-ef2148ff-2f18-4089-a8e8-dbfceb1257f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-18dab036-a5ab-4e83-ac92-e7fee5005bed,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-228cabed-6a93-450a-b9a9-28ba016b6102,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-0c111f72-c288-4726-8893-7d95406d360c,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-65fea13d-59a9-42ab-b0c0-457acbc2def7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659742260-172.17.0.2-1597690232267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-ea7c06c1-7331-433d-939c-3086d581584c,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-98e1efa9-d00b-4657-9b2f-0cbc6e0eac42,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-ad16c02b-635c-4931-a629-521e51c09471,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-ff1145b3-7cf4-4cd9-9188-56885328ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-4bfd5d6a-7751-45d1-aaef-1b62f9a4b80c,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-67076b73-c862-4ad9-bd18-ef9fd17960ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-70dc10c7-872c-4916-a67c-26915d07b811,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-9400e1d5-d3e9-4a6b-baf0-b21a7443080e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659742260-172.17.0.2-1597690232267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-ea7c06c1-7331-433d-939c-3086d581584c,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-98e1efa9-d00b-4657-9b2f-0cbc6e0eac42,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-ad16c02b-635c-4931-a629-521e51c09471,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-ff1145b3-7cf4-4cd9-9188-56885328ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-4bfd5d6a-7751-45d1-aaef-1b62f9a4b80c,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-67076b73-c862-4ad9-bd18-ef9fd17960ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-70dc10c7-872c-4916-a67c-26915d07b811,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-9400e1d5-d3e9-4a6b-baf0-b21a7443080e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952292981-172.17.0.2-1597690780685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-002c9e20-560e-498e-b73a-deb8a699f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-65394e23-2264-4123-8cfb-6388dc21c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-2dddf24c-3c76-4db1-a886-11fadad60818,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-346fe492-bbff-413c-b971-afb4d96ecd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-23a16281-bffd-4c8a-8192-d8185ec75e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-f0726b07-6acd-4232-9094-100492772e49,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-a3bed39d-0efe-4449-a334-ed3ae592f531,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-0e7638ff-911a-4d00-8f26-4df69b3ddfcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952292981-172.17.0.2-1597690780685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-002c9e20-560e-498e-b73a-deb8a699f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-65394e23-2264-4123-8cfb-6388dc21c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-2dddf24c-3c76-4db1-a886-11fadad60818,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-346fe492-bbff-413c-b971-afb4d96ecd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-23a16281-bffd-4c8a-8192-d8185ec75e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-f0726b07-6acd-4232-9094-100492772e49,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-a3bed39d-0efe-4449-a334-ed3ae592f531,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-0e7638ff-911a-4d00-8f26-4df69b3ddfcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703922005-172.17.0.2-1597691690435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36206,DS-6b7ea7de-9978-4dd0-ae58-e25b474890b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-8d8251e6-4b41-4376-9a4b-648e981a538c,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-03fa4ebb-c201-4ce7-8fdc-01d81f5f9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-12617931-d816-4515-a01e-8e37648d3ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-01301f8e-07a9-4cbb-a4e4-aea0ea599777,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-b9472b30-57e6-4886-98b8-bdf971c20b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-2bd33a23-04f7-401a-a5e0-60f5e7758ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-6baf7bb3-4a8f-4a3a-bfd9-cd970dba37c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703922005-172.17.0.2-1597691690435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36206,DS-6b7ea7de-9978-4dd0-ae58-e25b474890b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-8d8251e6-4b41-4376-9a4b-648e981a538c,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-03fa4ebb-c201-4ce7-8fdc-01d81f5f9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-12617931-d816-4515-a01e-8e37648d3ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-01301f8e-07a9-4cbb-a4e4-aea0ea599777,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-b9472b30-57e6-4886-98b8-bdf971c20b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-2bd33a23-04f7-401a-a5e0-60f5e7758ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-6baf7bb3-4a8f-4a3a-bfd9-cd970dba37c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202920286-172.17.0.2-1597691929593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41786,DS-2c84f907-7001-445c-8609-50c52185a652,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-426f7a16-06bf-41e0-b2be-fe7bc64b7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-69193712-5ada-4be7-afb7-ec97853dedd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-754ace6c-6e2d-4ee5-93cf-4bf6217c2556,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-8df1c146-8e8e-48d1-85c8-79cbccbd94a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-ce0e98d3-7538-4cf2-8055-ee74a9ea631a,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-ff39753c-0381-4afb-93b2-6e05611eebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-3754707d-6f7c-4685-b1ae-f9f584012dde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202920286-172.17.0.2-1597691929593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41786,DS-2c84f907-7001-445c-8609-50c52185a652,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-426f7a16-06bf-41e0-b2be-fe7bc64b7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-69193712-5ada-4be7-afb7-ec97853dedd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-754ace6c-6e2d-4ee5-93cf-4bf6217c2556,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-8df1c146-8e8e-48d1-85c8-79cbccbd94a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-ce0e98d3-7538-4cf2-8055-ee74a9ea631a,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-ff39753c-0381-4afb-93b2-6e05611eebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-3754707d-6f7c-4685-b1ae-f9f584012dde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687190295-172.17.0.2-1597691961468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42449,DS-a11f5c59-44ce-4162-86e6-668478724d01,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-b1f33064-7a11-41dd-a908-6083386496f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-58e1b17a-2f1e-4bcd-b9c9-2901eeefe915,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-ec640e6e-43fb-4641-930f-22c42e8dd0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-0f2fe8eb-34d4-4bdc-82ee-976f817c97d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-ade41d17-f08c-4241-8e76-f30c0b93a832,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-a5d422d5-561a-44ec-9b06-01777f618364,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-a2e66324-ec48-4bab-9470-805ec0a54d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687190295-172.17.0.2-1597691961468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42449,DS-a11f5c59-44ce-4162-86e6-668478724d01,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-b1f33064-7a11-41dd-a908-6083386496f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-58e1b17a-2f1e-4bcd-b9c9-2901eeefe915,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-ec640e6e-43fb-4641-930f-22c42e8dd0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-0f2fe8eb-34d4-4bdc-82ee-976f817c97d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-ade41d17-f08c-4241-8e76-f30c0b93a832,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-a5d422d5-561a-44ec-9b06-01777f618364,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-a2e66324-ec48-4bab-9470-805ec0a54d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781567145-172.17.0.2-1597691995617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39212,DS-8128f728-b1d8-4f47-a8f5-e8df40111bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-c903074a-a4cd-40f1-a3fd-67faa9860778,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-bb7ff4b2-82b3-444e-b1e2-869aeba67932,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-e14baf4c-8a87-4e19-9706-7b2f2ca536e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-7ca1c220-c7f6-4bd6-b77a-2426ba94e3be,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-ea7ec538-4a56-4384-8fc5-cd180b2379c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-53693c66-8b4c-42c4-b928-ac16cc499b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-961973f4-1190-4af4-bbf2-4885414d12df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781567145-172.17.0.2-1597691995617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39212,DS-8128f728-b1d8-4f47-a8f5-e8df40111bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-c903074a-a4cd-40f1-a3fd-67faa9860778,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-bb7ff4b2-82b3-444e-b1e2-869aeba67932,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-e14baf4c-8a87-4e19-9706-7b2f2ca536e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-7ca1c220-c7f6-4bd6-b77a-2426ba94e3be,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-ea7ec538-4a56-4384-8fc5-cd180b2379c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-53693c66-8b4c-42c4-b928-ac16cc499b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-961973f4-1190-4af4-bbf2-4885414d12df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59207294-172.17.0.2-1597692140407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37023,DS-12db01e4-1ddb-4571-a170-06ff06e4beba,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-215cfa2a-5319-43ec-bb62-890c72a54a69,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-282ec737-406b-495d-b1a3-aa97794d0eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-c8b427e7-48b5-42cf-9bbe-3edc2740f258,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-0e61c27e-3b1b-416a-ad4c-d0b2f14e376b,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-72c03a89-abda-4cc4-858b-1bf937cfe2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-3ad836ca-b6fe-4ff4-8b57-e9e24bc7af99,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-c73cccde-6c6d-4c8a-ac40-05db07bee71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59207294-172.17.0.2-1597692140407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37023,DS-12db01e4-1ddb-4571-a170-06ff06e4beba,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-215cfa2a-5319-43ec-bb62-890c72a54a69,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-282ec737-406b-495d-b1a3-aa97794d0eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-c8b427e7-48b5-42cf-9bbe-3edc2740f258,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-0e61c27e-3b1b-416a-ad4c-d0b2f14e376b,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-72c03a89-abda-4cc4-858b-1bf937cfe2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-3ad836ca-b6fe-4ff4-8b57-e9e24bc7af99,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-c73cccde-6c6d-4c8a-ac40-05db07bee71a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5239
