reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811407248-172.17.0.2-1597758641998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45292,DS-e4e4f1bd-9096-47d3-93fe-b9b8ba642834,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-a39a2bb2-2af3-48e8-bdfc-cc4e84d62f94,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-6d85be9d-8a8f-44cb-92b9-2f3d9e613dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-a854736b-3621-4762-a167-a6137891f769,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-4adfbdd0-febe-45a7-8f40-2be99cc0e166,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-c6fdf99d-344f-4c37-91bf-33f88958713f,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-96d7a557-edb4-4b44-b853-4e46a1e551b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-f24a73fa-0da2-42b0-8431-a6bfe28e48a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811407248-172.17.0.2-1597758641998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45292,DS-e4e4f1bd-9096-47d3-93fe-b9b8ba642834,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-a39a2bb2-2af3-48e8-bdfc-cc4e84d62f94,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-6d85be9d-8a8f-44cb-92b9-2f3d9e613dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-a854736b-3621-4762-a167-a6137891f769,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-4adfbdd0-febe-45a7-8f40-2be99cc0e166,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-c6fdf99d-344f-4c37-91bf-33f88958713f,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-96d7a557-edb4-4b44-b853-4e46a1e551b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-f24a73fa-0da2-42b0-8431-a6bfe28e48a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728102603-172.17.0.2-1597758764274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44774,DS-8b5d0e03-84bf-49c4-8606-841758d88721,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-969d5f1d-55f6-4ac5-bae2-8f8c5fb1e2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-455e6704-59e6-41e2-b03f-f183a72b5593,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-21a45a92-18db-4cfb-a3b3-b58080003bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-55cf48cc-f6f3-4af7-91e7-06cbcb393e09,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-a89cef16-c136-4dad-992b-211c24aaaaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-fe8a0b72-3145-455d-85e0-0c9d7a5ad04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-79d5de48-12df-4874-a1b5-8a95564bd216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728102603-172.17.0.2-1597758764274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44774,DS-8b5d0e03-84bf-49c4-8606-841758d88721,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-969d5f1d-55f6-4ac5-bae2-8f8c5fb1e2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-455e6704-59e6-41e2-b03f-f183a72b5593,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-21a45a92-18db-4cfb-a3b3-b58080003bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-55cf48cc-f6f3-4af7-91e7-06cbcb393e09,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-a89cef16-c136-4dad-992b-211c24aaaaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-fe8a0b72-3145-455d-85e0-0c9d7a5ad04a,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-79d5de48-12df-4874-a1b5-8a95564bd216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355948536-172.17.0.2-1597759629482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34907,DS-84eae2cc-7feb-4568-9c24-ec7d8cf2e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-b48b7f5d-9acd-4297-8672-5b7e2fdf3255,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-b8470324-c759-43f9-bd7c-671967f67774,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-fcea6468-3339-43a1-a660-84bf49a5380e,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-57152cc4-63db-4645-ad37-dbb21b3b8125,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-370c701d-e1ca-4fa5-8afa-7e00132b6e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-52eb0544-6eae-48d4-84bd-b6a5bc593d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-bb0fec1b-b44c-4ffa-bcb4-258cbe0eaf14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355948536-172.17.0.2-1597759629482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34907,DS-84eae2cc-7feb-4568-9c24-ec7d8cf2e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-b48b7f5d-9acd-4297-8672-5b7e2fdf3255,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-b8470324-c759-43f9-bd7c-671967f67774,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-fcea6468-3339-43a1-a660-84bf49a5380e,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-57152cc4-63db-4645-ad37-dbb21b3b8125,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-370c701d-e1ca-4fa5-8afa-7e00132b6e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-52eb0544-6eae-48d4-84bd-b6a5bc593d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-bb0fec1b-b44c-4ffa-bcb4-258cbe0eaf14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449239568-172.17.0.2-1597760072776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36097,DS-78c38755-532f-4906-a2f5-8a6489879ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-ad4d6fb1-c4a7-4830-9a76-7bbfe21dc027,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-6e78ac21-3847-4ac2-af1f-ae12cdde36ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-2e80e681-f8e2-4e9d-aacc-aa75c283ee18,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-19320c9c-255b-49d1-8451-d980e0618f81,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-d1875603-8af1-4079-a9c7-09b213c02bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-b64bf4d9-8fa6-4d97-9eec-2195c79b7afa,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-365192e6-6113-4835-8840-c7fa8295e20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449239568-172.17.0.2-1597760072776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36097,DS-78c38755-532f-4906-a2f5-8a6489879ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-ad4d6fb1-c4a7-4830-9a76-7bbfe21dc027,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-6e78ac21-3847-4ac2-af1f-ae12cdde36ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-2e80e681-f8e2-4e9d-aacc-aa75c283ee18,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-19320c9c-255b-49d1-8451-d980e0618f81,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-d1875603-8af1-4079-a9c7-09b213c02bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-b64bf4d9-8fa6-4d97-9eec-2195c79b7afa,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-365192e6-6113-4835-8840-c7fa8295e20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883556083-172.17.0.2-1597760260241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-0d79bd9d-ed75-4eb5-bc10-6143f925594a,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-88226b66-b4aa-45fa-bf37-a4eacf336b95,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-1383b034-b0a6-4055-afbd-b793aacdfed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-14acbeea-f4b3-4b29-bacf-209c162e544d,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-2dfcdc84-3973-463d-81d2-a84c3d888040,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-4aa6bd19-3ef1-4c97-8500-37af59597039,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-7f771bb9-7e6b-43a0-a6f9-7bdef6428f87,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-02584f8f-57ea-40de-98e8-80267f5b656d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883556083-172.17.0.2-1597760260241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-0d79bd9d-ed75-4eb5-bc10-6143f925594a,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-88226b66-b4aa-45fa-bf37-a4eacf336b95,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-1383b034-b0a6-4055-afbd-b793aacdfed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-14acbeea-f4b3-4b29-bacf-209c162e544d,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-2dfcdc84-3973-463d-81d2-a84c3d888040,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-4aa6bd19-3ef1-4c97-8500-37af59597039,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-7f771bb9-7e6b-43a0-a6f9-7bdef6428f87,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-02584f8f-57ea-40de-98e8-80267f5b656d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092492769-172.17.0.2-1597760480204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46690,DS-5335a1f8-93d2-40c3-9b45-1be132e31aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-3ebd77ca-0328-40b3-ba6e-62b8a6a85de4,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-7f272498-4e18-40d6-9a96-6facdd7a4fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-cb502d6e-01af-48a2-89af-b4cbf28566ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-991fb90c-8916-44e9-8965-474acc1a1b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-72d563bc-1dc0-4841-ac15-d88014617e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-75c310d4-9e1b-4ab9-afd3-e36b87814f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-fe50b10c-8bf9-4af6-93f1-5635829a6982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092492769-172.17.0.2-1597760480204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46690,DS-5335a1f8-93d2-40c3-9b45-1be132e31aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-3ebd77ca-0328-40b3-ba6e-62b8a6a85de4,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-7f272498-4e18-40d6-9a96-6facdd7a4fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-cb502d6e-01af-48a2-89af-b4cbf28566ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-991fb90c-8916-44e9-8965-474acc1a1b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-72d563bc-1dc0-4841-ac15-d88014617e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-75c310d4-9e1b-4ab9-afd3-e36b87814f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-fe50b10c-8bf9-4af6-93f1-5635829a6982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548987105-172.17.0.2-1597760518640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33816,DS-79699a62-5d85-4102-baed-0e7e0f54ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-19aadf36-30cd-4d73-98a9-7b1556a0199a,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-ef6df20c-bc6a-4eeb-a3e9-6d0005012063,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-99445e7a-de89-4d0c-89b4-6b0b13c9ad13,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-7c027994-a684-4001-9180-7064dc9991d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-4378b36f-245f-4530-95c7-36bcb9c6777f,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-44759800-5c33-4bd7-baf3-4ae52b251fec,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-9fd4ea92-417d-4d1a-832b-e12c9264cb27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548987105-172.17.0.2-1597760518640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33816,DS-79699a62-5d85-4102-baed-0e7e0f54ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-19aadf36-30cd-4d73-98a9-7b1556a0199a,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-ef6df20c-bc6a-4eeb-a3e9-6d0005012063,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-99445e7a-de89-4d0c-89b4-6b0b13c9ad13,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-7c027994-a684-4001-9180-7064dc9991d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-4378b36f-245f-4530-95c7-36bcb9c6777f,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-44759800-5c33-4bd7-baf3-4ae52b251fec,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-9fd4ea92-417d-4d1a-832b-e12c9264cb27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117820617-172.17.0.2-1597760951573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36261,DS-0701a44c-fda1-4873-bc61-54ff45fbbbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-d2f46e08-db74-42c7-9a40-2270769dc29f,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-76b216b7-9578-4345-879b-3d3638fc56d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-a69e4b8a-84c4-4c5a-9bf8-6cacc52c3f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-96edd369-384a-43b7-b080-7f63b7877a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-ea87199c-05ce-4eb7-9dce-f80b0e43263f,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-d31a09b6-0cb0-4dfa-a202-8c3dda106943,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-8a995681-de59-465f-b125-26ac9a93fd96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117820617-172.17.0.2-1597760951573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36261,DS-0701a44c-fda1-4873-bc61-54ff45fbbbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-d2f46e08-db74-42c7-9a40-2270769dc29f,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-76b216b7-9578-4345-879b-3d3638fc56d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-a69e4b8a-84c4-4c5a-9bf8-6cacc52c3f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-96edd369-384a-43b7-b080-7f63b7877a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-ea87199c-05ce-4eb7-9dce-f80b0e43263f,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-d31a09b6-0cb0-4dfa-a202-8c3dda106943,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-8a995681-de59-465f-b125-26ac9a93fd96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913700398-172.17.0.2-1597761496659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43891,DS-0f8923c4-14fa-4567-8e45-85d7aed87699,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-57145e35-8b6a-4c81-acaa-ccab7d8bfefb,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-408b5648-ee07-49b7-b1a7-af775f83c233,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-12cbe1e7-7904-419f-bba5-6c859dfeb277,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-afc869f1-05d9-4c8c-8ffd-0fb3bee34e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-06b4b634-8706-451f-9a95-16ba16cebc32,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-a3aa42be-5835-425f-9c08-c5203790d753,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-9500d911-42cc-4196-9fc4-35c6dd9fa68e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913700398-172.17.0.2-1597761496659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43891,DS-0f8923c4-14fa-4567-8e45-85d7aed87699,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-57145e35-8b6a-4c81-acaa-ccab7d8bfefb,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-408b5648-ee07-49b7-b1a7-af775f83c233,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-12cbe1e7-7904-419f-bba5-6c859dfeb277,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-afc869f1-05d9-4c8c-8ffd-0fb3bee34e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-06b4b634-8706-451f-9a95-16ba16cebc32,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-a3aa42be-5835-425f-9c08-c5203790d753,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-9500d911-42cc-4196-9fc4-35c6dd9fa68e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014102042-172.17.0.2-1597762519520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40774,DS-8caa9539-a2ec-455c-8f0f-48aebaf6af05,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-956be810-508a-48f2-a973-2d1bb334921b,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-7fa8a2b0-e502-4218-845a-251ded6cd13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-6157b6ad-0a9f-4809-bc6a-c4cd2930817a,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-58d907f3-42e0-4d46-bc78-73903fad127c,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-79b997b0-8820-4553-b023-a5207b102abe,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-8aa99cab-81b6-4ab9-b5ef-c50df86458f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-25b0aa5d-a573-478f-b13a-28c7d709c85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014102042-172.17.0.2-1597762519520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40774,DS-8caa9539-a2ec-455c-8f0f-48aebaf6af05,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-956be810-508a-48f2-a973-2d1bb334921b,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-7fa8a2b0-e502-4218-845a-251ded6cd13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-6157b6ad-0a9f-4809-bc6a-c4cd2930817a,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-58d907f3-42e0-4d46-bc78-73903fad127c,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-79b997b0-8820-4553-b023-a5207b102abe,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-8aa99cab-81b6-4ab9-b5ef-c50df86458f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-25b0aa5d-a573-478f-b13a-28c7d709c85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529189249-172.17.0.2-1597762939287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-2d42fea9-2112-4a7c-a5de-a5f767a92420,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-21e60b61-ea28-4637-b896-c72983650ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-9f015928-a60b-4609-9924-c1a4d43ddd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-865ce7de-16e6-4852-a96a-ba373acffa89,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-a8efdbf7-1ec4-4a18-83b7-10034070db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-728374d6-dcef-4842-85ce-5cfbce0a633b,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-6bf05f98-4401-46b6-8740-77ddce361b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-f423760c-d753-40a3-b441-0eb90505d7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529189249-172.17.0.2-1597762939287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-2d42fea9-2112-4a7c-a5de-a5f767a92420,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-21e60b61-ea28-4637-b896-c72983650ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-9f015928-a60b-4609-9924-c1a4d43ddd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-865ce7de-16e6-4852-a96a-ba373acffa89,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-a8efdbf7-1ec4-4a18-83b7-10034070db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-728374d6-dcef-4842-85ce-5cfbce0a633b,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-6bf05f98-4401-46b6-8740-77ddce361b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-f423760c-d753-40a3-b441-0eb90505d7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417457819-172.17.0.2-1597763244912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-667bfb6b-49de-4741-8dee-2e5c8bbc1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-c487550f-9383-4d0c-93a4-cd7e375e8374,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-c93d7b32-ffb4-4672-9922-5baafad9dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-16176e99-5cb4-4677-83a3-4c9133a15108,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-dddfba61-0918-429b-88bd-02c9a2b6ae06,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-2847d0c7-7045-4287-8ff0-9cc379e7c9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-503587da-1c96-48fa-b3f0-981682ccb15f,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-f52e26eb-64c5-4275-baf5-65c44dcad42d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417457819-172.17.0.2-1597763244912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-667bfb6b-49de-4741-8dee-2e5c8bbc1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-c487550f-9383-4d0c-93a4-cd7e375e8374,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-c93d7b32-ffb4-4672-9922-5baafad9dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-16176e99-5cb4-4677-83a3-4c9133a15108,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-dddfba61-0918-429b-88bd-02c9a2b6ae06,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-2847d0c7-7045-4287-8ff0-9cc379e7c9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-503587da-1c96-48fa-b3f0-981682ccb15f,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-f52e26eb-64c5-4275-baf5-65c44dcad42d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44316834-172.17.0.2-1597763287429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-b1af42d0-f442-44e9-9d67-55ac8bfd368e,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-26dd1018-a1ff-4c2b-a47e-b597da791908,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-8dafffda-88b5-44b6-9345-908968fce7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-7f257d1b-10ff-4e4b-b74f-4dabcdb9d38b,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-c6003a2d-8ce8-4630-814b-5ecb0f4a825c,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-1ef49302-5d27-44fe-b415-468368488a69,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-eb485e79-8aa6-4988-8ba1-f1b5d787e4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-c0ca78f7-79a9-4e61-bcf0-5decba6ea881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44316834-172.17.0.2-1597763287429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-b1af42d0-f442-44e9-9d67-55ac8bfd368e,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-26dd1018-a1ff-4c2b-a47e-b597da791908,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-8dafffda-88b5-44b6-9345-908968fce7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-7f257d1b-10ff-4e4b-b74f-4dabcdb9d38b,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-c6003a2d-8ce8-4630-814b-5ecb0f4a825c,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-1ef49302-5d27-44fe-b415-468368488a69,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-eb485e79-8aa6-4988-8ba1-f1b5d787e4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-c0ca78f7-79a9-4e61-bcf0-5decba6ea881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545873692-172.17.0.2-1597763633255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34143,DS-4d34bf48-5632-43f2-99b2-d96426320e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-70e151ce-c812-4632-b7c3-f1c2362b27dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-309f3502-f179-488c-8dbc-20c40919da9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-ded4f47b-a46b-495d-9e85-abcd06766982,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-e5426d4d-5b94-417b-8389-9a5e25ab97ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-29f3bf5b-1242-467f-8a72-2b6a4de2a6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-bf63203b-1acc-4371-9214-40d4475f7c28,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-36867ea6-83f3-4514-9262-4851e91ac7d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545873692-172.17.0.2-1597763633255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34143,DS-4d34bf48-5632-43f2-99b2-d96426320e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-70e151ce-c812-4632-b7c3-f1c2362b27dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-309f3502-f179-488c-8dbc-20c40919da9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-ded4f47b-a46b-495d-9e85-abcd06766982,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-e5426d4d-5b94-417b-8389-9a5e25ab97ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-29f3bf5b-1242-467f-8a72-2b6a4de2a6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-bf63203b-1acc-4371-9214-40d4475f7c28,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-36867ea6-83f3-4514-9262-4851e91ac7d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6541
