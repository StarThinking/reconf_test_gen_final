reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565986176-172.17.0.18-1597369019982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38474,DS-097dc990-4438-4bd1-8158-d02e0d3261dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-2c9c8e6a-7ac7-4012-a19b-8661f67eea40,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-69b84050-4646-443f-9ef2-6b887f29ebec,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-42546352-dab7-4ef7-8286-1a52c3da7787,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-e1ec2fd1-67b1-4f5d-a694-5f1cea29adf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-f8a02438-b23c-4270-b17b-634673bc2ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-72346e15-8dd9-4512-ac8c-5e234af36c56,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-36c9e409-00bd-4fd0-ab7e-225a05b1b754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565986176-172.17.0.18-1597369019982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38474,DS-097dc990-4438-4bd1-8158-d02e0d3261dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-2c9c8e6a-7ac7-4012-a19b-8661f67eea40,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-69b84050-4646-443f-9ef2-6b887f29ebec,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-42546352-dab7-4ef7-8286-1a52c3da7787,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-e1ec2fd1-67b1-4f5d-a694-5f1cea29adf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-f8a02438-b23c-4270-b17b-634673bc2ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-72346e15-8dd9-4512-ac8c-5e234af36c56,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-36c9e409-00bd-4fd0-ab7e-225a05b1b754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157448989-172.17.0.18-1597369095745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-4e4a6cea-db46-467d-a44d-b08183ae05d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-8c5b5ddd-9c75-458e-8c99-807e29f85487,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-64573336-62f0-4c6f-9e58-677cbc5ed973,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-e5ebe588-cb8f-4498-8d18-54096e1e607a,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-ac5d28a1-9878-45e5-a1e8-be3259f51b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-bfb8ba2c-4725-4356-94eb-80678c27bdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-43fb346a-7410-4cdb-83f5-081897e680d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-db4a28fa-4ccd-4262-8690-1a575ca8aede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157448989-172.17.0.18-1597369095745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-4e4a6cea-db46-467d-a44d-b08183ae05d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-8c5b5ddd-9c75-458e-8c99-807e29f85487,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-64573336-62f0-4c6f-9e58-677cbc5ed973,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-e5ebe588-cb8f-4498-8d18-54096e1e607a,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-ac5d28a1-9878-45e5-a1e8-be3259f51b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-bfb8ba2c-4725-4356-94eb-80678c27bdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-43fb346a-7410-4cdb-83f5-081897e680d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-db4a28fa-4ccd-4262-8690-1a575ca8aede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794516810-172.17.0.18-1597369467214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-2e011d8a-f3c9-40ac-b388-65aae3d5bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-9f4b1a62-6e1d-4f8a-9994-640f91447e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-0c31f066-0340-48b5-a215-99ce63fdcb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-469fbda8-a380-44f1-8039-0832c8e7a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-f5794bcc-430b-4395-9512-9178d5674ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-e4350722-36ed-4fb1-94d4-221c33e120af,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-fd640669-175c-475b-8025-7e2885bf1069,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-05ffd84a-cd76-4eed-a63e-b9d49b152c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794516810-172.17.0.18-1597369467214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-2e011d8a-f3c9-40ac-b388-65aae3d5bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-9f4b1a62-6e1d-4f8a-9994-640f91447e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-0c31f066-0340-48b5-a215-99ce63fdcb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-469fbda8-a380-44f1-8039-0832c8e7a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-f5794bcc-430b-4395-9512-9178d5674ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-e4350722-36ed-4fb1-94d4-221c33e120af,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-fd640669-175c-475b-8025-7e2885bf1069,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-05ffd84a-cd76-4eed-a63e-b9d49b152c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502471370-172.17.0.18-1597369542893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34987,DS-5be86e4b-9051-488b-bb44-e9dee0f621fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-d0ccd0e5-e934-46ab-8692-39f1d3fa2f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-41cea8c4-8b58-4f46-8f33-72c6cfd9096b,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-d4170771-0c35-4553-8479-4e05f10750d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-120eef7b-a182-4f3a-b661-6cd081d42fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-1e9ddcbd-01bc-4b4f-9b34-7001442dc8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-91b2efa2-43b4-4ea7-b7f7-d19278238545,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-492404c4-647c-4132-9ce9-0a85cdee0bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502471370-172.17.0.18-1597369542893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34987,DS-5be86e4b-9051-488b-bb44-e9dee0f621fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-d0ccd0e5-e934-46ab-8692-39f1d3fa2f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-41cea8c4-8b58-4f46-8f33-72c6cfd9096b,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-d4170771-0c35-4553-8479-4e05f10750d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-120eef7b-a182-4f3a-b661-6cd081d42fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-1e9ddcbd-01bc-4b4f-9b34-7001442dc8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-91b2efa2-43b4-4ea7-b7f7-d19278238545,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-492404c4-647c-4132-9ce9-0a85cdee0bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926445033-172.17.0.18-1597369584740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-7f9eb646-a641-482e-8cea-e3bc72928c74,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-6f792dc8-5ff0-4e25-bc29-9977644f1cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-92b8fba7-0a2e-4a3e-9a10-66bce2d40eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-25a67402-20f6-42fd-8a91-36240e4115a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-9bdc03f8-318b-4f30-8b41-f0dc17c305db,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-9ac84ca2-bd45-406a-aa2b-5e3fdc385896,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-7eec5c6d-4ff8-437e-b22f-e1ed927ea7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-2d26a5f8-1507-447f-927a-f679053e2d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1926445033-172.17.0.18-1597369584740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-7f9eb646-a641-482e-8cea-e3bc72928c74,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-6f792dc8-5ff0-4e25-bc29-9977644f1cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-92b8fba7-0a2e-4a3e-9a10-66bce2d40eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-25a67402-20f6-42fd-8a91-36240e4115a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-9bdc03f8-318b-4f30-8b41-f0dc17c305db,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-9ac84ca2-bd45-406a-aa2b-5e3fdc385896,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-7eec5c6d-4ff8-437e-b22f-e1ed927ea7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-2d26a5f8-1507-447f-927a-f679053e2d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852346946-172.17.0.18-1597369694697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45515,DS-137e4912-32d5-4cdf-b6ba-7f683943a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-690cd9c0-19bb-4c99-9026-35b6e7b60763,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-b7647347-c3f6-4756-9334-603e1b2abffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-04d1edc2-17eb-4535-8b24-bd865a37fce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-0e7dead8-993f-431c-bab4-d5ed02febac9,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-774c6d3b-91f4-424f-b38d-2b2be29a1edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-c8acd045-e4e5-4db2-988b-c4be7ad527b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-05c1ccd6-a956-4142-939c-7e14c18b6db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852346946-172.17.0.18-1597369694697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45515,DS-137e4912-32d5-4cdf-b6ba-7f683943a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-690cd9c0-19bb-4c99-9026-35b6e7b60763,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-b7647347-c3f6-4756-9334-603e1b2abffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-04d1edc2-17eb-4535-8b24-bd865a37fce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-0e7dead8-993f-431c-bab4-d5ed02febac9,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-774c6d3b-91f4-424f-b38d-2b2be29a1edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-c8acd045-e4e5-4db2-988b-c4be7ad527b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-05c1ccd6-a956-4142-939c-7e14c18b6db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842170509-172.17.0.18-1597369777459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-42b40888-72db-4fde-afe5-e9c52eb25fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-b17fdbbc-092f-4294-a657-2c1c48baa4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-2664c25f-3562-4b87-8a81-9997918a0f47,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-4e28febc-42d2-4525-ae2d-1b7f4f395aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-bc1d0634-3ebe-4b2c-8cf1-d3171134a586,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-66d80c26-d665-44ea-8c9d-b493efdacddc,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-3fca7dac-a4da-4237-a42c-8cdf220f2ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-0accebc4-5cbc-4dc6-a9c4-07be8951ddcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842170509-172.17.0.18-1597369777459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-42b40888-72db-4fde-afe5-e9c52eb25fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-b17fdbbc-092f-4294-a657-2c1c48baa4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-2664c25f-3562-4b87-8a81-9997918a0f47,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-4e28febc-42d2-4525-ae2d-1b7f4f395aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-bc1d0634-3ebe-4b2c-8cf1-d3171134a586,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-66d80c26-d665-44ea-8c9d-b493efdacddc,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-3fca7dac-a4da-4237-a42c-8cdf220f2ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-0accebc4-5cbc-4dc6-a9c4-07be8951ddcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28290727-172.17.0.18-1597369893087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42651,DS-a3b941ff-dc64-457e-b893-4d2ba19832ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-f73a0e3e-241e-412d-b994-fc8a47ebae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-7860ba63-e26d-437c-9499-eba35ae63592,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-2efc7c7b-2e7e-4f0f-b439-53e25c0e0115,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-13ae9fc1-730b-4da2-8d09-6191fde3c1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-b21dfce9-4fa0-4860-8a19-613350407a87,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-159b0b3b-661e-4440-88a8-92aadea26336,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-b9bc3039-a998-4416-97c0-44e0b842c32b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28290727-172.17.0.18-1597369893087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42651,DS-a3b941ff-dc64-457e-b893-4d2ba19832ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-f73a0e3e-241e-412d-b994-fc8a47ebae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-7860ba63-e26d-437c-9499-eba35ae63592,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-2efc7c7b-2e7e-4f0f-b439-53e25c0e0115,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-13ae9fc1-730b-4da2-8d09-6191fde3c1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-b21dfce9-4fa0-4860-8a19-613350407a87,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-159b0b3b-661e-4440-88a8-92aadea26336,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-b9bc3039-a998-4416-97c0-44e0b842c32b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531078057-172.17.0.18-1597370851419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46564,DS-b67e4edd-7664-454f-9768-def5cb083a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-256c0af6-32a3-4e3c-bc22-89aee92b8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-60b7ae47-0efa-4449-966a-a8c05da76f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-06f07e57-8e24-43dc-a063-f20fa9fbba75,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-549b0dbe-90f0-4852-a6b1-535dea9c2493,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-f07540e9-8778-45f0-b634-66381c3cad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-9a094239-c5c6-4326-9527-44b2569e9bce,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-7a6db125-5568-41bd-b952-219db007b79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531078057-172.17.0.18-1597370851419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46564,DS-b67e4edd-7664-454f-9768-def5cb083a32,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-256c0af6-32a3-4e3c-bc22-89aee92b8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-60b7ae47-0efa-4449-966a-a8c05da76f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-06f07e57-8e24-43dc-a063-f20fa9fbba75,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-549b0dbe-90f0-4852-a6b1-535dea9c2493,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-f07540e9-8778-45f0-b634-66381c3cad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-9a094239-c5c6-4326-9527-44b2569e9bce,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-7a6db125-5568-41bd-b952-219db007b79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538588850-172.17.0.18-1597371341306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-dfb27ecc-86a1-4382-84ce-18989101009d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-3338de88-669c-4e90-8dd8-5849819538fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-2fe469ac-55c8-4dc7-8e66-1b1e049d44ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-0bf83568-be95-4949-88cd-52ff4f952457,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-87a3133b-7e0f-4a3c-800a-1f9c39612fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-6fb1835a-a22e-4c04-81ed-9a88c5da3c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-5474ebf0-66e0-4309-8e98-42348606d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-543a84ea-75a9-47a9-9a66-9fc19dd04b12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538588850-172.17.0.18-1597371341306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-dfb27ecc-86a1-4382-84ce-18989101009d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-3338de88-669c-4e90-8dd8-5849819538fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-2fe469ac-55c8-4dc7-8e66-1b1e049d44ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-0bf83568-be95-4949-88cd-52ff4f952457,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-87a3133b-7e0f-4a3c-800a-1f9c39612fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-6fb1835a-a22e-4c04-81ed-9a88c5da3c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-5474ebf0-66e0-4309-8e98-42348606d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-543a84ea-75a9-47a9-9a66-9fc19dd04b12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682371690-172.17.0.18-1597371379125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40549,DS-e8a68191-5e2c-4c33-bbd8-3e15d3540ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-c7b7db9b-fc3e-4626-926e-0aeefcb8c398,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-d83be61d-683c-4219-a8cb-befa7f35042c,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-00724cdc-9a0e-4d45-8beb-b00ae06270c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-a1a983d7-96a9-4d82-b80d-bc8cd3e9d1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-b60b416d-ae0d-400b-a25e-4a0ac3b327b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-08329c05-2cd8-483c-851e-ddae4b00bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-4411f490-38fd-425f-890a-479e8bb53845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682371690-172.17.0.18-1597371379125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40549,DS-e8a68191-5e2c-4c33-bbd8-3e15d3540ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-c7b7db9b-fc3e-4626-926e-0aeefcb8c398,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-d83be61d-683c-4219-a8cb-befa7f35042c,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-00724cdc-9a0e-4d45-8beb-b00ae06270c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-a1a983d7-96a9-4d82-b80d-bc8cd3e9d1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-b60b416d-ae0d-400b-a25e-4a0ac3b327b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-08329c05-2cd8-483c-851e-ddae4b00bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-4411f490-38fd-425f-890a-479e8bb53845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009625999-172.17.0.18-1597371642628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40041,DS-3152ab09-e6b6-4d4f-8c43-98d61523f52c,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-8b5ed178-ee5b-4e32-8ff9-c5721ccb635b,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-24abef3e-c297-4db3-a29d-1f5379378a26,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-fd554c1e-6b1c-4b51-8555-f7a549ecdec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-7f39ba02-450f-428a-88dc-8895b8e9bbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-504990df-a53a-4b1d-8053-9dc37e334847,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-3d00ee0a-1588-4a44-b567-1a8240d5f2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-8fdc9c28-1aa0-4484-be49-dc757484ec4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009625999-172.17.0.18-1597371642628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40041,DS-3152ab09-e6b6-4d4f-8c43-98d61523f52c,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-8b5ed178-ee5b-4e32-8ff9-c5721ccb635b,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-24abef3e-c297-4db3-a29d-1f5379378a26,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-fd554c1e-6b1c-4b51-8555-f7a549ecdec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-7f39ba02-450f-428a-88dc-8895b8e9bbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-504990df-a53a-4b1d-8053-9dc37e334847,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-3d00ee0a-1588-4a44-b567-1a8240d5f2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-8fdc9c28-1aa0-4484-be49-dc757484ec4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657932192-172.17.0.18-1597372261884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38063,DS-04d9f7fc-70ea-4768-8c67-0a99e3571b44,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-f3767d3a-4809-49ff-9e99-91e8c938063a,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-c383814b-6967-434a-bae4-559f8de74d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-83ff1fcc-2d60-4b0b-bdbd-4b9ed7770c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-68757891-6eda-45e7-8a78-315391940dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-ebe6593a-32a7-4c3f-b52f-b4cc11eee7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-c6d375f7-184a-4ec9-8db9-7f2b5e9ecd70,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-6db1deca-981f-4d24-86b1-c14fe756532e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657932192-172.17.0.18-1597372261884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38063,DS-04d9f7fc-70ea-4768-8c67-0a99e3571b44,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-f3767d3a-4809-49ff-9e99-91e8c938063a,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-c383814b-6967-434a-bae4-559f8de74d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-83ff1fcc-2d60-4b0b-bdbd-4b9ed7770c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-68757891-6eda-45e7-8a78-315391940dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-ebe6593a-32a7-4c3f-b52f-b4cc11eee7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-c6d375f7-184a-4ec9-8db9-7f2b5e9ecd70,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-6db1deca-981f-4d24-86b1-c14fe756532e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530972213-172.17.0.18-1597373238614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37104,DS-0fed88c7-a312-4dff-9c76-f0a7232cf303,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-c9c8b90a-47eb-4e97-b935-f3e20bcbb64e,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-5a0b5222-5fd5-4efd-ab5a-25b21d8ea468,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-52ed5f02-23f3-4761-96ff-89cfc8a89cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-4f9c1065-3fa4-41c9-b3b2-4651df94d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-b6ffcc42-2283-4a8b-abe0-76364f47d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-5f203945-c9d8-4d40-8603-475040f24826,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-6c5d8afd-637f-4499-9559-88abf0f89e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530972213-172.17.0.18-1597373238614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37104,DS-0fed88c7-a312-4dff-9c76-f0a7232cf303,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-c9c8b90a-47eb-4e97-b935-f3e20bcbb64e,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-5a0b5222-5fd5-4efd-ab5a-25b21d8ea468,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-52ed5f02-23f3-4761-96ff-89cfc8a89cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-4f9c1065-3fa4-41c9-b3b2-4651df94d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-b6ffcc42-2283-4a8b-abe0-76364f47d6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-5f203945-c9d8-4d40-8603-475040f24826,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-6c5d8afd-637f-4499-9559-88abf0f89e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667901647-172.17.0.18-1597373316912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-09c1e212-d82c-488f-81c0-3a0221fa2563,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-691216a3-ed31-4baf-b901-69f19bd91ece,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-4d17a23c-01a0-4629-bd9f-d16bc3780478,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-7289b495-4e9c-479e-b47c-48cb2a1e569b,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-8e475c25-9244-49e2-9f48-7c756d9eeeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-919947fc-37d1-4ed5-85de-c7c5309edba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-0fdc6073-f5f9-4653-a971-b8ecd3655763,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-8ecbb652-e45d-430f-b88e-e4d45c889147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667901647-172.17.0.18-1597373316912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-09c1e212-d82c-488f-81c0-3a0221fa2563,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-691216a3-ed31-4baf-b901-69f19bd91ece,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-4d17a23c-01a0-4629-bd9f-d16bc3780478,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-7289b495-4e9c-479e-b47c-48cb2a1e569b,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-8e475c25-9244-49e2-9f48-7c756d9eeeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-919947fc-37d1-4ed5-85de-c7c5309edba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-0fdc6073-f5f9-4653-a971-b8ecd3655763,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-8ecbb652-e45d-430f-b88e-e4d45c889147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564535014-172.17.0.18-1597373479684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-1c09e28e-f963-4b45-9ac6-51a1c68741d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-98c472ee-707f-4b3e-8d7b-51f3328c0211,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-7c765a70-52a0-4733-abcd-8653aa28ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-6c184437-f100-4b0e-914a-efc35f3a8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-abf2d739-07a3-4668-8809-a9bef79b2218,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-4da69f02-211c-42e8-9f02-41e6dfce7a40,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-958a55f1-ca64-4b6c-83a4-ba488ca3991f,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-1436ee2b-846a-47ee-90a2-08c590bc294a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564535014-172.17.0.18-1597373479684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-1c09e28e-f963-4b45-9ac6-51a1c68741d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-98c472ee-707f-4b3e-8d7b-51f3328c0211,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-7c765a70-52a0-4733-abcd-8653aa28ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-6c184437-f100-4b0e-914a-efc35f3a8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-abf2d739-07a3-4668-8809-a9bef79b2218,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-4da69f02-211c-42e8-9f02-41e6dfce7a40,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-958a55f1-ca64-4b6c-83a4-ba488ca3991f,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-1436ee2b-846a-47ee-90a2-08c590bc294a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829580296-172.17.0.18-1597373624567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-3cec4683-a400-4e3a-987d-27be35c15838,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-eb2167d8-e269-4241-be91-12a855a69a11,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-52edd0ea-00c2-484a-a448-8a60469cd3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-7a1c4d75-c442-4fd9-80b7-432b7b10ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-eafc1a40-5a56-4f0f-b010-0ea67a227b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-c70f010a-6328-4a93-a6fa-9b84e52e43b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-4abcc670-eccf-4ea4-bfe9-6588d7697c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-fc957cc7-d0f7-4fde-a828-e67df1732d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829580296-172.17.0.18-1597373624567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-3cec4683-a400-4e3a-987d-27be35c15838,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-eb2167d8-e269-4241-be91-12a855a69a11,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-52edd0ea-00c2-484a-a448-8a60469cd3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-7a1c4d75-c442-4fd9-80b7-432b7b10ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-eafc1a40-5a56-4f0f-b010-0ea67a227b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-c70f010a-6328-4a93-a6fa-9b84e52e43b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-4abcc670-eccf-4ea4-bfe9-6588d7697c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-fc957cc7-d0f7-4fde-a828-e67df1732d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 64
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436746803-172.17.0.18-1597374253339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-1f1dcff1-81b0-4047-ad09-ee9a081e4bca,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-d736dc45-9954-4408-a8ea-9820c966e341,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-71a6ea23-69a2-49c2-bcb9-fd014c14efe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-45a1511b-007e-431a-8afd-124615ba67fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-d565e6ce-e3a5-4811-ac20-1516cb1cb330,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-d9f9fce9-aaff-4816-b462-df5fe86b10fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-dafd5806-4d9c-46fb-abe9-7983ba613bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-43e6e2f6-b41c-4667-ada8-8344bc16920e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436746803-172.17.0.18-1597374253339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37162,DS-1f1dcff1-81b0-4047-ad09-ee9a081e4bca,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-d736dc45-9954-4408-a8ea-9820c966e341,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-71a6ea23-69a2-49c2-bcb9-fd014c14efe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-45a1511b-007e-431a-8afd-124615ba67fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-d565e6ce-e3a5-4811-ac20-1516cb1cb330,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-d9f9fce9-aaff-4816-b462-df5fe86b10fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-dafd5806-4d9c-46fb-abe9-7983ba613bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-43e6e2f6-b41c-4667-ada8-8344bc16920e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5607
