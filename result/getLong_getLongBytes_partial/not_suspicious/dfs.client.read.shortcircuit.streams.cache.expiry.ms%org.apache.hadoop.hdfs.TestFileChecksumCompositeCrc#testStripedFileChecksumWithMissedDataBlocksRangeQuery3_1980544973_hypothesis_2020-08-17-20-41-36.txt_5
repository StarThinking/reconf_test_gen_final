reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018623051-172.17.0.17-1597697426934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45933,DS-f4df51cc-570d-4ab8-8125-6fb30ead25d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-c2a4243c-f0e2-4296-99ca-ba24e2446b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-f98a86d2-25db-41a8-9934-2d9f6258fb80,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-fa588b28-2ffb-4466-9821-78554efe8d90,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-4ffade78-bed8-4a43-9c7a-91f17105f891,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-58126b22-5848-446c-a0ea-5b6fb66abea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-ece97f1b-65a9-4eac-ac9c-551a62dab17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-7d62a556-17b5-4784-aa74-23bb6f21b17d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018623051-172.17.0.17-1597697426934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45933,DS-f4df51cc-570d-4ab8-8125-6fb30ead25d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-c2a4243c-f0e2-4296-99ca-ba24e2446b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-f98a86d2-25db-41a8-9934-2d9f6258fb80,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-fa588b28-2ffb-4466-9821-78554efe8d90,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-4ffade78-bed8-4a43-9c7a-91f17105f891,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-58126b22-5848-446c-a0ea-5b6fb66abea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-ece97f1b-65a9-4eac-ac9c-551a62dab17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-7d62a556-17b5-4784-aa74-23bb6f21b17d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172003639-172.17.0.17-1597697675258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38591,DS-a68d7b73-9ae9-45c6-8795-6bb5aec1c790,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-490edf4e-11c7-4484-b804-0aa108812b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-45c637ad-5bfb-447b-a3b9-8703b7c928f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-c86c0fc1-dcdd-4cab-8d90-0735483479c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-505d4449-0af1-4059-ae61-7c9d489bd324,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-5e5d9dfb-8ecd-45a5-a9cd-98084b652524,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-dbd1e900-578c-4e7c-bb00-2f511a6f8573,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-ab57ea6b-9fef-42d1-a0f6-c22eeb70d19c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172003639-172.17.0.17-1597697675258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38591,DS-a68d7b73-9ae9-45c6-8795-6bb5aec1c790,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-490edf4e-11c7-4484-b804-0aa108812b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-45c637ad-5bfb-447b-a3b9-8703b7c928f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-c86c0fc1-dcdd-4cab-8d90-0735483479c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-505d4449-0af1-4059-ae61-7c9d489bd324,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-5e5d9dfb-8ecd-45a5-a9cd-98084b652524,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-dbd1e900-578c-4e7c-bb00-2f511a6f8573,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-ab57ea6b-9fef-42d1-a0f6-c22eeb70d19c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183980488-172.17.0.17-1597697904255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-91fbdae9-01c5-405c-a1c3-2a7b813ecafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-37d9f9ff-0853-42e3-b8e2-412de52ec647,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-8e98a5e2-bde4-482e-9ec9-72abf0ec0846,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-39ce7953-9881-4c18-9451-7011ba41e85a,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-8b44d71a-4865-4738-9621-044db6743114,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-b1db1341-e708-4a53-bc86-65cf0fb77118,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-783987b0-6f61-4a69-b366-231431832796,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-90f1612f-18cb-48dd-bfd8-9a696af8fa80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183980488-172.17.0.17-1597697904255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-91fbdae9-01c5-405c-a1c3-2a7b813ecafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-37d9f9ff-0853-42e3-b8e2-412de52ec647,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-8e98a5e2-bde4-482e-9ec9-72abf0ec0846,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-39ce7953-9881-4c18-9451-7011ba41e85a,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-8b44d71a-4865-4738-9621-044db6743114,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-b1db1341-e708-4a53-bc86-65cf0fb77118,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-783987b0-6f61-4a69-b366-231431832796,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-90f1612f-18cb-48dd-bfd8-9a696af8fa80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857088925-172.17.0.17-1597698165335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35002,DS-5e1d4c38-10cf-44ee-95ae-039de25a903f,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-e213090d-4f85-4a7b-bbab-f7cca0add9da,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-692269db-5009-4196-b26a-c061eea4fb31,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-37d88046-680a-4bdc-a4f3-08879a177bca,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-a02e953f-c009-4068-90e0-58dbf233051e,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-c263cbde-6616-469d-ad96-8db220c72e78,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-77e22377-907e-42df-840f-98bfacd9e250,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-0565c2e9-00b3-418c-b0d8-a1f331e03d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857088925-172.17.0.17-1597698165335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35002,DS-5e1d4c38-10cf-44ee-95ae-039de25a903f,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-e213090d-4f85-4a7b-bbab-f7cca0add9da,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-692269db-5009-4196-b26a-c061eea4fb31,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-37d88046-680a-4bdc-a4f3-08879a177bca,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-a02e953f-c009-4068-90e0-58dbf233051e,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-c263cbde-6616-469d-ad96-8db220c72e78,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-77e22377-907e-42df-840f-98bfacd9e250,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-0565c2e9-00b3-418c-b0d8-a1f331e03d57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125039991-172.17.0.17-1597698816257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41496,DS-01d35333-9ca4-462e-9316-6268d2e07e28,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-4e0f1dc9-3507-4c5f-90ec-d85c45fe12e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-59c7e5a3-7c2b-4297-be38-c9945b4c144b,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-626e1acc-85f4-417b-bd0d-e28aa9b03e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-0fd551db-45b5-4734-ab01-86ac5ca66a38,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-49a8ee67-8b04-4c0b-bcfb-f0ef457d595e,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-00df1642-0862-4e58-a726-7dea54d287ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-a349f43f-0658-455d-9988-a5bc8fcfcf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125039991-172.17.0.17-1597698816257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41496,DS-01d35333-9ca4-462e-9316-6268d2e07e28,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-4e0f1dc9-3507-4c5f-90ec-d85c45fe12e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-59c7e5a3-7c2b-4297-be38-c9945b4c144b,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-626e1acc-85f4-417b-bd0d-e28aa9b03e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-0fd551db-45b5-4734-ab01-86ac5ca66a38,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-49a8ee67-8b04-4c0b-bcfb-f0ef457d595e,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-00df1642-0862-4e58-a726-7dea54d287ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-a349f43f-0658-455d-9988-a5bc8fcfcf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178645798-172.17.0.17-1597699220427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-5451a7fa-c2c6-432b-ab65-7ae9e7c52257,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-3940ec54-e0d6-4763-97c0-9df5378a467e,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-77bda3eb-55f6-4f10-91d1-160414cde25f,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-4c43ac14-7e48-4a6e-a43d-c48b4e77a017,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-066103df-3a2d-4b32-82f9-ba7a467bda7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-2f74a360-83a3-4f70-9a93-ff6f0c153b05,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-30ab2417-cb81-4be9-9ecb-822a1bcea8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1e60e0ba-0e1a-4b95-9d76-430233be7111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178645798-172.17.0.17-1597699220427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-5451a7fa-c2c6-432b-ab65-7ae9e7c52257,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-3940ec54-e0d6-4763-97c0-9df5378a467e,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-77bda3eb-55f6-4f10-91d1-160414cde25f,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-4c43ac14-7e48-4a6e-a43d-c48b4e77a017,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-066103df-3a2d-4b32-82f9-ba7a467bda7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-2f74a360-83a3-4f70-9a93-ff6f0c153b05,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-30ab2417-cb81-4be9-9ecb-822a1bcea8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1e60e0ba-0e1a-4b95-9d76-430233be7111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764881318-172.17.0.17-1597699386296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42557,DS-199f4a76-991a-4209-a932-654d4bc60fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-34def4a0-5b45-47ce-b86c-09b166d28b61,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-faaba7ea-e681-4c72-ba02-7f43acb4ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-dd76db17-2bc4-4fe8-ad90-a8d1785ddc41,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-64ac0262-469a-40eb-af73-309b1522a6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-4e6fb19b-fe24-4553-978b-4d6af57f6392,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-e5dfd789-9feb-461c-9da0-6746f1226961,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-b695fc58-2c2b-4bb6-a7db-5e4bf7d3dffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764881318-172.17.0.17-1597699386296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42557,DS-199f4a76-991a-4209-a932-654d4bc60fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-34def4a0-5b45-47ce-b86c-09b166d28b61,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-faaba7ea-e681-4c72-ba02-7f43acb4ae68,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-dd76db17-2bc4-4fe8-ad90-a8d1785ddc41,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-64ac0262-469a-40eb-af73-309b1522a6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-4e6fb19b-fe24-4553-978b-4d6af57f6392,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-e5dfd789-9feb-461c-9da0-6746f1226961,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-b695fc58-2c2b-4bb6-a7db-5e4bf7d3dffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417986303-172.17.0.17-1597699620158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40186,DS-38ef94f3-1ea6-448c-9f9d-7c72ff1c782c,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-86007cbf-2a3e-4919-ae7d-71079e5a63c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-28f0120a-f10e-4682-b335-07330dd4455a,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-5f6135e3-052e-4ab5-8839-6c00cc7d55e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-cfa2fb3b-ff35-4736-b5b8-d51e6a181bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-1d63d483-c20a-444c-92b7-944dc1d6368a,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-d0b63f35-0d9a-4d60-a55c-df1850819a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-4fb570f6-f13b-4cc4-89c2-ef995bda27d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417986303-172.17.0.17-1597699620158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40186,DS-38ef94f3-1ea6-448c-9f9d-7c72ff1c782c,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-86007cbf-2a3e-4919-ae7d-71079e5a63c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-28f0120a-f10e-4682-b335-07330dd4455a,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-5f6135e3-052e-4ab5-8839-6c00cc7d55e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-cfa2fb3b-ff35-4736-b5b8-d51e6a181bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-1d63d483-c20a-444c-92b7-944dc1d6368a,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-d0b63f35-0d9a-4d60-a55c-df1850819a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-4fb570f6-f13b-4cc4-89c2-ef995bda27d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838277617-172.17.0.17-1597699878544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-1609a910-2f87-42e7-927e-2bf8e7745181,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-44ccaea6-a630-4ad3-8605-785060560398,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-222f59a0-7511-42ea-b8b3-ae138ff1b005,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-a06dcf21-a4a7-4b12-9d72-0de95205c374,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-417b3a8c-7c0b-4627-85d0-bb209784708a,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-4a6ac26f-7a55-4c3c-890e-b7292acf6335,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-02b2460b-58c6-4706-b387-d191a424611a,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-2ab096eb-e758-4cdd-a00d-feda10323464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838277617-172.17.0.17-1597699878544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-1609a910-2f87-42e7-927e-2bf8e7745181,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-44ccaea6-a630-4ad3-8605-785060560398,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-222f59a0-7511-42ea-b8b3-ae138ff1b005,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-a06dcf21-a4a7-4b12-9d72-0de95205c374,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-417b3a8c-7c0b-4627-85d0-bb209784708a,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-4a6ac26f-7a55-4c3c-890e-b7292acf6335,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-02b2460b-58c6-4706-b387-d191a424611a,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-2ab096eb-e758-4cdd-a00d-feda10323464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161509650-172.17.0.17-1597699998619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-0655d6e2-eda7-4b7b-bd5b-1f6286024427,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-5e2bd648-8fd9-448c-9d5b-2eff14497967,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-c4056602-099f-4234-af3d-517c95501c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-9b478b4f-639a-45ec-bd48-57839b7866f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-35b39aac-cf28-4011-8eb0-d910505cb5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-b6147746-9627-492e-af28-db09583977b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-c3c706f7-c016-4d66-8cb0-588b2106d616,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-31fb3e69-0e4b-4115-80f4-b08817cf2c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161509650-172.17.0.17-1597699998619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-0655d6e2-eda7-4b7b-bd5b-1f6286024427,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-5e2bd648-8fd9-448c-9d5b-2eff14497967,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-c4056602-099f-4234-af3d-517c95501c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-9b478b4f-639a-45ec-bd48-57839b7866f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-35b39aac-cf28-4011-8eb0-d910505cb5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-b6147746-9627-492e-af28-db09583977b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-c3c706f7-c016-4d66-8cb0-588b2106d616,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-31fb3e69-0e4b-4115-80f4-b08817cf2c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485119828-172.17.0.17-1597700464610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46081,DS-4b09a8d4-98c7-42c4-9f6f-02b155251f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-6178c52b-e291-4801-b4ad-e861b534e810,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-dd5378de-6e8b-4b79-b6c5-02c84370d4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-fad24710-8fe0-4657-b6e5-fac7d187d433,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-71021f86-345b-4cc2-9930-cf772d7a3354,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-0d185cbf-169c-40a4-9fde-fb612372d023,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-86c63bf2-d1f5-4c23-88b2-01eb8b78088d,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-0ed491bc-3dac-4e72-9684-c29ebdba0913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485119828-172.17.0.17-1597700464610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46081,DS-4b09a8d4-98c7-42c4-9f6f-02b155251f21,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-6178c52b-e291-4801-b4ad-e861b534e810,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-dd5378de-6e8b-4b79-b6c5-02c84370d4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-fad24710-8fe0-4657-b6e5-fac7d187d433,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-71021f86-345b-4cc2-9930-cf772d7a3354,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-0d185cbf-169c-40a4-9fde-fb612372d023,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-86c63bf2-d1f5-4c23-88b2-01eb8b78088d,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-0ed491bc-3dac-4e72-9684-c29ebdba0913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634012414-172.17.0.17-1597700612016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40743,DS-38368f3d-e39c-4428-9fd2-2ca778d96d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-ca859d5e-551c-4788-83a9-486981653586,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-34eb2d97-8c4e-41fd-9d1e-028c6a38a18d,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-1536938b-c0c6-4c9a-9f84-0727f3d8540a,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-cbebc043-4442-4a5f-862c-1edf45e3af15,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-2aacaa78-9364-437e-8539-5133c9ba1218,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-9d8f933a-5186-4b4c-af93-d23fcfa0a4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-014e2976-c2b0-42b0-abad-2d658dad50ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634012414-172.17.0.17-1597700612016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40743,DS-38368f3d-e39c-4428-9fd2-2ca778d96d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-ca859d5e-551c-4788-83a9-486981653586,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-34eb2d97-8c4e-41fd-9d1e-028c6a38a18d,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-1536938b-c0c6-4c9a-9f84-0727f3d8540a,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-cbebc043-4442-4a5f-862c-1edf45e3af15,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-2aacaa78-9364-437e-8539-5133c9ba1218,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-9d8f933a-5186-4b4c-af93-d23fcfa0a4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-014e2976-c2b0-42b0-abad-2d658dad50ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530112565-172.17.0.17-1597700813162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-54613b27-f5ad-4967-b0bf-d77e7469d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-33f3ebfc-54b5-4aa0-bbfc-bf864c5fdedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-31ab6e01-d5c4-4e60-8f63-05bce69ebecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-92d93a6b-27b2-4580-8d97-e2dfef0bdda5,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-c21062c7-850a-490e-aef5-9487d4d47ded,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-dda48052-f8cc-487a-b6ce-6ed805880241,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-21682a62-4e8b-48bd-956f-644f795fd6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-ee208dca-16e7-40f9-970e-29d4b9a46abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530112565-172.17.0.17-1597700813162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-54613b27-f5ad-4967-b0bf-d77e7469d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-33f3ebfc-54b5-4aa0-bbfc-bf864c5fdedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-31ab6e01-d5c4-4e60-8f63-05bce69ebecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-92d93a6b-27b2-4580-8d97-e2dfef0bdda5,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-c21062c7-850a-490e-aef5-9487d4d47ded,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-dda48052-f8cc-487a-b6ce-6ed805880241,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-21682a62-4e8b-48bd-956f-644f795fd6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-ee208dca-16e7-40f9-970e-29d4b9a46abc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737471886-172.17.0.17-1597701878859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-2ff0e458-951f-4f50-87e7-335f3cd58c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-27031977-11c4-4645-b130-596733735f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-8d77dcc8-c85c-40a0-8c65-1172a5444138,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-e9d34c63-e9ed-4c02-b9ee-342f88d148e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-65a46d38-9ec0-4464-b16e-3f0cb3dbcb47,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-10e7ba1e-4f0f-4c84-bcc1-85ee426124cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-d1c346c9-c8f2-47d8-b1d3-8f4377a12d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-9b898c46-c14b-4c3b-b510-7b17cd7eb408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737471886-172.17.0.17-1597701878859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-2ff0e458-951f-4f50-87e7-335f3cd58c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-27031977-11c4-4645-b130-596733735f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-8d77dcc8-c85c-40a0-8c65-1172a5444138,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-e9d34c63-e9ed-4c02-b9ee-342f88d148e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-65a46d38-9ec0-4464-b16e-3f0cb3dbcb47,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-10e7ba1e-4f0f-4c84-bcc1-85ee426124cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-d1c346c9-c8f2-47d8-b1d3-8f4377a12d49,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-9b898c46-c14b-4c3b-b510-7b17cd7eb408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580565437-172.17.0.17-1597702160242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39421,DS-6a8290a7-d6e6-4b84-8c70-c9be1cef1ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-532e88b0-42f4-44b0-8aa1-029a9fdaef21,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-ea9573be-6d78-4069-a2fa-b903e802950f,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-6c0e7bbe-da40-439a-b58e-604ef999bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-08f81a0c-9cca-4a5c-bfcb-43b271a77d20,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-89dc4d0c-2894-4a63-bb4e-0110e41386a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-36151a2b-d9ae-4a9e-ad44-79f7bc21501d,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-5e47d9a2-81c0-46c2-b992-6bef4834702b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580565437-172.17.0.17-1597702160242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39421,DS-6a8290a7-d6e6-4b84-8c70-c9be1cef1ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-532e88b0-42f4-44b0-8aa1-029a9fdaef21,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-ea9573be-6d78-4069-a2fa-b903e802950f,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-6c0e7bbe-da40-439a-b58e-604ef999bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-08f81a0c-9cca-4a5c-bfcb-43b271a77d20,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-89dc4d0c-2894-4a63-bb4e-0110e41386a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-36151a2b-d9ae-4a9e-ad44-79f7bc21501d,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-5e47d9a2-81c0-46c2-b992-6bef4834702b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218063602-172.17.0.17-1597702437286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-d01da828-b6cc-4a72-87fd-89c1ec0c1a78,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-e0f1ac9e-c8e0-4fa8-9c86-1f0615fb4dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-d3d59b61-b4a8-4f9f-8f2f-4d9989c45e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-5966e14c-76f1-452c-8700-e61f1d4d446a,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-b84c3bd3-5418-40e1-b781-cc19840fe0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-ee6b2a46-0d99-4494-b308-02b78a949551,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-2b7f4f0a-442c-44d4-b8d4-5263fac14eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-fec1f563-eac3-442f-9271-a72589517ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218063602-172.17.0.17-1597702437286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-d01da828-b6cc-4a72-87fd-89c1ec0c1a78,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-e0f1ac9e-c8e0-4fa8-9c86-1f0615fb4dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-d3d59b61-b4a8-4f9f-8f2f-4d9989c45e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-5966e14c-76f1-452c-8700-e61f1d4d446a,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-b84c3bd3-5418-40e1-b781-cc19840fe0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-ee6b2a46-0d99-4494-b308-02b78a949551,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-2b7f4f0a-442c-44d4-b8d4-5263fac14eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-fec1f563-eac3-442f-9271-a72589517ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366617588-172.17.0.17-1597702471195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41383,DS-099ba75b-a986-4da3-809f-1de25618515c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-ecb57855-e40c-4c87-9eee-ce8fc4f9a3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-fce17c5f-f3d4-487f-acc8-fc07185382a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-5ef96273-4277-4a2f-a7c7-681a75b499a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-21299b24-70ce-4184-83f9-68e968a58da2,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-89d7d31e-6c1c-4de0-92f1-96cf654ecc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-3f21a536-6602-4a3d-9524-937bdd62c6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-540bc9df-8d36-4afc-a278-f2a53a759817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366617588-172.17.0.17-1597702471195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41383,DS-099ba75b-a986-4da3-809f-1de25618515c,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-ecb57855-e40c-4c87-9eee-ce8fc4f9a3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-fce17c5f-f3d4-487f-acc8-fc07185382a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-5ef96273-4277-4a2f-a7c7-681a75b499a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-21299b24-70ce-4184-83f9-68e968a58da2,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-89d7d31e-6c1c-4de0-92f1-96cf654ecc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-3f21a536-6602-4a3d-9524-937bdd62c6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-540bc9df-8d36-4afc-a278-f2a53a759817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5800
