reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990249949-172.17.0.21-1597705191491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33803,DS-ec895044-bcb1-4bd7-b3ba-dde830d91abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-fc0fce78-bf46-495a-9f6a-ed6f9493c50a,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-f34fc6ac-9ca6-4192-888f-2afddc1e1b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-d818e423-6046-408c-a284-7a64026b8b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-5795e11a-a7db-44b9-a549-8052b7e0f3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-f3306d1c-3c5f-4c88-8861-2237e9f13d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-42457d96-b1a6-4293-95f1-96ea540af055,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-bcbde048-d324-4ae5-afd5-6f8ce91e5cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990249949-172.17.0.21-1597705191491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33803,DS-ec895044-bcb1-4bd7-b3ba-dde830d91abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-fc0fce78-bf46-495a-9f6a-ed6f9493c50a,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-f34fc6ac-9ca6-4192-888f-2afddc1e1b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-d818e423-6046-408c-a284-7a64026b8b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-5795e11a-a7db-44b9-a549-8052b7e0f3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-f3306d1c-3c5f-4c88-8861-2237e9f13d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-42457d96-b1a6-4293-95f1-96ea540af055,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-bcbde048-d324-4ae5-afd5-6f8ce91e5cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412288633-172.17.0.21-1597705302939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-59bd2d65-0f96-4c9d-bd62-3b4c0718820a,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-82a9c58f-1f3f-484e-93fc-8e06f7649a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-be48c3f9-6924-45c0-a78d-3985b5a46138,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-7b1c1586-7d75-450f-b27f-1c4a15bb4721,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-83ca05fc-ab6f-4127-94cf-67bad71ee2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-70aad033-66a7-4ceb-85aa-f78dfad6d227,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-30b061a5-2fe6-4cf6-b11f-4bae7075437c,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-8b3f1253-3f15-4812-901b-10d264870595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412288633-172.17.0.21-1597705302939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-59bd2d65-0f96-4c9d-bd62-3b4c0718820a,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-82a9c58f-1f3f-484e-93fc-8e06f7649a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-be48c3f9-6924-45c0-a78d-3985b5a46138,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-7b1c1586-7d75-450f-b27f-1c4a15bb4721,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-83ca05fc-ab6f-4127-94cf-67bad71ee2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-70aad033-66a7-4ceb-85aa-f78dfad6d227,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-30b061a5-2fe6-4cf6-b11f-4bae7075437c,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-8b3f1253-3f15-4812-901b-10d264870595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333765180-172.17.0.21-1597705341480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36932,DS-eb3327d4-cea6-4cce-b674-f1962a60e407,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-add3d64f-cc8e-42a3-aa3b-6dae525eaefb,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-52f64f08-7f99-4ac5-8c26-36ff5d426d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-c91e470d-ce61-478b-a8d6-8d105024ffe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-039bb92f-ee5e-45ff-ba86-3f74e00b73b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-52ff50f3-7667-4ebd-9da0-fede6e041286,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-56794111-fb69-4c42-9d7e-863151140dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-10b13b15-9621-4cd6-8ed1-265602027bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333765180-172.17.0.21-1597705341480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36932,DS-eb3327d4-cea6-4cce-b674-f1962a60e407,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-add3d64f-cc8e-42a3-aa3b-6dae525eaefb,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-52f64f08-7f99-4ac5-8c26-36ff5d426d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-c91e470d-ce61-478b-a8d6-8d105024ffe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-039bb92f-ee5e-45ff-ba86-3f74e00b73b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-52ff50f3-7667-4ebd-9da0-fede6e041286,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-56794111-fb69-4c42-9d7e-863151140dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-10b13b15-9621-4cd6-8ed1-265602027bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297152513-172.17.0.21-1597705717391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-ceba1eb4-ef08-4aec-858a-6fe5bbc53c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-e0957f91-5f5a-4c38-9b33-2d6af346615e,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-5ccf12f1-566c-4865-aa22-ce314600808c,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-00260ed4-e5ce-4b01-8535-d9b9a292b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-2315bd8a-b755-4202-a097-b362d139be26,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-63ce4ab3-be3c-47c3-bae0-291c7d6e0ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-1ca5f24f-7a1a-4351-b3b5-cf13c6f865d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-c85fd9cc-cefa-4b83-89ff-0b748bbe620e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297152513-172.17.0.21-1597705717391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-ceba1eb4-ef08-4aec-858a-6fe5bbc53c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-e0957f91-5f5a-4c38-9b33-2d6af346615e,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-5ccf12f1-566c-4865-aa22-ce314600808c,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-00260ed4-e5ce-4b01-8535-d9b9a292b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-2315bd8a-b755-4202-a097-b362d139be26,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-63ce4ab3-be3c-47c3-bae0-291c7d6e0ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-1ca5f24f-7a1a-4351-b3b5-cf13c6f865d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-c85fd9cc-cefa-4b83-89ff-0b748bbe620e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557772514-172.17.0.21-1597706089757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-fd36b35e-984d-4488-88d8-dedbc04a2236,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-05ac9af3-9493-4d1b-9ace-0535817f0956,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-d2f9a0e9-de98-47e8-9b9b-144dffa3ab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-f24bb26c-a779-475e-867b-36bbfa224e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-3e971e06-c3b2-4e0b-ab31-ff362de2fd90,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-0fcc3c39-55c6-41b7-aa1e-24db2b54bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-a9e09a00-a8c3-42df-892d-5461712fa4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-c3723832-f8a2-4be0-8068-486c4f493f89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557772514-172.17.0.21-1597706089757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-fd36b35e-984d-4488-88d8-dedbc04a2236,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-05ac9af3-9493-4d1b-9ace-0535817f0956,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-d2f9a0e9-de98-47e8-9b9b-144dffa3ab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-f24bb26c-a779-475e-867b-36bbfa224e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-3e971e06-c3b2-4e0b-ab31-ff362de2fd90,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-0fcc3c39-55c6-41b7-aa1e-24db2b54bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-a9e09a00-a8c3-42df-892d-5461712fa4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-c3723832-f8a2-4be0-8068-486c4f493f89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976501012-172.17.0.21-1597706335791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32769,DS-9f77aaad-5e56-4646-9b67-68553f47c639,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-38772e7b-2d45-4fcb-8f02-7e6d5ee757f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-9e97e870-68e7-4df6-9ae7-5af6b4831094,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-e0759013-4694-4db1-b8d7-18e21175cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-3cb01f73-1795-40ca-8ad9-3c2d17e8cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-8204430b-0546-4901-b50c-f6de7dcc74ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-7a78c5cf-23c9-4217-96f2-a5b9e2afe3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-c1c42542-d6f0-4dab-8b03-cb6889dd0e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976501012-172.17.0.21-1597706335791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32769,DS-9f77aaad-5e56-4646-9b67-68553f47c639,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-38772e7b-2d45-4fcb-8f02-7e6d5ee757f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-9e97e870-68e7-4df6-9ae7-5af6b4831094,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-e0759013-4694-4db1-b8d7-18e21175cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-3cb01f73-1795-40ca-8ad9-3c2d17e8cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-8204430b-0546-4901-b50c-f6de7dcc74ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-7a78c5cf-23c9-4217-96f2-a5b9e2afe3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-c1c42542-d6f0-4dab-8b03-cb6889dd0e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820080641-172.17.0.21-1597706500987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-76f31ef3-7bd6-4275-ae1f-57d3aca943c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-3e146323-b3d6-42c5-8caa-a901d504d7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-3fb5e181-e9be-4126-aed3-578639a02a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-b74b9873-903c-467a-8610-c7dcf903bb59,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-b36bb2ac-67d6-462a-b141-24d95f6f7688,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-d715780f-ea00-420e-9188-9b5dfb6b46c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-52b7ba16-84be-4e62-9132-3cef0fae7428,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-971d444d-f268-41e6-a0d5-14ff3bc137e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820080641-172.17.0.21-1597706500987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-76f31ef3-7bd6-4275-ae1f-57d3aca943c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-3e146323-b3d6-42c5-8caa-a901d504d7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-3fb5e181-e9be-4126-aed3-578639a02a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-b74b9873-903c-467a-8610-c7dcf903bb59,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-b36bb2ac-67d6-462a-b141-24d95f6f7688,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-d715780f-ea00-420e-9188-9b5dfb6b46c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-52b7ba16-84be-4e62-9132-3cef0fae7428,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-971d444d-f268-41e6-a0d5-14ff3bc137e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37287547-172.17.0.21-1597707178130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-bea8bf1e-4b0f-4fb0-bb2d-fd24b1ee85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-ac08b838-0077-4757-bb83-614bd6ff52c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-44c944bc-8303-497e-88e6-894200b97843,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-0ffebabe-674d-4b90-a3c4-033a09ed9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-7e2a8d56-48e7-4b79-bd19-2d008494221c,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-42ba320a-1022-49ac-9996-1bf2da07af2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-e6b429d8-3b4b-42ba-b971-0801cd6b6007,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-ea59f4ac-07a1-4442-89f5-b036a49ab536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37287547-172.17.0.21-1597707178130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-bea8bf1e-4b0f-4fb0-bb2d-fd24b1ee85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-ac08b838-0077-4757-bb83-614bd6ff52c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-44c944bc-8303-497e-88e6-894200b97843,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-0ffebabe-674d-4b90-a3c4-033a09ed9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-7e2a8d56-48e7-4b79-bd19-2d008494221c,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-42ba320a-1022-49ac-9996-1bf2da07af2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-e6b429d8-3b4b-42ba-b971-0801cd6b6007,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-ea59f4ac-07a1-4442-89f5-b036a49ab536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135065167-172.17.0.21-1597707389885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33550,DS-158ac3d6-5373-419f-9f27-4251b17516b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-db861403-d67d-4eba-b617-c70aa2774e19,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-6b947304-c9b6-4a8d-bdac-9f4278197bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-c8fb5bde-82d1-4c28-b629-cf9ed6868f41,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-470dd063-a283-465c-bc55-85041fc89dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-7dc0d7db-1653-47c0-9cb9-49ef937cdfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-5f050a11-87fd-4e09-8d5a-3752531b4026,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-e5a54d40-1651-4302-a346-b1ed8a2c06b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135065167-172.17.0.21-1597707389885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33550,DS-158ac3d6-5373-419f-9f27-4251b17516b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-db861403-d67d-4eba-b617-c70aa2774e19,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-6b947304-c9b6-4a8d-bdac-9f4278197bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-c8fb5bde-82d1-4c28-b629-cf9ed6868f41,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-470dd063-a283-465c-bc55-85041fc89dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-7dc0d7db-1653-47c0-9cb9-49ef937cdfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-5f050a11-87fd-4e09-8d5a-3752531b4026,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-e5a54d40-1651-4302-a346-b1ed8a2c06b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635992029-172.17.0.21-1597707455196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34569,DS-48f80042-b4b3-4bf1-9356-16bbf57477e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-df98f268-de59-4963-a60f-88c9c5b470da,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-7ecad187-dc87-4e52-9912-1d3bcc188500,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-69be6267-61a3-4254-84dd-ab32e2069ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-ae5c507a-83bd-4c74-a8fc-56832e91abce,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-a0ca29b1-5c12-448e-88d3-344e265940c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-18d08047-f3f5-4448-a8a7-e1e1237fd8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-cac61cd5-f10c-4787-9f8a-ab48f2e0e9e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635992029-172.17.0.21-1597707455196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34569,DS-48f80042-b4b3-4bf1-9356-16bbf57477e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-df98f268-de59-4963-a60f-88c9c5b470da,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-7ecad187-dc87-4e52-9912-1d3bcc188500,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-69be6267-61a3-4254-84dd-ab32e2069ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-ae5c507a-83bd-4c74-a8fc-56832e91abce,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-a0ca29b1-5c12-448e-88d3-344e265940c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-18d08047-f3f5-4448-a8a7-e1e1237fd8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-cac61cd5-f10c-4787-9f8a-ab48f2e0e9e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916830376-172.17.0.21-1597707528497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41805,DS-11006a7d-3b69-4d9f-ab75-a68c1d05f021,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-7f289b5d-719f-48da-be8c-1fc44d012b93,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-305bb6da-866c-4032-a207-4a8d745734ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-915c7dcc-9b9b-4d0c-8e52-65316945fad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-6812e595-cefc-48b5-be9c-24bfa57b3011,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-4a6d9938-54ce-4c5e-b011-d3a72b8c72e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-6035c289-3a01-4b40-95a9-eb18097cae26,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-bb859459-eec6-4f48-9d46-79ad8246f644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916830376-172.17.0.21-1597707528497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41805,DS-11006a7d-3b69-4d9f-ab75-a68c1d05f021,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-7f289b5d-719f-48da-be8c-1fc44d012b93,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-305bb6da-866c-4032-a207-4a8d745734ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-915c7dcc-9b9b-4d0c-8e52-65316945fad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-6812e595-cefc-48b5-be9c-24bfa57b3011,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-4a6d9938-54ce-4c5e-b011-d3a72b8c72e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-6035c289-3a01-4b40-95a9-eb18097cae26,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-bb859459-eec6-4f48-9d46-79ad8246f644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117731863-172.17.0.21-1597707598901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-8669614a-e426-4a89-a425-cd0ddbbfc275,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-4dcee62e-ca22-479b-9a0f-6f94c8a5c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-4c9f44c2-346d-46a1-b3c5-ce7b3823e129,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-099b601e-2d64-4513-9fb2-0436019caa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-a643ca17-e7d1-47d8-91a9-c1cd3842e6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-51912bb6-cca7-4db0-95c6-e331cb43d5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-da20f57d-aba3-447e-96cd-e9265bc45ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-fbeea291-a39e-4bd4-a990-5b0551d03095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117731863-172.17.0.21-1597707598901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-8669614a-e426-4a89-a425-cd0ddbbfc275,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-4dcee62e-ca22-479b-9a0f-6f94c8a5c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-4c9f44c2-346d-46a1-b3c5-ce7b3823e129,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-099b601e-2d64-4513-9fb2-0436019caa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-a643ca17-e7d1-47d8-91a9-c1cd3842e6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-51912bb6-cca7-4db0-95c6-e331cb43d5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-da20f57d-aba3-447e-96cd-e9265bc45ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-fbeea291-a39e-4bd4-a990-5b0551d03095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109890656-172.17.0.21-1597707930468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39521,DS-93f7d5d4-2b3d-4ed1-b3a3-b974d5644814,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-1036925e-2177-4c3d-9746-8d099145e622,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-000f3cb1-752a-4c44-8f12-cc7bbe14987b,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-f0a517f1-5992-4111-8297-8db8d57be366,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-41944692-c21c-4469-ae6b-eb0689caaf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-fc54eb88-c9a8-4625-95c0-c14536795d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-dc00e1fa-a3e5-45d2-8a23-3086f2f52ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-19591f79-6d0c-4e42-a4e3-276bd1d12385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109890656-172.17.0.21-1597707930468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39521,DS-93f7d5d4-2b3d-4ed1-b3a3-b974d5644814,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-1036925e-2177-4c3d-9746-8d099145e622,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-000f3cb1-752a-4c44-8f12-cc7bbe14987b,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-f0a517f1-5992-4111-8297-8db8d57be366,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-41944692-c21c-4469-ae6b-eb0689caaf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-fc54eb88-c9a8-4625-95c0-c14536795d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-dc00e1fa-a3e5-45d2-8a23-3086f2f52ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-19591f79-6d0c-4e42-a4e3-276bd1d12385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424822876-172.17.0.21-1597708211228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-d637e070-efcd-444e-884b-57dbc645fa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-4b7cb267-65b4-49f9-bc46-5bf9a415628f,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-5d2dec69-33da-4c69-b47e-45d9193c8c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-a08c7145-2533-4ac3-a8c3-6c1201b957cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-a7a67929-811b-4028-837e-e4a45156d486,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-86b6dc91-2d40-424f-a734-3db90109fe12,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-efa03aa7-9798-4a47-b0bf-4a50fa9dab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-215d414b-f05d-412b-ad72-5d1eb87412a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424822876-172.17.0.21-1597708211228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-d637e070-efcd-444e-884b-57dbc645fa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-4b7cb267-65b4-49f9-bc46-5bf9a415628f,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-5d2dec69-33da-4c69-b47e-45d9193c8c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-a08c7145-2533-4ac3-a8c3-6c1201b957cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-a7a67929-811b-4028-837e-e4a45156d486,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-86b6dc91-2d40-424f-a734-3db90109fe12,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-efa03aa7-9798-4a47-b0bf-4a50fa9dab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-215d414b-f05d-412b-ad72-5d1eb87412a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397133137-172.17.0.21-1597708391455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45121,DS-a056091b-e6d5-4961-a3d9-7aa3202bfccc,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-b7549f3a-fe80-4305-bd26-b7d7ee0bfe49,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-05f8fe2e-1329-40cb-96ac-c73be8266bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-7281c49e-a937-45dc-9821-adc6732c3835,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-0c096a43-a1db-4dc4-b09c-ba9ebcb01d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-f4c4eb19-851e-446a-b556-3e4f7c6024c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-78ea9603-bb4c-4417-a404-b82791cd02a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-ce43e7a9-7701-4ddb-b05d-d3c6fc4470e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397133137-172.17.0.21-1597708391455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45121,DS-a056091b-e6d5-4961-a3d9-7aa3202bfccc,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-b7549f3a-fe80-4305-bd26-b7d7ee0bfe49,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-05f8fe2e-1329-40cb-96ac-c73be8266bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-7281c49e-a937-45dc-9821-adc6732c3835,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-0c096a43-a1db-4dc4-b09c-ba9ebcb01d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-f4c4eb19-851e-446a-b556-3e4f7c6024c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-78ea9603-bb4c-4417-a404-b82791cd02a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-ce43e7a9-7701-4ddb-b05d-d3c6fc4470e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282468552-172.17.0.21-1597709075787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40470,DS-481e6fcb-7bf3-48b1-b29d-0055b3910fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-fb04e0e1-7e03-47e5-815e-fd3e549287eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-9e3c39e9-a326-4580-9e6c-e89811b3d794,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-03fde2e3-5f73-4ca8-a859-4560245bd6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-d549144e-80e5-4bd8-87ab-47ca61403c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-04066e6a-553a-4d99-a091-b5a1ab93fb05,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-11619a5e-a039-466e-84ac-841688b9e774,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-77d41847-a8e8-4403-8727-5b1b047f54a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282468552-172.17.0.21-1597709075787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40470,DS-481e6fcb-7bf3-48b1-b29d-0055b3910fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-fb04e0e1-7e03-47e5-815e-fd3e549287eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-9e3c39e9-a326-4580-9e6c-e89811b3d794,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-03fde2e3-5f73-4ca8-a859-4560245bd6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-d549144e-80e5-4bd8-87ab-47ca61403c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-04066e6a-553a-4d99-a091-b5a1ab93fb05,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-11619a5e-a039-466e-84ac-841688b9e774,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-77d41847-a8e8-4403-8727-5b1b047f54a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671094012-172.17.0.21-1597709357160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-b4d20e9a-5131-4817-ab4b-faf02694041f,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-985d744e-802f-41d9-aa19-311516659d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-35b67f93-bb66-4d5f-9850-1af4a35b5fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-c42af5a9-2787-44b3-b4d3-8b679e80ab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-81f4805e-40fc-4fd6-97bf-ed74af1ff25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-27abd6fd-3a23-4a3e-b7ae-860263ebb077,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-2055828d-f189-4913-a039-8314c0f571f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-57e4cee3-1164-4216-a8f4-e6f4c25ff809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671094012-172.17.0.21-1597709357160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-b4d20e9a-5131-4817-ab4b-faf02694041f,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-985d744e-802f-41d9-aa19-311516659d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-35b67f93-bb66-4d5f-9850-1af4a35b5fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-c42af5a9-2787-44b3-b4d3-8b679e80ab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-81f4805e-40fc-4fd6-97bf-ed74af1ff25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-27abd6fd-3a23-4a3e-b7ae-860263ebb077,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-2055828d-f189-4913-a039-8314c0f571f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-57e4cee3-1164-4216-a8f4-e6f4c25ff809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648311635-172.17.0.21-1597709386412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-8afc64fa-d7f9-462a-835a-834cc52d475d,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-b8c34ce8-93e6-4188-a3ad-3dfe4f06feed,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-a4d3e084-3b10-40ae-88a8-452bccea77e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-de0e4715-6e61-484e-9167-36e1ec8a39d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-3b86b435-550c-4ce8-9217-1724a99b4545,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-580a3820-3b67-4b0f-8034-01baa61df776,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-68a1e8b4-abdc-4722-8aba-29838ec77a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-0ee72cef-0bc0-4d33-9002-434bfa476d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648311635-172.17.0.21-1597709386412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-8afc64fa-d7f9-462a-835a-834cc52d475d,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-b8c34ce8-93e6-4188-a3ad-3dfe4f06feed,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-a4d3e084-3b10-40ae-88a8-452bccea77e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-de0e4715-6e61-484e-9167-36e1ec8a39d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-3b86b435-550c-4ce8-9217-1724a99b4545,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-580a3820-3b67-4b0f-8034-01baa61df776,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-68a1e8b4-abdc-4722-8aba-29838ec77a73,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-0ee72cef-0bc0-4d33-9002-434bfa476d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795757367-172.17.0.21-1597709767199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37033,DS-d0dc8350-f46c-405e-82f6-91aad0483c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-bcc5132b-0e84-4a54-a71f-e71033a41416,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-1f6b7b93-2ffd-4bc1-998d-2ba81d571bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-5bd64095-efee-4571-8efb-02a6a994f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-d3ed43e0-4618-4be6-86a3-51afde614616,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-5884fd61-8826-49da-9a09-25f307ed4ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-77f49fef-dca8-450a-a008-8a5ba1cf11b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-521079ba-1f4c-4b98-8891-c73e68436402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795757367-172.17.0.21-1597709767199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37033,DS-d0dc8350-f46c-405e-82f6-91aad0483c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-bcc5132b-0e84-4a54-a71f-e71033a41416,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-1f6b7b93-2ffd-4bc1-998d-2ba81d571bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-5bd64095-efee-4571-8efb-02a6a994f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-d3ed43e0-4618-4be6-86a3-51afde614616,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-5884fd61-8826-49da-9a09-25f307ed4ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-77f49fef-dca8-450a-a008-8a5ba1cf11b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-521079ba-1f4c-4b98-8891-c73e68436402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836570673-172.17.0.21-1597710222202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36246,DS-cab6d7ec-60d0-4dc2-acdc-93da53988356,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-7c816925-ee40-40eb-bee4-048d9c5a9282,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-5376c3b0-b5e5-4311-99b6-70b6e9d8e494,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-a9c64312-c9bf-4361-9924-f2aa55df9d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-28cc3c34-8cec-4fb9-8743-f2110d5f90ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-6e3e00b6-1394-46ae-8991-2f1b9f465711,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-ea14319a-6199-4b47-908b-452766f72d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-1ecbda79-ce36-4a80-937b-18d612da4b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836570673-172.17.0.21-1597710222202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36246,DS-cab6d7ec-60d0-4dc2-acdc-93da53988356,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-7c816925-ee40-40eb-bee4-048d9c5a9282,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-5376c3b0-b5e5-4311-99b6-70b6e9d8e494,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-a9c64312-c9bf-4361-9924-f2aa55df9d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-28cc3c34-8cec-4fb9-8743-f2110d5f90ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-6e3e00b6-1394-46ae-8991-2f1b9f465711,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-ea14319a-6199-4b47-908b-452766f72d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-1ecbda79-ce36-4a80-937b-18d612da4b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400978317-172.17.0.21-1597710256063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45661,DS-96fb2695-8780-4bef-9b8c-315b3de3ef27,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-e3b88771-17de-4144-be9f-1c2a21cc397f,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-2a3e2b5f-52a0-4d37-be76-fcc4614f0024,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-ce753212-ce63-4315-b409-e18e9c9c1e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-4ba44fe2-494e-444b-9640-cd4bb54f5153,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-29d056a8-f313-4ffd-9572-abad11b47a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-cf600496-bd89-4d9e-ac48-b04064c7c382,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-26eb245e-3b2c-48ac-b39a-bdf4294bf3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400978317-172.17.0.21-1597710256063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45661,DS-96fb2695-8780-4bef-9b8c-315b3de3ef27,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-e3b88771-17de-4144-be9f-1c2a21cc397f,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-2a3e2b5f-52a0-4d37-be76-fcc4614f0024,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-ce753212-ce63-4315-b409-e18e9c9c1e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-4ba44fe2-494e-444b-9640-cd4bb54f5153,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-29d056a8-f313-4ffd-9572-abad11b47a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-cf600496-bd89-4d9e-ac48-b04064c7c382,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-26eb245e-3b2c-48ac-b39a-bdf4294bf3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5283
