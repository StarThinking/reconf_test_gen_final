reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713584700-172.17.0.10-1597697896082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33133,DS-67095b87-b7e2-4402-bec6-770dc69444d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-91b2d004-7e03-4510-a23a-752cf79bc013,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-cf63e7e4-8746-4f16-b3e4-4bfaa91464ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-75be8173-40fd-4972-a95c-f6655b4571d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-c243a486-4ed2-4e14-b3f4-d6697c8bb5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-11ac1b38-f2fe-4654-8847-62764159a490,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-f2801d9e-7f79-4ad5-9906-1be4332699f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-6b8c6bc9-7f2a-4a7c-b18e-e3012341189c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713584700-172.17.0.10-1597697896082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33133,DS-67095b87-b7e2-4402-bec6-770dc69444d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-91b2d004-7e03-4510-a23a-752cf79bc013,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-cf63e7e4-8746-4f16-b3e4-4bfaa91464ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-75be8173-40fd-4972-a95c-f6655b4571d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-c243a486-4ed2-4e14-b3f4-d6697c8bb5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-11ac1b38-f2fe-4654-8847-62764159a490,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-f2801d9e-7f79-4ad5-9906-1be4332699f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-6b8c6bc9-7f2a-4a7c-b18e-e3012341189c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951033085-172.17.0.10-1597699154891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-43e5c25a-1014-49dc-adc3-750677bcea88,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-0c309487-96ff-490f-a6ba-b48709d5a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-426bbb29-e0f3-49cb-9cec-3c3b1966d716,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-94aa7b87-dda8-42a7-8525-172d57fc0064,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-478d1738-3e30-4dfd-a0ff-6eb133f3e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-5ae57328-6401-4b5f-ac1a-2a95bb47ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-62e60594-0681-473f-8cb9-a1a26f517a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-43ce8072-f82d-47a7-b96c-5054931b5390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951033085-172.17.0.10-1597699154891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-43e5c25a-1014-49dc-adc3-750677bcea88,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-0c309487-96ff-490f-a6ba-b48709d5a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-426bbb29-e0f3-49cb-9cec-3c3b1966d716,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-94aa7b87-dda8-42a7-8525-172d57fc0064,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-478d1738-3e30-4dfd-a0ff-6eb133f3e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-5ae57328-6401-4b5f-ac1a-2a95bb47ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-62e60594-0681-473f-8cb9-a1a26f517a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-43ce8072-f82d-47a7-b96c-5054931b5390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353950640-172.17.0.10-1597699538701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-4055bded-f29d-4697-8b95-cfb9d26a7d26,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-0bdfe370-b95a-455e-9f88-4bd109358ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-1abbe2e8-e57e-4f3c-a924-cb6b85669131,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-cb6a3c8b-dfce-4357-8130-23fea207c315,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-76e0c0b2-84fe-4115-a8ad-5996e9a183d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-82f68c0d-c7e5-4922-8b30-0b17ca152e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-e776b0ea-a5da-417e-b1c9-37a954c23496,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-cc555e8e-cabb-4a43-9556-1decb69ae3d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353950640-172.17.0.10-1597699538701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44854,DS-4055bded-f29d-4697-8b95-cfb9d26a7d26,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-0bdfe370-b95a-455e-9f88-4bd109358ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-1abbe2e8-e57e-4f3c-a924-cb6b85669131,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-cb6a3c8b-dfce-4357-8130-23fea207c315,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-76e0c0b2-84fe-4115-a8ad-5996e9a183d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-82f68c0d-c7e5-4922-8b30-0b17ca152e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-e776b0ea-a5da-417e-b1c9-37a954c23496,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-cc555e8e-cabb-4a43-9556-1decb69ae3d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087003541-172.17.0.10-1597699857095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-4ffc4272-23f7-43d3-be4e-6a11efa10acc,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-dd896da5-8cef-454e-b083-2cb9a29b78a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-e3ed222b-3113-4418-93af-8e2d1f3b73c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-91e1cf83-a275-4aec-b466-74197be3fbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-96347068-5e14-474a-bae7-91cf8fc5ce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-e108b06a-bac0-458c-80d4-9263b3cc855a,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-7913e8be-68c4-45a3-9fa9-c3ea9801ed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-1b5b7cb3-9455-4314-a3f8-545a7bbca4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087003541-172.17.0.10-1597699857095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-4ffc4272-23f7-43d3-be4e-6a11efa10acc,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-dd896da5-8cef-454e-b083-2cb9a29b78a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-e3ed222b-3113-4418-93af-8e2d1f3b73c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-91e1cf83-a275-4aec-b466-74197be3fbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-96347068-5e14-474a-bae7-91cf8fc5ce5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-e108b06a-bac0-458c-80d4-9263b3cc855a,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-7913e8be-68c4-45a3-9fa9-c3ea9801ed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-1b5b7cb3-9455-4314-a3f8-545a7bbca4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156170142-172.17.0.10-1597699998664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-91ad5b68-a3d9-4d23-8cd3-e3a688f371fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-96121a83-e90a-43d9-965a-2d3e3e7cd3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-27325063-68df-4410-a173-8f177fd5a51b,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-13109320-ea30-4117-8e4d-61e855fcb5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-feab6ec7-e86a-4d18-9de4-84eacd86284e,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-4971f0d4-6074-4ae8-82e4-9d8b3c3c762e,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-88d9effb-0570-4ceb-a798-b2c7a1178854,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-5a401bff-1f6c-457d-a79e-f05e4aa553ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156170142-172.17.0.10-1597699998664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-91ad5b68-a3d9-4d23-8cd3-e3a688f371fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-96121a83-e90a-43d9-965a-2d3e3e7cd3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-27325063-68df-4410-a173-8f177fd5a51b,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-13109320-ea30-4117-8e4d-61e855fcb5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-feab6ec7-e86a-4d18-9de4-84eacd86284e,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-4971f0d4-6074-4ae8-82e4-9d8b3c3c762e,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-88d9effb-0570-4ceb-a798-b2c7a1178854,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-5a401bff-1f6c-457d-a79e-f05e4aa553ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247953033-172.17.0.10-1597700061405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41885,DS-a3c6b385-560a-4cb5-b749-bb53508253b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-a7e58c19-b722-4e83-baa5-5e792ebf01fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-61ae71be-aa14-41f7-8c16-bc994f4b6386,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-d45a1e17-e9be-443f-a823-2887d562f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-cba23298-977f-429b-bb62-4a7a77814aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-481eba0b-6174-4048-a893-84291989fed0,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-1f6a12b0-3659-499d-beaa-297a57c661ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-605bba75-6c90-48ae-9bb9-1947e7e6c8c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247953033-172.17.0.10-1597700061405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41885,DS-a3c6b385-560a-4cb5-b749-bb53508253b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-a7e58c19-b722-4e83-baa5-5e792ebf01fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-61ae71be-aa14-41f7-8c16-bc994f4b6386,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-d45a1e17-e9be-443f-a823-2887d562f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-cba23298-977f-429b-bb62-4a7a77814aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-481eba0b-6174-4048-a893-84291989fed0,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-1f6a12b0-3659-499d-beaa-297a57c661ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-605bba75-6c90-48ae-9bb9-1947e7e6c8c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776617076-172.17.0.10-1597700616987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36724,DS-e37dfe07-1cb2-4457-84b9-ddcef8b93ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-2b1a0597-ffd0-49ab-94ae-3e58695df625,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-296230cd-3c7b-418d-8a57-283fcf388f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-3838d530-8275-449d-9d86-222d2152feb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-9821de2d-68f7-453a-a644-043b5e429e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-ad6844f9-2d2c-4556-9f44-96bdf10221df,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-68be2bd0-bc9d-46b0-874d-5811d2d7d373,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-c9884421-3383-48cc-ba53-931a4d489e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776617076-172.17.0.10-1597700616987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36724,DS-e37dfe07-1cb2-4457-84b9-ddcef8b93ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-2b1a0597-ffd0-49ab-94ae-3e58695df625,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-296230cd-3c7b-418d-8a57-283fcf388f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-3838d530-8275-449d-9d86-222d2152feb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-9821de2d-68f7-453a-a644-043b5e429e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-ad6844f9-2d2c-4556-9f44-96bdf10221df,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-68be2bd0-bc9d-46b0-874d-5811d2d7d373,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-c9884421-3383-48cc-ba53-931a4d489e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270076619-172.17.0.10-1597700981632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42791,DS-8c0f265a-81da-4853-94f9-2e5f91548b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-17b342a6-11a4-4f76-ae14-ef8594a6b6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-188e041c-3be3-4b35-a8bd-ac79d0f6afb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-4b3a6b33-0e4a-4e37-9730-2e8a84a2bba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-d2eb1142-b4dd-453c-a2dd-ffe93b30f0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-315b1cbc-1547-4108-a41e-e337aeb8cd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-d922e376-1904-4434-895d-48b982fdd4da,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-a5c48e8d-1001-4c7e-9c52-9b9f295abed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270076619-172.17.0.10-1597700981632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42791,DS-8c0f265a-81da-4853-94f9-2e5f91548b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-17b342a6-11a4-4f76-ae14-ef8594a6b6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-188e041c-3be3-4b35-a8bd-ac79d0f6afb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-4b3a6b33-0e4a-4e37-9730-2e8a84a2bba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-d2eb1142-b4dd-453c-a2dd-ffe93b30f0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-315b1cbc-1547-4108-a41e-e337aeb8cd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-d922e376-1904-4434-895d-48b982fdd4da,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-a5c48e8d-1001-4c7e-9c52-9b9f295abed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722588009-172.17.0.10-1597701285432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-52f33f55-54d7-4148-9651-3a92efea70e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-8f3d8cfb-29dc-4724-9d1a-ad6ec761e0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-c23e3330-19a1-4f39-912b-69055d8d0e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-68c2dab7-3fdc-4347-aacd-514785d155c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-8bc619ea-c158-411b-b1ce-d5fe0b3396df,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-a3aea622-72eb-4895-89eb-065a42bbc93c,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-10edf704-a36a-464e-8fa6-3a7a282d22a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-4399e3ed-f2ac-47c7-9472-98b4b23aab28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722588009-172.17.0.10-1597701285432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-52f33f55-54d7-4148-9651-3a92efea70e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-8f3d8cfb-29dc-4724-9d1a-ad6ec761e0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-c23e3330-19a1-4f39-912b-69055d8d0e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-68c2dab7-3fdc-4347-aacd-514785d155c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-8bc619ea-c158-411b-b1ce-d5fe0b3396df,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-a3aea622-72eb-4895-89eb-065a42bbc93c,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-10edf704-a36a-464e-8fa6-3a7a282d22a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-4399e3ed-f2ac-47c7-9472-98b4b23aab28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247293952-172.17.0.10-1597701322352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33225,DS-0eb1b3f2-ffde-400c-a811-ab05559d11ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-8428b6b2-5d85-4fe5-83fb-42645ca54ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-ae3588ce-71c4-4039-a65e-820ecf3b295a,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-91265cd5-5a93-49cd-ae4e-fc7b129c6825,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-ab2fff37-ac5f-4fe9-9869-a54ce33f138a,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-852a17a8-bfff-46b3-bf23-e3a7817de20e,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-cb944317-37b6-4129-9803-f3537fc38dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-7e9d8460-50bb-4f6c-8390-691bbc723c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247293952-172.17.0.10-1597701322352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33225,DS-0eb1b3f2-ffde-400c-a811-ab05559d11ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-8428b6b2-5d85-4fe5-83fb-42645ca54ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-ae3588ce-71c4-4039-a65e-820ecf3b295a,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-91265cd5-5a93-49cd-ae4e-fc7b129c6825,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-ab2fff37-ac5f-4fe9-9869-a54ce33f138a,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-852a17a8-bfff-46b3-bf23-e3a7817de20e,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-cb944317-37b6-4129-9803-f3537fc38dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-7e9d8460-50bb-4f6c-8390-691bbc723c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640496140-172.17.0.10-1597701650499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44874,DS-c5e82e3c-7658-40c4-83a7-4a2daf7b980d,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-81882d5d-732d-4aec-8bc8-637b0ecf47f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-3c856444-b353-4baf-b636-347db21a3559,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-2b49dc0d-cb76-4a5a-9ebd-969805002f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-54c582db-c7be-4a90-b61b-7d98c13f992a,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-78ab27aa-3c57-4393-9573-808f34e14aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-bf1638b7-2dc4-43a0-b6dd-471e21744245,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-d7ffed34-c46f-4566-b4a8-d64ec400d4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640496140-172.17.0.10-1597701650499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44874,DS-c5e82e3c-7658-40c4-83a7-4a2daf7b980d,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-81882d5d-732d-4aec-8bc8-637b0ecf47f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-3c856444-b353-4baf-b636-347db21a3559,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-2b49dc0d-cb76-4a5a-9ebd-969805002f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-54c582db-c7be-4a90-b61b-7d98c13f992a,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-78ab27aa-3c57-4393-9573-808f34e14aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-bf1638b7-2dc4-43a0-b6dd-471e21744245,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-d7ffed34-c46f-4566-b4a8-d64ec400d4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886614796-172.17.0.10-1597702017566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33591,DS-e3cd01aa-bd95-4cc2-b43e-ae66ffe57fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-41a16d26-0321-4335-a707-562a75bb2f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-975cb95c-f84f-4972-ba5e-3a9d96860e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-6e82fd07-c0e9-4819-a113-7d755f17e0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-66eb79c4-da79-4739-a656-9702c1281bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-94dfb1a8-bf8a-4d25-8bd2-1aa224162dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-f3be102a-5ff9-4463-86ff-84a51382bef9,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-59c0ed43-957d-426b-8143-e31f0affa52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886614796-172.17.0.10-1597702017566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33591,DS-e3cd01aa-bd95-4cc2-b43e-ae66ffe57fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-41a16d26-0321-4335-a707-562a75bb2f80,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-975cb95c-f84f-4972-ba5e-3a9d96860e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-6e82fd07-c0e9-4819-a113-7d755f17e0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-66eb79c4-da79-4739-a656-9702c1281bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-94dfb1a8-bf8a-4d25-8bd2-1aa224162dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-f3be102a-5ff9-4463-86ff-84a51382bef9,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-59c0ed43-957d-426b-8143-e31f0affa52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5509
