reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556490620-172.17.0.15-1597717446178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-8e9b8747-dc34-4526-be55-d282ba86cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-30a97793-7c68-4609-a245-42a126288991,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-be8cfa75-d5ab-466d-982e-6d3fa3cb751a,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-7e178468-621e-44b3-971b-6c1064eef000,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-bd8c88c2-3027-43c2-a760-31d33a25d0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-ddfc2fdb-0263-4ca5-8bd7-44ee997f2c29,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-7c703a45-fffb-4605-9f97-3c1f06cb18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-7bf4d0bd-f003-4a35-83c7-659810569702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556490620-172.17.0.15-1597717446178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-8e9b8747-dc34-4526-be55-d282ba86cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-30a97793-7c68-4609-a245-42a126288991,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-be8cfa75-d5ab-466d-982e-6d3fa3cb751a,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-7e178468-621e-44b3-971b-6c1064eef000,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-bd8c88c2-3027-43c2-a760-31d33a25d0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-ddfc2fdb-0263-4ca5-8bd7-44ee997f2c29,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-7c703a45-fffb-4605-9f97-3c1f06cb18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-7bf4d0bd-f003-4a35-83c7-659810569702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784165953-172.17.0.15-1597717894932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-16de0bac-9810-4b5e-b674-55a1591a7b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-f450e009-16ed-4a95-a870-0c8071f9553a,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-7d4963e1-2edc-456d-a3c1-30c86525b2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-06cdfb6b-22ab-4ad4-a732-00c347464fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-b7d2b3d6-1609-4555-83eb-a72043af42ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-bb9f0274-a8fd-4ba5-ae5b-9c240aef2d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-bc9e14f6-9ad1-4d06-8dc7-7452c3583f51,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-9c9ef958-57f9-48d6-91cf-52638548a992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784165953-172.17.0.15-1597717894932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-16de0bac-9810-4b5e-b674-55a1591a7b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-f450e009-16ed-4a95-a870-0c8071f9553a,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-7d4963e1-2edc-456d-a3c1-30c86525b2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-06cdfb6b-22ab-4ad4-a732-00c347464fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-b7d2b3d6-1609-4555-83eb-a72043af42ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-bb9f0274-a8fd-4ba5-ae5b-9c240aef2d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-bc9e14f6-9ad1-4d06-8dc7-7452c3583f51,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-9c9ef958-57f9-48d6-91cf-52638548a992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784559767-172.17.0.15-1597718036351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32854,DS-9bd77187-3487-4c0e-80a4-857678241a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-ca349a06-be0a-4515-88a7-2ce84635ba82,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-eb22d55c-67c9-4d5b-b426-3eb4c87820a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-c4320fd1-d8ad-47c8-9ec7-d9ea8df36850,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-1b0ceced-fec2-4d25-a62a-be31c5252ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-c9fe8b91-ac7e-4ba2-809b-741827391b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-29250251-7564-4c3a-a2af-ab6524e7d524,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-06264a71-07b7-45b5-9bcb-482d0d2fd08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784559767-172.17.0.15-1597718036351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32854,DS-9bd77187-3487-4c0e-80a4-857678241a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-ca349a06-be0a-4515-88a7-2ce84635ba82,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-eb22d55c-67c9-4d5b-b426-3eb4c87820a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-c4320fd1-d8ad-47c8-9ec7-d9ea8df36850,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-1b0ceced-fec2-4d25-a62a-be31c5252ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-c9fe8b91-ac7e-4ba2-809b-741827391b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-29250251-7564-4c3a-a2af-ab6524e7d524,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-06264a71-07b7-45b5-9bcb-482d0d2fd08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237001751-172.17.0.15-1597718072932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-66a39396-ec5e-449b-8ee2-692149b8d72e,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-8f0c7e92-7554-4ae3-86b6-3c7374b65121,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-1d47153f-73c9-4b66-8821-dab7c0c59a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-a4a4b94c-5ad4-4f2b-aeea-c8ffdcf3d1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-5245b170-7580-4f6c-b360-e0adb4c5b266,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-f67a34f1-172e-4afc-8abf-41f0a8b454cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-b7790af3-9b0e-4de4-b324-f81b43ebb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-ab1501b1-190c-4135-bfdb-c4b3f8c015f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237001751-172.17.0.15-1597718072932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-66a39396-ec5e-449b-8ee2-692149b8d72e,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-8f0c7e92-7554-4ae3-86b6-3c7374b65121,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-1d47153f-73c9-4b66-8821-dab7c0c59a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-a4a4b94c-5ad4-4f2b-aeea-c8ffdcf3d1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-5245b170-7580-4f6c-b360-e0adb4c5b266,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-f67a34f1-172e-4afc-8abf-41f0a8b454cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-b7790af3-9b0e-4de4-b324-f81b43ebb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-ab1501b1-190c-4135-bfdb-c4b3f8c015f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832139706-172.17.0.15-1597718215206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-f4951975-a184-40c3-a6a6-fb79e089bf38,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-05832c92-feff-4752-a11f-d75e0cbd93ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-88159994-7b86-4ee3-9ba0-7abeda4be2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-a7587faf-e111-44bd-9dcd-7a0059310e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-bae6ab22-198d-44e0-834b-5f4ce742d794,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-c16872af-dea1-47af-bfac-678102713676,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-b87adf66-cd46-4b6a-8457-2ef5be7e029f,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-9f98504d-37fb-43b7-a743-7dfc91b65dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832139706-172.17.0.15-1597718215206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-f4951975-a184-40c3-a6a6-fb79e089bf38,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-05832c92-feff-4752-a11f-d75e0cbd93ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-88159994-7b86-4ee3-9ba0-7abeda4be2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-a7587faf-e111-44bd-9dcd-7a0059310e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-bae6ab22-198d-44e0-834b-5f4ce742d794,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-c16872af-dea1-47af-bfac-678102713676,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-b87adf66-cd46-4b6a-8457-2ef5be7e029f,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-9f98504d-37fb-43b7-a743-7dfc91b65dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336054040-172.17.0.15-1597718284568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-8987023a-5d15-4fc9-882f-43d9024cbcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-61c27515-5c09-4f60-96d8-f0d2dd90eabc,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-b8a53347-cea4-4bcd-b3b9-c754f88b30d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-f4d3acb3-29eb-491f-aef4-6cb6410c8499,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-161b68e6-6538-4e46-8d78-b696a89ef62f,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-6c9c00d6-4de3-4db6-a636-e5efcbd6ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-336a0c1f-178b-4bc1-8f71-d6b9dab9617e,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-5d3be88c-60dd-4cb7-a147-0d7af6153de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336054040-172.17.0.15-1597718284568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-8987023a-5d15-4fc9-882f-43d9024cbcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-61c27515-5c09-4f60-96d8-f0d2dd90eabc,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-b8a53347-cea4-4bcd-b3b9-c754f88b30d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-f4d3acb3-29eb-491f-aef4-6cb6410c8499,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-161b68e6-6538-4e46-8d78-b696a89ef62f,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-6c9c00d6-4de3-4db6-a636-e5efcbd6ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-336a0c1f-178b-4bc1-8f71-d6b9dab9617e,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-5d3be88c-60dd-4cb7-a147-0d7af6153de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471354-172.17.0.15-1597718728660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41256,DS-2be15d94-585f-4563-be84-c418e05a856c,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-a48774e1-8a9e-484e-a49d-24ea276a8347,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-eae7af95-1bfc-4840-b1a6-3d9fd6878723,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-6be3b4c1-5273-431a-84f6-2ce3e8c27dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-b7c6f8d9-de46-4ff1-a9b3-b53086c7155b,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-268d58ac-24f0-46c2-b627-cf18e6ede6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-145c35e3-a19b-43b5-8528-07a0fc7ae725,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-c9d0f32c-3ceb-4291-a498-c41461085ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471354-172.17.0.15-1597718728660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41256,DS-2be15d94-585f-4563-be84-c418e05a856c,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-a48774e1-8a9e-484e-a49d-24ea276a8347,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-eae7af95-1bfc-4840-b1a6-3d9fd6878723,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-6be3b4c1-5273-431a-84f6-2ce3e8c27dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-b7c6f8d9-de46-4ff1-a9b3-b53086c7155b,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-268d58ac-24f0-46c2-b627-cf18e6ede6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-145c35e3-a19b-43b5-8528-07a0fc7ae725,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-c9d0f32c-3ceb-4291-a498-c41461085ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930866096-172.17.0.15-1597718773854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-dd84bab6-43d9-4599-ba84-f9d29e886f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-91397be9-cc30-4923-92e0-f7c813d70e89,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-64f027b6-1255-448d-a554-01fed0265755,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-0d62ce12-2303-40c5-85a2-90b4e3e12bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-bbc2d54f-a091-48c8-9869-0882fad9ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-53930d6d-ebd6-43ea-86f2-a80e9547db2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-867c05e8-695c-4608-88ef-76af7dc3316f,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-0cc25ff7-403f-4477-8bd6-eeff4ca059f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930866096-172.17.0.15-1597718773854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-dd84bab6-43d9-4599-ba84-f9d29e886f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-91397be9-cc30-4923-92e0-f7c813d70e89,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-64f027b6-1255-448d-a554-01fed0265755,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-0d62ce12-2303-40c5-85a2-90b4e3e12bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-bbc2d54f-a091-48c8-9869-0882fad9ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-53930d6d-ebd6-43ea-86f2-a80e9547db2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-867c05e8-695c-4608-88ef-76af7dc3316f,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-0cc25ff7-403f-4477-8bd6-eeff4ca059f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457016590-172.17.0.15-1597718802428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-c947b28c-6d98-460b-bd83-5beb276cc0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-a8a0cc82-2c0a-44a4-ac49-3701e1f15194,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-aec4a2a4-d451-465b-b966-9bd56e17f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-2e5747c0-3653-4bf7-b482-42dfdbc08b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-52af46bc-d404-495d-b89b-8616d4673ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-ea90d135-344e-4c44-ada6-7a6c77661240,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-15d5148c-c647-4f84-affb-4c075f975152,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-ece102c3-5905-4bb7-909b-f8c8e4801bbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457016590-172.17.0.15-1597718802428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42777,DS-c947b28c-6d98-460b-bd83-5beb276cc0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-a8a0cc82-2c0a-44a4-ac49-3701e1f15194,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-aec4a2a4-d451-465b-b966-9bd56e17f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-2e5747c0-3653-4bf7-b482-42dfdbc08b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-52af46bc-d404-495d-b89b-8616d4673ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-ea90d135-344e-4c44-ada6-7a6c77661240,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-15d5148c-c647-4f84-affb-4c075f975152,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-ece102c3-5905-4bb7-909b-f8c8e4801bbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101570895-172.17.0.15-1597719175770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44741,DS-d9e243a6-86b5-49d1-af05-cc158261828a,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-ef652ada-7bb4-4e12-ad3b-c0b976d1488f,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-7079a4b7-6bd4-421a-aac9-b89abf2aa6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-a808565c-c085-44c8-bad2-5b8632329be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-12d33aab-e496-4996-85d5-b492c540fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-01605825-02d5-4f75-980a-6c76f45ee13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-39f94c78-550d-4964-b799-0c6dc0e7ed66,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-c9396bd1-bda0-4c90-a65f-61f02af0c5ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101570895-172.17.0.15-1597719175770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44741,DS-d9e243a6-86b5-49d1-af05-cc158261828a,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-ef652ada-7bb4-4e12-ad3b-c0b976d1488f,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-7079a4b7-6bd4-421a-aac9-b89abf2aa6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-a808565c-c085-44c8-bad2-5b8632329be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-12d33aab-e496-4996-85d5-b492c540fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-01605825-02d5-4f75-980a-6c76f45ee13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-39f94c78-550d-4964-b799-0c6dc0e7ed66,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-c9396bd1-bda0-4c90-a65f-61f02af0c5ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349302941-172.17.0.15-1597719495409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-32acdf77-541f-416e-9acf-2f7d4ea8ddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-09fdf2f7-84ac-4c00-90b6-859f146005aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-eb4a89d0-ded4-4b97-9d42-3fb3683f956b,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-aa0951d3-a8d9-48a8-8497-d8daf6c3c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-d7b975d4-24ff-402a-9244-3f07ba0b042f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-77bea19e-2ddd-494e-a4fa-f3ddf6965ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-ac22e53b-023c-452e-b5c1-9321be032d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-e9196099-7a0d-4934-90f1-bd8753124e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349302941-172.17.0.15-1597719495409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45856,DS-32acdf77-541f-416e-9acf-2f7d4ea8ddb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-09fdf2f7-84ac-4c00-90b6-859f146005aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-eb4a89d0-ded4-4b97-9d42-3fb3683f956b,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-aa0951d3-a8d9-48a8-8497-d8daf6c3c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-d7b975d4-24ff-402a-9244-3f07ba0b042f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-77bea19e-2ddd-494e-a4fa-f3ddf6965ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-ac22e53b-023c-452e-b5c1-9321be032d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-e9196099-7a0d-4934-90f1-bd8753124e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473294997-172.17.0.15-1597719784798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45937,DS-5f0c0702-725d-43e6-8b06-1b2f45b53596,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-0105e9dd-eabe-4290-9a82-f7e820ec9169,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-80eec1a2-eb5e-4fae-aa58-ec43b5c81721,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-22a47b48-c81f-4326-b738-1ed7124f08e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-739f71ee-3c2a-4459-b742-9a92cd05c6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-cc0195f8-91a2-47f3-b3da-ccef033da04d,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-43561913-c71c-40f1-8664-feb468ee519d,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-40f39f16-1088-4f77-b1a9-9e611c34f4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473294997-172.17.0.15-1597719784798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45937,DS-5f0c0702-725d-43e6-8b06-1b2f45b53596,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-0105e9dd-eabe-4290-9a82-f7e820ec9169,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-80eec1a2-eb5e-4fae-aa58-ec43b5c81721,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-22a47b48-c81f-4326-b738-1ed7124f08e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-739f71ee-3c2a-4459-b742-9a92cd05c6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-cc0195f8-91a2-47f3-b3da-ccef033da04d,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-43561913-c71c-40f1-8664-feb468ee519d,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-40f39f16-1088-4f77-b1a9-9e611c34f4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559273573-172.17.0.15-1597719990278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46160,DS-4426924f-38d3-42dd-9d9f-d215732c519d,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-77685675-4565-4796-b67e-0719bd934bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-a3097b1c-d341-4e53-b7b8-777f16a00f77,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-f757ab6f-96ed-4dd4-9038-9fdc75b3f09d,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-1d5580a2-c48c-4667-8bf2-67553d687457,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-eea09701-7d19-479c-ab2a-1de1cf29ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-b7a916e0-3514-4636-929f-eb6375374d30,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-6b712f7d-b0ee-4f2b-8c81-fec4dbf9b0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559273573-172.17.0.15-1597719990278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46160,DS-4426924f-38d3-42dd-9d9f-d215732c519d,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-77685675-4565-4796-b67e-0719bd934bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-a3097b1c-d341-4e53-b7b8-777f16a00f77,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-f757ab6f-96ed-4dd4-9038-9fdc75b3f09d,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-1d5580a2-c48c-4667-8bf2-67553d687457,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-eea09701-7d19-479c-ab2a-1de1cf29ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-b7a916e0-3514-4636-929f-eb6375374d30,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-6b712f7d-b0ee-4f2b-8c81-fec4dbf9b0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059602132-172.17.0.15-1597720420095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42175,DS-bb41ac46-107b-49be-948e-2a2c2e6a29a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-5d86284e-1810-4778-9a82-470832b3f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-8119329d-470e-459f-8a82-7710bc81f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-e477dc0a-1b91-49d2-bb51-129ae15bf24e,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-11cf1ef9-3afd-4c36-9f90-c41acc79f222,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-ebe6077e-e3ab-41c6-8272-c6231f299c08,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-046d6beb-a1c8-463d-8f49-85b9c52a432d,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-5b344abc-4a9a-47b3-a502-0d9fba48de19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059602132-172.17.0.15-1597720420095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42175,DS-bb41ac46-107b-49be-948e-2a2c2e6a29a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-5d86284e-1810-4778-9a82-470832b3f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-8119329d-470e-459f-8a82-7710bc81f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-e477dc0a-1b91-49d2-bb51-129ae15bf24e,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-11cf1ef9-3afd-4c36-9f90-c41acc79f222,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-ebe6077e-e3ab-41c6-8272-c6231f299c08,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-046d6beb-a1c8-463d-8f49-85b9c52a432d,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-5b344abc-4a9a-47b3-a502-0d9fba48de19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341029730-172.17.0.15-1597720788119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35287,DS-d13969d2-e05b-4b54-b38d-aba572991402,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-b98a6440-d8fd-4ae2-96c3-8b32c6457af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-e55c12dd-aee3-468b-a412-452bf3549f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-848edd50-6875-4903-a3b8-15fe67daa9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-3ab9038a-5aee-4158-82d4-fe4ac3403438,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-4991ddf5-457e-4c76-a35a-89fad989df51,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-d5d542fd-46d0-4daa-a59e-e087a1976e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-48c6eb44-7171-4495-8033-844d44beebe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1341029730-172.17.0.15-1597720788119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35287,DS-d13969d2-e05b-4b54-b38d-aba572991402,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-b98a6440-d8fd-4ae2-96c3-8b32c6457af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-e55c12dd-aee3-468b-a412-452bf3549f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-848edd50-6875-4903-a3b8-15fe67daa9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-3ab9038a-5aee-4158-82d4-fe4ac3403438,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-4991ddf5-457e-4c76-a35a-89fad989df51,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-d5d542fd-46d0-4daa-a59e-e087a1976e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-48c6eb44-7171-4495-8033-844d44beebe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711259812-172.17.0.15-1597721321177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41148,DS-d2169167-acb7-49bc-aba0-bc8c21e6ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-84c7dfec-c458-41da-928a-257adcc91d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-86a4e004-7523-454e-a497-e731b1057bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-7f0c1171-d4c5-45d1-bc7e-2a9132537673,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-a142b999-2bdf-4879-b4fe-15ca76d0a3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-a46c51bd-ee23-49b9-92c6-86481a2279c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-3a73ec36-e873-4e56-a520-82e2e877849b,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-f46d98f1-4d04-42ac-9214-0c564d4cd33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711259812-172.17.0.15-1597721321177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41148,DS-d2169167-acb7-49bc-aba0-bc8c21e6ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-84c7dfec-c458-41da-928a-257adcc91d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-86a4e004-7523-454e-a497-e731b1057bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-7f0c1171-d4c5-45d1-bc7e-2a9132537673,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-a142b999-2bdf-4879-b4fe-15ca76d0a3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-a46c51bd-ee23-49b9-92c6-86481a2279c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-3a73ec36-e873-4e56-a520-82e2e877849b,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-f46d98f1-4d04-42ac-9214-0c564d4cd33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358320340-172.17.0.15-1597721587734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35170,DS-3588453e-14f3-4d57-9369-e04154d18f72,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-14ff8806-f450-4156-a02e-0abc8f69cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-a026d2ed-9183-4619-aaab-367edc9cabb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-567d70b7-af9d-4cd2-8f3b-24fbc923c73b,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-7ca93f06-8a56-408e-b509-9985659c299f,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-ea67c6ae-ddd8-42e6-9ab4-7bb83626cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-65bb1355-30fb-4b95-a4e3-447cec25e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-82654e80-9eaf-4a13-b779-3ec01305093a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358320340-172.17.0.15-1597721587734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35170,DS-3588453e-14f3-4d57-9369-e04154d18f72,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-14ff8806-f450-4156-a02e-0abc8f69cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-a026d2ed-9183-4619-aaab-367edc9cabb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-567d70b7-af9d-4cd2-8f3b-24fbc923c73b,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-7ca93f06-8a56-408e-b509-9985659c299f,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-ea67c6ae-ddd8-42e6-9ab4-7bb83626cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-65bb1355-30fb-4b95-a4e3-447cec25e2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-82654e80-9eaf-4a13-b779-3ec01305093a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434860329-172.17.0.15-1597721936444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33134,DS-909f1b44-fc7a-4819-aec2-764715c7d9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-057e8870-a027-4f04-8313-8c496ad81769,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-2d9da4b6-b918-438a-a253-7aa181433523,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-bb776ade-ab33-4b31-b0bc-a8b07008cd43,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-e1fa19ab-4a37-4bdd-964e-ab92b259529e,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-ebe87074-0d5b-4d26-aa8a-9c3a92a8ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-a17dc48a-c845-4eac-8c7d-b8d452dcc6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-20dd3185-1378-4a45-8f2a-630e7aa8478d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434860329-172.17.0.15-1597721936444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33134,DS-909f1b44-fc7a-4819-aec2-764715c7d9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-057e8870-a027-4f04-8313-8c496ad81769,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-2d9da4b6-b918-438a-a253-7aa181433523,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-bb776ade-ab33-4b31-b0bc-a8b07008cd43,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-e1fa19ab-4a37-4bdd-964e-ab92b259529e,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-ebe87074-0d5b-4d26-aa8a-9c3a92a8ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-a17dc48a-c845-4eac-8c7d-b8d452dcc6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-20dd3185-1378-4a45-8f2a-630e7aa8478d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5305
