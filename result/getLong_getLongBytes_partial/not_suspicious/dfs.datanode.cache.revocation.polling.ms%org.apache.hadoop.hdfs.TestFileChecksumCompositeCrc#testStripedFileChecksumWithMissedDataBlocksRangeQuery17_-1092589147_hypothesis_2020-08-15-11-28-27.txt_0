reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151360008-172.17.0.18-1597491379528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-547ef5a3-8e1a-4a61-8442-0d541d87630f,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-57ddbfa2-dd44-4303-9d6e-67fde9db2507,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-38b0daae-eb54-4771-911f-2e204bd297b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-86920c28-e6ef-447a-af9c-aa2ec894bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-bdc1e456-892e-4fd8-a045-ff388f086542,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-7ac85c74-e075-48fc-9e1a-81701aa2dd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-a17d53a5-f8fa-45d7-a6f0-26b17f21d135,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-63ff36da-736f-40c7-9771-ae05d0f6426b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151360008-172.17.0.18-1597491379528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-547ef5a3-8e1a-4a61-8442-0d541d87630f,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-57ddbfa2-dd44-4303-9d6e-67fde9db2507,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-38b0daae-eb54-4771-911f-2e204bd297b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-86920c28-e6ef-447a-af9c-aa2ec894bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-bdc1e456-892e-4fd8-a045-ff388f086542,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-7ac85c74-e075-48fc-9e1a-81701aa2dd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-a17d53a5-f8fa-45d7-a6f0-26b17f21d135,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-63ff36da-736f-40c7-9771-ae05d0f6426b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180796941-172.17.0.18-1597491421557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33597,DS-85e647ab-87e9-4d5e-8bd1-afc6e317cb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-c41cb19c-169e-4553-8268-4c48abfb3441,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-2214b2ed-74ee-4986-9d90-22799e07698b,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-f5afc149-157c-4358-895d-439c44968f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-ed6e75db-df24-480b-9e62-95d1965fc6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-2238e278-6a69-4ecd-bdb5-44ec5b2bdf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-92b72a2b-a85f-400a-94fa-1244857d166e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-628c0a80-f6c5-4b5f-9121-fd78a8c302b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180796941-172.17.0.18-1597491421557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33597,DS-85e647ab-87e9-4d5e-8bd1-afc6e317cb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-c41cb19c-169e-4553-8268-4c48abfb3441,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-2214b2ed-74ee-4986-9d90-22799e07698b,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-f5afc149-157c-4358-895d-439c44968f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-ed6e75db-df24-480b-9e62-95d1965fc6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-2238e278-6a69-4ecd-bdb5-44ec5b2bdf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-92b72a2b-a85f-400a-94fa-1244857d166e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-628c0a80-f6c5-4b5f-9121-fd78a8c302b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089148260-172.17.0.18-1597491524840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39874,DS-8e25b8e3-702d-49f5-855b-2d676057570a,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-3e837167-1ec7-407d-8305-3ce0f41a209c,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-0d392590-1e9a-4498-8f56-ce0481b62c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-542ff533-3ab1-484d-84d7-ab35b4c1012a,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-e3ced518-594c-4737-911a-98bfc88ae0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-bada893d-fb84-476f-be6d-4df519eadb95,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-1e34d363-3654-406d-bcd0-5ee7ad8b52cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-107e77a5-c007-4d94-bb1b-64a898b5acc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089148260-172.17.0.18-1597491524840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39874,DS-8e25b8e3-702d-49f5-855b-2d676057570a,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-3e837167-1ec7-407d-8305-3ce0f41a209c,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-0d392590-1e9a-4498-8f56-ce0481b62c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-542ff533-3ab1-484d-84d7-ab35b4c1012a,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-e3ced518-594c-4737-911a-98bfc88ae0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-bada893d-fb84-476f-be6d-4df519eadb95,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-1e34d363-3654-406d-bcd0-5ee7ad8b52cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-107e77a5-c007-4d94-bb1b-64a898b5acc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274583835-172.17.0.18-1597491902941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34489,DS-2b92edbd-fa73-4f60-8bf1-dc078553df14,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-a9abc329-673c-47ec-8812-133b4c8fb450,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-22b0b833-441a-4f96-8d8c-19ea1b7fd363,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-913f9892-5cc5-41fc-bc94-079bfa0606c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-2e269f86-6a7c-4674-80b6-bb4885456994,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-89d0f504-b064-4773-b6ee-088f53cf849a,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-e816d479-fd8a-472b-b6c3-b215e613df12,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-1ae91765-1c96-4e13-bcc7-61da6dc22c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274583835-172.17.0.18-1597491902941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34489,DS-2b92edbd-fa73-4f60-8bf1-dc078553df14,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-a9abc329-673c-47ec-8812-133b4c8fb450,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-22b0b833-441a-4f96-8d8c-19ea1b7fd363,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-913f9892-5cc5-41fc-bc94-079bfa0606c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-2e269f86-6a7c-4674-80b6-bb4885456994,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-89d0f504-b064-4773-b6ee-088f53cf849a,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-e816d479-fd8a-472b-b6c3-b215e613df12,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-1ae91765-1c96-4e13-bcc7-61da6dc22c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733582866-172.17.0.18-1597492225493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34113,DS-ffbc4c97-0c1c-4440-bb81-70c861bdd6db,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-88dc4592-6ad9-470b-b45b-c3bb6888785e,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-4e33905e-cfa3-4117-b892-77add1d84469,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-9e5bd292-ebc6-4480-8020-02a0bfbcd5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-fc029ac2-458f-432a-a4f0-da78063e3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-233c5325-b649-4922-9290-0808421acb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-20d41ad3-3fc3-45b5-bda9-9921d9d3051d,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-52182a51-0abc-4709-9ad4-de5042716bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733582866-172.17.0.18-1597492225493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34113,DS-ffbc4c97-0c1c-4440-bb81-70c861bdd6db,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-88dc4592-6ad9-470b-b45b-c3bb6888785e,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-4e33905e-cfa3-4117-b892-77add1d84469,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-9e5bd292-ebc6-4480-8020-02a0bfbcd5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-fc029ac2-458f-432a-a4f0-da78063e3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-233c5325-b649-4922-9290-0808421acb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-20d41ad3-3fc3-45b5-bda9-9921d9d3051d,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-52182a51-0abc-4709-9ad4-de5042716bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770153063-172.17.0.18-1597492413525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-50a17d11-0a61-4045-ad26-9d603c4044a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-fe9400ac-eda1-4bc0-91a5-21d6bf2cb9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-cae7c678-2650-4199-8599-d4d9d34f3cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-f5ac5dd8-2376-47c8-88fc-1a1cd02713ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-fabd69f7-18fa-4f3f-a2b2-10e72356dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-fd173ac7-520b-4048-89a9-3c11c29a8f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-4569a8f1-e7ed-4602-8946-2242c347bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-3f07de8b-4c47-4c50-a67d-c54558b24e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770153063-172.17.0.18-1597492413525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-50a17d11-0a61-4045-ad26-9d603c4044a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-fe9400ac-eda1-4bc0-91a5-21d6bf2cb9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-cae7c678-2650-4199-8599-d4d9d34f3cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-f5ac5dd8-2376-47c8-88fc-1a1cd02713ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-fabd69f7-18fa-4f3f-a2b2-10e72356dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-fd173ac7-520b-4048-89a9-3c11c29a8f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-4569a8f1-e7ed-4602-8946-2242c347bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-3f07de8b-4c47-4c50-a67d-c54558b24e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461527233-172.17.0.18-1597492480187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45857,DS-15be0d25-16d2-4c7b-92ba-6d11513e10b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-c275bcc9-b156-4765-b01e-3286afe9b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-2f8473d0-d73b-43c9-8b57-1769795cab97,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-162884a5-5399-4424-ac7b-d63814c69a82,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-0b376dcc-c627-4264-b24b-4e09e6b5ff54,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-6c487581-d34a-4e7d-af24-330edca3efbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-d9fc3e2a-719e-4399-a165-d580cf964bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-18b4ed0a-6545-4af2-a8c9-6e6b59517bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461527233-172.17.0.18-1597492480187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45857,DS-15be0d25-16d2-4c7b-92ba-6d11513e10b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-c275bcc9-b156-4765-b01e-3286afe9b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-2f8473d0-d73b-43c9-8b57-1769795cab97,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-162884a5-5399-4424-ac7b-d63814c69a82,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-0b376dcc-c627-4264-b24b-4e09e6b5ff54,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-6c487581-d34a-4e7d-af24-330edca3efbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-d9fc3e2a-719e-4399-a165-d580cf964bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-18b4ed0a-6545-4af2-a8c9-6e6b59517bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032871934-172.17.0.18-1597492927808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43009,DS-18dc959c-849c-498d-b529-6ab106ecc0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-d344fb46-81f3-4bee-a406-88716537a840,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-6508f441-aa44-4866-8543-5bf83818c01c,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-895c490e-e89e-42cd-a4b8-82c8730f3647,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-8771e1a6-b5a5-4538-836d-0b20be2d0c38,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-1d7afc99-a5fa-49de-a17c-ba679eded8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-744df690-9b67-461e-87cd-70e2feb71a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-d7b147df-a250-41f3-adc5-9c4ab5dd2252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032871934-172.17.0.18-1597492927808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43009,DS-18dc959c-849c-498d-b529-6ab106ecc0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-d344fb46-81f3-4bee-a406-88716537a840,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-6508f441-aa44-4866-8543-5bf83818c01c,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-895c490e-e89e-42cd-a4b8-82c8730f3647,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-8771e1a6-b5a5-4538-836d-0b20be2d0c38,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-1d7afc99-a5fa-49de-a17c-ba679eded8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-744df690-9b67-461e-87cd-70e2feb71a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-d7b147df-a250-41f3-adc5-9c4ab5dd2252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177623965-172.17.0.18-1597493070908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43750,DS-04f68302-5d5c-492c-adaf-ac15c1d03606,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-24628889-cdc8-40f9-a3af-3a6c3d8468d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-a13ca9c5-84bb-45ff-805a-a924b70d092c,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-6f49b763-114a-496f-a238-97c4f85fd1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-de909429-884f-40d1-bdca-545779b3f241,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-b6af6c4b-af42-4d42-b1fe-4e2906de78de,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-a04e9c4f-acac-476a-a6ee-26118de55db5,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-36fa1391-1f67-43f2-ba04-63019508c1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177623965-172.17.0.18-1597493070908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43750,DS-04f68302-5d5c-492c-adaf-ac15c1d03606,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-24628889-cdc8-40f9-a3af-3a6c3d8468d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-a13ca9c5-84bb-45ff-805a-a924b70d092c,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-6f49b763-114a-496f-a238-97c4f85fd1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-de909429-884f-40d1-bdca-545779b3f241,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-b6af6c4b-af42-4d42-b1fe-4e2906de78de,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-a04e9c4f-acac-476a-a6ee-26118de55db5,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-36fa1391-1f67-43f2-ba04-63019508c1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706701028-172.17.0.18-1597493224086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-cc12bbec-bf16-4712-ab50-b217445fbd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-83d0f4b1-15b0-4fe4-815c-5134bba588d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a0a64139-1e21-4a0e-a667-9ed3b293ece7,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-51bf581b-327f-4698-a2eb-62d43940ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-4654a3c3-271c-416d-83da-dbbff34b111b,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-455a2ca4-4ca5-4154-85cf-fe3b3af8aa39,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-adab21e7-8e35-4a47-98fd-29b58f500729,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-8d244366-1a7b-44d6-955a-5623d37210fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706701028-172.17.0.18-1597493224086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-cc12bbec-bf16-4712-ab50-b217445fbd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-83d0f4b1-15b0-4fe4-815c-5134bba588d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a0a64139-1e21-4a0e-a667-9ed3b293ece7,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-51bf581b-327f-4698-a2eb-62d43940ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-4654a3c3-271c-416d-83da-dbbff34b111b,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-455a2ca4-4ca5-4154-85cf-fe3b3af8aa39,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-adab21e7-8e35-4a47-98fd-29b58f500729,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-8d244366-1a7b-44d6-955a-5623d37210fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47012588-172.17.0.18-1597493340569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-0e0325fc-4fe0-43a9-9096-3bf10a73d906,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-b99aaa3f-bf97-460e-8524-e23d8aa12fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-e7bb6931-3a83-427f-a588-8c717f44c795,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-37be7f90-0586-49b8-b063-505492ee0db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-69430f8c-532a-4148-97d6-f3094c53a01c,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-f9f89222-967f-4f34-92de-8e2761bef3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-df9f30df-914b-467b-bedb-3672a6ef04b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-0f38ae9f-2004-483a-9618-5bb2c1b1b497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47012588-172.17.0.18-1597493340569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-0e0325fc-4fe0-43a9-9096-3bf10a73d906,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-b99aaa3f-bf97-460e-8524-e23d8aa12fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-e7bb6931-3a83-427f-a588-8c717f44c795,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-37be7f90-0586-49b8-b063-505492ee0db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-69430f8c-532a-4148-97d6-f3094c53a01c,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-f9f89222-967f-4f34-92de-8e2761bef3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-df9f30df-914b-467b-bedb-3672a6ef04b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-0f38ae9f-2004-483a-9618-5bb2c1b1b497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537812126-172.17.0.18-1597493485479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46291,DS-0286cca3-f84f-4a06-b1d8-6f15a9e2ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-18e627f3-2126-49aa-9b94-e1f741479103,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-d0f0b493-54b1-4b30-b108-452484f57af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-e709dedd-7d01-4dbd-b8f6-4ea63f50236d,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-722cadcf-30fb-4157-9e54-b4d1fb3e127c,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-b438c5e7-c5fa-4d2c-a0b4-746b92b4af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-9256e5b6-fca7-48fb-894c-0005cbe36871,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-fb1bef7d-672a-4f7d-ac86-c930ad548c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537812126-172.17.0.18-1597493485479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46291,DS-0286cca3-f84f-4a06-b1d8-6f15a9e2ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-18e627f3-2126-49aa-9b94-e1f741479103,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-d0f0b493-54b1-4b30-b108-452484f57af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-e709dedd-7d01-4dbd-b8f6-4ea63f50236d,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-722cadcf-30fb-4157-9e54-b4d1fb3e127c,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-b438c5e7-c5fa-4d2c-a0b4-746b92b4af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-9256e5b6-fca7-48fb-894c-0005cbe36871,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-fb1bef7d-672a-4f7d-ac86-c930ad548c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183427469-172.17.0.18-1597494027669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39576,DS-e47178d6-cae1-448d-931a-83eae3754b80,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-b31f5308-b2b6-4075-ab89-a1b765f50d49,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-deffea8c-ff24-4c5c-91c4-1b768d2c3470,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-f34e7184-81e0-4e5e-b599-64afa5ea4310,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-d0046a8c-95f3-4e48-8339-2a93e6f6ff78,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-7d02317c-1471-49d5-ae3a-564dea9f4a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-cab0a9b7-ee4d-4141-a4cd-6ea30d7678de,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-f8f4135b-09d1-411e-b456-3bd042f10755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183427469-172.17.0.18-1597494027669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39576,DS-e47178d6-cae1-448d-931a-83eae3754b80,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-b31f5308-b2b6-4075-ab89-a1b765f50d49,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-deffea8c-ff24-4c5c-91c4-1b768d2c3470,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-f34e7184-81e0-4e5e-b599-64afa5ea4310,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-d0046a8c-95f3-4e48-8339-2a93e6f6ff78,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-7d02317c-1471-49d5-ae3a-564dea9f4a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-cab0a9b7-ee4d-4141-a4cd-6ea30d7678de,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-f8f4135b-09d1-411e-b456-3bd042f10755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497882284-172.17.0.18-1597494343811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36882,DS-f5b4d434-8bcb-4ffb-80e1-439f57fbff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-513395f1-1ab0-4fb6-b6e8-70b2b3c053c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-4c2e3b45-502f-41a9-b0b3-8f86aba4fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-5aabff14-50c7-457b-b189-bd1ea811092d,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-5bd488e4-7184-4c82-9a96-ca64d91caa78,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-6ca57aa5-b76a-4fab-b7cc-7aa3cb05b2de,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-302a4460-b4d5-4c18-b855-8043895b2c50,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-627df7eb-f3fc-49e5-978f-b544e6ccf449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497882284-172.17.0.18-1597494343811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36882,DS-f5b4d434-8bcb-4ffb-80e1-439f57fbff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-513395f1-1ab0-4fb6-b6e8-70b2b3c053c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-4c2e3b45-502f-41a9-b0b3-8f86aba4fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-5aabff14-50c7-457b-b189-bd1ea811092d,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-5bd488e4-7184-4c82-9a96-ca64d91caa78,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-6ca57aa5-b76a-4fab-b7cc-7aa3cb05b2de,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-302a4460-b4d5-4c18-b855-8043895b2c50,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-627df7eb-f3fc-49e5-978f-b544e6ccf449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546358640-172.17.0.18-1597494616638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-0301377c-008d-4192-93ac-86cf32144bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-1923a1a2-f64b-4b2b-b20c-64b33242dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-10664d90-e700-447e-ae6d-341de14594e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-6fedb05e-54e7-4e84-af0a-2dcd58c5eb20,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-112ee49e-7d54-4b30-928d-0f6975cb909c,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-a0c7bdf9-9b0f-4cd5-8b15-4881df6ef677,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-4602468b-bfcf-404c-b818-f27cc73d0f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-2929e049-493d-44bb-a25e-cd7fd6790494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546358640-172.17.0.18-1597494616638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-0301377c-008d-4192-93ac-86cf32144bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-1923a1a2-f64b-4b2b-b20c-64b33242dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-10664d90-e700-447e-ae6d-341de14594e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-6fedb05e-54e7-4e84-af0a-2dcd58c5eb20,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-112ee49e-7d54-4b30-928d-0f6975cb909c,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-a0c7bdf9-9b0f-4cd5-8b15-4881df6ef677,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-4602468b-bfcf-404c-b818-f27cc73d0f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-2929e049-493d-44bb-a25e-cd7fd6790494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272333984-172.17.0.18-1597495390304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-82e0fea8-74ce-4005-903a-bec0eeae86a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-7a044a2b-f341-4703-b555-2247d38375d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-d129455b-f9fb-45ec-b7a6-ecf09e9dc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-105364d6-f600-45e2-af8e-b6f0c5267c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-6d4dea5b-9f91-4e6d-9f4a-c59994c8b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-176b41c0-0362-4754-8248-b7244d94fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-12020a7b-bf10-4117-85ea-f76269921618,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-63421093-79ad-42e7-95b9-b351a2215388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272333984-172.17.0.18-1597495390304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-82e0fea8-74ce-4005-903a-bec0eeae86a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-7a044a2b-f341-4703-b555-2247d38375d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-d129455b-f9fb-45ec-b7a6-ecf09e9dc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-105364d6-f600-45e2-af8e-b6f0c5267c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-6d4dea5b-9f91-4e6d-9f4a-c59994c8b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-176b41c0-0362-4754-8248-b7244d94fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-12020a7b-bf10-4117-85ea-f76269921618,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-63421093-79ad-42e7-95b9-b351a2215388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14724455-172.17.0.18-1597495427880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-d2e5e722-f700-4152-82ed-ee36c9fc2084,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-50c03164-8b2f-474f-808a-41680ec49fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-cd356644-ae11-42a3-bbd5-db7ece3134e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-dc5eaa50-bac8-4819-952e-2f64fa02ef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-9a4eb879-aa89-4549-b110-9d307c84ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-9d06fda6-2bd0-4f7f-a60f-2e6a0fda2497,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-485a6818-558e-4ae4-a847-1be93a903cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-7b9d8289-a54f-4eb5-9dbf-7c08217ceee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14724455-172.17.0.18-1597495427880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-d2e5e722-f700-4152-82ed-ee36c9fc2084,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-50c03164-8b2f-474f-808a-41680ec49fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-cd356644-ae11-42a3-bbd5-db7ece3134e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-dc5eaa50-bac8-4819-952e-2f64fa02ef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-9a4eb879-aa89-4549-b110-9d307c84ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-9d06fda6-2bd0-4f7f-a60f-2e6a0fda2497,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-485a6818-558e-4ae4-a847-1be93a903cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-7b9d8289-a54f-4eb5-9dbf-7c08217ceee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430611618-172.17.0.18-1597495461684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42431,DS-d7084528-c4bb-445d-b96a-6f13ffbd475b,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-880ae2e0-0405-4c40-a47e-dc67603fac19,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-1617048b-81a7-497c-9b51-73ebc4571eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-0f7d5dc8-7d0e-4ddb-9268-43260fef4d82,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-14bcc4da-fc2d-4709-989f-aa07010dc27e,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-45ffc0ee-ff06-44e3-8bf6-db34d5a0456c,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-79575402-ca73-4001-b1c3-52ccf7cfd2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-ada147cf-dc18-416f-82d1-8330352ee16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430611618-172.17.0.18-1597495461684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42431,DS-d7084528-c4bb-445d-b96a-6f13ffbd475b,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-880ae2e0-0405-4c40-a47e-dc67603fac19,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-1617048b-81a7-497c-9b51-73ebc4571eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-0f7d5dc8-7d0e-4ddb-9268-43260fef4d82,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-14bcc4da-fc2d-4709-989f-aa07010dc27e,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-45ffc0ee-ff06-44e3-8bf6-db34d5a0456c,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-79575402-ca73-4001-b1c3-52ccf7cfd2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-ada147cf-dc18-416f-82d1-8330352ee16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394863165-172.17.0.18-1597495548144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34799,DS-e8bae516-3caf-4a76-81b0-38f897a9ab95,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-b46c9c56-222b-44fc-82bd-921572ccf5be,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-3a44e730-8bed-4a2d-b9a9-8d0d3753f315,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-36300d4f-6fb0-4a4d-8111-1575b86b2ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-860b2663-35f5-43c8-b661-88a7ad1605ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-bbd9ce16-395c-4801-badf-16e8e92956eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-6c171025-e459-48d5-b381-18ce9825ad04,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-5d784f75-2cf3-405d-9394-6d6bea33c38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394863165-172.17.0.18-1597495548144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34799,DS-e8bae516-3caf-4a76-81b0-38f897a9ab95,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-b46c9c56-222b-44fc-82bd-921572ccf5be,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-3a44e730-8bed-4a2d-b9a9-8d0d3753f315,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-36300d4f-6fb0-4a4d-8111-1575b86b2ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-860b2663-35f5-43c8-b661-88a7ad1605ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-bbd9ce16-395c-4801-badf-16e8e92956eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-6c171025-e459-48d5-b381-18ce9825ad04,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-5d784f75-2cf3-405d-9394-6d6bea33c38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336146832-172.17.0.18-1597495861262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-6878898e-3b56-4883-8a93-f37b8c02e4df,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-3c28e846-622e-406d-ba05-962c09dd2c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-f8e39f9d-30d6-497c-83a3-ec706837153e,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-9dd24f48-4108-4add-ae8b-be75b2b02889,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-7d1564d8-98eb-43ae-8381-f6119eae4f82,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-622b6ec3-be0d-4db2-b755-ac1ae8106b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-710ad4ba-e018-4076-8a74-547d69a786fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-947db99d-50dc-49d4-aaf5-740f8a006178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336146832-172.17.0.18-1597495861262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44901,DS-6878898e-3b56-4883-8a93-f37b8c02e4df,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-3c28e846-622e-406d-ba05-962c09dd2c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-f8e39f9d-30d6-497c-83a3-ec706837153e,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-9dd24f48-4108-4add-ae8b-be75b2b02889,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-7d1564d8-98eb-43ae-8381-f6119eae4f82,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-622b6ec3-be0d-4db2-b755-ac1ae8106b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-710ad4ba-e018-4076-8a74-547d69a786fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-947db99d-50dc-49d4-aaf5-740f8a006178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5589
