reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345933185-172.17.0.11-1597655981382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-f6a0a717-e745-4d65-b1d1-a936fe43150a,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-59f550c8-7119-453c-a0c1-b49327b8bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-5f0254d1-b4c0-4293-9ad5-d5ded7184855,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-51bfe754-6977-4768-9d7a-5ed4d55cf3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7ab9da39-a2e3-4f90-a390-8f8b807b7bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-1b100dff-614c-475f-b6f2-6f23886282e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-e64f2fea-9f33-454c-820f-5620e4e7d0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-f354c12e-80fc-4757-9cf2-015a84164b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345933185-172.17.0.11-1597655981382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-f6a0a717-e745-4d65-b1d1-a936fe43150a,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-59f550c8-7119-453c-a0c1-b49327b8bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-5f0254d1-b4c0-4293-9ad5-d5ded7184855,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-51bfe754-6977-4768-9d7a-5ed4d55cf3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7ab9da39-a2e3-4f90-a390-8f8b807b7bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-1b100dff-614c-475f-b6f2-6f23886282e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-e64f2fea-9f33-454c-820f-5620e4e7d0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-f354c12e-80fc-4757-9cf2-015a84164b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975587614-172.17.0.11-1597656704803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40684,DS-6b3015f5-3183-4729-8360-80ddff2c453d,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-8496d24c-4ec1-45a7-832c-267cd9718f60,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-df07d77c-eb33-4939-9bc7-29d4bf2ab641,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-7560604e-3b75-41f0-bbab-c0da1c8850d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-0ebba434-5294-4ec7-940e-e09be46d929a,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-f08fa020-b5bc-4156-90e6-e5e324713b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-312b79b0-5d7d-4063-89c4-eaaf022cbc80,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-2d05f81c-7c7e-4f8d-b5e6-e432597ef210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975587614-172.17.0.11-1597656704803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40684,DS-6b3015f5-3183-4729-8360-80ddff2c453d,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-8496d24c-4ec1-45a7-832c-267cd9718f60,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-df07d77c-eb33-4939-9bc7-29d4bf2ab641,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-7560604e-3b75-41f0-bbab-c0da1c8850d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-0ebba434-5294-4ec7-940e-e09be46d929a,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-f08fa020-b5bc-4156-90e6-e5e324713b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-312b79b0-5d7d-4063-89c4-eaaf022cbc80,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-2d05f81c-7c7e-4f8d-b5e6-e432597ef210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123146208-172.17.0.11-1597656745447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-ff80bdc6-5fd3-4355-8cd8-fed010360d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-309962cc-9bc1-4453-8148-b9a78b3a3e14,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-19069bab-162f-4f44-95be-645be13f67a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-e77c6d73-e827-42da-bc2a-69902bbc7cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-7587e405-7685-4bef-9e55-ba409becc5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-79048748-393c-4029-a529-a8d969d3f9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-15d13577-a497-4db0-941e-50383c765045,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-51dc1bc3-a8d8-4672-9d05-2c8ddb6832f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123146208-172.17.0.11-1597656745447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-ff80bdc6-5fd3-4355-8cd8-fed010360d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-309962cc-9bc1-4453-8148-b9a78b3a3e14,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-19069bab-162f-4f44-95be-645be13f67a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-e77c6d73-e827-42da-bc2a-69902bbc7cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-7587e405-7685-4bef-9e55-ba409becc5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-79048748-393c-4029-a529-a8d969d3f9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-15d13577-a497-4db0-941e-50383c765045,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-51dc1bc3-a8d8-4672-9d05-2c8ddb6832f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364096815-172.17.0.11-1597657004702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-331a3222-d3eb-4a3b-91a8-7423314fece4,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-03ade4dc-a563-44f8-be7f-1d6d1fac60c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-0763c22c-d092-4e6a-8f28-ae1d7bd2dc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-b55bfa96-86c2-4871-945a-66a48c5d2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-c791541f-d198-4bcd-9cef-3cdfa26f05a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-344601d5-87d8-4efc-ab2f-9eb6b8587614,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-0a0cae56-6af0-4e7c-8c18-d75bb2441577,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-3c851e39-89a1-4305-b730-71885971bbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364096815-172.17.0.11-1597657004702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-331a3222-d3eb-4a3b-91a8-7423314fece4,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-03ade4dc-a563-44f8-be7f-1d6d1fac60c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-0763c22c-d092-4e6a-8f28-ae1d7bd2dc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-b55bfa96-86c2-4871-945a-66a48c5d2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-c791541f-d198-4bcd-9cef-3cdfa26f05a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-344601d5-87d8-4efc-ab2f-9eb6b8587614,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-0a0cae56-6af0-4e7c-8c18-d75bb2441577,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-3c851e39-89a1-4305-b730-71885971bbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061327123-172.17.0.11-1597657202558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-2bc549f1-bf89-494a-8080-ef9264c4b710,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-689fe64d-0d53-45cb-80a3-4f769746bfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-089f1fb4-0bc5-495f-bf44-5820ccbaa9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-6b41a8bf-20b1-4f26-ade3-de1fc67e98de,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-5214801d-77c5-4c3d-a18e-947435598b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-538422b9-87d4-423c-bb4e-15fd853a6e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-971b4936-aad4-40c5-b488-87ad0352759e,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-ec60be95-f025-43d9-aba2-00e15bb5252e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061327123-172.17.0.11-1597657202558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-2bc549f1-bf89-494a-8080-ef9264c4b710,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-689fe64d-0d53-45cb-80a3-4f769746bfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-089f1fb4-0bc5-495f-bf44-5820ccbaa9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-6b41a8bf-20b1-4f26-ade3-de1fc67e98de,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-5214801d-77c5-4c3d-a18e-947435598b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-538422b9-87d4-423c-bb4e-15fd853a6e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-971b4936-aad4-40c5-b488-87ad0352759e,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-ec60be95-f025-43d9-aba2-00e15bb5252e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819539459-172.17.0.11-1597657314005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-8c67e2d8-74f9-4b96-a2d7-735c140ca548,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-6016919d-48d5-405b-9ab4-fa99f3d42798,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-d9d09ef3-e670-4c60-8e03-d2712a211deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-7537edae-eafd-48f9-9953-378ee0c23b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-9cf10374-6313-4ded-9f1a-5f7bfe268fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-8ad7e780-18c5-4232-947f-b8fff7274ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-344bb39f-a7d6-447a-8858-6c6fb2bd20d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-41692bee-dbbd-4caa-85eb-ab1322a6cf72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819539459-172.17.0.11-1597657314005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-8c67e2d8-74f9-4b96-a2d7-735c140ca548,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-6016919d-48d5-405b-9ab4-fa99f3d42798,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-d9d09ef3-e670-4c60-8e03-d2712a211deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-7537edae-eafd-48f9-9953-378ee0c23b96,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-9cf10374-6313-4ded-9f1a-5f7bfe268fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-8ad7e780-18c5-4232-947f-b8fff7274ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-344bb39f-a7d6-447a-8858-6c6fb2bd20d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-41692bee-dbbd-4caa-85eb-ab1322a6cf72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487009187-172.17.0.11-1597657574933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40688,DS-fed73bec-b36d-4294-a60a-78c3e792e906,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-9abc0c5f-b880-42db-b902-3680371a6679,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-ea7277ce-43a1-4372-aadf-9fa1974a4887,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-cc189202-693d-4b72-885a-ce641a78453e,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-76b91c5a-462d-41cc-bbb2-e83e87b2bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-65c50699-d88d-4516-a704-418a849b63b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-ea39c34e-8239-40ee-bf86-5cbf917d7965,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-8fb1f27f-fd7c-421f-a870-ceb234572b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487009187-172.17.0.11-1597657574933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40688,DS-fed73bec-b36d-4294-a60a-78c3e792e906,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-9abc0c5f-b880-42db-b902-3680371a6679,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-ea7277ce-43a1-4372-aadf-9fa1974a4887,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-cc189202-693d-4b72-885a-ce641a78453e,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-76b91c5a-462d-41cc-bbb2-e83e87b2bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-65c50699-d88d-4516-a704-418a849b63b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-ea39c34e-8239-40ee-bf86-5cbf917d7965,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-8fb1f27f-fd7c-421f-a870-ceb234572b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124619825-172.17.0.11-1597657752852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-b45b564d-7cb6-4480-bddd-cad6a8a38997,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-8b48108d-ca2d-4b84-b6ec-e4118abd9497,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-d83fc5e1-0256-4dc8-bee6-5cfcb2fdb524,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-15e4ce46-0a9b-49a3-897e-adcca0cd5efa,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-55c80429-7922-4fa1-8c43-80655fcc7f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-0006e810-655c-48b1-bb95-5b9087fd7dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-9a3867cb-8e17-4687-8482-9f46465c6328,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-94f457a8-9c3a-4c8a-97d1-b67d1651cdee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124619825-172.17.0.11-1597657752852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-b45b564d-7cb6-4480-bddd-cad6a8a38997,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-8b48108d-ca2d-4b84-b6ec-e4118abd9497,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-d83fc5e1-0256-4dc8-bee6-5cfcb2fdb524,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-15e4ce46-0a9b-49a3-897e-adcca0cd5efa,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-55c80429-7922-4fa1-8c43-80655fcc7f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-0006e810-655c-48b1-bb95-5b9087fd7dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-9a3867cb-8e17-4687-8482-9f46465c6328,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-94f457a8-9c3a-4c8a-97d1-b67d1651cdee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160280318-172.17.0.11-1597658433597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-3889899c-94be-41ff-89ae-e01a2a0d8962,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-88fc26d4-23d4-487e-8e36-9a58950a82c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-f6ab81fc-6fdb-4ec0-b2fd-88eca37dc331,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-3f2534e2-cbe9-45d9-9c18-dfa89db8448c,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-7f312482-930c-4a24-bf21-871a916814dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-7a145e15-c423-470c-b711-e1282060f915,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-671357d7-e74e-4436-899b-2121d8e6b1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-289f46b6-1617-4030-bc47-6c3b186d6125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160280318-172.17.0.11-1597658433597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32787,DS-3889899c-94be-41ff-89ae-e01a2a0d8962,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-88fc26d4-23d4-487e-8e36-9a58950a82c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-f6ab81fc-6fdb-4ec0-b2fd-88eca37dc331,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-3f2534e2-cbe9-45d9-9c18-dfa89db8448c,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-7f312482-930c-4a24-bf21-871a916814dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-7a145e15-c423-470c-b711-e1282060f915,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-671357d7-e74e-4436-899b-2121d8e6b1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-289f46b6-1617-4030-bc47-6c3b186d6125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741802766-172.17.0.11-1597658515632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39857,DS-e74890d5-c3a4-4c61-805c-41288bd4b10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-0c7e46f6-85b4-4c96-831a-6a233c8e29e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-b602a1bc-6d84-4903-9d87-72b9659ef8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-f661e73a-8c34-449c-9a98-e75d8ab61f24,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-aa07b62c-909a-4f08-9a35-160e20a0b524,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-9076b1e1-d21d-4de2-b91b-40e4360d784e,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-7312a197-b9a4-4750-ba26-2f30a3d83af1,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-889a222b-4004-43ee-b134-90918ec2b0b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-741802766-172.17.0.11-1597658515632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39857,DS-e74890d5-c3a4-4c61-805c-41288bd4b10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-0c7e46f6-85b4-4c96-831a-6a233c8e29e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-b602a1bc-6d84-4903-9d87-72b9659ef8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-f661e73a-8c34-449c-9a98-e75d8ab61f24,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-aa07b62c-909a-4f08-9a35-160e20a0b524,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-9076b1e1-d21d-4de2-b91b-40e4360d784e,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-7312a197-b9a4-4750-ba26-2f30a3d83af1,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-889a222b-4004-43ee-b134-90918ec2b0b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725122529-172.17.0.11-1597658618089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-5778ee1a-1f14-45b9-9028-fd2b3e6219c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-8152bdf8-a337-42a7-8b46-3af11f308884,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-2fb24c4f-9280-40f0-9ba2-92a3c3d007cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-93f73be3-e4cc-46e0-a6bc-d10a5e3e7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-1b67ecd8-7f32-4d62-8fb8-a85ef3ece524,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-46c156a0-6911-427b-9123-786ac87cd177,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-84b95172-67f1-4373-9443-f7ef31cc09a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-90fe5bb7-817e-4989-836c-467624769ab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725122529-172.17.0.11-1597658618089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-5778ee1a-1f14-45b9-9028-fd2b3e6219c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-8152bdf8-a337-42a7-8b46-3af11f308884,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-2fb24c4f-9280-40f0-9ba2-92a3c3d007cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-93f73be3-e4cc-46e0-a6bc-d10a5e3e7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-1b67ecd8-7f32-4d62-8fb8-a85ef3ece524,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-46c156a0-6911-427b-9123-786ac87cd177,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-84b95172-67f1-4373-9443-f7ef31cc09a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-90fe5bb7-817e-4989-836c-467624769ab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75788826-172.17.0.11-1597659063308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-71631118-34c6-4d85-a14c-974bc277bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-7286a6d2-1602-4da5-bfb7-44f185131bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-9ab9bb0c-1e03-48a0-8120-363cd4c40572,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-25864966-e113-41ff-aed9-4241745a4de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-afd9ac87-9838-44ec-9ae2-9000e475eda9,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-1cb10283-1153-4d8e-b94a-64fe0ef31f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-fd5ea851-52fa-4af6-a1de-9e70431c13ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-c85b0af4-da7d-45dc-b807-1bce299cf6d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75788826-172.17.0.11-1597659063308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-71631118-34c6-4d85-a14c-974bc277bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-7286a6d2-1602-4da5-bfb7-44f185131bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-9ab9bb0c-1e03-48a0-8120-363cd4c40572,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-25864966-e113-41ff-aed9-4241745a4de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-afd9ac87-9838-44ec-9ae2-9000e475eda9,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-1cb10283-1153-4d8e-b94a-64fe0ef31f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-fd5ea851-52fa-4af6-a1de-9e70431c13ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-c85b0af4-da7d-45dc-b807-1bce299cf6d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006904228-172.17.0.11-1597659366202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-0c64d0cc-d53a-4aa2-aec5-1dc77ccfae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-8524db43-41aa-4ae8-83ac-058a85abf424,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-019f4b33-e416-4b33-82d9-f5915c6ad0db,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-1dda7566-f26e-45d8-9966-da84db6366bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-5df815ff-82aa-4733-bf07-8626fdd9fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-834e4a97-17c8-4b6b-8e91-d19c9fbebd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-e68f7583-309b-4ce6-b273-cae26bdb3358,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-c0c6ce7e-6099-41cb-b079-99bf63844ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006904228-172.17.0.11-1597659366202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-0c64d0cc-d53a-4aa2-aec5-1dc77ccfae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-8524db43-41aa-4ae8-83ac-058a85abf424,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-019f4b33-e416-4b33-82d9-f5915c6ad0db,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-1dda7566-f26e-45d8-9966-da84db6366bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-5df815ff-82aa-4733-bf07-8626fdd9fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-834e4a97-17c8-4b6b-8e91-d19c9fbebd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-e68f7583-309b-4ce6-b273-cae26bdb3358,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-c0c6ce7e-6099-41cb-b079-99bf63844ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901582608-172.17.0.11-1597659560726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-1e5f000b-300d-4b8f-9775-90826118b649,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-4090b99f-a6fe-455d-8895-ebd1e89a5191,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-ae365e22-41dc-4ba4-b062-64667f6b786b,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-7c34b629-4ad7-4195-8a0d-4571decd7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-2e4dd499-7cd5-4aec-8560-267f71dd9ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-dc596e30-87e0-4860-b33b-15b0d2914160,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-bd8d7ba1-a071-4e77-a012-56b7f1429b98,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-0f308cb1-4e04-4efa-8952-c50bf3d8a0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901582608-172.17.0.11-1597659560726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-1e5f000b-300d-4b8f-9775-90826118b649,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-4090b99f-a6fe-455d-8895-ebd1e89a5191,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-ae365e22-41dc-4ba4-b062-64667f6b786b,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-7c34b629-4ad7-4195-8a0d-4571decd7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-2e4dd499-7cd5-4aec-8560-267f71dd9ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-dc596e30-87e0-4860-b33b-15b0d2914160,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-bd8d7ba1-a071-4e77-a012-56b7f1429b98,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-0f308cb1-4e04-4efa-8952-c50bf3d8a0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819194166-172.17.0.11-1597659751931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39878,DS-865970e1-43df-48e5-861f-c0f78f9281d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-42da5cfd-e155-4c81-99a7-23a251203de0,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-be2d3a8f-e0b0-4d8a-a9c1-346d7c1132b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-55e3a0db-34ab-4f64-af4a-61e34c91f670,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-e9448d75-f869-434a-913d-ab5b9e0e5211,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-f8cbe3ed-b72b-4606-8fb1-373ffb80ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-5d4fa6fa-4b03-4475-804d-92cf81e1b126,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-1b90ffb1-a7ff-45dd-94e0-290a21cd0c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819194166-172.17.0.11-1597659751931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39878,DS-865970e1-43df-48e5-861f-c0f78f9281d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-42da5cfd-e155-4c81-99a7-23a251203de0,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-be2d3a8f-e0b0-4d8a-a9c1-346d7c1132b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-55e3a0db-34ab-4f64-af4a-61e34c91f670,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-e9448d75-f869-434a-913d-ab5b9e0e5211,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-f8cbe3ed-b72b-4606-8fb1-373ffb80ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-5d4fa6fa-4b03-4475-804d-92cf81e1b126,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-1b90ffb1-a7ff-45dd-94e0-290a21cd0c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838912372-172.17.0.11-1597660092124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43063,DS-7306675b-47f4-4831-9c39-bc19da4b29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-a401e950-acc8-4c62-b215-aa0689f25f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-77ba3e12-121a-46b7-bd15-23f7b1795820,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-795630e2-c5bc-41ec-aac8-a79fd449028c,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-1a5a61b1-d4a6-44eb-8c8e-406a5ff34f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-e27fabb4-b8e4-4f03-8f41-ada77b621b82,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-3fdc910d-a743-4941-8102-5abfdc1fb3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-31b9fcd0-17ef-4524-a846-0520a22431ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838912372-172.17.0.11-1597660092124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43063,DS-7306675b-47f4-4831-9c39-bc19da4b29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-a401e950-acc8-4c62-b215-aa0689f25f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-77ba3e12-121a-46b7-bd15-23f7b1795820,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-795630e2-c5bc-41ec-aac8-a79fd449028c,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-1a5a61b1-d4a6-44eb-8c8e-406a5ff34f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-e27fabb4-b8e4-4f03-8f41-ada77b621b82,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-3fdc910d-a743-4941-8102-5abfdc1fb3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-31b9fcd0-17ef-4524-a846-0520a22431ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533932261-172.17.0.11-1597660177685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-c22ab234-8935-439b-ad6f-68e259fb1c67,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-08341a03-a2b2-4187-8a73-36302d5caceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-2e1844ec-648c-44dc-8138-63092b7487d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-aaf86ad5-9e2e-48de-a60b-e8fbe1240724,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-3dc2202c-e9fc-4d4d-b640-aa955240beb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-f8a2df1a-fdd3-4ef7-bbcf-325b030e625e,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-0ffbe593-008e-4440-8bba-dccc7275fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-f0e4a7da-c565-49ad-8c6c-28eea2fbc562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533932261-172.17.0.11-1597660177685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-c22ab234-8935-439b-ad6f-68e259fb1c67,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-08341a03-a2b2-4187-8a73-36302d5caceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-2e1844ec-648c-44dc-8138-63092b7487d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-aaf86ad5-9e2e-48de-a60b-e8fbe1240724,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-3dc2202c-e9fc-4d4d-b640-aa955240beb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-f8a2df1a-fdd3-4ef7-bbcf-325b030e625e,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-0ffbe593-008e-4440-8bba-dccc7275fa53,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-f0e4a7da-c565-49ad-8c6c-28eea2fbc562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985889288-172.17.0.11-1597660788116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34438,DS-0beccf22-0863-4aa0-8261-ccaa72c9e96e,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-94267e69-e712-40a9-96de-028de0e137f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-2199f123-ce3f-4af3-848c-a6008e9e39e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-68c51b59-fa29-4d65-84b7-99d98c151e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-5b150fa7-7bd7-407c-a634-8692f0615714,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-ef07439e-3719-456f-aaf7-b461d77b7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-e021ad4d-5de3-4421-a02e-2c6ae5de798d,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-ffa03b5c-f033-4f7b-8570-d7c2254d053b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985889288-172.17.0.11-1597660788116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34438,DS-0beccf22-0863-4aa0-8261-ccaa72c9e96e,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-94267e69-e712-40a9-96de-028de0e137f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-2199f123-ce3f-4af3-848c-a6008e9e39e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-68c51b59-fa29-4d65-84b7-99d98c151e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-5b150fa7-7bd7-407c-a634-8692f0615714,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-ef07439e-3719-456f-aaf7-b461d77b7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-e021ad4d-5de3-4421-a02e-2c6ae5de798d,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-ffa03b5c-f033-4f7b-8570-d7c2254d053b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5655
