reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850312128-172.17.0.9-1597663799233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-4778a3f1-1fa4-4965-97a7-074d0a54f7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-fccecdc9-8792-43b8-bf45-54ed4dca2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-daa50c80-646a-46ea-97d6-de6ddcfdd0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-fd82aa89-13ab-406a-b116-3ad403c0898a,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-9c0ce27f-fdb0-4856-9011-f70c02174c21,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-66072a1c-5b0a-4f51-b14d-567d067c7992,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-55c472ff-b982-4f55-b283-819879d63f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-71606a73-f766-4048-89fc-ac496e586e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850312128-172.17.0.9-1597663799233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-4778a3f1-1fa4-4965-97a7-074d0a54f7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-fccecdc9-8792-43b8-bf45-54ed4dca2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-daa50c80-646a-46ea-97d6-de6ddcfdd0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-fd82aa89-13ab-406a-b116-3ad403c0898a,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-9c0ce27f-fdb0-4856-9011-f70c02174c21,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-66072a1c-5b0a-4f51-b14d-567d067c7992,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-55c472ff-b982-4f55-b283-819879d63f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-71606a73-f766-4048-89fc-ac496e586e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684439388-172.17.0.9-1597663900088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45500,DS-c985da2f-6b9e-4fc8-88a8-f4b683c26967,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-d621eb01-c434-464a-876b-50960129890e,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-ee7f5c0d-9399-498c-a4b6-b92f1aaa41f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-3236cf41-fcd6-4607-bd7a-fafbca10c351,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-2173051e-23fd-4475-80e9-a15eee56b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-1c75e228-50ea-4f68-ac2c-6844de8340ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-02299e2a-0f31-46b5-9bfc-9c7e3ba41b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-dbb9655e-ea24-41d6-87dc-dbf70dc0e319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684439388-172.17.0.9-1597663900088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45500,DS-c985da2f-6b9e-4fc8-88a8-f4b683c26967,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-d621eb01-c434-464a-876b-50960129890e,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-ee7f5c0d-9399-498c-a4b6-b92f1aaa41f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-3236cf41-fcd6-4607-bd7a-fafbca10c351,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-2173051e-23fd-4475-80e9-a15eee56b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-1c75e228-50ea-4f68-ac2c-6844de8340ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-02299e2a-0f31-46b5-9bfc-9c7e3ba41b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-dbb9655e-ea24-41d6-87dc-dbf70dc0e319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761218247-172.17.0.9-1597664287652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-6098e090-e2a2-4171-bf00-5450b4a5b327,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-0f3f2e2e-b114-455b-9b9f-420ca1966574,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-99d1f952-6886-4d92-b4ef-daf88926aee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-02e26264-404d-4d6b-92c9-1e4ca413d663,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-818f6c55-51c4-4a09-8cea-e0c92f22b6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-3c48b448-0c29-42df-9233-c201ba828a71,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-9d23bea4-e476-4c98-bcfe-5428eee5a0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-130860ac-a8c5-476f-8573-ddef0e88e147,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761218247-172.17.0.9-1597664287652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-6098e090-e2a2-4171-bf00-5450b4a5b327,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-0f3f2e2e-b114-455b-9b9f-420ca1966574,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-99d1f952-6886-4d92-b4ef-daf88926aee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-02e26264-404d-4d6b-92c9-1e4ca413d663,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-818f6c55-51c4-4a09-8cea-e0c92f22b6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-3c48b448-0c29-42df-9233-c201ba828a71,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-9d23bea4-e476-4c98-bcfe-5428eee5a0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-130860ac-a8c5-476f-8573-ddef0e88e147,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212570384-172.17.0.9-1597664343739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36158,DS-2c14a069-dcf0-481b-93f0-eeb0740414da,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-893b4cf5-b49c-4973-915c-c4c665f040dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-36e7b59f-9a8c-4c3d-9c26-17287e4ef613,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-5c63f08d-813b-4a15-8e52-ef3e2060c90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-75043d8b-5d43-4ca1-90e6-786e7ffa9ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-787d7928-e771-4223-9ab3-6fd5b74edf09,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-8f159b59-a49c-4d4e-ad51-516140d65fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-aaac13a4-0db8-4da6-bb4d-05ed4e781d96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212570384-172.17.0.9-1597664343739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36158,DS-2c14a069-dcf0-481b-93f0-eeb0740414da,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-893b4cf5-b49c-4973-915c-c4c665f040dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-36e7b59f-9a8c-4c3d-9c26-17287e4ef613,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-5c63f08d-813b-4a15-8e52-ef3e2060c90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-75043d8b-5d43-4ca1-90e6-786e7ffa9ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-787d7928-e771-4223-9ab3-6fd5b74edf09,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-8f159b59-a49c-4d4e-ad51-516140d65fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-aaac13a4-0db8-4da6-bb4d-05ed4e781d96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016019422-172.17.0.9-1597664474957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-c55ff434-f662-4597-bf21-af6429dc57cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-cb8ccc8d-99d9-4dab-9295-8bd427d65898,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-d9953d84-60df-4247-b213-ae586e612d21,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-c8ff7296-4aca-4cbe-8cde-d3876c5a2672,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-af25d0e3-e3c9-4458-9fea-6369a492d4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-9b0eb1f7-47fd-4447-9a51-1c69f00c9c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-78bb69ed-1c9e-4897-a397-fe9e31a679c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-9807b66b-1c49-41ae-8e67-7266adbb55aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016019422-172.17.0.9-1597664474957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-c55ff434-f662-4597-bf21-af6429dc57cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-cb8ccc8d-99d9-4dab-9295-8bd427d65898,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-d9953d84-60df-4247-b213-ae586e612d21,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-c8ff7296-4aca-4cbe-8cde-d3876c5a2672,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-af25d0e3-e3c9-4458-9fea-6369a492d4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-9b0eb1f7-47fd-4447-9a51-1c69f00c9c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-78bb69ed-1c9e-4897-a397-fe9e31a679c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-9807b66b-1c49-41ae-8e67-7266adbb55aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267641582-172.17.0.9-1597664532256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35165,DS-a7e5f3a9-d8f8-4e57-bf80-d12261b6e314,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-d5c4f9a8-73a8-4741-a457-0716c0d2c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-eb7a8fb4-f403-4315-8c8f-39e8e07d0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-74f4d039-5101-45a2-8d29-e4962894be40,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-f1f47fca-491f-431c-8251-ae50dab63f13,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-e6f1d859-fe39-47c4-8f99-2da5627c1890,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-e75ccb07-0094-4fdb-8741-0371159bcda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-ff73b3e7-0df6-4458-84b9-07d8d77fbd10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267641582-172.17.0.9-1597664532256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35165,DS-a7e5f3a9-d8f8-4e57-bf80-d12261b6e314,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-d5c4f9a8-73a8-4741-a457-0716c0d2c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-eb7a8fb4-f403-4315-8c8f-39e8e07d0b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-74f4d039-5101-45a2-8d29-e4962894be40,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-f1f47fca-491f-431c-8251-ae50dab63f13,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-e6f1d859-fe39-47c4-8f99-2da5627c1890,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-e75ccb07-0094-4fdb-8741-0371159bcda5,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-ff73b3e7-0df6-4458-84b9-07d8d77fbd10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394515153-172.17.0.9-1597664704872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-f5d44580-ea5e-435b-a5d1-72e23bfa2798,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-2e957426-f11e-4a7a-be11-301838d190e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-d18b273e-db11-4fae-affb-4553f2648830,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-99e832ff-af99-4fba-9605-802e9f70aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-cb9728f8-0069-4faf-bbeb-b844825e8129,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-81245854-6ed3-41c8-ab0f-79fc7776ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-c99a3bee-b98c-4285-9bec-abf00d310cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-8fc2188e-07cc-4e44-88a3-20e1134fd917,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394515153-172.17.0.9-1597664704872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-f5d44580-ea5e-435b-a5d1-72e23bfa2798,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-2e957426-f11e-4a7a-be11-301838d190e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-d18b273e-db11-4fae-affb-4553f2648830,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-99e832ff-af99-4fba-9605-802e9f70aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-cb9728f8-0069-4faf-bbeb-b844825e8129,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-81245854-6ed3-41c8-ab0f-79fc7776ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-c99a3bee-b98c-4285-9bec-abf00d310cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-8fc2188e-07cc-4e44-88a3-20e1134fd917,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289467882-172.17.0.9-1597664830292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39580,DS-b22a3305-2222-4df2-a09c-c36c9513c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-e35ec764-d6ac-4c95-abc8-db70325144b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-23dd4c73-e6fc-4c44-a1c2-27ed8f4fced9,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-0f410687-273a-4946-b123-0c6ba669c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-3d0b9f3d-9c5f-48bc-8fce-b21bce350a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-8270966d-4ebe-4a61-aa6c-15af6420615c,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-c839b083-8e62-4d75-a40e-e25269b0bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-a0d8f214-6a4b-4a4d-9425-244d93ac4c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289467882-172.17.0.9-1597664830292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39580,DS-b22a3305-2222-4df2-a09c-c36c9513c47a,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-e35ec764-d6ac-4c95-abc8-db70325144b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-23dd4c73-e6fc-4c44-a1c2-27ed8f4fced9,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-0f410687-273a-4946-b123-0c6ba669c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-3d0b9f3d-9c5f-48bc-8fce-b21bce350a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-8270966d-4ebe-4a61-aa6c-15af6420615c,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-c839b083-8e62-4d75-a40e-e25269b0bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-a0d8f214-6a4b-4a4d-9425-244d93ac4c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476976781-172.17.0.9-1597664871366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-5b3aeafd-f342-42e1-a45e-043bcd72f67f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-0655ed69-a739-47cb-869e-a57f3f9d5539,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-600b4d16-d5fe-4d46-aa44-4fc70b1c1866,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-fd6d3717-7588-4af2-896c-f414cb12edfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-97715d57-1cb0-4c9f-964a-0ae1581964d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-5ce8fe73-548c-4e39-b0d4-4f521dfffd71,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-ec5c38ad-aaf8-4a65-b15a-09d6039aa7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8f8501a1-4dcc-4a74-afe9-d40bd3bb79f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476976781-172.17.0.9-1597664871366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-5b3aeafd-f342-42e1-a45e-043bcd72f67f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-0655ed69-a739-47cb-869e-a57f3f9d5539,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-600b4d16-d5fe-4d46-aa44-4fc70b1c1866,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-fd6d3717-7588-4af2-896c-f414cb12edfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-97715d57-1cb0-4c9f-964a-0ae1581964d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-5ce8fe73-548c-4e39-b0d4-4f521dfffd71,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-ec5c38ad-aaf8-4a65-b15a-09d6039aa7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8f8501a1-4dcc-4a74-afe9-d40bd3bb79f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796848464-172.17.0.9-1597664913836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44775,DS-0cc51b4d-780c-42d5-b448-43204571099b,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-d25ffdc6-a863-4033-ae7e-b30d53fa959a,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-5718cbda-1b22-47d5-acd3-8af64e2c721b,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-3793ab7d-fd7a-4691-acd0-a2a3e5ac405d,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-6c15e024-ba05-446b-8734-2ca497cd98a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-bf7eb609-d464-4513-99d2-56bf33d637d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-4c031778-8009-4255-942e-a2dc5b0cade1,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-406b6b86-24b9-49a0-89e0-ece46661a1b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796848464-172.17.0.9-1597664913836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44775,DS-0cc51b4d-780c-42d5-b448-43204571099b,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-d25ffdc6-a863-4033-ae7e-b30d53fa959a,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-5718cbda-1b22-47d5-acd3-8af64e2c721b,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-3793ab7d-fd7a-4691-acd0-a2a3e5ac405d,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-6c15e024-ba05-446b-8734-2ca497cd98a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-bf7eb609-d464-4513-99d2-56bf33d637d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-4c031778-8009-4255-942e-a2dc5b0cade1,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-406b6b86-24b9-49a0-89e0-ece46661a1b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380307828-172.17.0.9-1597665045006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-f07ab3ea-8c9d-4584-90d4-6960e778c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-714fe496-cb2e-4cfc-af86-4416ddbab1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-08bd4d30-b074-4814-afa8-bd05ab5986ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-fa1d6a6c-4f00-43c4-bc15-001710024051,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-80c6dea1-82e7-4131-b901-8aafcf04c5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-fdbf3690-44ed-4839-87f5-a80fd3ac8cba,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-8410f7d8-bd02-4ac5-a276-6b596cb431a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-71752cb4-6396-4883-835f-3a51cadf9b98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380307828-172.17.0.9-1597665045006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-f07ab3ea-8c9d-4584-90d4-6960e778c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-714fe496-cb2e-4cfc-af86-4416ddbab1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-08bd4d30-b074-4814-afa8-bd05ab5986ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-fa1d6a6c-4f00-43c4-bc15-001710024051,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-80c6dea1-82e7-4131-b901-8aafcf04c5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-fdbf3690-44ed-4839-87f5-a80fd3ac8cba,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-8410f7d8-bd02-4ac5-a276-6b596cb431a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-71752cb4-6396-4883-835f-3a51cadf9b98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822588085-172.17.0.9-1597665354537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-8dfdb1bc-1aa7-43c4-b8ed-426c94c36e48,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-8c84a2dc-f170-4147-a2ea-77315122abf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-fb07b9eb-bd1e-49e5-be66-1ea8f02ba685,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-a9286013-6284-4e13-b4f1-1f0af397dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-a97e7666-a014-4194-8054-6505d43eceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-4906bc9f-bd84-4b09-90df-fdda090419e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-a018c42c-7753-4c47-8bc0-a18425c83603,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-d2769cd2-1d49-4f45-8c6e-a7a57927eeab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822588085-172.17.0.9-1597665354537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-8dfdb1bc-1aa7-43c4-b8ed-426c94c36e48,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-8c84a2dc-f170-4147-a2ea-77315122abf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-fb07b9eb-bd1e-49e5-be66-1ea8f02ba685,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-a9286013-6284-4e13-b4f1-1f0af397dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-a97e7666-a014-4194-8054-6505d43eceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-4906bc9f-bd84-4b09-90df-fdda090419e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-a018c42c-7753-4c47-8bc0-a18425c83603,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-d2769cd2-1d49-4f45-8c6e-a7a57927eeab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365230332-172.17.0.9-1597665496833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-5a2b8af8-6a3f-4360-8e79-648d74c91b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-9663362e-2a6c-4161-a12a-0c3167482f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-87e6bf18-b4ff-4065-a232-5971e17d5bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-9f5cd707-5fc0-4d5f-a6ba-9ff1771ce7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-645a2065-121e-4960-a0f6-d22a33daa255,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-41daebfd-8b58-4b3e-939f-5e4e56498d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-5f448e30-9f03-42f5-92f6-9114634c3688,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-50ba00d6-e02c-457f-b77a-cab9a6c3c394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365230332-172.17.0.9-1597665496833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-5a2b8af8-6a3f-4360-8e79-648d74c91b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-9663362e-2a6c-4161-a12a-0c3167482f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-87e6bf18-b4ff-4065-a232-5971e17d5bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-9f5cd707-5fc0-4d5f-a6ba-9ff1771ce7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-645a2065-121e-4960-a0f6-d22a33daa255,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-41daebfd-8b58-4b3e-939f-5e4e56498d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-5f448e30-9f03-42f5-92f6-9114634c3688,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-50ba00d6-e02c-457f-b77a-cab9a6c3c394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35442236-172.17.0.9-1597665772754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37112,DS-b1548a55-85b0-4849-a50f-5264e5736cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-b97aaf09-1574-4904-b268-f83ce1e7e1de,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-23f387dd-8d54-4c01-ac5d-d1686b0ca3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-53c95e11-bc7f-4ee1-a41b-56409191a47e,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-7a2aa500-b81a-45de-9b11-ca31c7c1ce77,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-25e89681-28bb-4b24-9108-027b5c9ea7be,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-414a1fe7-f3fa-4ed1-ae1e-e8ea767d3ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-735c1fb0-ffad-4030-b752-db76d00760da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35442236-172.17.0.9-1597665772754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37112,DS-b1548a55-85b0-4849-a50f-5264e5736cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-b97aaf09-1574-4904-b268-f83ce1e7e1de,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-23f387dd-8d54-4c01-ac5d-d1686b0ca3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-53c95e11-bc7f-4ee1-a41b-56409191a47e,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-7a2aa500-b81a-45de-9b11-ca31c7c1ce77,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-25e89681-28bb-4b24-9108-027b5c9ea7be,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-414a1fe7-f3fa-4ed1-ae1e-e8ea767d3ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-735c1fb0-ffad-4030-b752-db76d00760da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569633449-172.17.0.9-1597665825207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-7763f586-5482-4761-9bf6-06af6c04b3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-a3cfa20a-8c8e-4c39-8d1b-dacd1c7b6ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-c6c18d89-a9e2-4856-9e05-9bfe62f59948,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-b0af2fcd-80a7-470d-85e7-8b4bb3535f09,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-80b1c069-e1c3-4b5f-bbe7-b788d7a0ba7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-a9e0885b-3d12-4f6b-99fd-6285bcaa1f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-7b4007aa-8908-4002-862a-c34bfc675e60,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-aeff8661-de7c-4469-afdc-b4bbc26a74fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569633449-172.17.0.9-1597665825207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-7763f586-5482-4761-9bf6-06af6c04b3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-a3cfa20a-8c8e-4c39-8d1b-dacd1c7b6ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-c6c18d89-a9e2-4856-9e05-9bfe62f59948,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-b0af2fcd-80a7-470d-85e7-8b4bb3535f09,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-80b1c069-e1c3-4b5f-bbe7-b788d7a0ba7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-a9e0885b-3d12-4f6b-99fd-6285bcaa1f04,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-7b4007aa-8908-4002-862a-c34bfc675e60,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-aeff8661-de7c-4469-afdc-b4bbc26a74fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651988841-172.17.0.9-1597665869695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-50f76920-e36c-466a-8b46-79e9c7e29155,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-55ac9172-c73b-46e4-a12f-fe86105cd514,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-d3277146-5fa6-4957-9fb4-dc492f9f8070,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-78cbf8ab-35ed-451c-95a1-16447be3fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-aa248a32-adad-4902-80a1-ca1bd5f6e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-c55c99bd-0649-4f6c-88c6-8508d71af4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-3d78c822-4c9c-43d8-a34a-9ae4715a53fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-d8a4471f-8811-4f51-aad2-f73efe194bd5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651988841-172.17.0.9-1597665869695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-50f76920-e36c-466a-8b46-79e9c7e29155,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-55ac9172-c73b-46e4-a12f-fe86105cd514,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-d3277146-5fa6-4957-9fb4-dc492f9f8070,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-78cbf8ab-35ed-451c-95a1-16447be3fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-aa248a32-adad-4902-80a1-ca1bd5f6e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-c55c99bd-0649-4f6c-88c6-8508d71af4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-3d78c822-4c9c-43d8-a34a-9ae4715a53fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-d8a4471f-8811-4f51-aad2-f73efe194bd5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655043392-172.17.0.9-1597666147363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44504,DS-782a9017-16a7-4405-af94-870a7a5043f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-7b086bc5-1c64-4e6d-a5f1-faf3215bf684,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-93a46c72-4b9d-4d4d-b798-77c7503ecbba,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-de94e32d-d9f2-4f8e-b8dc-4a1bbd137990,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-086220ac-823f-402d-8850-5c5a0f82daba,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-1cf50b4d-a9db-47b3-9c6d-8700971cd011,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-06798aa6-9153-4d69-826c-69ec4b088caa,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-b8319b33-364c-49fc-beb6-a371e9c4b588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655043392-172.17.0.9-1597666147363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44504,DS-782a9017-16a7-4405-af94-870a7a5043f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-7b086bc5-1c64-4e6d-a5f1-faf3215bf684,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-93a46c72-4b9d-4d4d-b798-77c7503ecbba,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-de94e32d-d9f2-4f8e-b8dc-4a1bbd137990,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-086220ac-823f-402d-8850-5c5a0f82daba,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-1cf50b4d-a9db-47b3-9c6d-8700971cd011,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-06798aa6-9153-4d69-826c-69ec4b088caa,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-b8319b33-364c-49fc-beb6-a371e9c4b588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401502966-172.17.0.9-1597666901387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40582,DS-7afa64bd-3d84-4223-ac67-822731441306,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-46c9e642-8648-4b86-95d3-e0a7c3655b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-e49d0c3f-13ad-4d51-8f81-11678342cf38,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-5d8ce68b-68eb-439b-b249-d4201fc0b424,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-4b3087ea-086d-421d-9f5e-7c11249f502e,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-6e4078ff-9300-468c-8295-cdc449a5b3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-fcc4908a-7757-4f3b-a581-77b8452c5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-ad7f5960-9384-45d5-b165-6f656156a6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401502966-172.17.0.9-1597666901387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40582,DS-7afa64bd-3d84-4223-ac67-822731441306,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-46c9e642-8648-4b86-95d3-e0a7c3655b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-e49d0c3f-13ad-4d51-8f81-11678342cf38,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-5d8ce68b-68eb-439b-b249-d4201fc0b424,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-4b3087ea-086d-421d-9f5e-7c11249f502e,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-6e4078ff-9300-468c-8295-cdc449a5b3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-fcc4908a-7757-4f3b-a581-77b8452c5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-ad7f5960-9384-45d5-b165-6f656156a6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245802647-172.17.0.9-1597667183822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38430,DS-e669c159-36f9-44df-9cdc-423c52e2c4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-2520aa97-cbca-4148-898f-e0267daf5e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-2d1cdf93-b200-4de1-9b17-1f1b837de36d,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-0e2a0e40-e7a4-4017-be3d-a6ca7027b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-f04fc496-9e91-4fe6-a44d-311722241bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-cabf2b00-3699-423a-83a9-8f20f97aa3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-fb12daaf-f666-418b-b380-9703a1b960ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-9aa5a58d-5a61-4910-8854-a435cec230c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245802647-172.17.0.9-1597667183822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38430,DS-e669c159-36f9-44df-9cdc-423c52e2c4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-2520aa97-cbca-4148-898f-e0267daf5e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-2d1cdf93-b200-4de1-9b17-1f1b837de36d,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-0e2a0e40-e7a4-4017-be3d-a6ca7027b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-f04fc496-9e91-4fe6-a44d-311722241bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-cabf2b00-3699-423a-83a9-8f20f97aa3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-fb12daaf-f666-418b-b380-9703a1b960ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-9aa5a58d-5a61-4910-8854-a435cec230c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911543482-172.17.0.9-1597667420577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-beeacf21-2aa0-41db-bcf2-06673b072aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-33cf4e17-6325-49ce-b225-79ca90fa1e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-234ad173-cfda-407d-b360-2deb32216594,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-a73dbb56-d219-4fd2-8b5b-1eea82e900a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-2c400423-f855-4c18-a877-a8d0e243ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-a8bd9ef1-74b4-4fac-8115-7accca121275,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-5112a4a0-f86f-46de-aeb5-6df25879ba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-58d847bc-d6be-4d39-9139-dc716d8f19c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911543482-172.17.0.9-1597667420577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-beeacf21-2aa0-41db-bcf2-06673b072aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-33cf4e17-6325-49ce-b225-79ca90fa1e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-234ad173-cfda-407d-b360-2deb32216594,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-a73dbb56-d219-4fd2-8b5b-1eea82e900a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-2c400423-f855-4c18-a877-a8d0e243ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-a8bd9ef1-74b4-4fac-8115-7accca121275,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-5112a4a0-f86f-46de-aeb5-6df25879ba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-58d847bc-d6be-4d39-9139-dc716d8f19c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177885234-172.17.0.9-1597667994742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32947,DS-a802c30c-f5a0-400e-9ebd-58b907c79b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-c8ea6e77-b6f3-443d-b609-6936303331f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-1ff8867d-5aa6-464d-81dc-a3abdd4a9673,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-50482374-cbf5-4055-9ea3-fdc2dd870135,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-5b010c4c-ffaf-4ba6-a041-6560457d41fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-2ba713a0-e6c6-4a91-8868-9fd259f1bc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-90e0ec44-ef16-4fbf-8221-d449fd10af31,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-e8152849-802d-4098-ad6c-f7d50f4a3541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177885234-172.17.0.9-1597667994742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32947,DS-a802c30c-f5a0-400e-9ebd-58b907c79b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-c8ea6e77-b6f3-443d-b609-6936303331f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-1ff8867d-5aa6-464d-81dc-a3abdd4a9673,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-50482374-cbf5-4055-9ea3-fdc2dd870135,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-5b010c4c-ffaf-4ba6-a041-6560457d41fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-2ba713a0-e6c6-4a91-8868-9fd259f1bc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-90e0ec44-ef16-4fbf-8221-d449fd10af31,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-e8152849-802d-4098-ad6c-f7d50f4a3541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480658565-172.17.0.9-1597668180581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-fbb4a7ce-d7f1-425b-91ab-e897ba431b74,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-72ff4b2b-3c7e-432f-804b-ce977cc45690,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-dd519dcb-a5ee-4a08-aead-ab5e1813b8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-c3f6cade-7488-480d-97c6-34eee61a46b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-ad5429db-4565-443e-b62e-e5470e435b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-8916d5f0-cff1-48a8-ae36-8831b71a1174,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-f898202c-f237-4222-992c-da6ac97ca252,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-9a389787-ac84-4932-93a4-8319f327c0ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480658565-172.17.0.9-1597668180581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-fbb4a7ce-d7f1-425b-91ab-e897ba431b74,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-72ff4b2b-3c7e-432f-804b-ce977cc45690,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-dd519dcb-a5ee-4a08-aead-ab5e1813b8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-c3f6cade-7488-480d-97c6-34eee61a46b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-ad5429db-4565-443e-b62e-e5470e435b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-8916d5f0-cff1-48a8-ae36-8831b71a1174,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-f898202c-f237-4222-992c-da6ac97ca252,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-9a389787-ac84-4932-93a4-8319f327c0ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353805452-172.17.0.9-1597668322993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-26442553-92c9-475b-8fd5-ec4d61690be1,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-4d607c9c-cd26-4cfb-9612-59ab6302b4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-a301c150-4f0f-40e1-aacc-50fc3a2e12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-0fe46f2c-5569-4a83-82f9-5dd1c6c25aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-b42d94cd-0186-4471-a3da-ac32aad8c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-8caed467-1418-45cf-8740-683901392387,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-2daaa672-629d-41e8-8315-d16c7ac6dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-54b5f700-5f56-44fe-981f-fdd623c3f21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353805452-172.17.0.9-1597668322993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-26442553-92c9-475b-8fd5-ec4d61690be1,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-4d607c9c-cd26-4cfb-9612-59ab6302b4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-a301c150-4f0f-40e1-aacc-50fc3a2e12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-0fe46f2c-5569-4a83-82f9-5dd1c6c25aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-b42d94cd-0186-4471-a3da-ac32aad8c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-8caed467-1418-45cf-8740-683901392387,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-2daaa672-629d-41e8-8315-d16c7ac6dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-54b5f700-5f56-44fe-981f-fdd623c3f21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807109991-172.17.0.9-1597668554173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41180,DS-0a1e757b-7d19-43c7-ae62-920a2905cecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-d8663d97-f13a-40bb-90d9-b75799f7e236,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-68563e71-eae1-4913-9f43-834e65057629,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-397e3587-f5ae-4dd6-b432-8b7e898a8950,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-c396b3ac-8e58-47d7-b494-aac0e87905c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-c7914405-cd6c-4738-92ec-8a48363de11f,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-2fa37f84-e027-43b8-acd1-6127563f495e,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-643b3edb-3fa1-486e-90b9-ec278869d2de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807109991-172.17.0.9-1597668554173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41180,DS-0a1e757b-7d19-43c7-ae62-920a2905cecb,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-d8663d97-f13a-40bb-90d9-b75799f7e236,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-68563e71-eae1-4913-9f43-834e65057629,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-397e3587-f5ae-4dd6-b432-8b7e898a8950,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-c396b3ac-8e58-47d7-b494-aac0e87905c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-c7914405-cd6c-4738-92ec-8a48363de11f,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-2fa37f84-e027-43b8-acd1-6127563f495e,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-643b3edb-3fa1-486e-90b9-ec278869d2de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165205232-172.17.0.9-1597669023490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34785,DS-a9407055-4045-4a20-a19b-d9c178ffbfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-65127946-cb88-430c-884d-e2b6fc710ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-ef28b0f5-ea46-43ab-aa52-c43e6acfe3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-b82d285c-31dc-4360-9116-6fdf642d47d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-baadf9b2-ee4a-46b9-89aa-101128701012,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-3de27e37-b485-4ddc-9e2c-5f6cbaec9230,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-cfd3f7e5-bfeb-4697-8a89-fc945c00192c,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-aabab866-9c86-4cc0-a00f-8c20a8ae2783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165205232-172.17.0.9-1597669023490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34785,DS-a9407055-4045-4a20-a19b-d9c178ffbfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-65127946-cb88-430c-884d-e2b6fc710ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-ef28b0f5-ea46-43ab-aa52-c43e6acfe3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-b82d285c-31dc-4360-9116-6fdf642d47d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-baadf9b2-ee4a-46b9-89aa-101128701012,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-3de27e37-b485-4ddc-9e2c-5f6cbaec9230,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-cfd3f7e5-bfeb-4697-8a89-fc945c00192c,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-aabab866-9c86-4cc0-a00f-8c20a8ae2783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426565937-172.17.0.9-1597669157511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-986b06a5-05ac-4cda-ac82-7f864af6f028,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-cb59b8a8-994b-41ae-b493-5c2e26af2a47,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-0ab96679-28d9-45c3-9713-4723790c0980,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-66063492-1744-4119-b935-99aa92b1f966,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-880cd190-3868-4dc8-99be-bab1bb80a76a,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-0a753fab-cf06-4750-8172-1e6c58151a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-f4014339-f8e3-4a7a-aa7a-d3fd90473de0,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-d991ca74-fc43-4c31-9f44-71f67f933ad3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426565937-172.17.0.9-1597669157511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-986b06a5-05ac-4cda-ac82-7f864af6f028,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-cb59b8a8-994b-41ae-b493-5c2e26af2a47,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-0ab96679-28d9-45c3-9713-4723790c0980,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-66063492-1744-4119-b935-99aa92b1f966,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-880cd190-3868-4dc8-99be-bab1bb80a76a,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-0a753fab-cf06-4750-8172-1e6c58151a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-f4014339-f8e3-4a7a-aa7a-d3fd90473de0,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-d991ca74-fc43-4c31-9f44-71f67f933ad3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37979356-172.17.0.9-1597669247024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36073,DS-1d1dfc95-ce1b-412f-8599-6a45925dd02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-2979b6cc-abf2-45eb-bf19-12b3f97e6438,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-c0e5d270-7895-46fc-b587-5f6443fb0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-2a46d64f-c11e-41f9-bd87-ae87d9b9cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-7c139acf-8def-4cdd-b25e-98a913339aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-1acb04ac-21f4-48e3-b3f4-574e7bcd16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d9b6feb3-472e-4efa-af8c-2170cce5781a,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-aa806031-9516-4c81-9c3c-b9a3edeb9221,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37979356-172.17.0.9-1597669247024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36073,DS-1d1dfc95-ce1b-412f-8599-6a45925dd02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-2979b6cc-abf2-45eb-bf19-12b3f97e6438,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-c0e5d270-7895-46fc-b587-5f6443fb0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-2a46d64f-c11e-41f9-bd87-ae87d9b9cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-7c139acf-8def-4cdd-b25e-98a913339aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-1acb04ac-21f4-48e3-b3f4-574e7bcd16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d9b6feb3-472e-4efa-af8c-2170cce5781a,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-aa806031-9516-4c81-9c3c-b9a3edeb9221,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006052948-172.17.0.9-1597669766046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37092,DS-6b536de2-1431-49dd-8cd5-bd57dca8d639,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-b50a31c4-0cf0-46f9-be63-197bdf2da723,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-58ef3a76-2585-4697-969e-9e92e5269c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-ae560412-fbe1-493b-9fa4-ac912387dd80,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-f6aa277f-4f27-4bba-a921-54ceec0e5aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-1e5bfd39-ffde-47dc-aa70-222ae470780a,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-9c291405-11ec-4384-baa0-075e5ec040fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-bb116c27-3e97-4a03-83eb-7674e889fcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006052948-172.17.0.9-1597669766046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37092,DS-6b536de2-1431-49dd-8cd5-bd57dca8d639,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-b50a31c4-0cf0-46f9-be63-197bdf2da723,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-58ef3a76-2585-4697-969e-9e92e5269c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-ae560412-fbe1-493b-9fa4-ac912387dd80,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-f6aa277f-4f27-4bba-a921-54ceec0e5aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-1e5bfd39-ffde-47dc-aa70-222ae470780a,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-9c291405-11ec-4384-baa0-075e5ec040fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-bb116c27-3e97-4a03-83eb-7674e889fcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557719313-172.17.0.9-1597669952646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43863,DS-b879f337-6f40-447c-af57-94e1b24ea2da,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-8e727460-ba4f-41e2-8886-21e07a87904d,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-1e8a96e6-f604-40cf-9a45-ee152b873d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-f4a8cea2-4b39-4bee-be76-16577e4ef3da,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-29973d75-94a2-42aa-8aa5-0ad671d53e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-8234ab41-8e4b-4731-923d-90e0f6e59901,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-a779c333-070d-4bb1-a628-eb401b805dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-cb9035fb-659a-4afc-ba52-ab8ee75f210e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557719313-172.17.0.9-1597669952646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43863,DS-b879f337-6f40-447c-af57-94e1b24ea2da,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-8e727460-ba4f-41e2-8886-21e07a87904d,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-1e8a96e6-f604-40cf-9a45-ee152b873d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-f4a8cea2-4b39-4bee-be76-16577e4ef3da,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-29973d75-94a2-42aa-8aa5-0ad671d53e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-8234ab41-8e4b-4731-923d-90e0f6e59901,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-a779c333-070d-4bb1-a628-eb401b805dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-cb9035fb-659a-4afc-ba52-ab8ee75f210e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893712218-172.17.0.9-1597670092337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-b6ae087d-526a-4b83-968c-1862cd5ce88d,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-ab7dd15c-acf4-4d9e-8ed1-b4001d8113aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-518573fa-95e0-4970-8f80-d6769c970106,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-6f003c6c-6be4-4f66-9bbd-8f3fe84d426d,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-6840f418-c3e7-4e74-bece-6b7a8c2d6453,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-a4a6d554-9c58-4a2d-82df-73b8d0355a02,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-ce7aa0c8-f0b4-41e1-9f78-60f019a7011d,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-8f561348-5a83-434e-80d0-1b707a635a95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893712218-172.17.0.9-1597670092337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-b6ae087d-526a-4b83-968c-1862cd5ce88d,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-ab7dd15c-acf4-4d9e-8ed1-b4001d8113aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-518573fa-95e0-4970-8f80-d6769c970106,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-6f003c6c-6be4-4f66-9bbd-8f3fe84d426d,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-6840f418-c3e7-4e74-bece-6b7a8c2d6453,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-a4a6d554-9c58-4a2d-82df-73b8d0355a02,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-ce7aa0c8-f0b4-41e1-9f78-60f019a7011d,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-8f561348-5a83-434e-80d0-1b707a635a95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976088003-172.17.0.9-1597670262895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38807,DS-5818111b-d3fb-4075-ae2c-f38f5050fef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-c8a3f2b5-2aa7-46d1-abcd-c9774e5a4363,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-5edb03c6-5730-48fc-8ea2-4d7c5c3f3fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-f1dd3c2d-a1da-45c9-af58-0c537c6d00b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-3d569884-6747-4ab7-9a5b-fb3649b6cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-df408747-1ae3-4c3e-9e9c-a592b411302c,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-7dbc51c9-69e0-42d4-aec8-c742d89ad846,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-4874f09a-a70f-409a-9f82-9ef6bea6320d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976088003-172.17.0.9-1597670262895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38807,DS-5818111b-d3fb-4075-ae2c-f38f5050fef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-c8a3f2b5-2aa7-46d1-abcd-c9774e5a4363,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-5edb03c6-5730-48fc-8ea2-4d7c5c3f3fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-f1dd3c2d-a1da-45c9-af58-0c537c6d00b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-3d569884-6747-4ab7-9a5b-fb3649b6cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-df408747-1ae3-4c3e-9e9c-a592b411302c,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-7dbc51c9-69e0-42d4-aec8-c742d89ad846,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-4874f09a-a70f-409a-9f82-9ef6bea6320d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 1000ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480286446-172.17.0.9-1597670477025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40837,DS-0ca7c2fb-1b63-440e-94ae-84bd702c9b57,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-d7ce552b-cb12-49dd-9abd-0a1ecaa900d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-29a54838-4304-4531-a03c-c498cfead415,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-754652b5-c6b0-4765-bd15-e7211848d877,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-3530c2be-55e2-48b8-b4d5-f39bfb59fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-26458ed0-18a0-44ce-bb4f-98f4e341c363,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-cf570abd-6732-4a75-8ba3-d8fc9beb09fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-8b0ed34f-cf49-4b0b-a4e7-34efbc6c0547,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480286446-172.17.0.9-1597670477025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40837,DS-0ca7c2fb-1b63-440e-94ae-84bd702c9b57,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-d7ce552b-cb12-49dd-9abd-0a1ecaa900d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-29a54838-4304-4531-a03c-c498cfead415,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-754652b5-c6b0-4765-bd15-e7211848d877,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-3530c2be-55e2-48b8-b4d5-f39bfb59fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-26458ed0-18a0-44ce-bb4f-98f4e341c363,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-cf570abd-6732-4a75-8ba3-d8fc9beb09fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-8b0ed34f-cf49-4b0b-a4e7-34efbc6c0547,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 6970
