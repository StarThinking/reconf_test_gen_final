reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022846360-172.17.0.2-1597397958063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-8a1dfc04-8793-4648-8a9e-0c916c901f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-0263a117-147a-4d1f-9c8d-ff0f8c6b2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-cbc5f3dc-1aff-435f-a076-910bd41ffc48,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-9fd64fa9-08b2-4968-9aa9-e07a7d00a71e,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-760ed491-6aa8-42a0-95ea-3b46c383d908,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-f09ac58c-9f3e-4e61-abe6-130d18354850,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-c335fa59-ef87-4f29-bd42-ac2131231fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-4b184cca-69bd-4ad1-be51-0df8b281b0fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022846360-172.17.0.2-1597397958063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-8a1dfc04-8793-4648-8a9e-0c916c901f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-0263a117-147a-4d1f-9c8d-ff0f8c6b2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-cbc5f3dc-1aff-435f-a076-910bd41ffc48,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-9fd64fa9-08b2-4968-9aa9-e07a7d00a71e,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-760ed491-6aa8-42a0-95ea-3b46c383d908,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-f09ac58c-9f3e-4e61-abe6-130d18354850,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-c335fa59-ef87-4f29-bd42-ac2131231fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-4b184cca-69bd-4ad1-be51-0df8b281b0fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358691565-172.17.0.2-1597398300445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-b52bfc73-2d73-416e-9701-d65c18db8762,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-7e29ac4a-804e-4807-b8f4-d23f6a7f75a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-29a8890f-098b-4f01-a634-0f0855d4c0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-fba1eee4-69cc-406a-9d46-55a97f02ad44,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-88c5eba3-09e3-4237-ab3d-8fcc12e27105,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-d72aaeae-a5b9-4dad-b489-9ffb20918b82,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-89174ddc-b2d9-4441-8720-1fc8e8566b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-7a144871-c305-4591-8921-83901594339d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358691565-172.17.0.2-1597398300445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-b52bfc73-2d73-416e-9701-d65c18db8762,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-7e29ac4a-804e-4807-b8f4-d23f6a7f75a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-29a8890f-098b-4f01-a634-0f0855d4c0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-fba1eee4-69cc-406a-9d46-55a97f02ad44,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-88c5eba3-09e3-4237-ab3d-8fcc12e27105,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-d72aaeae-a5b9-4dad-b489-9ffb20918b82,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-89174ddc-b2d9-4441-8720-1fc8e8566b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-7a144871-c305-4591-8921-83901594339d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446480509-172.17.0.2-1597399074023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46816,DS-0fb11d6e-a805-4428-afcf-c548150f4d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-67eb0452-7ac3-4b9f-84cb-dbfa6ecfe25a,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-e87eae0e-974c-4e03-bb28-272fdd912cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-a3b7cad9-186c-44e5-947a-44fb253415fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-b6d5dcbe-0fac-44db-9d25-cae38a2acbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-3ab69789-a6ca-47a3-b2f3-4032b3a6de3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-1f858f8c-e6d0-47d2-bb40-040c05134a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-46e35287-b3f6-423c-84a5-caef1bc1072c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446480509-172.17.0.2-1597399074023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46816,DS-0fb11d6e-a805-4428-afcf-c548150f4d10,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-67eb0452-7ac3-4b9f-84cb-dbfa6ecfe25a,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-e87eae0e-974c-4e03-bb28-272fdd912cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-a3b7cad9-186c-44e5-947a-44fb253415fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-b6d5dcbe-0fac-44db-9d25-cae38a2acbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-3ab69789-a6ca-47a3-b2f3-4032b3a6de3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-1f858f8c-e6d0-47d2-bb40-040c05134a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-46e35287-b3f6-423c-84a5-caef1bc1072c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925174405-172.17.0.2-1597399116152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39530,DS-6a26e389-e909-41b0-8730-8e6017c031e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-5b68e9c4-5bbe-426e-a3a2-cd4e9fdf445f,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-a7ca825a-2bea-4827-8013-54c2b0a3e1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-01c6aba4-a6b0-4022-ba64-430e747fce27,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-afe1d4ca-a5a8-4157-a460-4f86e62a3404,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-ec8c5968-4bde-45ae-9bce-c117029fcfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-76090bda-cc63-4ae9-bf5b-dc2fe6eb9066,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-4e991b66-2fe0-4fe6-aff9-2ce31433f672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925174405-172.17.0.2-1597399116152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39530,DS-6a26e389-e909-41b0-8730-8e6017c031e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-5b68e9c4-5bbe-426e-a3a2-cd4e9fdf445f,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-a7ca825a-2bea-4827-8013-54c2b0a3e1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-01c6aba4-a6b0-4022-ba64-430e747fce27,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-afe1d4ca-a5a8-4157-a460-4f86e62a3404,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-ec8c5968-4bde-45ae-9bce-c117029fcfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-76090bda-cc63-4ae9-bf5b-dc2fe6eb9066,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-4e991b66-2fe0-4fe6-aff9-2ce31433f672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588924331-172.17.0.2-1597399409148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37178,DS-e25819af-bbe4-43fc-9fca-43387fe91106,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-a68a5244-9441-46cc-bd0d-7bfc07f771ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-c73b2337-8d78-4b79-b34e-4a13f0f8d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-b4f7bb6d-875f-4945-94f1-81822dd9b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-1255ffe3-6bfc-43c7-b3be-126360145e94,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-ac6f5a0b-9aa1-4981-a47f-c56aee3bece8,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-f4499d3f-cb53-4e22-a536-b7c14e00e909,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-5b40b5e5-f96a-4bdf-8888-002e553a2c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588924331-172.17.0.2-1597399409148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37178,DS-e25819af-bbe4-43fc-9fca-43387fe91106,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-a68a5244-9441-46cc-bd0d-7bfc07f771ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-c73b2337-8d78-4b79-b34e-4a13f0f8d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-b4f7bb6d-875f-4945-94f1-81822dd9b1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-1255ffe3-6bfc-43c7-b3be-126360145e94,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-ac6f5a0b-9aa1-4981-a47f-c56aee3bece8,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-f4499d3f-cb53-4e22-a536-b7c14e00e909,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-5b40b5e5-f96a-4bdf-8888-002e553a2c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211869868-172.17.0.2-1597399536064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-cc9f320a-a02d-4789-ac88-3d50f5630fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-09095a85-3636-4cfa-8ff4-5490bb0f29bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-2d8a0fe9-7734-4660-a1d5-08c04a680cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-a9f1e6ff-c873-44e8-baf5-873f3287740e,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-1f41b41e-56c6-4e3e-ba8d-9ffb253ef287,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-185342a8-aacb-4d62-8673-fa297d0bec2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-d7eba9d1-de2c-4fd8-b4f9-09258c5b33d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-6d2f5a8d-e656-4f3d-b409-97c1299d361e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211869868-172.17.0.2-1597399536064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-cc9f320a-a02d-4789-ac88-3d50f5630fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-09095a85-3636-4cfa-8ff4-5490bb0f29bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-2d8a0fe9-7734-4660-a1d5-08c04a680cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-a9f1e6ff-c873-44e8-baf5-873f3287740e,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-1f41b41e-56c6-4e3e-ba8d-9ffb253ef287,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-185342a8-aacb-4d62-8673-fa297d0bec2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-d7eba9d1-de2c-4fd8-b4f9-09258c5b33d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-6d2f5a8d-e656-4f3d-b409-97c1299d361e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774935471-172.17.0.2-1597399621850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-169b1bc2-b56d-4377-b1cf-9619432beefe,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-8dcac288-c902-46e0-8c30-9d4f4c3b51cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-fe1dc7aa-f71d-4e16-b110-285e2d68fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-b3499765-eb56-4616-a459-4cdedd94c536,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-63b4c2bb-a2f2-49f3-9505-30ec8bd8354f,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-79ede053-f35f-495c-bc15-081c0afb3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-4e19d6cd-093c-4582-af9a-0247fd6134e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-9b55e679-09aa-408d-a683-38d7231067b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774935471-172.17.0.2-1597399621850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-169b1bc2-b56d-4377-b1cf-9619432beefe,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-8dcac288-c902-46e0-8c30-9d4f4c3b51cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-fe1dc7aa-f71d-4e16-b110-285e2d68fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-b3499765-eb56-4616-a459-4cdedd94c536,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-63b4c2bb-a2f2-49f3-9505-30ec8bd8354f,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-79ede053-f35f-495c-bc15-081c0afb3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-4e19d6cd-093c-4582-af9a-0247fd6134e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-9b55e679-09aa-408d-a683-38d7231067b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051463559-172.17.0.2-1597399732427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-235ec4ba-58ec-4fa6-9c15-4a86a33f061e,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-3c500c4d-095d-4d78-802e-2d9e92d76fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-2190fa04-3ef3-4306-96eb-99afc833663a,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-ccdb3fbc-4c6e-4004-8604-6cf1370eda64,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-afaa31b3-f8fa-4bda-83a0-39015359bae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-ae999ded-57a7-4319-96c2-0498cbab38e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-85e7567f-252f-482d-8c86-c5ef54dfe06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-24d7b1cd-6b19-4aef-bac1-ed356d722911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051463559-172.17.0.2-1597399732427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-235ec4ba-58ec-4fa6-9c15-4a86a33f061e,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-3c500c4d-095d-4d78-802e-2d9e92d76fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-2190fa04-3ef3-4306-96eb-99afc833663a,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-ccdb3fbc-4c6e-4004-8604-6cf1370eda64,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-afaa31b3-f8fa-4bda-83a0-39015359bae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-ae999ded-57a7-4319-96c2-0498cbab38e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-85e7567f-252f-482d-8c86-c5ef54dfe06e,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-24d7b1cd-6b19-4aef-bac1-ed356d722911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828701957-172.17.0.2-1597400054032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-107ded21-8c1d-414c-a67c-f89252228a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-bbc0af56-6319-4e8e-865a-24946d479086,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-940eb456-ccc3-4953-a2e8-b4d337e885c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-64f0953e-c4b9-4c69-8c2f-3d0c96f076e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-1bbc4545-e9f3-47f8-aa7d-5df54ce37751,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-6a21f754-e967-4c9c-86b1-afe0d4abd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-43096f00-84b5-4d5a-abb0-d29cdc31db83,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-01733035-8692-460c-9a65-eed706c4e547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828701957-172.17.0.2-1597400054032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-107ded21-8c1d-414c-a67c-f89252228a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-bbc0af56-6319-4e8e-865a-24946d479086,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-940eb456-ccc3-4953-a2e8-b4d337e885c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-64f0953e-c4b9-4c69-8c2f-3d0c96f076e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-1bbc4545-e9f3-47f8-aa7d-5df54ce37751,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-6a21f754-e967-4c9c-86b1-afe0d4abd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-43096f00-84b5-4d5a-abb0-d29cdc31db83,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-01733035-8692-460c-9a65-eed706c4e547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711485940-172.17.0.2-1597400161922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37894,DS-14396b09-6eff-4a70-ac80-abea1ab357d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-010eec31-358f-4fa7-b2bb-d8ab02fa8228,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-fb4aa719-7fb3-4c28-a05b-fc8c2bcb2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-b43a56b4-0e64-4277-be42-9fe60fed4684,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-03a169f6-1bab-4e54-96e5-59806680a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e15a0b13-fcd8-4c4e-9080-d253fd05abc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-5835a30a-8187-4653-b435-b6a420c1a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-d928e487-c302-4c83-96f9-eff2312d9c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711485940-172.17.0.2-1597400161922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37894,DS-14396b09-6eff-4a70-ac80-abea1ab357d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-010eec31-358f-4fa7-b2bb-d8ab02fa8228,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-fb4aa719-7fb3-4c28-a05b-fc8c2bcb2ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-b43a56b4-0e64-4277-be42-9fe60fed4684,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-03a169f6-1bab-4e54-96e5-59806680a7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e15a0b13-fcd8-4c4e-9080-d253fd05abc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-5835a30a-8187-4653-b435-b6a420c1a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-d928e487-c302-4c83-96f9-eff2312d9c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212498778-172.17.0.2-1597400314197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-6edd19b0-cff4-4cf9-bbb1-422186b2c515,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-a64329ec-fa0f-4a89-872c-3a70c22cd53d,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-6ffbe621-2c77-488f-b7aa-7c6bf5b2a429,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-41586aaf-7449-408a-bcf6-6604651b805d,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-e6476ad9-6a81-43fa-b0b4-64cb4bb9dfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-ef6226df-cf73-4095-a25f-6d14e4839be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-9c71dfcf-5548-46f4-b502-1e166cedae07,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-5bbdadff-836a-4ef6-b224-17695b8aacc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212498778-172.17.0.2-1597400314197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-6edd19b0-cff4-4cf9-bbb1-422186b2c515,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-a64329ec-fa0f-4a89-872c-3a70c22cd53d,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-6ffbe621-2c77-488f-b7aa-7c6bf5b2a429,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-41586aaf-7449-408a-bcf6-6604651b805d,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-e6476ad9-6a81-43fa-b0b4-64cb4bb9dfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-ef6226df-cf73-4095-a25f-6d14e4839be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-9c71dfcf-5548-46f4-b502-1e166cedae07,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-5bbdadff-836a-4ef6-b224-17695b8aacc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693796061-172.17.0.2-1597400494421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-a61798e8-8499-4390-ac33-c153a3f1814a,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-a6a06d7f-6ccb-4423-b3b5-700c501de0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-361253cf-f04a-4b67-9664-d20b22c6f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-17386ae4-a947-4945-bb05-b0f646c4377f,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-f84f9ab3-2c4c-4058-bc73-3ce6a64a0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-853dfbe4-7398-44f2-95c1-e7f43decd91f,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-45e06bda-ea96-4d02-ba4f-5111c2e5d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-0d3d03b6-6041-4a06-9096-e1a874c989e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693796061-172.17.0.2-1597400494421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-a61798e8-8499-4390-ac33-c153a3f1814a,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-a6a06d7f-6ccb-4423-b3b5-700c501de0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-361253cf-f04a-4b67-9664-d20b22c6f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-17386ae4-a947-4945-bb05-b0f646c4377f,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-f84f9ab3-2c4c-4058-bc73-3ce6a64a0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-853dfbe4-7398-44f2-95c1-e7f43decd91f,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-45e06bda-ea96-4d02-ba4f-5111c2e5d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-0d3d03b6-6041-4a06-9096-e1a874c989e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56676124-172.17.0.2-1597400631242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-e62c984f-b5d7-48b9-9ae2-5a38d13a9790,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-b33aecd9-9611-4bbf-ba4d-1df5f3edb0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-3a9a68f1-df17-475a-9027-cb1044bf060e,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-a81feb20-ea4a-4d51-901a-950a80cfef77,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-93a4120c-d6e2-4eb6-ad3f-8b62cdc22ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-626bbac9-a2dd-4d17-85ff-5895c26e4608,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-21a89c4c-0c2f-4970-bd7d-e1a83f1c2706,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-19c04010-be81-44c6-a553-71ebce6876f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56676124-172.17.0.2-1597400631242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-e62c984f-b5d7-48b9-9ae2-5a38d13a9790,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-b33aecd9-9611-4bbf-ba4d-1df5f3edb0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-3a9a68f1-df17-475a-9027-cb1044bf060e,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-a81feb20-ea4a-4d51-901a-950a80cfef77,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-93a4120c-d6e2-4eb6-ad3f-8b62cdc22ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-626bbac9-a2dd-4d17-85ff-5895c26e4608,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-21a89c4c-0c2f-4970-bd7d-e1a83f1c2706,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-19c04010-be81-44c6-a553-71ebce6876f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54416532-172.17.0.2-1597401271532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-4d9aaa64-9e05-437d-9233-c17f76fd7bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-29ff7485-a905-4843-920d-a40694ed1e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-c8315d1e-158a-422c-a3f8-ca3e2657bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-d92143b9-4eb8-43b8-974c-e6c70cfc314e,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-204b29b5-e604-4ef8-9aa7-01b48cd4aa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-574eb3f1-45ac-4387-abd7-f33e1d0a187b,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-0da564ee-9de5-40b8-85a9-c31a687687a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-239efa1a-5721-4de5-ba68-bf30cfb60749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54416532-172.17.0.2-1597401271532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-4d9aaa64-9e05-437d-9233-c17f76fd7bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-29ff7485-a905-4843-920d-a40694ed1e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-c8315d1e-158a-422c-a3f8-ca3e2657bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-d92143b9-4eb8-43b8-974c-e6c70cfc314e,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-204b29b5-e604-4ef8-9aa7-01b48cd4aa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-574eb3f1-45ac-4387-abd7-f33e1d0a187b,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-0da564ee-9de5-40b8-85a9-c31a687687a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-239efa1a-5721-4de5-ba68-bf30cfb60749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067905665-172.17.0.2-1597401734189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-1790754d-1a62-4d62-a11f-3b54cd72fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-a8b18895-53d0-4fea-8a80-bf8df086dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-7e5eff68-7115-46b0-b84e-0029d3b7d92f,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-eebb5efa-f845-49fd-8248-b9fb85baf22c,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-498a7125-a94a-456e-b911-d0eb6d774139,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-928293f7-8d54-442d-b52e-2400e5d40275,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-26527497-784f-42c7-872a-d4bc9262b25f,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-a1985ed4-798a-45e0-875d-592d4dd3ae0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067905665-172.17.0.2-1597401734189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-1790754d-1a62-4d62-a11f-3b54cd72fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-a8b18895-53d0-4fea-8a80-bf8df086dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-7e5eff68-7115-46b0-b84e-0029d3b7d92f,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-eebb5efa-f845-49fd-8248-b9fb85baf22c,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-498a7125-a94a-456e-b911-d0eb6d774139,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-928293f7-8d54-442d-b52e-2400e5d40275,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-26527497-784f-42c7-872a-d4bc9262b25f,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-a1985ed4-798a-45e0-875d-592d4dd3ae0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320023369-172.17.0.2-1597401803076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45688,DS-4d268bd6-d9d0-40eb-a13d-ebc898c5f3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-c0354928-d7e2-4070-9fe7-043aa932c231,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-3ce23f2e-53de-4e15-b906-556d4e888b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-a3904266-35e2-411d-ba24-f051b9033fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-0e9a258d-acbd-47b9-9807-11b3793d7133,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-e71dd7e5-a77b-4b3b-b7a4-f4a4f7310f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-a15a5c5c-b32f-404b-b7c2-c683858fcb33,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-df8c9cd3-9a0c-4110-81bf-a3e35c32db45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320023369-172.17.0.2-1597401803076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45688,DS-4d268bd6-d9d0-40eb-a13d-ebc898c5f3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-c0354928-d7e2-4070-9fe7-043aa932c231,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-3ce23f2e-53de-4e15-b906-556d4e888b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-a3904266-35e2-411d-ba24-f051b9033fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-0e9a258d-acbd-47b9-9807-11b3793d7133,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-e71dd7e5-a77b-4b3b-b7a4-f4a4f7310f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-a15a5c5c-b32f-404b-b7c2-c683858fcb33,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-df8c9cd3-9a0c-4110-81bf-a3e35c32db45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357420188-172.17.0.2-1597401843415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44672,DS-3ec24c75-deac-4087-89f3-56737f69d168,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-539e8bc1-089a-4a06-8160-c421a9cb0014,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-9c5c90d9-771b-4913-8324-d17b34a39305,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-a39ee84e-be53-4f5a-95c7-7968f41edcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-c9397cf8-11e0-451d-b6d9-a2017825682d,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a242ca47-ea5d-4597-ad3e-fbca375a676b,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-5a8ee754-7eef-4f75-bd2a-aad05e8a7843,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-9912d7ab-aa66-46aa-8f0c-8717ff8197f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357420188-172.17.0.2-1597401843415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44672,DS-3ec24c75-deac-4087-89f3-56737f69d168,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-539e8bc1-089a-4a06-8160-c421a9cb0014,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-9c5c90d9-771b-4913-8324-d17b34a39305,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-a39ee84e-be53-4f5a-95c7-7968f41edcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-c9397cf8-11e0-451d-b6d9-a2017825682d,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-a242ca47-ea5d-4597-ad3e-fbca375a676b,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-5a8ee754-7eef-4f75-bd2a-aad05e8a7843,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-9912d7ab-aa66-46aa-8f0c-8717ff8197f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016939626-172.17.0.2-1597402001830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-0e3ac30f-5d5f-4c4d-b8a3-8d16c493cce2,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-05aa668d-421b-4f0d-8c71-2dce2bd41370,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-2bddc466-2348-47dc-84ab-9171b09d7d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-c7ae13e0-cad6-4dec-a564-9ed443a1214c,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-122e07fa-64e2-493b-8b4c-b596b2aa3226,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-194381b8-206e-4888-92c4-9ca60964bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-18f8258d-5e05-4ff4-825c-8f9ab54271da,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-810486e3-afaf-4e78-b37a-82c6ca85bc1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016939626-172.17.0.2-1597402001830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-0e3ac30f-5d5f-4c4d-b8a3-8d16c493cce2,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-05aa668d-421b-4f0d-8c71-2dce2bd41370,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-2bddc466-2348-47dc-84ab-9171b09d7d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-c7ae13e0-cad6-4dec-a564-9ed443a1214c,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-122e07fa-64e2-493b-8b4c-b596b2aa3226,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-194381b8-206e-4888-92c4-9ca60964bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-18f8258d-5e05-4ff4-825c-8f9ab54271da,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-810486e3-afaf-4e78-b37a-82c6ca85bc1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799704235-172.17.0.2-1597402304857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-88b50353-6304-4bf4-ae04-a5b8cb41db06,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-9ce46935-8ddc-4061-aa14-b854c5be5d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-0ae441ea-98f5-4b60-9686-66e0cf3cb64f,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-724507f4-6168-4b7b-b9d0-0e8985c54a05,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-afe5af55-b3fd-44f5-aec9-a9ea46a1e8db,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-d1aaf051-6625-48e1-9b36-c3153bbfefdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-e75ec8aa-c1ce-401b-ad7f-3bd676a6e320,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-845eeb1d-42f6-4c59-a663-4511aed70ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799704235-172.17.0.2-1597402304857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-88b50353-6304-4bf4-ae04-a5b8cb41db06,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-9ce46935-8ddc-4061-aa14-b854c5be5d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-0ae441ea-98f5-4b60-9686-66e0cf3cb64f,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-724507f4-6168-4b7b-b9d0-0e8985c54a05,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-afe5af55-b3fd-44f5-aec9-a9ea46a1e8db,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-d1aaf051-6625-48e1-9b36-c3153bbfefdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-e75ec8aa-c1ce-401b-ad7f-3bd676a6e320,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-845eeb1d-42f6-4c59-a663-4511aed70ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5497
