reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824567912-172.17.0.9-1597583146537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-6baf771f-080a-49a0-b630-26c8b0bdd5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-95a04428-d3e4-4a67-b9ef-376b785970f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-5ad4dd55-2037-4a6d-9070-951dd7c4311d,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-d8f3e44e-2aa9-43ee-abbf-002cf5bad263,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-260adce0-2611-466d-8bd0-af8d27c64c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2601651b-7e49-4989-be6a-07332c7a3527,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-4d90a1df-da89-4f8d-8a4b-b0ff9d337160,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-27ba25e0-ce1a-4638-b243-bc7f39a69f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824567912-172.17.0.9-1597583146537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38121,DS-6baf771f-080a-49a0-b630-26c8b0bdd5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-95a04428-d3e4-4a67-b9ef-376b785970f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-5ad4dd55-2037-4a6d-9070-951dd7c4311d,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-d8f3e44e-2aa9-43ee-abbf-002cf5bad263,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-260adce0-2611-466d-8bd0-af8d27c64c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2601651b-7e49-4989-be6a-07332c7a3527,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-4d90a1df-da89-4f8d-8a4b-b0ff9d337160,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-27ba25e0-ce1a-4638-b243-bc7f39a69f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776595658-172.17.0.9-1597583242711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41319,DS-96cb9308-8c98-4b3d-8d03-f46779742543,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-704de672-5953-400f-b638-cea6d3031fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-a0748d93-25a9-48cf-be55-91ff02d8e983,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-f68d07d0-6640-4768-9840-821f74bcf5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-26dc02ea-3148-4078-aa06-2ce66bf42cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-033756a1-aede-4216-a65f-c0ee4637c98b,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-09cd3a53-3ad0-4294-bbf7-a52cbf33dcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-448bf237-94a2-491b-b859-9c276c98235d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776595658-172.17.0.9-1597583242711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41319,DS-96cb9308-8c98-4b3d-8d03-f46779742543,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-704de672-5953-400f-b638-cea6d3031fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-a0748d93-25a9-48cf-be55-91ff02d8e983,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-f68d07d0-6640-4768-9840-821f74bcf5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-26dc02ea-3148-4078-aa06-2ce66bf42cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-033756a1-aede-4216-a65f-c0ee4637c98b,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-09cd3a53-3ad0-4294-bbf7-a52cbf33dcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-448bf237-94a2-491b-b859-9c276c98235d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370034880-172.17.0.9-1597583582728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-dc9197dc-2b9a-4e84-a385-696e6f74049c,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-a9834ca6-8560-4935-abfa-82b417da8b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-d79c3ddc-ca62-4f25-84b5-34f3488b627d,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-91ca23ab-b042-424f-b6e9-2de477707bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-bea5a515-c3b0-47f4-999c-c6c279318f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-0562eff1-4a2c-484d-9ce2-c2bcce9129c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-a2c3dcaf-3b82-4eec-a711-02f73f496dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-200d68d5-1ebe-494c-a758-fba936b5dc60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370034880-172.17.0.9-1597583582728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-dc9197dc-2b9a-4e84-a385-696e6f74049c,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-a9834ca6-8560-4935-abfa-82b417da8b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-d79c3ddc-ca62-4f25-84b5-34f3488b627d,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-91ca23ab-b042-424f-b6e9-2de477707bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-bea5a515-c3b0-47f4-999c-c6c279318f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-0562eff1-4a2c-484d-9ce2-c2bcce9129c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-a2c3dcaf-3b82-4eec-a711-02f73f496dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-200d68d5-1ebe-494c-a758-fba936b5dc60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369112308-172.17.0.9-1597584387237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34701,DS-a92a19f9-6c13-462b-b685-012fbfe5e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-14f0858a-8130-4f07-a3c6-1028fc432687,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-ad90a6d3-d983-4f71-b5fd-f683d0d76e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-cdd86786-8e01-43d7-827a-c15c41a8cff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-74eb51a2-8b7e-4a4c-90ed-d048eafb034d,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-e1a7ca32-5d06-43d1-8732-81fabe3a24aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-fb508d7c-7dc5-4caf-8638-c14e1a3b13df,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-1e78302b-7597-421c-84e7-dc2683f4d32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369112308-172.17.0.9-1597584387237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34701,DS-a92a19f9-6c13-462b-b685-012fbfe5e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-14f0858a-8130-4f07-a3c6-1028fc432687,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-ad90a6d3-d983-4f71-b5fd-f683d0d76e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-cdd86786-8e01-43d7-827a-c15c41a8cff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-74eb51a2-8b7e-4a4c-90ed-d048eafb034d,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-e1a7ca32-5d06-43d1-8732-81fabe3a24aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-fb508d7c-7dc5-4caf-8638-c14e1a3b13df,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-1e78302b-7597-421c-84e7-dc2683f4d32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909674566-172.17.0.9-1597585078618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39745,DS-46c4fad6-3c83-442b-80a8-6bef75457a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-b0ed364f-9021-4b6d-a943-e39ae89a9b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-5306e9ba-f31a-492b-b792-01b2c1184869,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-b228098e-2abe-4615-a075-8375c0da45cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-2cb4c2fe-4cbb-4b61-b6f5-68d87b5210fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-20c60150-56ac-4499-800e-cae4cbaf7fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-ad6b154f-63f2-450a-ba42-f44c53a4ed25,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-2b566098-97f5-4744-96b1-29853b1b8b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909674566-172.17.0.9-1597585078618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39745,DS-46c4fad6-3c83-442b-80a8-6bef75457a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-b0ed364f-9021-4b6d-a943-e39ae89a9b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-5306e9ba-f31a-492b-b792-01b2c1184869,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-b228098e-2abe-4615-a075-8375c0da45cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-2cb4c2fe-4cbb-4b61-b6f5-68d87b5210fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-20c60150-56ac-4499-800e-cae4cbaf7fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-ad6b154f-63f2-450a-ba42-f44c53a4ed25,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-2b566098-97f5-4744-96b1-29853b1b8b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819895307-172.17.0.9-1597585260611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38500,DS-36cd808d-85a8-4959-bc5e-bfc6b071dc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-a08537b0-3d2d-41fc-ab3f-a214debd7d17,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-38fc0f16-4de3-42f2-9c24-74306c2c8e61,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-8f2fb723-f63e-4849-bd02-955e4174806e,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-cceb9f5e-6132-4967-bc4b-f3ef181fd557,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-2f9154b7-0ce4-4ce0-aa76-05105500a973,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-3d6304ae-2aba-4574-beb7-ce87e6ef75bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-3b40205b-fdf1-499e-960a-c292b1160a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819895307-172.17.0.9-1597585260611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38500,DS-36cd808d-85a8-4959-bc5e-bfc6b071dc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-a08537b0-3d2d-41fc-ab3f-a214debd7d17,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-38fc0f16-4de3-42f2-9c24-74306c2c8e61,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-8f2fb723-f63e-4849-bd02-955e4174806e,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-cceb9f5e-6132-4967-bc4b-f3ef181fd557,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-2f9154b7-0ce4-4ce0-aa76-05105500a973,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-3d6304ae-2aba-4574-beb7-ce87e6ef75bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-3b40205b-fdf1-499e-960a-c292b1160a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432963869-172.17.0.9-1597585712596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34312,DS-bbcb2065-07b6-43f8-8815-2e70ff178a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-4ee43a9f-e18c-4188-af62-04588034c747,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b1e2e635-452f-4119-a993-66818cdf81a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-e61e3db3-1428-4f96-90ac-f3687536477b,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-d62b17f9-03d3-45f5-915b-c0de23f8a4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-083fd0bc-2b8c-486b-bb95-db1b3dd260e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-76296993-6600-464b-b554-44e524daa415,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-d182b2b1-0e26-47f0-905f-1ea6515e8edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432963869-172.17.0.9-1597585712596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34312,DS-bbcb2065-07b6-43f8-8815-2e70ff178a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-4ee43a9f-e18c-4188-af62-04588034c747,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b1e2e635-452f-4119-a993-66818cdf81a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-e61e3db3-1428-4f96-90ac-f3687536477b,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-d62b17f9-03d3-45f5-915b-c0de23f8a4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-083fd0bc-2b8c-486b-bb95-db1b3dd260e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-76296993-6600-464b-b554-44e524daa415,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-d182b2b1-0e26-47f0-905f-1ea6515e8edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074684142-172.17.0.9-1597585964031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-3bdacd9f-ccf8-4ba7-8119-e8703628fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-11fcb6c8-40b4-45bb-907b-efcc0f8494fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-ea71c90f-4487-4244-8355-14ebddabf8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-de83a4ab-37b9-4770-a42b-0869774db086,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-54f972ad-c534-4551-8795-0c973a39b87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-6edd88b1-d514-41f4-8a9f-40b680b8745d,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-8dd72477-192a-4fbd-b101-725bdad1615c,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-ebbf46f5-b83c-491c-b2a0-4eee484b00d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074684142-172.17.0.9-1597585964031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-3bdacd9f-ccf8-4ba7-8119-e8703628fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-11fcb6c8-40b4-45bb-907b-efcc0f8494fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-ea71c90f-4487-4244-8355-14ebddabf8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-de83a4ab-37b9-4770-a42b-0869774db086,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-54f972ad-c534-4551-8795-0c973a39b87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-6edd88b1-d514-41f4-8a9f-40b680b8745d,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-8dd72477-192a-4fbd-b101-725bdad1615c,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-ebbf46f5-b83c-491c-b2a0-4eee484b00d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480637260-172.17.0.9-1597586568936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-843f32af-82d6-480e-a618-1b4689021df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-871afc2c-389d-43a7-92f9-b3d83574a643,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-6915258a-a6fb-4b75-8c1a-be20d490051e,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-cdab311c-1a94-4f6a-8cce-5edc43c6677f,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-8e837838-20c1-4899-8be5-f1b8f71f06dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-a455dc23-f933-4f38-a122-e4517244a3df,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-fc1be0f7-cf0a-4283-b26b-a70cea0dbd84,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-5ec2b2e9-a455-4bf5-86d6-76e2666938f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480637260-172.17.0.9-1597586568936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-843f32af-82d6-480e-a618-1b4689021df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-871afc2c-389d-43a7-92f9-b3d83574a643,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-6915258a-a6fb-4b75-8c1a-be20d490051e,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-cdab311c-1a94-4f6a-8cce-5edc43c6677f,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-8e837838-20c1-4899-8be5-f1b8f71f06dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-a455dc23-f933-4f38-a122-e4517244a3df,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-fc1be0f7-cf0a-4283-b26b-a70cea0dbd84,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-5ec2b2e9-a455-4bf5-86d6-76e2666938f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488533287-172.17.0.9-1597586631141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36959,DS-235a50f8-4513-47cd-9a0a-b04f3d0de90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-72a2cc62-61f8-4ec9-8483-0afa97eb2ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-bb57d1d9-fdbc-4e16-942e-c6a2376fe63b,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-a7d17445-06ab-47b4-a6c5-ecd3edaf688a,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-4224904f-5073-4d3b-b930-476dac58ec19,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-6dfab0e1-8082-42d9-bfa3-e6531e395341,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-59a665d5-9c5a-470f-be74-8373037e1aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-a04d6317-e21e-4deb-934b-41a950c060a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488533287-172.17.0.9-1597586631141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36959,DS-235a50f8-4513-47cd-9a0a-b04f3d0de90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-72a2cc62-61f8-4ec9-8483-0afa97eb2ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-bb57d1d9-fdbc-4e16-942e-c6a2376fe63b,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-a7d17445-06ab-47b4-a6c5-ecd3edaf688a,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-4224904f-5073-4d3b-b930-476dac58ec19,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-6dfab0e1-8082-42d9-bfa3-e6531e395341,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-59a665d5-9c5a-470f-be74-8373037e1aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-a04d6317-e21e-4deb-934b-41a950c060a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963384365-172.17.0.9-1597586999839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40743,DS-77d6a1b2-b3c9-4c7b-950c-3fbc8543eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-155ffbad-2a7e-4663-8dd1-dfcfc0d39717,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-9cdc97e6-d3d3-41ce-816b-c50a700e2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-8d9c6ea3-24d4-48d5-b725-5657ecb6d796,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-9900b618-cf23-4a35-b4c8-d752d7da949f,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-6e5fc276-d796-47af-ba63-ca936b57b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-48b40756-6bf9-436a-9ef5-dfd7f2c923cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-1a4ebcca-e799-4217-9d01-13b7528aae6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963384365-172.17.0.9-1597586999839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40743,DS-77d6a1b2-b3c9-4c7b-950c-3fbc8543eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-155ffbad-2a7e-4663-8dd1-dfcfc0d39717,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-9cdc97e6-d3d3-41ce-816b-c50a700e2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-8d9c6ea3-24d4-48d5-b725-5657ecb6d796,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-9900b618-cf23-4a35-b4c8-d752d7da949f,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-6e5fc276-d796-47af-ba63-ca936b57b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-48b40756-6bf9-436a-9ef5-dfd7f2c923cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-1a4ebcca-e799-4217-9d01-13b7528aae6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19211276-172.17.0.9-1597587110214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42192,DS-a51c1d0c-6f26-4797-8cba-fd2c05ee93b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-175275ec-911b-477c-8ef1-eb1588bf13cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-fbf2cf85-1f55-463a-b41c-670fb0679473,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-6437f4a6-a67e-461f-aa36-f8facbcc4d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-2e740ec2-4baa-45b8-912e-fe10efc2a4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-6f516bab-e5d8-4da9-a5ed-ba82ef940823,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-b9142917-8d36-4d0f-a7ce-39b05cf010e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-9dbbf714-030b-433e-a95f-67bdfd2888a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19211276-172.17.0.9-1597587110214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42192,DS-a51c1d0c-6f26-4797-8cba-fd2c05ee93b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-175275ec-911b-477c-8ef1-eb1588bf13cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-fbf2cf85-1f55-463a-b41c-670fb0679473,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-6437f4a6-a67e-461f-aa36-f8facbcc4d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-2e740ec2-4baa-45b8-912e-fe10efc2a4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-6f516bab-e5d8-4da9-a5ed-ba82ef940823,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-b9142917-8d36-4d0f-a7ce-39b05cf010e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-9dbbf714-030b-433e-a95f-67bdfd2888a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017305376-172.17.0.9-1597587622553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45924,DS-3607b8f9-8de1-41b8-82d9-eb4398d48c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-13cc0e08-5e6a-4371-9801-4229b43bc14c,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-57a5f709-44a8-4277-85c7-12fbd75c78f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-f723e927-23d1-4c96-87d2-a95962ce4834,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-9ff17a36-27bb-4907-b7f9-f5d11b630abd,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-8b12f1f3-db63-4897-aaae-9ae83070ce65,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-aec105c6-0238-435f-8da9-40808c86b72c,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-cc5c6613-3048-4cc4-b21e-2013aa61c860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017305376-172.17.0.9-1597587622553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45924,DS-3607b8f9-8de1-41b8-82d9-eb4398d48c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-13cc0e08-5e6a-4371-9801-4229b43bc14c,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-57a5f709-44a8-4277-85c7-12fbd75c78f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-f723e927-23d1-4c96-87d2-a95962ce4834,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-9ff17a36-27bb-4907-b7f9-f5d11b630abd,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-8b12f1f3-db63-4897-aaae-9ae83070ce65,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-aec105c6-0238-435f-8da9-40808c86b72c,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-cc5c6613-3048-4cc4-b21e-2013aa61c860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928589382-172.17.0.9-1597588323502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44800,DS-242a4738-cb3e-49ec-8222-2feb7058a484,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-c5db9fde-8226-43f7-a1e6-5dd80f05e6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-8281623a-62b2-4232-9d65-afb574dd12a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-bb278db9-1765-4710-9b7b-be560e022796,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-ee0f971b-798f-445b-9d00-a5be2414dc30,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-251ba142-b627-455a-9531-60ee9e6ed602,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-9ba2aec1-550a-4ec3-8622-bbf675f6e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-cef2f53a-9d23-4354-bbe3-e504ba7d3a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928589382-172.17.0.9-1597588323502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44800,DS-242a4738-cb3e-49ec-8222-2feb7058a484,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-c5db9fde-8226-43f7-a1e6-5dd80f05e6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-8281623a-62b2-4232-9d65-afb574dd12a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-bb278db9-1765-4710-9b7b-be560e022796,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-ee0f971b-798f-445b-9d00-a5be2414dc30,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-251ba142-b627-455a-9531-60ee9e6ed602,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-9ba2aec1-550a-4ec3-8622-bbf675f6e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-cef2f53a-9d23-4354-bbe3-e504ba7d3a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641005849-172.17.0.9-1597588549805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42643,DS-867a5d84-1dad-44a6-abc3-b6a07e5fda52,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-e1e8a880-1ae4-48dc-bbf0-0dd24ba10283,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-bb0432ec-cf9b-4ea4-b205-5d4b9a22f057,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-a956f0be-25d6-4112-9993-854fb59c8980,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-1aea3d9d-b1c8-48f1-8d7b-3ebffc285cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-e3d5fcbd-6a28-41da-86e6-b6375caaeae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-39a02418-9097-4268-9f96-1063ca7525fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-34bc8b42-6e9f-4b5c-95c7-997cda7de17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641005849-172.17.0.9-1597588549805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42643,DS-867a5d84-1dad-44a6-abc3-b6a07e5fda52,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-e1e8a880-1ae4-48dc-bbf0-0dd24ba10283,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-bb0432ec-cf9b-4ea4-b205-5d4b9a22f057,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-a956f0be-25d6-4112-9993-854fb59c8980,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-1aea3d9d-b1c8-48f1-8d7b-3ebffc285cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-e3d5fcbd-6a28-41da-86e6-b6375caaeae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-39a02418-9097-4268-9f96-1063ca7525fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-34bc8b42-6e9f-4b5c-95c7-997cda7de17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132448992-172.17.0.9-1597588723129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-95a1cf41-9046-4157-932f-dd198b52d27a,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-5d1ee470-cb9e-4c0c-a8ea-2958fade8bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-4ea918f0-a3ce-4683-b0b8-36c0959936d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-94176e66-f6e4-4b5f-8fc2-ea4fc909a352,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-eafa52d3-6272-4caf-b49e-be3642692c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-3b1438f2-1a1b-4a07-833f-7f329e102650,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-080c1629-91f1-48ae-9b6d-55ce02e8a1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-2d0ef6f8-1a70-463d-8360-535b58921966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132448992-172.17.0.9-1597588723129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-95a1cf41-9046-4157-932f-dd198b52d27a,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-5d1ee470-cb9e-4c0c-a8ea-2958fade8bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-4ea918f0-a3ce-4683-b0b8-36c0959936d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-94176e66-f6e4-4b5f-8fc2-ea4fc909a352,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-eafa52d3-6272-4caf-b49e-be3642692c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-3b1438f2-1a1b-4a07-833f-7f329e102650,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-080c1629-91f1-48ae-9b6d-55ce02e8a1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-2d0ef6f8-1a70-463d-8360-535b58921966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368641682-172.17.0.9-1597589432300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-fb941a41-910c-41a3-8517-57b87d48cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-3615d1c0-a0af-4cf2-a489-4f1363799921,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-623509a7-6008-4e83-9fda-c6c14e57ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-a468e33d-3ac7-4add-ad9b-fea692393097,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-34b4bff8-80d6-4353-a2d2-cc6fd26e3239,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-65719156-7d0a-4d12-826e-32e78dcc5a55,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-742b5598-805a-4aab-b3c5-c6172fb98068,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-0515dd09-9f11-4325-b831-c1473dd55550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368641682-172.17.0.9-1597589432300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-fb941a41-910c-41a3-8517-57b87d48cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-3615d1c0-a0af-4cf2-a489-4f1363799921,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-623509a7-6008-4e83-9fda-c6c14e57ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-a468e33d-3ac7-4add-ad9b-fea692393097,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-34b4bff8-80d6-4353-a2d2-cc6fd26e3239,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-65719156-7d0a-4d12-826e-32e78dcc5a55,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-742b5598-805a-4aab-b3c5-c6172fb98068,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-0515dd09-9f11-4325-b831-c1473dd55550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407330419-172.17.0.9-1597589588312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45913,DS-494c8dad-9bbd-4136-b2af-f0051241dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-c4c9b3d7-2b78-4e6e-b698-614068ad1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-1476ca6b-03da-4ea9-b813-7b84a8a55409,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-fd197575-3e3e-4b57-8cea-4f3624791f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-9ead5a6a-4b0b-4352-afa9-72bf0236e2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-bbebbde3-a245-4b5e-8c02-ff636216c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-6c16db98-db45-4900-b89b-ef094d0ed8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-0c2350c0-1106-4e43-84f9-64b94c9027cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407330419-172.17.0.9-1597589588312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45913,DS-494c8dad-9bbd-4136-b2af-f0051241dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-c4c9b3d7-2b78-4e6e-b698-614068ad1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-1476ca6b-03da-4ea9-b813-7b84a8a55409,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-fd197575-3e3e-4b57-8cea-4f3624791f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-9ead5a6a-4b0b-4352-afa9-72bf0236e2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-bbebbde3-a245-4b5e-8c02-ff636216c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-6c16db98-db45-4900-b89b-ef094d0ed8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-0c2350c0-1106-4e43-84f9-64b94c9027cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659096675-172.17.0.9-1597589735836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38331,DS-34263fd4-f255-43bc-83c3-1d7f177cb3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-d18a9e08-cde1-46b0-8257-492c4500fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-3a5ceeff-ddf9-4beb-9928-11aa674b02fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-24cc4e8f-7e4f-444e-ad7a-ed5c4932da20,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-85500183-d13b-4a12-a527-b0712553e4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-ac6d4308-3cf7-436c-b328-89867e41e56f,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-28e2ca5a-ea7c-4ea2-958a-0ff509c4a754,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-2aced5d7-a371-4d71-94c5-a933aa74be67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659096675-172.17.0.9-1597589735836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38331,DS-34263fd4-f255-43bc-83c3-1d7f177cb3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-d18a9e08-cde1-46b0-8257-492c4500fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-3a5ceeff-ddf9-4beb-9928-11aa674b02fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-24cc4e8f-7e4f-444e-ad7a-ed5c4932da20,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-85500183-d13b-4a12-a527-b0712553e4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-ac6d4308-3cf7-436c-b328-89867e41e56f,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-28e2ca5a-ea7c-4ea2-958a-0ff509c4a754,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-2aced5d7-a371-4d71-94c5-a933aa74be67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243657418-172.17.0.9-1597589773171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-2d4f646a-cdcc-4c68-bbbb-c6dcc68fd52f,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-a81b010b-d52b-4409-974e-21b228473f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-edadd84a-79a5-4d8e-a0f1-c49b7a1cb32b,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-fea86eb8-8854-431d-8768-2284387a423f,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-7eb14b4b-49f4-42c9-929f-683a54844761,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-87f3d546-0a9d-4853-b8f7-1ddde6ea723d,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-18d70e49-8e32-46e6-a9f3-ca75bd719cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-57f656a4-9500-458e-913d-049cd048019f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243657418-172.17.0.9-1597589773171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-2d4f646a-cdcc-4c68-bbbb-c6dcc68fd52f,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-a81b010b-d52b-4409-974e-21b228473f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-edadd84a-79a5-4d8e-a0f1-c49b7a1cb32b,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-fea86eb8-8854-431d-8768-2284387a423f,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-7eb14b4b-49f4-42c9-929f-683a54844761,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-87f3d546-0a9d-4853-b8f7-1ddde6ea723d,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-18d70e49-8e32-46e6-a9f3-ca75bd719cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-57f656a4-9500-458e-913d-049cd048019f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7165
