reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136843822-172.17.0.15-1597637234284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-4f2e9207-0406-4f36-95fd-08f997eb339d,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-fe7182c7-8d1c-4653-b862-54c770147a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-87ae3130-44bc-43b0-b986-4d6835cb551c,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-926e8203-fe00-4d7b-a1c1-31b7dc909b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-8441ee36-ee4a-4908-a0c1-3da0cb9ea473,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-72147f2a-bee6-42b9-8901-866ba0bcedb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-46ba96e8-2b13-49b8-9758-d4075d5063e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-0f81518f-7f40-467d-a3a7-4037102e38a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136843822-172.17.0.15-1597637234284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-4f2e9207-0406-4f36-95fd-08f997eb339d,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-fe7182c7-8d1c-4653-b862-54c770147a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-87ae3130-44bc-43b0-b986-4d6835cb551c,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-926e8203-fe00-4d7b-a1c1-31b7dc909b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-8441ee36-ee4a-4908-a0c1-3da0cb9ea473,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-72147f2a-bee6-42b9-8901-866ba0bcedb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-46ba96e8-2b13-49b8-9758-d4075d5063e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-0f81518f-7f40-467d-a3a7-4037102e38a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406103875-172.17.0.15-1597637268747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-142488a3-c7ac-4bcc-bb1d-3c70cc47f00e,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-3d111383-55d5-45b6-be25-26f5b80ab3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-e71c8b95-94aa-43e5-b7fc-b8fab55eab87,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-9ec7e2e8-13be-4261-ac78-0565fce8608e,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-34f55701-3b6a-4d2d-bc5b-962d57e8ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-c0678347-6888-4bb7-b3fe-7c23986dfebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-35908e7c-3973-4533-91e5-20c2d9957651,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-ad79111c-011b-412f-af09-274a21ebbd60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406103875-172.17.0.15-1597637268747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-142488a3-c7ac-4bcc-bb1d-3c70cc47f00e,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-3d111383-55d5-45b6-be25-26f5b80ab3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-e71c8b95-94aa-43e5-b7fc-b8fab55eab87,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-9ec7e2e8-13be-4261-ac78-0565fce8608e,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-34f55701-3b6a-4d2d-bc5b-962d57e8ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-c0678347-6888-4bb7-b3fe-7c23986dfebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-35908e7c-3973-4533-91e5-20c2d9957651,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-ad79111c-011b-412f-af09-274a21ebbd60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388753015-172.17.0.15-1597637300124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-b6cea9ca-ecbf-41d1-8a5c-8c3806386a50,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-85225fb0-46bf-4e18-8795-5ea6c514655d,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-0fa510ea-bb89-4aa4-8d73-913cba2cf05e,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-cf849666-5633-4d14-9a38-4d311e315652,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-43c02373-3818-4555-acfb-6f2cb5d28f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-be0cef32-6900-47f9-afff-7a4de38690ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-c6253f60-bbcd-469a-9363-7a9630eff629,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-ad14ac71-41a5-4814-9ce2-c8e5d982d21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388753015-172.17.0.15-1597637300124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-b6cea9ca-ecbf-41d1-8a5c-8c3806386a50,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-85225fb0-46bf-4e18-8795-5ea6c514655d,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-0fa510ea-bb89-4aa4-8d73-913cba2cf05e,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-cf849666-5633-4d14-9a38-4d311e315652,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-43c02373-3818-4555-acfb-6f2cb5d28f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-be0cef32-6900-47f9-afff-7a4de38690ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-c6253f60-bbcd-469a-9363-7a9630eff629,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-ad14ac71-41a5-4814-9ce2-c8e5d982d21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131582937-172.17.0.15-1597637369770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-e721f56a-bb62-4e22-8b89-5fcf8b9a99fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-e536e805-2d08-4913-ab2b-61c328797f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-dfd0d4e0-5256-42c6-9903-399060eccd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-9cf156cb-981b-4ed9-a58a-b1bfb8baa2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-d4f5cb47-28b9-4d39-b8f5-8c45f2c0740b,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-f92f317c-7ca7-40cb-b952-491cc138ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-aa937cd6-01f2-46f3-aec5-6cd96c82bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-66673151-2082-4299-b771-8375bb1d92c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131582937-172.17.0.15-1597637369770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-e721f56a-bb62-4e22-8b89-5fcf8b9a99fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-e536e805-2d08-4913-ab2b-61c328797f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-dfd0d4e0-5256-42c6-9903-399060eccd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-9cf156cb-981b-4ed9-a58a-b1bfb8baa2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-d4f5cb47-28b9-4d39-b8f5-8c45f2c0740b,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-f92f317c-7ca7-40cb-b952-491cc138ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-aa937cd6-01f2-46f3-aec5-6cd96c82bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-66673151-2082-4299-b771-8375bb1d92c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655988518-172.17.0.15-1597637733161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-f08a6624-8442-4c83-a4a4-73a713fff1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-6f5a37e8-ae38-4019-a17d-127692e48bff,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-68a0edc3-947e-431b-9e43-c0d783cf6e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-048f1000-ffe7-4d9a-bb0f-2c60f14a8362,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-7c15b1da-e682-4cac-92b9-79ae6209ce7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-1d0abe9b-3c69-4c5c-8554-49e5e284ef4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-0e76137a-89c8-4c77-b033-e48ae1d75844,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-5501081e-ff67-4459-a33a-9e2fe9f81085,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655988518-172.17.0.15-1597637733161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-f08a6624-8442-4c83-a4a4-73a713fff1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-6f5a37e8-ae38-4019-a17d-127692e48bff,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-68a0edc3-947e-431b-9e43-c0d783cf6e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-048f1000-ffe7-4d9a-bb0f-2c60f14a8362,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-7c15b1da-e682-4cac-92b9-79ae6209ce7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-1d0abe9b-3c69-4c5c-8554-49e5e284ef4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-0e76137a-89c8-4c77-b033-e48ae1d75844,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-5501081e-ff67-4459-a33a-9e2fe9f81085,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207384939-172.17.0.15-1597637846803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38186,DS-7a6593f0-8abb-4109-9d34-494239983bee,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-5bcafc69-4828-46a6-8eaf-c9aa3d5ddf04,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-7c149651-aeb7-46a3-b6a1-89b634098374,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-8689e537-b203-482e-8e66-65b36f4058ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-de960a3b-a467-4657-a2cd-62fb38b32dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-aa518fcc-b57f-4db3-890d-a541948405db,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-d7446f29-44cb-4a21-96bc-08809076c91f,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-818a2b69-bb5a-481c-85fc-8f57cff1acd7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207384939-172.17.0.15-1597637846803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38186,DS-7a6593f0-8abb-4109-9d34-494239983bee,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-5bcafc69-4828-46a6-8eaf-c9aa3d5ddf04,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-7c149651-aeb7-46a3-b6a1-89b634098374,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-8689e537-b203-482e-8e66-65b36f4058ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-de960a3b-a467-4657-a2cd-62fb38b32dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-aa518fcc-b57f-4db3-890d-a541948405db,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-d7446f29-44cb-4a21-96bc-08809076c91f,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-818a2b69-bb5a-481c-85fc-8f57cff1acd7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811208271-172.17.0.15-1597637961606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39573,DS-6331027a-17ca-4a6f-9e28-1fc0176c907f,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-5bea3309-3058-42d2-819b-2d0e6006ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-664f32c0-1b14-4e44-81b6-7d764041a7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-c4400f03-7861-450d-862a-5ca1d52b61e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-ffd660a1-b49f-4dcb-9ca6-62170d49b746,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-f0901e4a-6f6d-4400-ba9d-68808bc115b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-b7c9ebbe-f84a-4e52-9434-46c88d5749c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-0bb2b0a1-ae1a-4493-8597-789c473ed430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811208271-172.17.0.15-1597637961606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39573,DS-6331027a-17ca-4a6f-9e28-1fc0176c907f,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-5bea3309-3058-42d2-819b-2d0e6006ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-664f32c0-1b14-4e44-81b6-7d764041a7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-c4400f03-7861-450d-862a-5ca1d52b61e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-ffd660a1-b49f-4dcb-9ca6-62170d49b746,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-f0901e4a-6f6d-4400-ba9d-68808bc115b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-b7c9ebbe-f84a-4e52-9434-46c88d5749c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-0bb2b0a1-ae1a-4493-8597-789c473ed430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086245222-172.17.0.15-1597638078293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-d652a4d9-30ee-4d15-96a2-ac2b6b66b1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-0bdc0c8d-e06b-47a6-9fc8-b0ee800be2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-1cce9a64-75b7-4783-b434-4bc7a309b3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-e6fc4c76-c135-4d01-8cf5-e55614d0a209,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-11dced51-d31e-4765-aeec-be859f103181,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-ee67fc9a-2327-44fb-bebe-223676d48ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-6a493155-6320-4862-8285-362a2f6d03bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-cc5f9a04-beba-4661-8fab-af5901a5ebbc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086245222-172.17.0.15-1597638078293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33894,DS-d652a4d9-30ee-4d15-96a2-ac2b6b66b1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-0bdc0c8d-e06b-47a6-9fc8-b0ee800be2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-1cce9a64-75b7-4783-b434-4bc7a309b3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-e6fc4c76-c135-4d01-8cf5-e55614d0a209,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-11dced51-d31e-4765-aeec-be859f103181,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-ee67fc9a-2327-44fb-bebe-223676d48ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-6a493155-6320-4862-8285-362a2f6d03bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-cc5f9a04-beba-4661-8fab-af5901a5ebbc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467155396-172.17.0.15-1597638451106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-024e39fd-b385-4a5d-a8d8-6f03fc706e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-6b5e4c29-d14f-4a89-8b06-3eab5957e4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-499e0ba8-7262-4f31-8d0f-20b33fdb58ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-1038288a-9718-4c28-a806-8280fc5e30b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-8ee0f459-f6d8-4711-b4f7-bd5b993c6fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-f7fc1421-c665-4509-a7e2-b70c14723d82,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-16ad0561-24c4-4db0-962c-e72a44e05e93,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-1f2dce13-b46f-4130-9b36-b8e3af6c0c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467155396-172.17.0.15-1597638451106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-024e39fd-b385-4a5d-a8d8-6f03fc706e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-6b5e4c29-d14f-4a89-8b06-3eab5957e4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-499e0ba8-7262-4f31-8d0f-20b33fdb58ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-1038288a-9718-4c28-a806-8280fc5e30b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-8ee0f459-f6d8-4711-b4f7-bd5b993c6fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-f7fc1421-c665-4509-a7e2-b70c14723d82,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-16ad0561-24c4-4db0-962c-e72a44e05e93,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-1f2dce13-b46f-4130-9b36-b8e3af6c0c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119160557-172.17.0.15-1597639034281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-3a43d2b4-377d-4b1d-8c47-137741ab32f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-a2d25d24-3c52-4cfb-9137-4eeb40f108eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-d1449b16-2c4d-4c07-a4b0-315657c4996c,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-a6fd6b96-ca18-4f35-af8c-56710ee87c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-b554ccfd-8660-47f9-afd4-d91d6106c3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-5e79c473-c01a-4d9c-8dcd-b33a37f0457a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-7f73f2c2-95b7-46dd-a71a-b728b829b8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-bf2d0d36-2f5a-4a29-ab1d-4ac285e9977e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119160557-172.17.0.15-1597639034281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-3a43d2b4-377d-4b1d-8c47-137741ab32f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-a2d25d24-3c52-4cfb-9137-4eeb40f108eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-d1449b16-2c4d-4c07-a4b0-315657c4996c,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-a6fd6b96-ca18-4f35-af8c-56710ee87c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-b554ccfd-8660-47f9-afd4-d91d6106c3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-5e79c473-c01a-4d9c-8dcd-b33a37f0457a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-7f73f2c2-95b7-46dd-a71a-b728b829b8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-bf2d0d36-2f5a-4a29-ab1d-4ac285e9977e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528572984-172.17.0.15-1597639078048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42717,DS-533f5782-5b08-4587-a703-748300856a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-e809be7e-275b-41d1-8f9f-01d1772dce82,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-e16a8977-4e1c-4739-944f-4fee2c22294f,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-943946ed-186b-46e8-80d6-67ff7bd6d11b,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-5747d935-d2a1-47a1-8cd3-e71b406c1ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-ff8a3066-4774-4c29-b267-7cffcf1e941d,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-f9fa6148-a0dd-48a4-8fb9-3e10a1a86273,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-d5fc1f88-2169-4197-94b1-d142205f6e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528572984-172.17.0.15-1597639078048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42717,DS-533f5782-5b08-4587-a703-748300856a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-e809be7e-275b-41d1-8f9f-01d1772dce82,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-e16a8977-4e1c-4739-944f-4fee2c22294f,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-943946ed-186b-46e8-80d6-67ff7bd6d11b,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-5747d935-d2a1-47a1-8cd3-e71b406c1ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-ff8a3066-4774-4c29-b267-7cffcf1e941d,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-f9fa6148-a0dd-48a4-8fb9-3e10a1a86273,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-d5fc1f88-2169-4197-94b1-d142205f6e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267888325-172.17.0.15-1597639147139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33571,DS-eab1e7e7-6e6f-40fd-973c-c5593bb8c183,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-08fcb84e-c641-4ab8-a63e-d8777a71bb68,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-4c3f836b-e96b-4fad-86c6-dfba0a93cd87,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-2f6fd170-dedf-4d02-b23c-333baad81c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-7df96a9d-880a-4b91-a3cb-c4e3734adfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-5d1e3ce6-d276-4b0e-9084-30c36d59ba4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-31d61e68-9e51-44ad-914d-700dc60c4be2,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-a6ca4fcf-96bf-453a-ba42-9700c51c89a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267888325-172.17.0.15-1597639147139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33571,DS-eab1e7e7-6e6f-40fd-973c-c5593bb8c183,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-08fcb84e-c641-4ab8-a63e-d8777a71bb68,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-4c3f836b-e96b-4fad-86c6-dfba0a93cd87,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-2f6fd170-dedf-4d02-b23c-333baad81c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-7df96a9d-880a-4b91-a3cb-c4e3734adfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-5d1e3ce6-d276-4b0e-9084-30c36d59ba4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-31d61e68-9e51-44ad-914d-700dc60c4be2,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-a6ca4fcf-96bf-453a-ba42-9700c51c89a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947762309-172.17.0.15-1597639481515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35013,DS-41f93778-1916-4975-a3de-e5aca4494faf,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-03ebd904-4cdc-4365-b527-b10bff77ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-3d311bc7-d484-4b63-9302-0fb3c8fc0a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-45e1a727-1a26-4ec1-8aac-a4b173ca619e,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-20e285f6-071c-4a4a-a2d6-ca14d79e0b35,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-00786782-d881-4d9b-a516-b8f4e182f61e,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-025d9f02-b2e8-45e9-916a-8c57e0f69fca,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-f3983018-e81c-4ff0-9806-00394fcbc60b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947762309-172.17.0.15-1597639481515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35013,DS-41f93778-1916-4975-a3de-e5aca4494faf,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-03ebd904-4cdc-4365-b527-b10bff77ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-3d311bc7-d484-4b63-9302-0fb3c8fc0a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-45e1a727-1a26-4ec1-8aac-a4b173ca619e,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-20e285f6-071c-4a4a-a2d6-ca14d79e0b35,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-00786782-d881-4d9b-a516-b8f4e182f61e,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-025d9f02-b2e8-45e9-916a-8c57e0f69fca,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-f3983018-e81c-4ff0-9806-00394fcbc60b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476860259-172.17.0.15-1597639521216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-5b175fe4-5ba6-4632-93e3-7d3de4f219e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-15b17fd7-7c03-470e-aae1-7838ded48eee,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-05c23fac-ace2-450d-b3d1-5ede3ae74a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-bf2ecb27-919a-4fed-b012-0dc08730da8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-21fc2a70-6cfb-4414-9f15-584d50b53974,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-14771ad5-7c52-444d-8a23-a2187d598a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-0cd64c3d-12ab-4196-adb0-4dec46218bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-6e34af89-f4b0-4b22-ace3-39124191d11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476860259-172.17.0.15-1597639521216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37848,DS-5b175fe4-5ba6-4632-93e3-7d3de4f219e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-15b17fd7-7c03-470e-aae1-7838ded48eee,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-05c23fac-ace2-450d-b3d1-5ede3ae74a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-bf2ecb27-919a-4fed-b012-0dc08730da8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-21fc2a70-6cfb-4414-9f15-584d50b53974,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-14771ad5-7c52-444d-8a23-a2187d598a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-0cd64c3d-12ab-4196-adb0-4dec46218bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-6e34af89-f4b0-4b22-ace3-39124191d11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734986032-172.17.0.15-1597639743016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-d2698a0d-21bc-4427-867a-4f9592dc01aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-a89114f3-4c09-4653-af05-74bcd75ddbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-b691100c-5d7c-4545-85af-e0c7d1a4e551,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-7614e41f-e49e-4528-8d48-79c7a0fa9db4,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-0f67a5ea-c52e-4ade-b6ed-6dea648cbea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-e5e9333b-e5fd-4990-96d0-e99242578e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-9c31c89c-ea07-4bdc-b56a-f94267c7099c,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-b129c240-f8a8-4eaf-bcd2-f418237d0d33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734986032-172.17.0.15-1597639743016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-d2698a0d-21bc-4427-867a-4f9592dc01aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-a89114f3-4c09-4653-af05-74bcd75ddbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-b691100c-5d7c-4545-85af-e0c7d1a4e551,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-7614e41f-e49e-4528-8d48-79c7a0fa9db4,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-0f67a5ea-c52e-4ade-b6ed-6dea648cbea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-e5e9333b-e5fd-4990-96d0-e99242578e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-9c31c89c-ea07-4bdc-b56a-f94267c7099c,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-b129c240-f8a8-4eaf-bcd2-f418237d0d33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679721742-172.17.0.15-1597639884716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-6d6abcf6-cd92-4645-b96f-28d7b57af4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-0bf5bcf0-5299-4181-ac9f-eaa0484fa943,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-0e9474d6-b6a8-414a-b283-bf997819c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-3d256f25-5772-45f1-86aa-e3ee3801e71f,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-094b1421-b7b4-4865-8677-10d333b9234b,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-5acc0eea-d4c0-4db2-b2d7-3bb1ff7fe563,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-9933f133-bb9d-4205-ab92-3b3564488087,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-e62da90f-cfc2-4033-a3c4-1c62897a0853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679721742-172.17.0.15-1597639884716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-6d6abcf6-cd92-4645-b96f-28d7b57af4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-0bf5bcf0-5299-4181-ac9f-eaa0484fa943,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-0e9474d6-b6a8-414a-b283-bf997819c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-3d256f25-5772-45f1-86aa-e3ee3801e71f,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-094b1421-b7b4-4865-8677-10d333b9234b,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-5acc0eea-d4c0-4db2-b2d7-3bb1ff7fe563,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-9933f133-bb9d-4205-ab92-3b3564488087,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-e62da90f-cfc2-4033-a3c4-1c62897a0853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005235078-172.17.0.15-1597639924422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-dfe36aff-4fd5-42e4-b1d0-a4977c1d7ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-c793cbef-5dd2-4256-8b12-8f35e13620cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-8355b47a-b191-4520-bd55-7bf06b62adae,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-69a97325-fadf-4dae-b952-1e5afd75bee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-4d13938f-32c9-43e2-a676-dc3a5cf57071,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-111aa272-ec9f-4cc4-a972-d93d88dbbba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-d811c07a-f7c2-4458-9da2-8ed11645cf02,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-ad9512d2-0247-44b7-b4a9-ad395c99432a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005235078-172.17.0.15-1597639924422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-dfe36aff-4fd5-42e4-b1d0-a4977c1d7ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-c793cbef-5dd2-4256-8b12-8f35e13620cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-8355b47a-b191-4520-bd55-7bf06b62adae,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-69a97325-fadf-4dae-b952-1e5afd75bee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-4d13938f-32c9-43e2-a676-dc3a5cf57071,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-111aa272-ec9f-4cc4-a972-d93d88dbbba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-d811c07a-f7c2-4458-9da2-8ed11645cf02,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-ad9512d2-0247-44b7-b4a9-ad395c99432a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403404732-172.17.0.15-1597640166968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-834b547e-f38f-4742-8e14-d37235192fca,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-1e2bc679-416b-4962-8520-b0d43400adf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-c1ec25ec-c001-4be9-860a-e1294b3c3b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-f4427de6-c17c-4523-8849-a5d6382a7bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-cedf43a9-6517-4d5d-b527-5ea95acb05fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-98f8991b-6317-4757-8752-80f129f3538c,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-5d0856a4-1582-4e33-8cf0-cab61cda048e,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-399f5622-69a9-453d-8e98-8cd8fcb41449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403404732-172.17.0.15-1597640166968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-834b547e-f38f-4742-8e14-d37235192fca,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-1e2bc679-416b-4962-8520-b0d43400adf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-c1ec25ec-c001-4be9-860a-e1294b3c3b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-f4427de6-c17c-4523-8849-a5d6382a7bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-cedf43a9-6517-4d5d-b527-5ea95acb05fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-98f8991b-6317-4757-8752-80f129f3538c,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-5d0856a4-1582-4e33-8cf0-cab61cda048e,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-399f5622-69a9-453d-8e98-8cd8fcb41449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160675920-172.17.0.15-1597640239947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-0f9e0917-3ff2-48aa-8bed-96406ffe3929,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-16800110-db1c-420c-a44b-081d65c38d90,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-5ec2c5a8-938b-4087-b38d-afafbc474de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-ed18511f-a0e8-437a-96e7-ec4bfb289f53,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-bcec323d-f5c8-42dd-8459-ccf68ba0d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-ce4dd34b-3e41-45d5-ac92-3096ec57f347,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-6dd1e4ed-3d67-4202-9db2-739ace524ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-d98c4643-7166-4830-a78f-181fb0338978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160675920-172.17.0.15-1597640239947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-0f9e0917-3ff2-48aa-8bed-96406ffe3929,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-16800110-db1c-420c-a44b-081d65c38d90,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-5ec2c5a8-938b-4087-b38d-afafbc474de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-ed18511f-a0e8-437a-96e7-ec4bfb289f53,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-bcec323d-f5c8-42dd-8459-ccf68ba0d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-ce4dd34b-3e41-45d5-ac92-3096ec57f347,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-6dd1e4ed-3d67-4202-9db2-739ace524ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-d98c4643-7166-4830-a78f-181fb0338978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744997081-172.17.0.15-1597640509412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37745,DS-965f5499-3b05-40f4-ba86-b885c6d4b520,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-66a44c84-bd1c-47f1-9346-f6e31be978b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-a572cd54-0195-41b9-b703-6397b438c643,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-81db4fc1-a378-43a6-8a14-38dc9d31406e,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-67ff9367-9dd1-4c78-8073-000928367039,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-625a9ad4-872e-4a15-9d7d-f2aa38018e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-71072441-cf66-42b4-9863-57472c0e9509,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-a6344ea3-611c-4784-950c-2cd9b18c157e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744997081-172.17.0.15-1597640509412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37745,DS-965f5499-3b05-40f4-ba86-b885c6d4b520,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-66a44c84-bd1c-47f1-9346-f6e31be978b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-a572cd54-0195-41b9-b703-6397b438c643,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-81db4fc1-a378-43a6-8a14-38dc9d31406e,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-67ff9367-9dd1-4c78-8073-000928367039,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-625a9ad4-872e-4a15-9d7d-f2aa38018e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-71072441-cf66-42b4-9863-57472c0e9509,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-a6344ea3-611c-4784-950c-2cd9b18c157e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161688428-172.17.0.15-1597640744631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38781,DS-37e29cdb-cc2f-4435-8985-4295447bf157,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-56308f89-90c4-4673-a7ec-ae017b8a5272,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-400f7431-6824-4c87-b7f2-ac7949a9cd67,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-3d395e95-d8f4-41ed-b306-3fe2e88b3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-8df85904-822a-4e0e-99dd-846885322c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-8c723428-e9ab-4e17-aa9e-f8481271586e,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-ff122506-3c78-4807-939f-52fc09d9cd74,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-6c2773bc-93dc-430d-84ea-5fd635f5f920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161688428-172.17.0.15-1597640744631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38781,DS-37e29cdb-cc2f-4435-8985-4295447bf157,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-56308f89-90c4-4673-a7ec-ae017b8a5272,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-400f7431-6824-4c87-b7f2-ac7949a9cd67,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-3d395e95-d8f4-41ed-b306-3fe2e88b3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-8df85904-822a-4e0e-99dd-846885322c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-8c723428-e9ab-4e17-aa9e-f8481271586e,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-ff122506-3c78-4807-939f-52fc09d9cd74,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-6c2773bc-93dc-430d-84ea-5fd635f5f920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206332095-172.17.0.15-1597640934407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32942,DS-abef3a20-437b-45bf-b178-671ff935bcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-c93c64de-9765-4404-ab02-cd1aa0de3915,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-6d1d2742-0827-4b1d-a607-3e540ae12966,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-eb073195-0534-4799-a3a9-368066d48363,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-822bcf77-dce4-4d28-afc7-be24755624f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-608ecdc3-abde-4cab-ae40-0f9b233f1b51,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-1a6f8632-1a89-4216-b3f9-1cf4f4665bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-48d9d5c0-497e-442c-be99-c5257e147b30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206332095-172.17.0.15-1597640934407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32942,DS-abef3a20-437b-45bf-b178-671ff935bcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-c93c64de-9765-4404-ab02-cd1aa0de3915,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-6d1d2742-0827-4b1d-a607-3e540ae12966,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-eb073195-0534-4799-a3a9-368066d48363,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-822bcf77-dce4-4d28-afc7-be24755624f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-608ecdc3-abde-4cab-ae40-0f9b233f1b51,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-1a6f8632-1a89-4216-b3f9-1cf4f4665bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-48d9d5c0-497e-442c-be99-c5257e147b30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68729448-172.17.0.15-1597641133121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-8c723b23-0a85-40eb-aeb3-e3f61470e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-bd98df78-ef1b-4c36-8777-78a1f37cfd09,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-ccac9bb5-6b03-4aa1-a748-2e41adf42339,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-c3348d1c-1a52-45fe-a3d9-9269d6d39c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-4b49c378-9113-48ee-b76c-0a82bc96587f,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-8b6d2b04-8063-4ea5-96c8-4f913f687671,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-fcb67caa-7768-47bd-a462-0be650559b29,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-f6d61f4c-db30-49d4-86e8-2b2fa510d98a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68729448-172.17.0.15-1597641133121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-8c723b23-0a85-40eb-aeb3-e3f61470e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-bd98df78-ef1b-4c36-8777-78a1f37cfd09,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-ccac9bb5-6b03-4aa1-a748-2e41adf42339,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-c3348d1c-1a52-45fe-a3d9-9269d6d39c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-4b49c378-9113-48ee-b76c-0a82bc96587f,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-8b6d2b04-8063-4ea5-96c8-4f913f687671,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-fcb67caa-7768-47bd-a462-0be650559b29,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-f6d61f4c-db30-49d4-86e8-2b2fa510d98a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428436533-172.17.0.15-1597641211329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38942,DS-8099d5c2-b1f1-41c5-bf43-c612fc0e0b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-64925042-7ee0-4f68-8bb0-8bf47b4ebac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-85a6289a-563d-451b-a121-cf8d47ca94c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-ecdaa421-e3bb-4db7-8d83-3122998ce8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-33ffa812-8cfb-41bd-9dd7-60c005febbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-ec273919-c87b-4c15-a7dd-5892c4c113cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-f0d27987-4222-4115-a81e-0dfea63b861f,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-75280b1e-77e5-403a-ba98-255e8b754032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428436533-172.17.0.15-1597641211329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38942,DS-8099d5c2-b1f1-41c5-bf43-c612fc0e0b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-64925042-7ee0-4f68-8bb0-8bf47b4ebac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-85a6289a-563d-451b-a121-cf8d47ca94c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-ecdaa421-e3bb-4db7-8d83-3122998ce8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-33ffa812-8cfb-41bd-9dd7-60c005febbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-ec273919-c87b-4c15-a7dd-5892c4c113cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-f0d27987-4222-4115-a81e-0dfea63b861f,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-75280b1e-77e5-403a-ba98-255e8b754032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143481383-172.17.0.15-1597641241598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-9fad88ee-f745-41e5-96ae-4f37d0783010,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-44273006-175d-435c-8f50-8de6435c9686,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-5a8940e1-ad2a-43ba-a3a0-180b6b2ce045,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-2503a3e2-489e-497b-b482-5d3df957508b,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-77610058-e094-47fe-ae5d-b1a8288bfb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-d7ee5cf2-d26d-48e8-a21b-a1fa86d807ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-7b9b1eea-4f97-4d78-b283-3edfd990b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-f3d6d1f4-9955-40fa-87e4-588d52d17d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143481383-172.17.0.15-1597641241598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-9fad88ee-f745-41e5-96ae-4f37d0783010,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-44273006-175d-435c-8f50-8de6435c9686,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-5a8940e1-ad2a-43ba-a3a0-180b6b2ce045,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-2503a3e2-489e-497b-b482-5d3df957508b,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-77610058-e094-47fe-ae5d-b1a8288bfb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-d7ee5cf2-d26d-48e8-a21b-a1fa86d807ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-7b9b1eea-4f97-4d78-b283-3edfd990b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-f3d6d1f4-9955-40fa-87e4-588d52d17d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416803090-172.17.0.15-1597641394906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-85fcba28-0688-4816-9a46-f160c85a93b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-e161b33d-bbe2-4815-98f4-ea75361ce1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-196f693b-c3bb-48c8-91ed-6360a8b34b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-5be969e1-baad-478d-9335-e0ae12063702,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-3b988b5c-bba6-4b0b-a388-d47de865476e,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-c34d5fb5-bf7d-4436-b1ee-3f8a8dab01a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-2b6c1f12-58cf-4af9-a14d-53799b103d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-fbbd6a21-d049-4195-bc7c-1547c0b5b42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416803090-172.17.0.15-1597641394906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42253,DS-85fcba28-0688-4816-9a46-f160c85a93b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-e161b33d-bbe2-4815-98f4-ea75361ce1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-196f693b-c3bb-48c8-91ed-6360a8b34b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-5be969e1-baad-478d-9335-e0ae12063702,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-3b988b5c-bba6-4b0b-a388-d47de865476e,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-c34d5fb5-bf7d-4436-b1ee-3f8a8dab01a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-2b6c1f12-58cf-4af9-a14d-53799b103d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-fbbd6a21-d049-4195-bc7c-1547c0b5b42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801938996-172.17.0.15-1597641435671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42521,DS-aca663cb-3eb9-4dbe-9974-62712e87ab56,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-85f6a6f3-f132-475c-a888-7d0531bed570,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-07a734a1-26d0-4e14-9565-b71dfa4e9f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-88b7d752-682e-4265-8ff2-e325a743d84b,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-c83b711c-067a-42a3-8e7b-32ca31235c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-c3854511-2666-41d8-a254-3b24bc4277e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-8a22dd23-dc06-40a2-b763-6431acb584bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-41ed971c-ed8c-4400-adaa-fbfaa9e2fde0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801938996-172.17.0.15-1597641435671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42521,DS-aca663cb-3eb9-4dbe-9974-62712e87ab56,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-85f6a6f3-f132-475c-a888-7d0531bed570,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-07a734a1-26d0-4e14-9565-b71dfa4e9f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-88b7d752-682e-4265-8ff2-e325a743d84b,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-c83b711c-067a-42a3-8e7b-32ca31235c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-c3854511-2666-41d8-a254-3b24bc4277e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-8a22dd23-dc06-40a2-b763-6431acb584bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-41ed971c-ed8c-4400-adaa-fbfaa9e2fde0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029166144-172.17.0.15-1597641518828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40646,DS-2f9b2a38-f04f-444a-83ff-589c1617b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-95f3562f-6644-4f80-ba1f-9b84cb62c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-48c95114-d10c-454d-a21d-aa6fbcda4519,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-e9aaff31-546e-458f-b157-2590efc2b730,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-ef44fbc6-610a-4219-9659-7067618ffd63,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e1f4a68c-ebb5-473f-8c90-fbde060c6d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-b1e71914-4386-411e-9da0-17c510f49c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-e987383f-4186-4d0e-940d-b6ab4f308687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029166144-172.17.0.15-1597641518828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40646,DS-2f9b2a38-f04f-444a-83ff-589c1617b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-95f3562f-6644-4f80-ba1f-9b84cb62c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-48c95114-d10c-454d-a21d-aa6fbcda4519,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-e9aaff31-546e-458f-b157-2590efc2b730,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-ef44fbc6-610a-4219-9659-7067618ffd63,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e1f4a68c-ebb5-473f-8c90-fbde060c6d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-b1e71914-4386-411e-9da0-17c510f49c98,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-e987383f-4186-4d0e-940d-b6ab4f308687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60281443-172.17.0.15-1597641715079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-bd64a53c-bbe5-4e37-b2e4-63b4e93de71c,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-681612ed-ede9-4972-9eb5-468919b93090,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-e71e595c-b74e-41f5-ad58-9bbdb23e6cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-824ae628-ff93-4318-b4c2-0027298b0f72,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-4ea2050a-fb89-4c19-a770-49a63fb29439,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-59482033-8b80-4b8f-acbe-b816a5af95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-18fb7c04-96ed-47f7-ba2b-d436eaeb00a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-c0c47f31-868b-4b52-a190-02d873b51787,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60281443-172.17.0.15-1597641715079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-bd64a53c-bbe5-4e37-b2e4-63b4e93de71c,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-681612ed-ede9-4972-9eb5-468919b93090,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-e71e595c-b74e-41f5-ad58-9bbdb23e6cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-824ae628-ff93-4318-b4c2-0027298b0f72,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-4ea2050a-fb89-4c19-a770-49a63fb29439,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-59482033-8b80-4b8f-acbe-b816a5af95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-18fb7c04-96ed-47f7-ba2b-d436eaeb00a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-c0c47f31-868b-4b52-a190-02d873b51787,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647005695-172.17.0.15-1597641959113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-8b1e40f9-2441-4afd-ac14-82c0427433c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-ad8b1f39-316e-4925-b618-262f8e7b918e,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-e7aab3b2-5917-4b64-b0cb-5858a757cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-837d2ac1-e0e8-4f0f-b35e-be62e54ad791,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-adef5654-27df-4156-a985-809ac66af76d,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-86d92539-962c-4521-bb90-b31b39107d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-b50cf6d7-7819-43f8-acde-218464622ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-c7d9f231-5a74-422b-a5b0-1429eed40c3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647005695-172.17.0.15-1597641959113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-8b1e40f9-2441-4afd-ac14-82c0427433c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-ad8b1f39-316e-4925-b618-262f8e7b918e,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-e7aab3b2-5917-4b64-b0cb-5858a757cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-837d2ac1-e0e8-4f0f-b35e-be62e54ad791,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-adef5654-27df-4156-a985-809ac66af76d,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-86d92539-962c-4521-bb90-b31b39107d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-b50cf6d7-7819-43f8-acde-218464622ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-c7d9f231-5a74-422b-a5b0-1429eed40c3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461551145-172.17.0.15-1597641992484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-f710b44b-1f0c-4a47-a3a8-fe456497da4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-0f6cfa42-1770-4059-b6c9-4d39b494d739,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-fac6bdaf-526c-43b4-a759-433ebbdeb808,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-67df7a9b-c11f-406f-bcc4-dc8d584dc493,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-0ea8aa87-a18d-474a-a820-9d026acc4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a8c7bd1a-dcb0-4e8a-8f26-612b4c6ee32b,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-c45520c4-d196-4dcb-9ac0-a3d573667923,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-e86b3d72-3f06-4bae-9144-d3f1acbebfdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461551145-172.17.0.15-1597641992484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-f710b44b-1f0c-4a47-a3a8-fe456497da4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-0f6cfa42-1770-4059-b6c9-4d39b494d739,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-fac6bdaf-526c-43b4-a759-433ebbdeb808,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-67df7a9b-c11f-406f-bcc4-dc8d584dc493,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-0ea8aa87-a18d-474a-a820-9d026acc4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a8c7bd1a-dcb0-4e8a-8f26-612b4c6ee32b,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-c45520c4-d196-4dcb-9ac0-a3d573667923,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-e86b3d72-3f06-4bae-9144-d3f1acbebfdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594207168-172.17.0.15-1597642221696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-99aa5d5c-0352-4409-9915-82581a100479,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-d8944e14-6b9b-4360-987e-2f6a391508ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-150cb50b-67dc-4095-a114-2defd17e0371,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-bf9b8c89-1f17-4195-9297-17bd1c71ba93,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-f1ab3527-d57e-4aa5-ba58-688a3468c974,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-dc310aa7-ac23-4b73-bf8b-f62dac563fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-241f72db-88bd-49db-b937-96165fe1d956,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-2e8bdbc0-7d93-4c4c-82c2-f113fa3e3f61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594207168-172.17.0.15-1597642221696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-99aa5d5c-0352-4409-9915-82581a100479,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-d8944e14-6b9b-4360-987e-2f6a391508ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-150cb50b-67dc-4095-a114-2defd17e0371,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-bf9b8c89-1f17-4195-9297-17bd1c71ba93,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-f1ab3527-d57e-4aa5-ba58-688a3468c974,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-dc310aa7-ac23-4b73-bf8b-f62dac563fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-241f72db-88bd-49db-b937-96165fe1d956,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-2e8bdbc0-7d93-4c4c-82c2-f113fa3e3f61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208773388-172.17.0.15-1597642334137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45888,DS-2530c0cc-8084-4a3d-b7dc-b0d934817ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-557b6c69-c7f0-4d84-8f52-ebfccfbc72d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-8e7f5986-7970-4348-98b7-418b3950689e,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-0790b8a2-b37d-420d-84aa-f6c7aea361de,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-9d0a4731-d6be-4539-8648-608fbcd8fc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-89d5f0e7-1181-4f19-9027-eb3387e4f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-3e624591-3f96-4d8c-8d69-57f9df54def3,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-7c71c110-8c05-49ad-b025-90f695997e88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208773388-172.17.0.15-1597642334137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45888,DS-2530c0cc-8084-4a3d-b7dc-b0d934817ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-557b6c69-c7f0-4d84-8f52-ebfccfbc72d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-8e7f5986-7970-4348-98b7-418b3950689e,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-0790b8a2-b37d-420d-84aa-f6c7aea361de,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-9d0a4731-d6be-4539-8648-608fbcd8fc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-89d5f0e7-1181-4f19-9027-eb3387e4f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-3e624591-3f96-4d8c-8d69-57f9df54def3,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-7c71c110-8c05-49ad-b025-90f695997e88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235488145-172.17.0.15-1597642370809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40841,DS-c8ced59d-97f1-44c9-8454-05a48ba88dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-9cf13d87-1f07-4a32-b424-18c4f90c9678,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-b99a1e1d-070a-4e06-9749-48cf2d491d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-7e404f82-8e5e-40c8-a18b-bb874ede654b,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-6bdda676-8f0f-4649-a0e3-18e083dac22b,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-16850e4b-2f9d-4f0b-84bb-6651aeec0158,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-3079c220-4862-492d-b55d-fb8917fd97d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-360dc5c0-d675-443f-902c-d42e7324c402,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235488145-172.17.0.15-1597642370809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40841,DS-c8ced59d-97f1-44c9-8454-05a48ba88dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-9cf13d87-1f07-4a32-b424-18c4f90c9678,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-b99a1e1d-070a-4e06-9749-48cf2d491d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-7e404f82-8e5e-40c8-a18b-bb874ede654b,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-6bdda676-8f0f-4649-a0e3-18e083dac22b,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-16850e4b-2f9d-4f0b-84bb-6651aeec0158,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-3079c220-4862-492d-b55d-fb8917fd97d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-360dc5c0-d675-443f-902c-d42e7324c402,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82282942-172.17.0.15-1597642486353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35724,DS-e14283f4-5be7-4036-98d9-9617f3c6ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-547e2fcc-3592-4811-93cb-93175bc17cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-59ccd48d-05d8-4f57-8485-f9cb34a90ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-8a5151d5-a6ec-4ee9-afdb-8d42de91b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-c8eecd68-94ce-4dc2-9e11-184194d83aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-2aca0619-9dfc-4f19-a372-a248dd44fe96,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-a5ada394-65aa-4427-ad8b-10e5720d2cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-b06941bb-b8f2-49a1-bce6-325263cc4e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82282942-172.17.0.15-1597642486353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35724,DS-e14283f4-5be7-4036-98d9-9617f3c6ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-547e2fcc-3592-4811-93cb-93175bc17cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-59ccd48d-05d8-4f57-8485-f9cb34a90ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-8a5151d5-a6ec-4ee9-afdb-8d42de91b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-c8eecd68-94ce-4dc2-9e11-184194d83aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-2aca0619-9dfc-4f19-a372-a248dd44fe96,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-a5ada394-65aa-4427-ad8b-10e5720d2cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40313,DS-b06941bb-b8f2-49a1-bce6-325263cc4e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351749502-172.17.0.15-1597642551660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45273,DS-28d2f70b-a3f5-4375-bd97-33434da0924e,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-9c184250-b761-41cd-934b-a92e0c4c2dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-fc693395-1582-4525-94c8-a2de43382c17,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-dc46eed9-67f6-45f7-884b-e67377830ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-2a840224-4bd5-4626-be9e-331c79ee01c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-87ba6a25-63c2-46ae-926f-42fbe5c9b533,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-b072a75e-870c-4db4-a660-dec4478d16d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-5f9f21d2-222b-4add-acec-d0aac9516222,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351749502-172.17.0.15-1597642551660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45273,DS-28d2f70b-a3f5-4375-bd97-33434da0924e,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-9c184250-b761-41cd-934b-a92e0c4c2dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-fc693395-1582-4525-94c8-a2de43382c17,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-dc46eed9-67f6-45f7-884b-e67377830ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-2a840224-4bd5-4626-be9e-331c79ee01c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-87ba6a25-63c2-46ae-926f-42fbe5c9b533,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-b072a75e-870c-4db4-a660-dec4478d16d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-5f9f21d2-222b-4add-acec-d0aac9516222,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154206086-172.17.0.15-1597642630013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-fc5794eb-8976-425e-a6f1-5776a50eb3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-d8a94655-03f3-4ddf-855e-7e530875be4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-04056b57-ea34-40d5-9f73-d52c0a5bc44c,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-14397ada-030b-4ef5-a6d4-6e22672d509d,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-6aa05537-4abd-4af0-a695-f5cbb98bba10,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-16c6dcca-7178-419b-a1b6-64063a79cd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-e99a29ab-9062-47fa-8e46-4caebc740109,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-aae3422f-c7f2-4a8b-9e72-8633f11d2331,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154206086-172.17.0.15-1597642630013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-fc5794eb-8976-425e-a6f1-5776a50eb3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-d8a94655-03f3-4ddf-855e-7e530875be4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-04056b57-ea34-40d5-9f73-d52c0a5bc44c,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-14397ada-030b-4ef5-a6d4-6e22672d509d,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-6aa05537-4abd-4af0-a695-f5cbb98bba10,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-16c6dcca-7178-419b-a1b6-64063a79cd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-e99a29ab-9062-47fa-8e46-4caebc740109,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-aae3422f-c7f2-4a8b-9e72-8633f11d2331,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962860198-172.17.0.15-1597642739812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40043,DS-b0c7d50b-19a5-49f7-981a-ef785764284e,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-0bf059f4-c9e3-4298-9953-f09645f1ba21,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-26cd6295-336a-42e9-9d6e-764c1f9efff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-93a67907-da2c-4fa1-864c-844b27480028,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-6530d8f3-193e-4547-beff-97f5b134044d,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-3cbedf00-fd96-47fe-82ae-e8528432c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-0b910b12-ff75-4757-85fe-bd3b7afbd4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-1a9dc2db-57c4-4c3f-a7d5-53546d660826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962860198-172.17.0.15-1597642739812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40043,DS-b0c7d50b-19a5-49f7-981a-ef785764284e,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-0bf059f4-c9e3-4298-9953-f09645f1ba21,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-26cd6295-336a-42e9-9d6e-764c1f9efff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-93a67907-da2c-4fa1-864c-844b27480028,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-6530d8f3-193e-4547-beff-97f5b134044d,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-3cbedf00-fd96-47fe-82ae-e8528432c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-0b910b12-ff75-4757-85fe-bd3b7afbd4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-1a9dc2db-57c4-4c3f-a7d5-53546d660826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 1s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701156281-172.17.0.15-1597642856623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-0598da3f-c45d-48be-b008-5d634389aabe,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-0c6ee4fc-fcc7-4cdf-8d23-b123a5e1bcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-d14b3438-a498-4716-b7a6-201711ed0779,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-a5e8bb81-2056-4e51-9fa0-b97d7ee8cbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-8bb14819-27ea-4549-ae07-0a864351fd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-db7fb26b-2883-45d8-a300-17c342c7be96,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-6fd5cb75-4cc8-41e6-b5c2-67817af65dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-a508058c-a9e5-43a8-a863-139a0166b9a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701156281-172.17.0.15-1597642856623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44536,DS-0598da3f-c45d-48be-b008-5d634389aabe,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-0c6ee4fc-fcc7-4cdf-8d23-b123a5e1bcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-d14b3438-a498-4716-b7a6-201711ed0779,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-a5e8bb81-2056-4e51-9fa0-b97d7ee8cbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-8bb14819-27ea-4549-ae07-0a864351fd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-db7fb26b-2883-45d8-a300-17c342c7be96,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-6fd5cb75-4cc8-41e6-b5c2-67817af65dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-a508058c-a9e5-43a8-a863-139a0166b9a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5661
