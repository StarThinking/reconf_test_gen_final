reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1755486289-172.17.0.12-1597292541616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34274,DS-3d788eb5-0581-48ea-8255-6613c13eebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-a6d1a149-dcc2-46ba-9bd2-b177ccd0927c,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-3db5314b-3f24-4eef-bcdd-2919806702fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-2043d34c-a655-4381-a46b-6336fcd2871a,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-a2aef651-b138-4a4e-b9c5-ec0917d44531,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-05062585-de85-4d65-bb96-d08bc89e80c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-17b28cac-04ff-4ad8-bd93-daceb9e8e2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-949a7b7a-26f3-4b7d-a173-9307154ad9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1755486289-172.17.0.12-1597292541616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34274,DS-3d788eb5-0581-48ea-8255-6613c13eebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-a6d1a149-dcc2-46ba-9bd2-b177ccd0927c,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-3db5314b-3f24-4eef-bcdd-2919806702fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-2043d34c-a655-4381-a46b-6336fcd2871a,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-a2aef651-b138-4a4e-b9c5-ec0917d44531,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-05062585-de85-4d65-bb96-d08bc89e80c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-17b28cac-04ff-4ad8-bd93-daceb9e8e2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-949a7b7a-26f3-4b7d-a173-9307154ad9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970224351-172.17.0.12-1597293158261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45992,DS-c5edd86b-1159-4647-8c55-0337b20ec356,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-cf1b1d05-dfaa-4fcd-acb8-f60984dcf92c,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-85843640-7260-4bf0-b082-4c625d14ba45,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-697beeb1-cc5a-48dc-8f47-32a6cd5c653b,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-87bd13aa-c2e9-45fe-a2fa-90c1cab9427e,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-65d718bc-38ce-4b58-b4e5-4b7f8ebeb267,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-9276eeac-a9fe-455b-a260-f40acfda1acd,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-e9d3ccb1-645f-4317-b264-870edff1a6ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970224351-172.17.0.12-1597293158261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45992,DS-c5edd86b-1159-4647-8c55-0337b20ec356,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-cf1b1d05-dfaa-4fcd-acb8-f60984dcf92c,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-85843640-7260-4bf0-b082-4c625d14ba45,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-697beeb1-cc5a-48dc-8f47-32a6cd5c653b,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-87bd13aa-c2e9-45fe-a2fa-90c1cab9427e,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-65d718bc-38ce-4b58-b4e5-4b7f8ebeb267,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-9276eeac-a9fe-455b-a260-f40acfda1acd,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-e9d3ccb1-645f-4317-b264-870edff1a6ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767738444-172.17.0.12-1597293553650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-22147d0d-e951-4d20-8e74-94ad39d14e83,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-b800084d-a5fa-4fff-980b-61f3a8e8b7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-736eb298-5348-4f96-bb81-df9ff303120e,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-e289a704-2f9e-4ad8-b2ef-60d462142447,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-05ab0672-aef0-4e0c-8a0b-c5dc64e05970,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-a2315cbd-1083-4ff3-b6b4-5f5cb3182f84,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-a9f51337-c99d-448c-901d-87eefc980dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-2a68159a-e2af-414a-85ff-cd8ce6def27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767738444-172.17.0.12-1597293553650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-22147d0d-e951-4d20-8e74-94ad39d14e83,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-b800084d-a5fa-4fff-980b-61f3a8e8b7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-736eb298-5348-4f96-bb81-df9ff303120e,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-e289a704-2f9e-4ad8-b2ef-60d462142447,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-05ab0672-aef0-4e0c-8a0b-c5dc64e05970,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-a2315cbd-1083-4ff3-b6b4-5f5cb3182f84,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-a9f51337-c99d-448c-901d-87eefc980dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-2a68159a-e2af-414a-85ff-cd8ce6def27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769391157-172.17.0.12-1597294102994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-5394c6d6-967a-4d41-8c70-d645606f2b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-371bbcc1-13e6-499e-b623-4dc73e42e094,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-6c8076c5-a4bf-4f31-9d4a-fdac8e1fe12c,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-384e7c85-cf34-4e81-b90e-3cd28ace1394,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-f26f2825-67fa-43a3-937a-43fdc376f03b,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-17379e28-5256-4f2c-8c6b-e919155e56e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-382efa81-21c8-41eb-9e77-343fc0ed3f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-68466bf4-2d10-4cc0-8196-014760530b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769391157-172.17.0.12-1597294102994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-5394c6d6-967a-4d41-8c70-d645606f2b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-371bbcc1-13e6-499e-b623-4dc73e42e094,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-6c8076c5-a4bf-4f31-9d4a-fdac8e1fe12c,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-384e7c85-cf34-4e81-b90e-3cd28ace1394,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-f26f2825-67fa-43a3-937a-43fdc376f03b,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-17379e28-5256-4f2c-8c6b-e919155e56e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-382efa81-21c8-41eb-9e77-343fc0ed3f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-68466bf4-2d10-4cc0-8196-014760530b2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165151659-172.17.0.12-1597294240757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36292,DS-e278b966-0c74-445e-a6d9-1206b547f57b,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-02d3542c-f6d2-4500-b25d-e5ecb58d31d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-260e7ec6-5374-4242-915b-b6f86e9ff2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-174d1704-523b-4e8c-9cf4-92c4952cf547,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-a6e3b476-05b0-465b-b6fb-2b95dd76d6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-bb7cd7fb-0a34-4278-92cb-e75b03d48be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-4a83fa2e-497a-442d-9fca-18fb5137dbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-fa9be586-ed70-4359-b6f5-060d6902f4b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165151659-172.17.0.12-1597294240757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36292,DS-e278b966-0c74-445e-a6d9-1206b547f57b,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-02d3542c-f6d2-4500-b25d-e5ecb58d31d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-260e7ec6-5374-4242-915b-b6f86e9ff2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-174d1704-523b-4e8c-9cf4-92c4952cf547,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-a6e3b476-05b0-465b-b6fb-2b95dd76d6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-bb7cd7fb-0a34-4278-92cb-e75b03d48be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-4a83fa2e-497a-442d-9fca-18fb5137dbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-fa9be586-ed70-4359-b6f5-060d6902f4b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125857757-172.17.0.12-1597294279014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42649,DS-14c4b399-46ab-4231-94b1-80bf5aee37a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-254b5998-06b5-4d3f-9a45-b04342727c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-107fc13c-dd93-4550-b292-11ca0fcd6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-9ec3aebf-ba89-4f62-bf34-920c8c890cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-fd464170-2fc6-4ebf-a8bd-cb48c087f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-19080222-d4c7-42a8-b41b-1b05a435567c,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-8a1d8fbb-adac-4c92-86af-520ff2e00d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-a1825ea4-673b-4359-a04e-c469828cc39e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125857757-172.17.0.12-1597294279014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42649,DS-14c4b399-46ab-4231-94b1-80bf5aee37a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-254b5998-06b5-4d3f-9a45-b04342727c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-107fc13c-dd93-4550-b292-11ca0fcd6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-9ec3aebf-ba89-4f62-bf34-920c8c890cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-fd464170-2fc6-4ebf-a8bd-cb48c087f5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-19080222-d4c7-42a8-b41b-1b05a435567c,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-8a1d8fbb-adac-4c92-86af-520ff2e00d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-a1825ea4-673b-4359-a04e-c469828cc39e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611674535-172.17.0.12-1597294425288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40022,DS-5e786e03-b571-48cc-8a88-094b0f3b0970,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-2f427634-9bcd-41ed-a9ac-c2b2af8bddce,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-adf4b437-8cb1-4aba-9c64-f6e88f780f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-0d631aef-3646-4c8e-8696-df8d2ce6ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-4290c411-fc19-4a10-8767-99b482bccd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-9f2cf277-c05d-4eab-88ba-43bdf891370e,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-3cf3781a-1ff0-4d4e-9a39-261fffd76746,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-0e063693-d82f-423f-9177-219b56b78761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611674535-172.17.0.12-1597294425288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40022,DS-5e786e03-b571-48cc-8a88-094b0f3b0970,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-2f427634-9bcd-41ed-a9ac-c2b2af8bddce,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-adf4b437-8cb1-4aba-9c64-f6e88f780f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-0d631aef-3646-4c8e-8696-df8d2ce6ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-4290c411-fc19-4a10-8767-99b482bccd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-9f2cf277-c05d-4eab-88ba-43bdf891370e,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-3cf3781a-1ff0-4d4e-9a39-261fffd76746,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-0e063693-d82f-423f-9177-219b56b78761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597666951-172.17.0.12-1597295023844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-017e9291-92ae-4c35-a4dd-d0a79386d4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-04ff0237-5eef-4c4e-bdcf-8ae53ef4803b,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-e21410c6-840c-49ff-a8f6-1a5c4cf39e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-35a2ff7b-16e2-4939-b7b1-a3303af7012b,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-62cd625d-2b0d-4f67-a3ec-64fb59ba8517,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-fbfc092a-de0c-4ae0-8564-588d00f663ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-d218f575-d828-4489-b1cc-72e59c57ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-09e22c3f-d159-4670-aae7-b32bf7a5a93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597666951-172.17.0.12-1597295023844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-017e9291-92ae-4c35-a4dd-d0a79386d4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-04ff0237-5eef-4c4e-bdcf-8ae53ef4803b,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-e21410c6-840c-49ff-a8f6-1a5c4cf39e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-35a2ff7b-16e2-4939-b7b1-a3303af7012b,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-62cd625d-2b0d-4f67-a3ec-64fb59ba8517,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-fbfc092a-de0c-4ae0-8564-588d00f663ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-d218f575-d828-4489-b1cc-72e59c57ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-09e22c3f-d159-4670-aae7-b32bf7a5a93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202230797-172.17.0.12-1597295671418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-fd25c8e2-f81a-49e8-acfa-321395686eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-d9d73113-5932-49a9-93d8-debdc639dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-de451be6-333a-44aa-98e3-d9c778078dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-9a0d2859-b54f-404a-b75b-aa16cbe3adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-d83dd885-6f9e-463c-8976-0b3b84a6a0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-673ebc0a-b9eb-4aee-af2a-a9d29a988e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-3f4c2695-55a1-4c80-ab0d-36b3744b8a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-2d1a8e26-a39e-421a-9696-bf556679a4c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202230797-172.17.0.12-1597295671418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-fd25c8e2-f81a-49e8-acfa-321395686eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-d9d73113-5932-49a9-93d8-debdc639dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-de451be6-333a-44aa-98e3-d9c778078dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-9a0d2859-b54f-404a-b75b-aa16cbe3adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-d83dd885-6f9e-463c-8976-0b3b84a6a0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-673ebc0a-b9eb-4aee-af2a-a9d29a988e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-3f4c2695-55a1-4c80-ab0d-36b3744b8a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-2d1a8e26-a39e-421a-9696-bf556679a4c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257741795-172.17.0.12-1597296350202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38488,DS-fad66751-0014-427b-97ab-577ef105fcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-a5bf5033-8537-4bac-b926-d8bbfe079f15,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-6b8a1dd3-6058-47c9-b623-fe08aa78f6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-6eedd1dd-e0be-41bb-9a31-f7fcde075be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-eb31bdbd-0681-41fb-9f7b-6644270fc3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-a56f64db-7418-476d-a39f-843935b7f0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-90c91fef-12a1-4a80-b009-39f31bfa6dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-3bc4c3a7-ce82-4d96-ac00-1cc9b32d1fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257741795-172.17.0.12-1597296350202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38488,DS-fad66751-0014-427b-97ab-577ef105fcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-a5bf5033-8537-4bac-b926-d8bbfe079f15,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-6b8a1dd3-6058-47c9-b623-fe08aa78f6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-6eedd1dd-e0be-41bb-9a31-f7fcde075be0,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-eb31bdbd-0681-41fb-9f7b-6644270fc3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-a56f64db-7418-476d-a39f-843935b7f0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-90c91fef-12a1-4a80-b009-39f31bfa6dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-3bc4c3a7-ce82-4d96-ac00-1cc9b32d1fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873202415-172.17.0.12-1597296460773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45695,DS-c23d5c21-3ee0-435e-8bf6-cfe20df6cfff,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-b9b0afe9-9122-4064-8492-6c288e51ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-eae00c25-9336-4c37-8eed-3faf5e982797,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-13a7a857-5413-4100-a8b4-d5ff43c5fea4,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-a107b356-ffc2-4e46-bd4d-612bc53741a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-7640421b-37a8-4e75-9553-c4897f41ae9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-2642e86f-3bc2-4235-b527-1a38c72fbe89,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-9d0bc51c-53b0-431c-af83-579fe3e2eae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873202415-172.17.0.12-1597296460773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45695,DS-c23d5c21-3ee0-435e-8bf6-cfe20df6cfff,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-b9b0afe9-9122-4064-8492-6c288e51ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-eae00c25-9336-4c37-8eed-3faf5e982797,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-13a7a857-5413-4100-a8b4-d5ff43c5fea4,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-a107b356-ffc2-4e46-bd4d-612bc53741a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-7640421b-37a8-4e75-9553-c4897f41ae9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-2642e86f-3bc2-4235-b527-1a38c72fbe89,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-9d0bc51c-53b0-431c-af83-579fe3e2eae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324446702-172.17.0.12-1597296600377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35192,DS-29c32d0d-66e9-4e7f-85c3-9e85e51d5cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-85036986-3fa8-4b70-811e-118063e694dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-7dea9ac1-4283-4024-aaa7-281ab4b2db8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-1dc5fa90-37b3-4ddd-83db-3b0238582120,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-44aca808-3c95-4669-88ba-b96bd2b05d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-a8fe4e41-2451-4534-94eb-1bf86da11d57,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-d33941ac-a78a-4ccd-8c21-217ca6e53269,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-1d432862-59d7-467a-bdaa-6aa93ae6f450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324446702-172.17.0.12-1597296600377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35192,DS-29c32d0d-66e9-4e7f-85c3-9e85e51d5cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-85036986-3fa8-4b70-811e-118063e694dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-7dea9ac1-4283-4024-aaa7-281ab4b2db8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-1dc5fa90-37b3-4ddd-83db-3b0238582120,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-44aca808-3c95-4669-88ba-b96bd2b05d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-a8fe4e41-2451-4534-94eb-1bf86da11d57,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-d33941ac-a78a-4ccd-8c21-217ca6e53269,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-1d432862-59d7-467a-bdaa-6aa93ae6f450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420970365-172.17.0.12-1597296899542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-271deac7-8dcf-4c35-ae88-0d459dc1995f,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-13fe879e-9257-4d7c-938c-09ad873ed8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-ca0ac408-eae7-48c3-b47d-1945eeb64ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-85cad493-5827-45a7-95b5-8ceb6160d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-d8e9639f-8dfc-4357-9210-24e529eaec62,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-22ed38f5-bdbc-47c9-93a3-eb7cc1b52f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-09fb9bba-3c0d-468d-9ab3-72dc71990e62,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-8b877e8e-afb4-4ff8-bedc-f56865ed5c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420970365-172.17.0.12-1597296899542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33563,DS-271deac7-8dcf-4c35-ae88-0d459dc1995f,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-13fe879e-9257-4d7c-938c-09ad873ed8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-ca0ac408-eae7-48c3-b47d-1945eeb64ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-85cad493-5827-45a7-95b5-8ceb6160d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-d8e9639f-8dfc-4357-9210-24e529eaec62,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-22ed38f5-bdbc-47c9-93a3-eb7cc1b52f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-09fb9bba-3c0d-468d-9ab3-72dc71990e62,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-8b877e8e-afb4-4ff8-bedc-f56865ed5c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316767379-172.17.0.12-1597296936020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-3e57e78b-271c-474f-8207-27dd0f45db5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-edeb8b66-6cdf-4f95-8e9b-21f271555cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-8ac0c61a-826c-454b-895c-441148b2e731,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-30cdaf9f-0edd-45a9-9edf-0c7275a0ca81,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-fe10728a-c11a-4618-8916-3c1a1f7af467,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-e7de1bd7-8e43-4e09-af3c-5733024ded0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-eea21538-c833-439b-b8a2-dc03eadbef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-55e2c446-4219-40d1-acbe-b2857412bb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316767379-172.17.0.12-1597296936020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-3e57e78b-271c-474f-8207-27dd0f45db5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-edeb8b66-6cdf-4f95-8e9b-21f271555cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-8ac0c61a-826c-454b-895c-441148b2e731,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-30cdaf9f-0edd-45a9-9edf-0c7275a0ca81,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-fe10728a-c11a-4618-8916-3c1a1f7af467,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-e7de1bd7-8e43-4e09-af3c-5733024ded0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-eea21538-c833-439b-b8a2-dc03eadbef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-55e2c446-4219-40d1-acbe-b2857412bb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104677108-172.17.0.12-1597297168902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41312,DS-49bec522-f06e-4f09-898f-31e7174bbfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-9b27e5fd-2939-4c0d-a95c-64d06af17ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-02dbb883-1016-45a4-b8d4-fbc94fa1d1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-ce3c2129-b621-4145-a447-80aa8f72c607,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-0e2c0783-3e55-41cd-9464-c6d136ee5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-fce81368-a3e9-4243-b37c-05da7843daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-097bf9a6-2488-488c-8e9c-28146a8e1a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-0a715770-e07c-4752-a237-04195324bab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104677108-172.17.0.12-1597297168902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41312,DS-49bec522-f06e-4f09-898f-31e7174bbfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-9b27e5fd-2939-4c0d-a95c-64d06af17ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-02dbb883-1016-45a4-b8d4-fbc94fa1d1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-ce3c2129-b621-4145-a447-80aa8f72c607,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-0e2c0783-3e55-41cd-9464-c6d136ee5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-fce81368-a3e9-4243-b37c-05da7843daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-097bf9a6-2488-488c-8e9c-28146a8e1a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-0a715770-e07c-4752-a237-04195324bab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987270761-172.17.0.12-1597297366738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-252202b4-4f2a-4e46-8347-f66b6ba50115,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-12f2a4fb-2ec9-4449-9185-d3109875f623,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-57f464c1-1479-4313-97a7-b0fc6b6b849a,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-539966fa-2efe-4e83-a42e-e69daedde86a,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-5242cda3-4033-468e-a50e-7813e76012ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-51cfe600-0a9e-4f18-83ea-4a1fc0e28eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-7e24858d-9b52-4be0-830e-975df17a86bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-90e5034f-de77-415c-8abd-ddd724441071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987270761-172.17.0.12-1597297366738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-252202b4-4f2a-4e46-8347-f66b6ba50115,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-12f2a4fb-2ec9-4449-9185-d3109875f623,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-57f464c1-1479-4313-97a7-b0fc6b6b849a,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-539966fa-2efe-4e83-a42e-e69daedde86a,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-5242cda3-4033-468e-a50e-7813e76012ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-51cfe600-0a9e-4f18-83ea-4a1fc0e28eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-7e24858d-9b52-4be0-830e-975df17a86bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-90e5034f-de77-415c-8abd-ddd724441071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5259
