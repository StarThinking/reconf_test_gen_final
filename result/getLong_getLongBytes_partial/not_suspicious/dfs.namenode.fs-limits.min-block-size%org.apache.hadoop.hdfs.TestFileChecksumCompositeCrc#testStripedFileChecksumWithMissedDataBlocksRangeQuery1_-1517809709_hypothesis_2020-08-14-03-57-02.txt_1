reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242515704-172.17.0.9-1597377731585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40740,DS-16fab608-2d23-492a-b01f-fb592c2f3d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-606013a1-ad14-41e0-b7c6-7afca3ca3415,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-353a0fe5-286b-433d-9115-0ae5c2a7dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-d5167084-7276-4021-8d5b-4df03f5c5266,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-efc1ea7e-4184-415d-a29a-59ad684d7955,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-c6afc5ed-5643-4e89-acc7-9d2f4ed7cd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-f7cb7ad3-da77-4b22-9935-bbedb313180a,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-b0ee7e44-808e-4e0c-b129-74728c8fc9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242515704-172.17.0.9-1597377731585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40740,DS-16fab608-2d23-492a-b01f-fb592c2f3d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-606013a1-ad14-41e0-b7c6-7afca3ca3415,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-353a0fe5-286b-433d-9115-0ae5c2a7dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-d5167084-7276-4021-8d5b-4df03f5c5266,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-efc1ea7e-4184-415d-a29a-59ad684d7955,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-c6afc5ed-5643-4e89-acc7-9d2f4ed7cd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-f7cb7ad3-da77-4b22-9935-bbedb313180a,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-b0ee7e44-808e-4e0c-b129-74728c8fc9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485726592-172.17.0.9-1597377849150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38300,DS-69a32374-46c8-417a-9291-3597c07f8bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-71a9f167-458f-45e1-b0e8-b6358b323575,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-b93681a9-c494-4b8a-9bd9-1653caf07bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-e49c8d50-8291-46b8-a6ee-cec9877cae17,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-5a813a72-e0b0-445c-a8bb-e509ddd5f91d,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-cc064d1c-6a58-4487-b43a-1534d02f45c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-59ae2c2d-eb08-49e0-9d02-563f664f6fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-bde09bad-4828-49bc-babe-78d07ded86fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485726592-172.17.0.9-1597377849150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38300,DS-69a32374-46c8-417a-9291-3597c07f8bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-71a9f167-458f-45e1-b0e8-b6358b323575,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-b93681a9-c494-4b8a-9bd9-1653caf07bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-e49c8d50-8291-46b8-a6ee-cec9877cae17,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-5a813a72-e0b0-445c-a8bb-e509ddd5f91d,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-cc064d1c-6a58-4487-b43a-1534d02f45c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-59ae2c2d-eb08-49e0-9d02-563f664f6fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-bde09bad-4828-49bc-babe-78d07ded86fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204352677-172.17.0.9-1597377883730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45237,DS-66a49aef-76fb-47e7-86ce-69d2a8b0f643,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-6bb27d2b-cb35-403a-8e44-ff7fa750a932,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-c7a6100c-f1e7-49e9-900f-a84af1799d08,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-83328735-2332-4c9f-841b-d439787513f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-3f86dea7-4c14-4cd7-8881-9e1ad7ffd5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-28ba8b61-e7b8-4df4-a00e-76b1a6e13f52,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-5d5abd1d-b778-442d-bbc9-3310b4aeca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-85a9d3f9-dda8-4a10-acd4-bcc084a6e314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204352677-172.17.0.9-1597377883730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45237,DS-66a49aef-76fb-47e7-86ce-69d2a8b0f643,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-6bb27d2b-cb35-403a-8e44-ff7fa750a932,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-c7a6100c-f1e7-49e9-900f-a84af1799d08,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-83328735-2332-4c9f-841b-d439787513f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-3f86dea7-4c14-4cd7-8881-9e1ad7ffd5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-28ba8b61-e7b8-4df4-a00e-76b1a6e13f52,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-5d5abd1d-b778-442d-bbc9-3310b4aeca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-85a9d3f9-dda8-4a10-acd4-bcc084a6e314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211572366-172.17.0.9-1597378007068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-dbec6518-baf7-4322-8364-a632c2066674,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-3edbefca-13f6-4005-ade4-2f65b3c06a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-46a39641-b035-42d1-990a-e9c961a54fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-594984ed-e2b6-4b01-8759-4bf11b2889c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-1a013e26-178a-4005-952f-95eb592f6a71,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-d5f0f4b8-513d-4640-b0b3-0100de38aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-449bf3f3-5091-4455-a276-56b0297de559,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-f15f958f-d477-46c3-8213-db97304c0f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211572366-172.17.0.9-1597378007068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-dbec6518-baf7-4322-8364-a632c2066674,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-3edbefca-13f6-4005-ade4-2f65b3c06a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-46a39641-b035-42d1-990a-e9c961a54fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-594984ed-e2b6-4b01-8759-4bf11b2889c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-1a013e26-178a-4005-952f-95eb592f6a71,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-d5f0f4b8-513d-4640-b0b3-0100de38aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-449bf3f3-5091-4455-a276-56b0297de559,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-f15f958f-d477-46c3-8213-db97304c0f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989554895-172.17.0.9-1597378765135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33539,DS-3273958e-26aa-4192-a5aa-60fe4b0569e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-9ea3b126-816a-4844-a41b-bf2f628bc75d,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-540ee28d-8d0b-464c-a209-a10a0b7feb56,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-13d09b98-b9de-4687-a141-573feedf0f25,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-655ec6c7-e3f3-4392-b2f5-a5c73170b0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-f10a4284-b9e7-49ee-ac75-87d400e5f0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-c04991c4-2861-4063-a768-ed1cd4909481,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-0954dfe0-9efe-44dc-9cd4-acf5e0fb28ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989554895-172.17.0.9-1597378765135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33539,DS-3273958e-26aa-4192-a5aa-60fe4b0569e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-9ea3b126-816a-4844-a41b-bf2f628bc75d,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-540ee28d-8d0b-464c-a209-a10a0b7feb56,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-13d09b98-b9de-4687-a141-573feedf0f25,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-655ec6c7-e3f3-4392-b2f5-a5c73170b0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-f10a4284-b9e7-49ee-ac75-87d400e5f0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-c04991c4-2861-4063-a768-ed1cd4909481,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-0954dfe0-9efe-44dc-9cd4-acf5e0fb28ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3844777-172.17.0.9-1597379508764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-502f1980-3ed0-4515-9d1d-cab66c1b9856,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-d7283dbc-3926-4c68-b83c-20a2e969d324,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-53949918-5b44-4760-8022-1d025c120f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-8f78b0fe-f1c5-4953-ab19-2bb86654186a,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-07a16034-7a70-4f7e-a907-554acc716a40,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-f0a0b625-d995-4719-b2f8-2fa23c88f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-f5c4b97b-353a-4cce-93db-ac30cde02738,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-c356ac10-52f1-4814-a222-b4a61328ae09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3844777-172.17.0.9-1597379508764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-502f1980-3ed0-4515-9d1d-cab66c1b9856,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-d7283dbc-3926-4c68-b83c-20a2e969d324,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-53949918-5b44-4760-8022-1d025c120f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-8f78b0fe-f1c5-4953-ab19-2bb86654186a,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-07a16034-7a70-4f7e-a907-554acc716a40,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-f0a0b625-d995-4719-b2f8-2fa23c88f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-f5c4b97b-353a-4cce-93db-ac30cde02738,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-c356ac10-52f1-4814-a222-b4a61328ae09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245045437-172.17.0.9-1597379712688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-416c04b0-0293-4f40-a511-09f4e26f7899,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-b6db0984-dc0a-4832-9b64-3fd5d6eab624,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-3fe0c759-7a6c-4caf-8e8d-65b2f08287c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-0cc42181-fdb9-4b93-a8a5-d8a88b2f5e00,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-69e04870-e7ef-4f35-9bdb-ff9926ac5859,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-996644cd-0af1-4e08-b12b-df0b6e8fbd03,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-18bf265a-0a18-49f5-9603-74e60d3c35e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-de8ca077-66c9-4831-bec3-2db4828a8564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245045437-172.17.0.9-1597379712688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-416c04b0-0293-4f40-a511-09f4e26f7899,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-b6db0984-dc0a-4832-9b64-3fd5d6eab624,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-3fe0c759-7a6c-4caf-8e8d-65b2f08287c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-0cc42181-fdb9-4b93-a8a5-d8a88b2f5e00,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-69e04870-e7ef-4f35-9bdb-ff9926ac5859,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-996644cd-0af1-4e08-b12b-df0b6e8fbd03,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-18bf265a-0a18-49f5-9603-74e60d3c35e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-de8ca077-66c9-4831-bec3-2db4828a8564,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207683702-172.17.0.9-1597380291421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35502,DS-0de52c2f-ab67-4517-ad4b-6888ccc5b71f,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-ce444849-db2c-40fe-9cdd-99b9ef42391a,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-10edfe06-b574-4ac1-870e-2cbab73a788b,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-61c48949-d0aa-4de4-a2e3-5412fda6aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-6bf5425c-97ad-40dc-af58-0d9b146c42bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-182410ba-0ed5-40e3-8a74-477eb3443b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-61a52cf6-0441-47aa-ac2a-2894d9f6a830,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-857fec9f-292d-41db-b322-84858137c432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207683702-172.17.0.9-1597380291421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35502,DS-0de52c2f-ab67-4517-ad4b-6888ccc5b71f,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-ce444849-db2c-40fe-9cdd-99b9ef42391a,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-10edfe06-b574-4ac1-870e-2cbab73a788b,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-61c48949-d0aa-4de4-a2e3-5412fda6aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-6bf5425c-97ad-40dc-af58-0d9b146c42bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-182410ba-0ed5-40e3-8a74-477eb3443b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-61a52cf6-0441-47aa-ac2a-2894d9f6a830,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-857fec9f-292d-41db-b322-84858137c432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754905125-172.17.0.9-1597380408504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-e9483f2b-22d6-43fd-bcb9-5141991cf845,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-8d9faba9-900b-476e-bff7-c0466511f9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-b67f5b42-fa1a-4386-ace9-9220cb454ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-91d9de74-f093-4fe8-a780-29e1f5f2b867,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-04656613-edaf-40a4-b573-fbff706aabaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-90ecafce-02e6-4a7f-b9df-82713f7fcd17,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-2839c44a-dbc2-49f9-ad04-aa579919a245,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-b5380c10-81c2-4bec-bdc2-1f62f686f61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754905125-172.17.0.9-1597380408504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-e9483f2b-22d6-43fd-bcb9-5141991cf845,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-8d9faba9-900b-476e-bff7-c0466511f9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-b67f5b42-fa1a-4386-ace9-9220cb454ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-91d9de74-f093-4fe8-a780-29e1f5f2b867,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-04656613-edaf-40a4-b573-fbff706aabaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-90ecafce-02e6-4a7f-b9df-82713f7fcd17,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-2839c44a-dbc2-49f9-ad04-aa579919a245,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-b5380c10-81c2-4bec-bdc2-1f62f686f61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998306463-172.17.0.9-1597380565241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40950,DS-d3cc7e4c-7c37-4880-8306-7165084dc8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-779ccc45-48a4-414c-90e1-f1caae6552bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-3ad1c36b-c296-4306-af32-8c923a834f31,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-b3886d0f-ee21-45ec-aeb5-60a2885e847a,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-25120d8f-d12b-4f66-8ebe-dff44ebf2b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-0aca66ed-0ed9-4f41-9997-2665a4df50fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-09c243fe-3941-4b97-a17a-6ec53dc746dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-f07d880d-7a7e-4d6d-8741-570e481ec098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998306463-172.17.0.9-1597380565241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40950,DS-d3cc7e4c-7c37-4880-8306-7165084dc8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-779ccc45-48a4-414c-90e1-f1caae6552bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-3ad1c36b-c296-4306-af32-8c923a834f31,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-b3886d0f-ee21-45ec-aeb5-60a2885e847a,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-25120d8f-d12b-4f66-8ebe-dff44ebf2b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-0aca66ed-0ed9-4f41-9997-2665a4df50fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-09c243fe-3941-4b97-a17a-6ec53dc746dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-f07d880d-7a7e-4d6d-8741-570e481ec098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238789449-172.17.0.9-1597380674551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43381,DS-24b8d611-21c9-4759-b738-2e558ec1fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-192696d2-29db-4893-a0f5-810054cd835e,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-442ab8ba-3628-44ea-937b-eec5dac18e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-74107fca-6575-4887-be4c-2349119712bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-287775e4-8182-4d3f-a20c-5c792612a800,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-9eaa0496-8cde-40f5-a8d4-b37b2c776953,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-a578d28f-5c6d-4f03-987e-7f8e177f58a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-f0698cb9-5e0d-46ab-906b-324f2769e348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238789449-172.17.0.9-1597380674551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43381,DS-24b8d611-21c9-4759-b738-2e558ec1fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-192696d2-29db-4893-a0f5-810054cd835e,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-442ab8ba-3628-44ea-937b-eec5dac18e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-74107fca-6575-4887-be4c-2349119712bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-287775e4-8182-4d3f-a20c-5c792612a800,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-9eaa0496-8cde-40f5-a8d4-b37b2c776953,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-a578d28f-5c6d-4f03-987e-7f8e177f58a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-f0698cb9-5e0d-46ab-906b-324f2769e348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421881590-172.17.0.9-1597380944098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-32f55150-7daa-4d86-bdb3-8bd3a43c49b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-997e6cfc-a88d-45f4-8db7-a3210f5a3414,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-2b85b80d-e511-4992-ae2d-e6231328fbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-e3e7aa59-9f8c-40f1-b0e6-bd1ed3207e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-a8e93588-897f-4095-bef7-76067b040391,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-6ca63a67-e0dd-4e5e-8ebb-2bae400a813a,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-bd34d12b-1168-49a6-aee9-a9cf25ff782d,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-20ffa651-3070-46a1-a5e2-79edde2c8b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421881590-172.17.0.9-1597380944098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-32f55150-7daa-4d86-bdb3-8bd3a43c49b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-997e6cfc-a88d-45f4-8db7-a3210f5a3414,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-2b85b80d-e511-4992-ae2d-e6231328fbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-e3e7aa59-9f8c-40f1-b0e6-bd1ed3207e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-a8e93588-897f-4095-bef7-76067b040391,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-6ca63a67-e0dd-4e5e-8ebb-2bae400a813a,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-bd34d12b-1168-49a6-aee9-a9cf25ff782d,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-20ffa651-3070-46a1-a5e2-79edde2c8b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26912896-172.17.0.9-1597381017698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44155,DS-16ccb8ae-b44a-4049-89a3-19a75db278c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-847f6ba4-0170-4a6c-8645-eacd1ec9b08f,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-be0555bf-6011-4a86-9034-34cb7102b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-4056e438-7274-4b80-a860-68219728e917,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-f5f4a1f4-ac85-4422-aa67-1d2e8c3a3d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-94d4f77c-822f-4d08-b35e-a5f315dab18a,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-f9a6147b-0391-48ac-a1c5-4700db40d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-05924a81-e958-4b73-abca-938b453fe67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26912896-172.17.0.9-1597381017698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44155,DS-16ccb8ae-b44a-4049-89a3-19a75db278c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-847f6ba4-0170-4a6c-8645-eacd1ec9b08f,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-be0555bf-6011-4a86-9034-34cb7102b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-4056e438-7274-4b80-a860-68219728e917,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-f5f4a1f4-ac85-4422-aa67-1d2e8c3a3d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-94d4f77c-822f-4d08-b35e-a5f315dab18a,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-f9a6147b-0391-48ac-a1c5-4700db40d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-05924a81-e958-4b73-abca-938b453fe67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691142499-172.17.0.9-1597381053178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-3546d902-1b75-4005-8421-4ae0f85d1055,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-84a3b360-8ea3-4225-b1b0-1e30de734078,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-b8a2d2e4-6a9c-4495-a352-7456174f06b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-35368192-457d-4269-af50-c9588286158c,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-4b42fb20-d3cd-4f97-ad0a-83e150eea82a,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-64543ef3-201e-4f42-ad0b-4ee22a85dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-e73bcd7d-7d83-45ef-8a82-b20b031a1baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-8e94fe67-2b1a-499c-b059-62357806e69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691142499-172.17.0.9-1597381053178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-3546d902-1b75-4005-8421-4ae0f85d1055,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-84a3b360-8ea3-4225-b1b0-1e30de734078,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-b8a2d2e4-6a9c-4495-a352-7456174f06b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-35368192-457d-4269-af50-c9588286158c,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-4b42fb20-d3cd-4f97-ad0a-83e150eea82a,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-64543ef3-201e-4f42-ad0b-4ee22a85dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-e73bcd7d-7d83-45ef-8a82-b20b031a1baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-8e94fe67-2b1a-499c-b059-62357806e69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442249596-172.17.0.9-1597381429455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-11eeebf4-1ebd-4fa2-ae6a-9620d705b992,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-42a73906-e965-4b7d-b95e-87155114febf,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-04838853-786d-49e6-a6a4-e406c8c2355a,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-bf9ad7a2-6286-47bd-8085-e19d16baafda,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-8c9aca93-8f67-416b-bd4e-5a94d2c96dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-b15d873c-5fb8-4557-b854-80a391e8ea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-97885054-d6b5-4a9c-8fb8-c59d75a0ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-264b15af-7673-47c3-8e61-797b05df8d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442249596-172.17.0.9-1597381429455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-11eeebf4-1ebd-4fa2-ae6a-9620d705b992,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-42a73906-e965-4b7d-b95e-87155114febf,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-04838853-786d-49e6-a6a4-e406c8c2355a,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-bf9ad7a2-6286-47bd-8085-e19d16baafda,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-8c9aca93-8f67-416b-bd4e-5a94d2c96dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-b15d873c-5fb8-4557-b854-80a391e8ea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-97885054-d6b5-4a9c-8fb8-c59d75a0ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-264b15af-7673-47c3-8e61-797b05df8d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191327816-172.17.0.9-1597381957064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34774,DS-74201f71-099e-488c-8de9-00afb5850e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-f64973fa-21a8-4d1f-b7e1-29129ca16350,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-b5ea257d-78f7-403c-8c5e-a334c0c46878,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-b03b4e62-efed-488b-aae6-357416573368,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-28cc8b4c-6e17-4ee9-a400-05791327350d,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-05ba9882-ad9f-43ba-838a-256dea58dffa,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-b5a36aec-7c08-432a-a173-e602cece8618,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-0d3c2898-83e7-49c3-9da1-e96192841986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191327816-172.17.0.9-1597381957064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34774,DS-74201f71-099e-488c-8de9-00afb5850e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-f64973fa-21a8-4d1f-b7e1-29129ca16350,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-b5ea257d-78f7-403c-8c5e-a334c0c46878,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-b03b4e62-efed-488b-aae6-357416573368,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-28cc8b4c-6e17-4ee9-a400-05791327350d,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-05ba9882-ad9f-43ba-838a-256dea58dffa,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-b5a36aec-7c08-432a-a173-e602cece8618,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-0d3c2898-83e7-49c3-9da1-e96192841986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932710126-172.17.0.9-1597382067897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-ee9a0aef-eeba-4bbb-b3fd-c31e40cbf6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-de355e81-d451-4958-a7d2-a3b1a297dc93,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-c4752199-253e-4773-b8d3-f961a9401304,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-de9b30d3-f8b1-4fd0-b300-a0a563072430,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-0b49c93d-5fd4-4f99-8001-67b477496143,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-c0ce2b85-243e-4656-ba77-dd668f8973e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-eb55c5e7-b08f-4e68-a280-3563abb1218e,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-37f7098c-c084-479a-bbc2-05f13a56be76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932710126-172.17.0.9-1597382067897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-ee9a0aef-eeba-4bbb-b3fd-c31e40cbf6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-de355e81-d451-4958-a7d2-a3b1a297dc93,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-c4752199-253e-4773-b8d3-f961a9401304,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-de9b30d3-f8b1-4fd0-b300-a0a563072430,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-0b49c93d-5fd4-4f99-8001-67b477496143,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-c0ce2b85-243e-4656-ba77-dd668f8973e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-eb55c5e7-b08f-4e68-a280-3563abb1218e,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-37f7098c-c084-479a-bbc2-05f13a56be76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009567151-172.17.0.9-1597382103575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40604,DS-170be2b1-b64f-407e-97c3-627511c6e106,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-78101606-52ea-4d2e-9975-e7da403fe898,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-d7951cb9-27c3-4fa1-b383-d36df1e2ca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-4d2b72eb-f6b7-469e-8236-20341a930354,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-b7ca4cde-1251-4b18-8955-3916bb2e00cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-aa3a7af9-dbb4-4924-8dda-88e9fe445faf,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-c40227f3-185c-4446-9b3a-951dfe591f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-840eb2ea-887e-4f71-baf9-c32134a3c87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009567151-172.17.0.9-1597382103575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40604,DS-170be2b1-b64f-407e-97c3-627511c6e106,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-78101606-52ea-4d2e-9975-e7da403fe898,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-d7951cb9-27c3-4fa1-b383-d36df1e2ca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-4d2b72eb-f6b7-469e-8236-20341a930354,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-b7ca4cde-1251-4b18-8955-3916bb2e00cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-aa3a7af9-dbb4-4924-8dda-88e9fe445faf,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-c40227f3-185c-4446-9b3a-951dfe591f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-840eb2ea-887e-4f71-baf9-c32134a3c87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197612483-172.17.0.9-1597382448006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39990,DS-99aab175-aaa1-4065-91f3-7bc07f726554,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-0c8499f4-0b6c-440d-be90-43e8dfaf5863,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-82201403-0697-4810-8d73-6264f2dad078,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-f8434c31-23c0-49ab-a088-970c274163fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-e89b9e6f-63b4-4f42-91d1-59c49a84a9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-6cf2ebad-ab1e-4613-91a7-e2387cdfdf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-b7c70323-9fa6-4ed8-b4bf-85101a3902e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-e8d3980e-e9db-45d3-8c26-e3b71afcd30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197612483-172.17.0.9-1597382448006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39990,DS-99aab175-aaa1-4065-91f3-7bc07f726554,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-0c8499f4-0b6c-440d-be90-43e8dfaf5863,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-82201403-0697-4810-8d73-6264f2dad078,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-f8434c31-23c0-49ab-a088-970c274163fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-e89b9e6f-63b4-4f42-91d1-59c49a84a9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-6cf2ebad-ab1e-4613-91a7-e2387cdfdf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-b7c70323-9fa6-4ed8-b4bf-85101a3902e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-e8d3980e-e9db-45d3-8c26-e3b71afcd30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489490605-172.17.0.9-1597382481448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-6b112d2d-6281-4b0a-a218-b7eb3e53995d,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-faa82695-fe1a-4dc3-8658-fa341b0ad345,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-20928be1-77e6-4ec3-99f0-5f67a4f84aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-e88ac8be-7ef8-4e26-a2a6-db04bee1e9de,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-9fdb4329-6406-4f2e-bf14-c91e6f83cf03,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-6fcf6f18-50e3-4bf1-8578-22e8c9550870,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-c3ba13ac-7dac-4de3-a0b4-70e666aaabc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-6471ee16-ee63-4aca-9eef-0b9899e729be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489490605-172.17.0.9-1597382481448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37873,DS-6b112d2d-6281-4b0a-a218-b7eb3e53995d,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-faa82695-fe1a-4dc3-8658-fa341b0ad345,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-20928be1-77e6-4ec3-99f0-5f67a4f84aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-e88ac8be-7ef8-4e26-a2a6-db04bee1e9de,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-9fdb4329-6406-4f2e-bf14-c91e6f83cf03,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-6fcf6f18-50e3-4bf1-8578-22e8c9550870,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-c3ba13ac-7dac-4de3-a0b4-70e666aaabc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-6471ee16-ee63-4aca-9eef-0b9899e729be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 4096
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478490155-172.17.0.9-1597382588071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-f8008b7c-128f-41a3-acbe-3b52c86de027,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-35f609e5-9fe0-411a-ba86-c9ace90ca2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-0efb028d-47f1-4da9-bfed-3752dc8ebd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-38b83289-d771-4ba8-a03c-f24521416f22,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-a2101778-69a6-4b3a-a2f7-dbb10e2973ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-79c0f3cd-a00e-4c97-8e8f-7fd3410edd24,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-f8a8c32e-53ef-47c5-b200-11d071917be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-acc30246-c728-4fd5-b45a-aca40522baa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478490155-172.17.0.9-1597382588071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-f8008b7c-128f-41a3-acbe-3b52c86de027,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-35f609e5-9fe0-411a-ba86-c9ace90ca2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-0efb028d-47f1-4da9-bfed-3752dc8ebd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-38b83289-d771-4ba8-a03c-f24521416f22,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-a2101778-69a6-4b3a-a2f7-dbb10e2973ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-79c0f3cd-a00e-4c97-8e8f-7fd3410edd24,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-f8a8c32e-53ef-47c5-b200-11d071917be9,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-acc30246-c728-4fd5-b45a-aca40522baa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5572
