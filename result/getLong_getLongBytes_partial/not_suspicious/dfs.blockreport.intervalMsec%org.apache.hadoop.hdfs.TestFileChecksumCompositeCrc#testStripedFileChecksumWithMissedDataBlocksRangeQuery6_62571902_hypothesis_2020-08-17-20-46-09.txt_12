reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226832267-172.17.0.3-1597697225431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44068,DS-71b93955-4027-4a8a-8f22-9940dc89db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-c586ebcb-74ec-4948-b366-801cb256d675,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-1a8219a6-18b4-4fc3-b538-a73e13baa8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-7534c5f5-e7cc-4a24-a60c-1b6ff60488cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-d9d77769-2cc6-4468-9c87-80f93979fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-9c9e47d4-a230-440d-91a0-1981551c18fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-fd708bd5-a92f-4b52-96cd-a9c50c42f505,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-66e854da-a8e2-442e-87e3-02a609825597,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226832267-172.17.0.3-1597697225431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44068,DS-71b93955-4027-4a8a-8f22-9940dc89db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-c586ebcb-74ec-4948-b366-801cb256d675,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-1a8219a6-18b4-4fc3-b538-a73e13baa8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-7534c5f5-e7cc-4a24-a60c-1b6ff60488cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-d9d77769-2cc6-4468-9c87-80f93979fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-9c9e47d4-a230-440d-91a0-1981551c18fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-fd708bd5-a92f-4b52-96cd-a9c50c42f505,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-66e854da-a8e2-442e-87e3-02a609825597,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756351038-172.17.0.3-1597697372047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39148,DS-eb696704-3e59-4be7-9b00-be41943d067e,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-d6afbb58-f91a-4eef-ab26-dbdffe728aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-8f14f6a8-f3e0-4bc5-9a93-418fa7a09def,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-10de5f87-b5fd-4465-bea6-db21d3c2d764,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-2fc438e8-4e3b-4398-ad0a-838f25e2473e,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-170d72d0-8117-473a-9486-dbc1a36e6c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-1d26c08d-04fa-4847-abee-930ef141a309,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-999b148b-cc00-4428-b234-48b64655569c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756351038-172.17.0.3-1597697372047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39148,DS-eb696704-3e59-4be7-9b00-be41943d067e,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-d6afbb58-f91a-4eef-ab26-dbdffe728aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-8f14f6a8-f3e0-4bc5-9a93-418fa7a09def,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-10de5f87-b5fd-4465-bea6-db21d3c2d764,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-2fc438e8-4e3b-4398-ad0a-838f25e2473e,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-170d72d0-8117-473a-9486-dbc1a36e6c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-1d26c08d-04fa-4847-abee-930ef141a309,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-999b148b-cc00-4428-b234-48b64655569c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891714056-172.17.0.3-1597697441610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37698,DS-6d0af0de-a467-42b8-8858-f5b75e9263cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-69ef1059-489b-426a-9fb1-52bbf214bc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-413434ba-4941-4403-ab75-3ae219ee5c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-a44e81c5-cd91-4ae4-8ad5-d6381b9a315d,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-236df859-f34f-4555-b4ea-6655fc6373ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-80c1bdc8-ebed-449f-bf8a-755f0dbb9a11,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-0e74436c-3a27-4d4b-88c7-0baac1bddb44,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-621710cc-74a0-4a71-8c64-387a415817ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891714056-172.17.0.3-1597697441610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37698,DS-6d0af0de-a467-42b8-8858-f5b75e9263cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-69ef1059-489b-426a-9fb1-52bbf214bc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-413434ba-4941-4403-ab75-3ae219ee5c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-a44e81c5-cd91-4ae4-8ad5-d6381b9a315d,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-236df859-f34f-4555-b4ea-6655fc6373ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-80c1bdc8-ebed-449f-bf8a-755f0dbb9a11,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-0e74436c-3a27-4d4b-88c7-0baac1bddb44,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-621710cc-74a0-4a71-8c64-387a415817ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600110633-172.17.0.3-1597697847034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35102,DS-35d3a584-2aae-4777-87a3-fca333beeac8,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-37739c36-1b0e-45f8-8c1f-f96da2e40086,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-f5ba8838-2974-4622-a3a4-acea55a055fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-e97b004e-be90-4753-a2f6-2839157c2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-5478dd8c-e333-4175-8fd3-81c980ac3e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-9c6a5ec6-b99f-439a-87da-02b522f5a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-0d5196a7-bf9c-4fd9-8086-6d91ddd17ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-0e819303-0cfe-4c81-a48c-a0db5a789787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600110633-172.17.0.3-1597697847034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35102,DS-35d3a584-2aae-4777-87a3-fca333beeac8,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-37739c36-1b0e-45f8-8c1f-f96da2e40086,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-f5ba8838-2974-4622-a3a4-acea55a055fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-e97b004e-be90-4753-a2f6-2839157c2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-5478dd8c-e333-4175-8fd3-81c980ac3e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-9c6a5ec6-b99f-439a-87da-02b522f5a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-0d5196a7-bf9c-4fd9-8086-6d91ddd17ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-0e819303-0cfe-4c81-a48c-a0db5a789787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031685407-172.17.0.3-1597697881330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-201e4ad0-6157-4c9b-b726-63980bfc2750,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-deb604a1-7d86-4453-a18b-4a3a2143ab97,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-8467c66c-b466-495b-9618-4cb6c5ea2863,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-85ccb465-4ffb-40a9-8310-ae8a0a4289d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-9f3a65eb-cfbd-4d3d-ac43-84ff909a0146,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-1bf68104-4481-43d2-90bb-367a09f6fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-8dfbbdbb-d07d-42c6-b990-6358520cf8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-d68653c5-f559-41db-b5a9-41bd3d5437e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031685407-172.17.0.3-1597697881330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-201e4ad0-6157-4c9b-b726-63980bfc2750,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-deb604a1-7d86-4453-a18b-4a3a2143ab97,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-8467c66c-b466-495b-9618-4cb6c5ea2863,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-85ccb465-4ffb-40a9-8310-ae8a0a4289d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-9f3a65eb-cfbd-4d3d-ac43-84ff909a0146,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-1bf68104-4481-43d2-90bb-367a09f6fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-8dfbbdbb-d07d-42c6-b990-6358520cf8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-d68653c5-f559-41db-b5a9-41bd3d5437e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409675219-172.17.0.3-1597697913408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43145,DS-df26426f-c35d-4a7d-a4f1-c8fedb9f8f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-af7c02af-3acf-4f86-9ca7-747629321008,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-8d719e5b-3ec7-4405-88d4-b9e22d6b9de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-ca66535a-897c-495c-8e06-57e0a7f9a9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-c2ae6821-5e0c-4aa2-92e5-b45e203a2c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-944567db-c4a5-4e82-a466-19557a099944,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-3e537360-3489-4e8a-91aa-301a09ada2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-28f52b1c-a252-4937-8547-e78e5806ecb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409675219-172.17.0.3-1597697913408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43145,DS-df26426f-c35d-4a7d-a4f1-c8fedb9f8f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-af7c02af-3acf-4f86-9ca7-747629321008,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-8d719e5b-3ec7-4405-88d4-b9e22d6b9de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-ca66535a-897c-495c-8e06-57e0a7f9a9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-c2ae6821-5e0c-4aa2-92e5-b45e203a2c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-944567db-c4a5-4e82-a466-19557a099944,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-3e537360-3489-4e8a-91aa-301a09ada2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-28f52b1c-a252-4937-8547-e78e5806ecb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171722888-172.17.0.3-1597697952898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-2a3d8760-32d5-4862-a57f-5a9442a474f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-06d18b43-adcc-4bf6-bde4-09ddcdb5fa10,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-bba52854-5bfb-4466-b36a-8a6d247474e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-52abb57e-2007-4db0-ba71-a0db0a63cd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-0fb62c2e-7f1a-42d7-9b84-70ae71c426ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-80669f66-b039-4132-84a9-0db48f0056a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-0678bfd5-d073-42c2-a2d1-d2867348cac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-8ea6b1e8-83b2-4f67-9efa-bb2de8e47ab6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171722888-172.17.0.3-1597697952898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-2a3d8760-32d5-4862-a57f-5a9442a474f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-06d18b43-adcc-4bf6-bde4-09ddcdb5fa10,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-bba52854-5bfb-4466-b36a-8a6d247474e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-52abb57e-2007-4db0-ba71-a0db0a63cd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-0fb62c2e-7f1a-42d7-9b84-70ae71c426ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-80669f66-b039-4132-84a9-0db48f0056a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-0678bfd5-d073-42c2-a2d1-d2867348cac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-8ea6b1e8-83b2-4f67-9efa-bb2de8e47ab6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288596434-172.17.0.3-1597698317060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-ce8b7e9e-037b-4467-ba1e-e4df676a1d43,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-3f6c4a07-c889-47c7-9222-ef63ed0e42ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-39946717-03ea-4a28-9eaf-80f535810a15,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-46e0b95b-1492-44b1-b2ba-35051e5f41d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-077853a7-3d6b-4cfe-9077-b26aeec04d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-125c462b-432d-4f5a-87c8-88d5b8d4b491,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-f45698ec-4375-401e-8f2e-940cf25f7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-e1365471-e2e6-431e-8b55-657cf66fbf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288596434-172.17.0.3-1597698317060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-ce8b7e9e-037b-4467-ba1e-e4df676a1d43,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-3f6c4a07-c889-47c7-9222-ef63ed0e42ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-39946717-03ea-4a28-9eaf-80f535810a15,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-46e0b95b-1492-44b1-b2ba-35051e5f41d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-077853a7-3d6b-4cfe-9077-b26aeec04d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-125c462b-432d-4f5a-87c8-88d5b8d4b491,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-f45698ec-4375-401e-8f2e-940cf25f7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-e1365471-e2e6-431e-8b55-657cf66fbf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822397541-172.17.0.3-1597698353296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-c0a654d3-009c-42a6-97cb-da6d9ac2b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-6f141677-f390-4a59-b0fc-44670cf61914,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-dc4ce5fe-440e-43cf-97ce-753437783c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-fb994ecd-4cba-447e-b77c-dd960702e699,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-bd393147-8f86-4bdd-9551-8541da52ecac,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-f1dae4e4-36d0-4e58-b4d3-c54d6d1fbc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-205e3aa7-35bb-4902-b133-98367543c423,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-c4366c30-4b23-47de-a424-e12f8bcaad08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822397541-172.17.0.3-1597698353296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-c0a654d3-009c-42a6-97cb-da6d9ac2b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-6f141677-f390-4a59-b0fc-44670cf61914,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-dc4ce5fe-440e-43cf-97ce-753437783c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-fb994ecd-4cba-447e-b77c-dd960702e699,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-bd393147-8f86-4bdd-9551-8541da52ecac,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-f1dae4e4-36d0-4e58-b4d3-c54d6d1fbc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-205e3aa7-35bb-4902-b133-98367543c423,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-c4366c30-4b23-47de-a424-e12f8bcaad08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440974130-172.17.0.3-1597698393161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-1786c595-0d43-438b-883a-30ae51206322,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-821dbaf7-9f22-4b73-b2b4-adf62c5e1d16,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-7e2fcb71-eb9f-452d-b2ef-412a3fdab566,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-fc61059d-b666-48b8-a1e5-b5dfbd7c53fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-57cba739-1c94-443b-a87d-e2d61030eb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-74f815b1-304e-4699-b167-0e93c6ac0797,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-c2623329-bcc5-4a73-a864-192b79df68c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-3332b9d8-f1c6-4149-9112-1859c5defe84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440974130-172.17.0.3-1597698393161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-1786c595-0d43-438b-883a-30ae51206322,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-821dbaf7-9f22-4b73-b2b4-adf62c5e1d16,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-7e2fcb71-eb9f-452d-b2ef-412a3fdab566,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-fc61059d-b666-48b8-a1e5-b5dfbd7c53fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-57cba739-1c94-443b-a87d-e2d61030eb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-74f815b1-304e-4699-b167-0e93c6ac0797,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-c2623329-bcc5-4a73-a864-192b79df68c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-3332b9d8-f1c6-4149-9112-1859c5defe84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634408923-172.17.0.3-1597698512326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37816,DS-fbfab422-dfc8-4256-a778-592d7c1ff072,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-9d9ad276-8412-466e-8d32-0efeba300483,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-78de371c-173a-49dc-83e9-0a0a25c42b39,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-6955a812-2039-45a0-85f6-19122fccb07c,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-24a6f5f1-2e8e-429e-86fb-a77a5b229fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-028adeb7-f206-49fc-8919-b50b8e8e8884,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-3d2e896b-cf0b-4bb1-91ac-d477a97664e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-dd7419ac-434d-4e69-bba8-3d5932a9cc3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634408923-172.17.0.3-1597698512326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37816,DS-fbfab422-dfc8-4256-a778-592d7c1ff072,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-9d9ad276-8412-466e-8d32-0efeba300483,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-78de371c-173a-49dc-83e9-0a0a25c42b39,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-6955a812-2039-45a0-85f6-19122fccb07c,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-24a6f5f1-2e8e-429e-86fb-a77a5b229fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-028adeb7-f206-49fc-8919-b50b8e8e8884,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-3d2e896b-cf0b-4bb1-91ac-d477a97664e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-dd7419ac-434d-4e69-bba8-3d5932a9cc3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606812282-172.17.0.3-1597698694814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42576,DS-b473b9c3-d72f-4f9d-8d2a-085751d89911,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-07c37832-e0ec-4342-8b9d-11696cc7daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-63ac26b5-2ab4-4daf-be82-98964ab7aa73,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-a27f6711-2407-4d3c-92c7-1d1c31aaab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-626e952b-7ef6-494b-b47d-3965a3adda1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-4616eb01-72ae-44ca-8352-5a710ef89202,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-107e6cf9-eac0-41d5-938c-48c03248e8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-4ef6cba6-41b4-482c-bfb7-c1fa1a6afad2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606812282-172.17.0.3-1597698694814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42576,DS-b473b9c3-d72f-4f9d-8d2a-085751d89911,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-07c37832-e0ec-4342-8b9d-11696cc7daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-63ac26b5-2ab4-4daf-be82-98964ab7aa73,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-a27f6711-2407-4d3c-92c7-1d1c31aaab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-626e952b-7ef6-494b-b47d-3965a3adda1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-4616eb01-72ae-44ca-8352-5a710ef89202,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-107e6cf9-eac0-41d5-938c-48c03248e8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-4ef6cba6-41b4-482c-bfb7-c1fa1a6afad2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949728898-172.17.0.3-1597698800182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-d20e41aa-3598-4543-8b22-356fd6ba03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-0d8e58f8-03e3-4fd7-bbf0-c924de9a6125,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-2a782269-b5f9-4c1a-8034-f6335042a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-c76aff0e-4ceb-4968-8c71-27bfc3f11962,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-2449284b-dc48-4af2-b974-720c4c5b6357,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-91751457-5505-4f25-8f84-c17f2fded7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-0fea47f3-69c7-408b-979b-5ce2413570b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-e12d5da4-42c1-496a-9617-57e11fa48999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949728898-172.17.0.3-1597698800182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-d20e41aa-3598-4543-8b22-356fd6ba03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-0d8e58f8-03e3-4fd7-bbf0-c924de9a6125,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-2a782269-b5f9-4c1a-8034-f6335042a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-c76aff0e-4ceb-4968-8c71-27bfc3f11962,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-2449284b-dc48-4af2-b974-720c4c5b6357,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-91751457-5505-4f25-8f84-c17f2fded7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-0fea47f3-69c7-408b-979b-5ce2413570b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-e12d5da4-42c1-496a-9617-57e11fa48999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346325479-172.17.0.3-1597698874055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38431,DS-2d2da896-0d96-4076-80e5-3cc4c2312215,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-53cba0c5-dd81-4094-a102-28cc520cf5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-45081ebc-1d60-4651-8f3d-d02f817c5456,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-77db2232-c7cd-444b-818e-8dc1161f1ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-41df64f4-74ec-4811-a6d6-a945550323fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-8af49426-7ae3-44a5-a9d5-8580e4a11e19,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-8d00aec9-6ff6-4dcb-ac2b-b097131af67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-882736ad-949a-487f-8453-c5b5e3fd58c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346325479-172.17.0.3-1597698874055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38431,DS-2d2da896-0d96-4076-80e5-3cc4c2312215,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-53cba0c5-dd81-4094-a102-28cc520cf5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-45081ebc-1d60-4651-8f3d-d02f817c5456,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-77db2232-c7cd-444b-818e-8dc1161f1ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-41df64f4-74ec-4811-a6d6-a945550323fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-8af49426-7ae3-44a5-a9d5-8580e4a11e19,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-8d00aec9-6ff6-4dcb-ac2b-b097131af67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-882736ad-949a-487f-8453-c5b5e3fd58c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328381453-172.17.0.3-1597698974566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-46d7d4fe-72c0-435f-a41d-a0734a71f226,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-d85cc9b2-3596-4045-b7a1-bde6eb9f6c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-34241d13-182a-4686-8e65-6f791784bc43,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-3f147064-5f0d-4774-a5d6-7707b50a6f32,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-19685f55-ffca-40e5-ad88-7cd91746deb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-14ff19f7-96df-4c60-b6eb-4ae988278333,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-6d6bb616-7358-447f-8797-43427bebcaae,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-0363f417-4c2e-4b95-bc6b-9da90e0079a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328381453-172.17.0.3-1597698974566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-46d7d4fe-72c0-435f-a41d-a0734a71f226,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-d85cc9b2-3596-4045-b7a1-bde6eb9f6c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-34241d13-182a-4686-8e65-6f791784bc43,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-3f147064-5f0d-4774-a5d6-7707b50a6f32,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-19685f55-ffca-40e5-ad88-7cd91746deb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-14ff19f7-96df-4c60-b6eb-4ae988278333,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-6d6bb616-7358-447f-8797-43427bebcaae,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-0363f417-4c2e-4b95-bc6b-9da90e0079a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050812793-172.17.0.3-1597699297678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-60f45b2d-4ca0-4188-a82e-24e34b55af80,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-182d76d6-f6c5-4b05-935b-f74ce172c21b,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-650eccd4-19eb-44da-84ab-22963cec2f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-a32e3696-9cba-4017-8618-c9da6fc61df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-3b6bf0a1-3254-49af-bf24-e0766f2d6e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-81d1d98f-ff5f-492a-9f89-7a94d7fab158,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-3607e7a2-20cf-48ae-82ba-c9f09825c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-12108b57-8dd6-4fa2-8eca-a3345b90f603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050812793-172.17.0.3-1597699297678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-60f45b2d-4ca0-4188-a82e-24e34b55af80,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-182d76d6-f6c5-4b05-935b-f74ce172c21b,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-650eccd4-19eb-44da-84ab-22963cec2f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-a32e3696-9cba-4017-8618-c9da6fc61df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-3b6bf0a1-3254-49af-bf24-e0766f2d6e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-81d1d98f-ff5f-492a-9f89-7a94d7fab158,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-3607e7a2-20cf-48ae-82ba-c9f09825c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-12108b57-8dd6-4fa2-8eca-a3345b90f603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406268232-172.17.0.3-1597699830960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42118,DS-71ba536d-1df2-4ea7-9d53-5a51db34cbde,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-d8e12c89-02b5-4f76-ab37-b70d9639837e,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-aea1b17d-8eec-4172-83a9-c2d9dc039c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-f685ef22-2660-4e40-9556-bc0d16569402,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-abe76d41-d07e-48e3-9b15-7339245428e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-6e0b7453-463f-4216-b412-974fe9c20a38,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-20f5c9ce-7665-4785-85c0-b35128ebc4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-3371e472-ae04-4e05-8a3f-1c5af8337e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406268232-172.17.0.3-1597699830960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42118,DS-71ba536d-1df2-4ea7-9d53-5a51db34cbde,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-d8e12c89-02b5-4f76-ab37-b70d9639837e,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-aea1b17d-8eec-4172-83a9-c2d9dc039c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-f685ef22-2660-4e40-9556-bc0d16569402,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-abe76d41-d07e-48e3-9b15-7339245428e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-6e0b7453-463f-4216-b412-974fe9c20a38,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-20f5c9ce-7665-4785-85c0-b35128ebc4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-3371e472-ae04-4e05-8a3f-1c5af8337e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468634402-172.17.0.3-1597699907727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40144,DS-4e8d9c5b-ad9f-4293-809a-a445f11889ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-d21ffae1-5cdb-48e9-9420-83d200226306,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-45f693c3-5c50-4770-aa83-a41d918835b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-1a006f17-fdad-452a-97f3-dca88c602993,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-63eeb414-8186-4ee1-a156-a54c203bb5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-909048ab-cbf3-4060-895c-3f9c59d27c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-6ef40b38-88e7-479e-86b2-f356ca3e592e,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-728a7526-d06d-4a7e-bc7c-303100ba2ce1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468634402-172.17.0.3-1597699907727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40144,DS-4e8d9c5b-ad9f-4293-809a-a445f11889ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-d21ffae1-5cdb-48e9-9420-83d200226306,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-45f693c3-5c50-4770-aa83-a41d918835b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-1a006f17-fdad-452a-97f3-dca88c602993,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-63eeb414-8186-4ee1-a156-a54c203bb5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-909048ab-cbf3-4060-895c-3f9c59d27c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-6ef40b38-88e7-479e-86b2-f356ca3e592e,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-728a7526-d06d-4a7e-bc7c-303100ba2ce1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724347574-172.17.0.3-1597700293461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43163,DS-7754ec55-f2bf-469d-95ff-0d36b0972dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-0b7b3e9e-3b3d-4079-a49a-19f365eb5abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-dabe993f-c0d3-4524-b124-f5be38c01083,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-9274e6f6-87aa-4e40-b9eb-e17a51334495,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-7a401020-5f15-4f39-8868-54d9f1b3fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-5f65fa06-db72-4564-adb7-74c3d2e63d49,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-8f5540e8-a7e0-4ac9-acc4-58747a4e55fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-b48aea9c-8d28-4fa2-95e2-5228636421f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724347574-172.17.0.3-1597700293461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43163,DS-7754ec55-f2bf-469d-95ff-0d36b0972dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-0b7b3e9e-3b3d-4079-a49a-19f365eb5abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-dabe993f-c0d3-4524-b124-f5be38c01083,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-9274e6f6-87aa-4e40-b9eb-e17a51334495,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-7a401020-5f15-4f39-8868-54d9f1b3fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-5f65fa06-db72-4564-adb7-74c3d2e63d49,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-8f5540e8-a7e0-4ac9-acc4-58747a4e55fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-b48aea9c-8d28-4fa2-95e2-5228636421f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926693632-172.17.0.3-1597700474916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44903,DS-1f3ef3f6-63df-4ac9-9f41-582a375f91c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-7b1b3031-e748-4872-b6b5-597fc7ea25ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-d44b60fd-986a-4786-899e-d6ca0a3db10c,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-fd4e09a1-66db-4505-b902-2b295133a409,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-07852c9f-a915-4afa-9acc-4b6f4edd3a93,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-86c19cee-85c5-4cee-bf62-4a9eb2cd0ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-cc3e57c8-a056-479b-beb1-d586e1863eac,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-befa6703-620b-45e5-8815-fce2a25f7fe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926693632-172.17.0.3-1597700474916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44903,DS-1f3ef3f6-63df-4ac9-9f41-582a375f91c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-7b1b3031-e748-4872-b6b5-597fc7ea25ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-d44b60fd-986a-4786-899e-d6ca0a3db10c,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-fd4e09a1-66db-4505-b902-2b295133a409,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-07852c9f-a915-4afa-9acc-4b6f4edd3a93,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-86c19cee-85c5-4cee-bf62-4a9eb2cd0ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-cc3e57c8-a056-479b-beb1-d586e1863eac,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-befa6703-620b-45e5-8815-fce2a25f7fe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415932681-172.17.0.3-1597700587564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-49ed0b75-a2b1-409a-b8da-07a24ccdce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-c0f0ccf4-0064-47b0-950a-93d2a3b931de,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-81cda5b7-1be3-4a8b-bf9b-83111e4a5574,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-e5860803-a435-41cb-a44b-990fdfbd81b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-b9973305-5065-47e6-b685-871010836810,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-aafdea9d-c09d-497e-8a50-0f2c3eb110ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-6472a6d9-16a3-475d-9cfc-1b045f860954,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-12ebb1e9-5a16-46ed-b2f3-dd84e63a1ec7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415932681-172.17.0.3-1597700587564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-49ed0b75-a2b1-409a-b8da-07a24ccdce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-c0f0ccf4-0064-47b0-950a-93d2a3b931de,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-81cda5b7-1be3-4a8b-bf9b-83111e4a5574,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-e5860803-a435-41cb-a44b-990fdfbd81b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-b9973305-5065-47e6-b685-871010836810,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-aafdea9d-c09d-497e-8a50-0f2c3eb110ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-6472a6d9-16a3-475d-9cfc-1b045f860954,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-12ebb1e9-5a16-46ed-b2f3-dd84e63a1ec7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134313266-172.17.0.3-1597700629054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-b422795a-d936-4a1b-9705-ea91ccb6d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-fe08e90e-74b5-4b7c-85b1-65a4d438d14b,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-9e15b874-f73a-4865-9d94-1fe2f4a77ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-a619adc1-2f70-4f09-8b90-f4ce6575521a,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-a0b9f4d9-3d0b-44e4-9b9e-f6dba719f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-152c109c-4c9e-4c29-89b1-b35d9cf289b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-1a01158f-3d64-427f-a66e-14b35b49842b,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-6582004e-33bd-4d40-a4b9-30700d72fb11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134313266-172.17.0.3-1597700629054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-b422795a-d936-4a1b-9705-ea91ccb6d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-fe08e90e-74b5-4b7c-85b1-65a4d438d14b,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-9e15b874-f73a-4865-9d94-1fe2f4a77ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-a619adc1-2f70-4f09-8b90-f4ce6575521a,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-a0b9f4d9-3d0b-44e4-9b9e-f6dba719f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-152c109c-4c9e-4c29-89b1-b35d9cf289b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-1a01158f-3d64-427f-a66e-14b35b49842b,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-6582004e-33bd-4d40-a4b9-30700d72fb11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112885509-172.17.0.3-1597700705851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-2d394376-33a4-4e58-91d9-b1735ffe190d,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-ba6a714d-7fb9-494f-b332-a9a0f7d94abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-afb33ec8-c182-46f2-a253-6b96e02c55dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-719e374e-e9f4-4ddc-b7ea-13735d15dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-d64b5e52-36e5-4a51-8a04-4297dff6b083,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-8e8b85c7-83bd-41ac-ab5c-944ad52b0a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-4ea576df-500c-48d0-88fd-3561e156b809,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-870cf6dc-a057-4a1e-b70f-42031a8b6c1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112885509-172.17.0.3-1597700705851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-2d394376-33a4-4e58-91d9-b1735ffe190d,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-ba6a714d-7fb9-494f-b332-a9a0f7d94abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-afb33ec8-c182-46f2-a253-6b96e02c55dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-719e374e-e9f4-4ddc-b7ea-13735d15dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-d64b5e52-36e5-4a51-8a04-4297dff6b083,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-8e8b85c7-83bd-41ac-ab5c-944ad52b0a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-4ea576df-500c-48d0-88fd-3561e156b809,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-870cf6dc-a057-4a1e-b70f-42031a8b6c1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106855607-172.17.0.3-1597700964231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-1443af71-0291-4fbb-b0c5-e4c6c48415d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-dd599c79-a7c9-4348-8916-1f82888fca20,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-9c2ddde0-ec21-4259-a795-f6b196616540,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-d1e812e3-1dfc-43db-8efe-c946e8ef8132,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-bd8992a2-0c3d-4b5b-877f-26b7e03b51da,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-e3b50a3a-0bdc-4d15-b4c7-579d8c93fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-bb48712c-1870-4124-a06d-e8057118a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-9dfdd5d4-8798-4918-ba4f-0a8831bc0ff0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106855607-172.17.0.3-1597700964231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-1443af71-0291-4fbb-b0c5-e4c6c48415d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-dd599c79-a7c9-4348-8916-1f82888fca20,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-9c2ddde0-ec21-4259-a795-f6b196616540,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-d1e812e3-1dfc-43db-8efe-c946e8ef8132,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-bd8992a2-0c3d-4b5b-877f-26b7e03b51da,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-e3b50a3a-0bdc-4d15-b4c7-579d8c93fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-bb48712c-1870-4124-a06d-e8057118a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-9dfdd5d4-8798-4918-ba4f-0a8831bc0ff0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621064050-172.17.0.3-1597701003437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42703,DS-966962c8-d167-4995-a231-da096d05afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-eab9d8e2-09f4-4d79-a8fa-856d373b9629,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-6195b426-6666-40c6-a7de-0aa886fb5745,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-3ecab686-aa14-4439-9149-d366be57c2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-4b610576-8487-4443-af41-697a5181c825,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-d2096adf-4609-49cc-b268-4a8f418234e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-95089172-744a-4bfc-aafb-05154ff0c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-49d85fb9-08a4-48cb-b8c5-d16c06a58a16,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621064050-172.17.0.3-1597701003437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42703,DS-966962c8-d167-4995-a231-da096d05afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-eab9d8e2-09f4-4d79-a8fa-856d373b9629,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-6195b426-6666-40c6-a7de-0aa886fb5745,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-3ecab686-aa14-4439-9149-d366be57c2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-4b610576-8487-4443-af41-697a5181c825,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-d2096adf-4609-49cc-b268-4a8f418234e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-95089172-744a-4bfc-aafb-05154ff0c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-49d85fb9-08a4-48cb-b8c5-d16c06a58a16,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989271274-172.17.0.3-1597701465689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-bfccb1d2-00ef-45ca-85ac-735531bf10ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-adb5a691-67c1-4049-bfc7-4659806fa8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-979f59d7-b36f-4ee8-9328-3da87193a646,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-2416efed-6a96-4f3d-8858-301ecfbfbb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-6df267ab-3f01-4e1f-a18d-ed00365132fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-7d9cc33b-b944-419c-9ea8-4e72e27a9710,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-e5f5c2e2-85c4-4a98-821a-fffa560a08e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-f40906e7-3233-4824-a6ed-aaeaa6cf0b6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989271274-172.17.0.3-1597701465689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-bfccb1d2-00ef-45ca-85ac-735531bf10ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-adb5a691-67c1-4049-bfc7-4659806fa8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-979f59d7-b36f-4ee8-9328-3da87193a646,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-2416efed-6a96-4f3d-8858-301ecfbfbb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-6df267ab-3f01-4e1f-a18d-ed00365132fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-7d9cc33b-b944-419c-9ea8-4e72e27a9710,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-e5f5c2e2-85c4-4a98-821a-fffa560a08e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-f40906e7-3233-4824-a6ed-aaeaa6cf0b6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104688485-172.17.0.3-1597701689835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-86a0472e-f03e-401f-b906-78dc7ef745ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-c84863cc-d7c8-4503-86dc-17a3f918afa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-953e8e94-1228-4e68-9c43-8ac899a8094f,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-36cee79e-7899-4868-be77-e14a784892da,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-ccdc6777-6432-4375-8723-77609013fa70,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-3f74352d-426e-431a-b462-0d7191c834dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-91e5828e-8da2-418c-969a-5ef4c378388d,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-1eb19462-c601-428d-846b-6cf7e95aaea3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104688485-172.17.0.3-1597701689835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-86a0472e-f03e-401f-b906-78dc7ef745ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-c84863cc-d7c8-4503-86dc-17a3f918afa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-953e8e94-1228-4e68-9c43-8ac899a8094f,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-36cee79e-7899-4868-be77-e14a784892da,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-ccdc6777-6432-4375-8723-77609013fa70,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-3f74352d-426e-431a-b462-0d7191c834dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-91e5828e-8da2-418c-969a-5ef4c378388d,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-1eb19462-c601-428d-846b-6cf7e95aaea3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342793801-172.17.0.3-1597702135203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40310,DS-cb164e2e-53b5-4b1f-a386-4072399136ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-bd389c58-23b3-4ada-90ca-f51965947ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-df49cdaa-1922-4dc3-aaa3-38fcf5077112,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-13d5cbd9-dd8f-4398-88b3-3a3b6a39527d,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-9317f3f4-e265-4395-b723-1d8a9d3960bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-2d4ebf47-467d-40a8-b67c-19daf79b5149,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-4764b9d9-5ee8-43b7-99e5-53c10f73e0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-e244af40-35fb-42a6-86eb-5064bc5fb855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342793801-172.17.0.3-1597702135203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40310,DS-cb164e2e-53b5-4b1f-a386-4072399136ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-bd389c58-23b3-4ada-90ca-f51965947ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-df49cdaa-1922-4dc3-aaa3-38fcf5077112,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-13d5cbd9-dd8f-4398-88b3-3a3b6a39527d,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-9317f3f4-e265-4395-b723-1d8a9d3960bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-2d4ebf47-467d-40a8-b67c-19daf79b5149,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-4764b9d9-5ee8-43b7-99e5-53c10f73e0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-e244af40-35fb-42a6-86eb-5064bc5fb855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947830603-172.17.0.3-1597702213915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45939,DS-6ea01aac-a5e8-4743-a67e-62afc7224627,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-0674fe1b-84e1-4c23-87ed-e64f7e5be884,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-4c056708-480c-41ee-aac9-57897b48b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-4bc516a7-05e7-4c59-b793-80bb277ee5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-c1d1c106-1663-4339-8c68-574f1841c5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-7c27ba55-e10b-4667-be1f-cc21e7734408,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-9faf44f0-5bc2-42d8-99e7-621d9b081956,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-eccbba54-3202-4ece-8142-b63a84694e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947830603-172.17.0.3-1597702213915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45939,DS-6ea01aac-a5e8-4743-a67e-62afc7224627,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-0674fe1b-84e1-4c23-87ed-e64f7e5be884,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-4c056708-480c-41ee-aac9-57897b48b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-4bc516a7-05e7-4c59-b793-80bb277ee5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-c1d1c106-1663-4339-8c68-574f1841c5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-7c27ba55-e10b-4667-be1f-cc21e7734408,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-9faf44f0-5bc2-42d8-99e7-621d9b081956,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-eccbba54-3202-4ece-8142-b63a84694e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795527226-172.17.0.3-1597702291238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42586,DS-c672f0f6-c0f9-413f-98d3-834692fbcd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-53e6c181-b477-4bf2-9463-369f8bf3060f,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-532350d1-ee04-4bb2-b697-eb30dde3c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-c907f813-a252-4f6c-be24-2cd0531203c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-c2e61bf0-5a99-427b-abc9-7fdbcc023816,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-b1ad9869-fae0-4147-950d-cd02eba7782c,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-68ad5eda-5317-45f6-a5a3-65637cab371e,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-f9c099ce-71c4-4575-a80f-89a13a3423cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795527226-172.17.0.3-1597702291238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42586,DS-c672f0f6-c0f9-413f-98d3-834692fbcd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-53e6c181-b477-4bf2-9463-369f8bf3060f,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-532350d1-ee04-4bb2-b697-eb30dde3c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-c907f813-a252-4f6c-be24-2cd0531203c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-c2e61bf0-5a99-427b-abc9-7fdbcc023816,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-b1ad9869-fae0-4147-950d-cd02eba7782c,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-68ad5eda-5317-45f6-a5a3-65637cab371e,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-f9c099ce-71c4-4575-a80f-89a13a3423cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373432178-172.17.0.3-1597702489063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-b8df5d3b-f57e-4520-ab46-30d475af81ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-b38a0617-ca7c-49f1-b347-bd8273c48be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-0b342f58-d4b0-4cc8-b95e-dbd26ad49de4,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-3e07b393-9ae9-48a0-a23f-9a3582458d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-4bc274de-40c7-4c79-8bf1-30ad8cdd4cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-992b470d-8439-4ad6-a6c3-33fe5c0385ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-59b9b340-b117-4211-9706-861b9b5cb13e,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-3fb50d74-a94a-4bcc-86e4-6fe0d1c7c06a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373432178-172.17.0.3-1597702489063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-b8df5d3b-f57e-4520-ab46-30d475af81ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-b38a0617-ca7c-49f1-b347-bd8273c48be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-0b342f58-d4b0-4cc8-b95e-dbd26ad49de4,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-3e07b393-9ae9-48a0-a23f-9a3582458d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-4bc274de-40c7-4c79-8bf1-30ad8cdd4cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-992b470d-8439-4ad6-a6c3-33fe5c0385ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-59b9b340-b117-4211-9706-861b9b5cb13e,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-3fb50d74-a94a-4bcc-86e4-6fe0d1c7c06a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850466728-172.17.0.3-1597702611006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34030,DS-48e0bf6e-06b2-499e-b867-ecdb91dd8539,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-97be8fe0-8a3e-4e86-b043-af1829f49cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-8516aed1-cecf-4e73-8e40-bdb52a7214a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-f675e666-d184-49f2-a392-e33d8920fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-98db1c8f-8d4b-456a-9b66-7e8b29b3bef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-f6aa750b-5c62-407f-b1a0-25db84e54e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-b726cd42-cfaf-40b5-970d-2c0c1e1a8e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-81c315ba-0b45-4886-acce-8db2e197d367,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850466728-172.17.0.3-1597702611006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34030,DS-48e0bf6e-06b2-499e-b867-ecdb91dd8539,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-97be8fe0-8a3e-4e86-b043-af1829f49cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-8516aed1-cecf-4e73-8e40-bdb52a7214a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-f675e666-d184-49f2-a392-e33d8920fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-98db1c8f-8d4b-456a-9b66-7e8b29b3bef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-f6aa750b-5c62-407f-b1a0-25db84e54e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-b726cd42-cfaf-40b5-970d-2c0c1e1a8e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-81c315ba-0b45-4886-acce-8db2e197d367,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841126408-172.17.0.3-1597702790303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-98c1bc80-cb9b-47cc-96e9-d58930f48dde,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-dfbfb7d9-38b5-4b6f-bc3a-a85018fdd34c,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-d2b3b53f-0461-4fb9-bada-606a1f0fe489,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-8bf7284b-f33f-441b-a350-eeab6d6fd1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-22200e9d-04bf-4aa6-9872-deec6b821cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-ef3b552b-4064-4d2a-a62e-4a8e2a40049f,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-709b464b-5691-4f1e-a4a2-3bcc6c527ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-d956e945-f418-496b-87ba-0db3617350c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841126408-172.17.0.3-1597702790303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-98c1bc80-cb9b-47cc-96e9-d58930f48dde,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-dfbfb7d9-38b5-4b6f-bc3a-a85018fdd34c,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-d2b3b53f-0461-4fb9-bada-606a1f0fe489,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-8bf7284b-f33f-441b-a350-eeab6d6fd1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-22200e9d-04bf-4aa6-9872-deec6b821cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-ef3b552b-4064-4d2a-a62e-4a8e2a40049f,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-709b464b-5691-4f1e-a4a2-3bcc6c527ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-d956e945-f418-496b-87ba-0db3617350c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5642
