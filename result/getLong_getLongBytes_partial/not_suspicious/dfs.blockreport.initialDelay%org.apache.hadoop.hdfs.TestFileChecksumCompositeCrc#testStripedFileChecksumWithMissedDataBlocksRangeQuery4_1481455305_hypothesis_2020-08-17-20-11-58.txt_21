reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092153597-172.17.0.17-1597695548175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43972,DS-55b3dda6-d87d-461d-af4d-44e607ae24d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-cda4dcb4-9089-47f9-b46b-1cf715879e13,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-b74c8f98-d775-4d4f-9c38-14415371ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-3b24c0bb-3c9b-4941-bddd-d252f8372998,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-7716188a-3cce-49fc-beeb-0ae516701b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-c6013fd3-6ce7-462c-b60c-06bba0937656,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-2119a2f9-87cc-4fda-a8dd-4f9fb01dee04,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-b0246b64-71d3-412c-9155-b27ec7248aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092153597-172.17.0.17-1597695548175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43972,DS-55b3dda6-d87d-461d-af4d-44e607ae24d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-cda4dcb4-9089-47f9-b46b-1cf715879e13,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-b74c8f98-d775-4d4f-9c38-14415371ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-3b24c0bb-3c9b-4941-bddd-d252f8372998,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-7716188a-3cce-49fc-beeb-0ae516701b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-c6013fd3-6ce7-462c-b60c-06bba0937656,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-2119a2f9-87cc-4fda-a8dd-4f9fb01dee04,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-b0246b64-71d3-412c-9155-b27ec7248aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599054491-172.17.0.17-1597695808674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33282,DS-5be98751-297e-4e4d-a862-7a3b2e1f0a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-5e04c2eb-c1fc-4bc0-b845-130248b2ff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-aa5da3fa-7bfe-4bbd-96cb-69faaf939299,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-c40f1e46-1a2e-435f-84ea-609eb4c4a47d,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-8d0a2735-6142-4983-85a4-d3ea06f78586,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-15d2978b-1d42-43e2-b393-f998864e576f,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-52b84e25-9e25-4df1-9d96-6c65881609d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-8a4a858d-28e6-49e5-9273-2e1bc51bb1df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599054491-172.17.0.17-1597695808674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33282,DS-5be98751-297e-4e4d-a862-7a3b2e1f0a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-5e04c2eb-c1fc-4bc0-b845-130248b2ff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-aa5da3fa-7bfe-4bbd-96cb-69faaf939299,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-c40f1e46-1a2e-435f-84ea-609eb4c4a47d,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-8d0a2735-6142-4983-85a4-d3ea06f78586,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-15d2978b-1d42-43e2-b393-f998864e576f,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-52b84e25-9e25-4df1-9d96-6c65881609d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-8a4a858d-28e6-49e5-9273-2e1bc51bb1df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500325324-172.17.0.17-1597696353954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41923,DS-df995053-bc61-4be8-9544-de59dc98d29a,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-cdc4b690-1d79-4e1d-8771-f056df0a63c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-0a7b601b-51f9-4588-8446-99ec2e473c04,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-0e083b87-3931-4d7a-b38a-a9f8fa11fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-554bdd4a-e09d-4d58-8aa5-2975e395d753,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-e51ab80c-e63c-4004-b13f-ccd935bb327b,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-ae9e88f6-4d87-4ea0-aa17-bd279ffeebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-23870974-5b69-421d-b655-413361ecbfd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500325324-172.17.0.17-1597696353954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41923,DS-df995053-bc61-4be8-9544-de59dc98d29a,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-cdc4b690-1d79-4e1d-8771-f056df0a63c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-0a7b601b-51f9-4588-8446-99ec2e473c04,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-0e083b87-3931-4d7a-b38a-a9f8fa11fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-554bdd4a-e09d-4d58-8aa5-2975e395d753,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-e51ab80c-e63c-4004-b13f-ccd935bb327b,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-ae9e88f6-4d87-4ea0-aa17-bd279ffeebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-23870974-5b69-421d-b655-413361ecbfd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2394930-172.17.0.17-1597697470808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-20288024-3919-4215-974c-eb7e2baafc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-ac415596-a742-4e53-aae2-347c73fcb128,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-609f353d-9743-4580-a960-5918fa0e5cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-36ec1bf7-e942-495f-a894-13438fab1d06,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-fcf097da-1a4a-477c-a117-263d6535f515,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-3908d0e5-52b1-486c-ba12-eab30cec880d,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-b1b28e35-9933-4c48-80a3-7bb1f31edb17,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-20b7167a-4f8a-4791-8f24-a8d109624408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2394930-172.17.0.17-1597697470808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41982,DS-20288024-3919-4215-974c-eb7e2baafc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-ac415596-a742-4e53-aae2-347c73fcb128,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-609f353d-9743-4580-a960-5918fa0e5cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-36ec1bf7-e942-495f-a894-13438fab1d06,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-fcf097da-1a4a-477c-a117-263d6535f515,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-3908d0e5-52b1-486c-ba12-eab30cec880d,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-b1b28e35-9933-4c48-80a3-7bb1f31edb17,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-20b7167a-4f8a-4791-8f24-a8d109624408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90383264-172.17.0.17-1597698907543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35104,DS-f3b552d2-9894-4623-80e2-9ac5b7235860,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-e2127d94-1e57-48d4-b6f0-991febd5955c,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-777e05f3-0194-47be-86f2-2b785b07b29e,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-a54c3c99-3619-4e40-9103-5561ea8f2b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-1b4c0430-8207-49ed-8359-2e20d44a8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-061cfd10-76e8-4899-8ad1-7fbcda81e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-979f3649-375b-415d-8a65-1e72ede6235f,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-2c0e57e9-855f-44a8-8e03-e195773943f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90383264-172.17.0.17-1597698907543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35104,DS-f3b552d2-9894-4623-80e2-9ac5b7235860,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-e2127d94-1e57-48d4-b6f0-991febd5955c,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-777e05f3-0194-47be-86f2-2b785b07b29e,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-a54c3c99-3619-4e40-9103-5561ea8f2b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-1b4c0430-8207-49ed-8359-2e20d44a8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-061cfd10-76e8-4899-8ad1-7fbcda81e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-979f3649-375b-415d-8a65-1e72ede6235f,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-2c0e57e9-855f-44a8-8e03-e195773943f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646032994-172.17.0.17-1597700292895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-29168fd0-836d-4e09-8d69-def324e93aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-6fce43da-273e-4d0c-9681-38cffc9b4164,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-558381ef-cf4f-491c-bdfd-fdc30454a2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-437c21f0-2c1a-42bc-9434-8a5f331d0e21,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-6ad99290-47c1-4c14-88dd-4b267f817f44,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-e23b8e78-b30d-4af4-bba7-048d33192cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-c0ffdb6d-981f-46be-89cc-3412193d5ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-b1886564-ec57-4011-80dc-c1a6ef23ec18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646032994-172.17.0.17-1597700292895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-29168fd0-836d-4e09-8d69-def324e93aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-6fce43da-273e-4d0c-9681-38cffc9b4164,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-558381ef-cf4f-491c-bdfd-fdc30454a2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-437c21f0-2c1a-42bc-9434-8a5f331d0e21,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-6ad99290-47c1-4c14-88dd-4b267f817f44,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-e23b8e78-b30d-4af4-bba7-048d33192cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-c0ffdb6d-981f-46be-89cc-3412193d5ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-b1886564-ec57-4011-80dc-c1a6ef23ec18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353313929-172.17.0.17-1597700984557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38112,DS-5ac89f3b-f398-4517-aeed-1c1069db2cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-d92170d5-5128-47dd-8227-694fc1bba907,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-01208157-6bc4-4d5c-9680-d9c55b91a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-6b11c2c0-0fd3-4784-8e82-3456e055f10e,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-e849d649-3df0-4dc0-9a11-d2840f299bde,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-511b3cb0-f626-4d63-b35c-9a87b4823c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-18960101-46ec-4815-9a56-ceb7b4cbf339,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-38a5a888-39c0-4ac8-b05b-68cac0ad430e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353313929-172.17.0.17-1597700984557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38112,DS-5ac89f3b-f398-4517-aeed-1c1069db2cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-d92170d5-5128-47dd-8227-694fc1bba907,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-01208157-6bc4-4d5c-9680-d9c55b91a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-6b11c2c0-0fd3-4784-8e82-3456e055f10e,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-e849d649-3df0-4dc0-9a11-d2840f299bde,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-511b3cb0-f626-4d63-b35c-9a87b4823c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-18960101-46ec-4815-9a56-ceb7b4cbf339,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-38a5a888-39c0-4ac8-b05b-68cac0ad430e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589429299-172.17.0.17-1597701281310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36000,DS-9665982f-3a7c-42c8-b0e4-d7e8f96d2197,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-f94d8e12-f6ba-4faf-8fd1-a6c4f1e169dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-4bd3e2d6-69c3-42f6-911a-09d2953dd2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-fea6a683-5a85-4148-9d05-365f92970d43,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-42e633d5-bf34-482c-9838-00b4b09b837c,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-244591bf-3a48-45c2-a3a5-fa936a8223df,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-81e8424f-555e-452f-b676-b07e2115f32c,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-82b32d76-1721-4985-ba6a-77e1c1c57e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589429299-172.17.0.17-1597701281310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36000,DS-9665982f-3a7c-42c8-b0e4-d7e8f96d2197,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-f94d8e12-f6ba-4faf-8fd1-a6c4f1e169dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-4bd3e2d6-69c3-42f6-911a-09d2953dd2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-fea6a683-5a85-4148-9d05-365f92970d43,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-42e633d5-bf34-482c-9838-00b4b09b837c,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-244591bf-3a48-45c2-a3a5-fa936a8223df,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-81e8424f-555e-452f-b676-b07e2115f32c,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-82b32d76-1721-4985-ba6a-77e1c1c57e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010722219-172.17.0.17-1597701749308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45260,DS-7b9f0238-4599-4eae-a739-d570c5942d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-e389074b-414e-444a-b2a2-b64bca3fd972,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-6d4dfa4f-db85-4f7d-bae2-7263f9ebccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-6d9d95e5-0dc0-47fb-aee9-747e6c31dd70,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-4a932fb5-5023-4402-9213-6e87dbcc11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-4f911f71-625b-4be5-b3b7-fb3f36d67062,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-2373cfa0-0e84-44fc-ae74-0f045788a5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-877ca14a-5ab2-4bbb-80c1-3fec803acc64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010722219-172.17.0.17-1597701749308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45260,DS-7b9f0238-4599-4eae-a739-d570c5942d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-e389074b-414e-444a-b2a2-b64bca3fd972,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-6d4dfa4f-db85-4f7d-bae2-7263f9ebccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-6d9d95e5-0dc0-47fb-aee9-747e6c31dd70,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-4a932fb5-5023-4402-9213-6e87dbcc11ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-4f911f71-625b-4be5-b3b7-fb3f36d67062,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-2373cfa0-0e84-44fc-ae74-0f045788a5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-877ca14a-5ab2-4bbb-80c1-3fec803acc64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 6882
