reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51876372-172.17.0.4-1597696343329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-b5db7dc0-d94e-4817-8f10-3b4c5d625a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-ca2af4b9-068b-422d-9908-2b2a239f2c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-8ad9d7a1-8c27-4cf7-bb28-c4249ff46a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-a1484cb6-b82e-4323-934b-f5a48ef47cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-0dc04a07-1dfd-45b2-ae73-fe6cd6b08196,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-429a1c85-8462-455b-b4f9-2bdf9a307835,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-d7c566b9-8a59-4227-8841-fb7ffb0efbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-0364c9e3-6f18-44c7-a375-40cea7c178c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51876372-172.17.0.4-1597696343329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-b5db7dc0-d94e-4817-8f10-3b4c5d625a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-ca2af4b9-068b-422d-9908-2b2a239f2c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-8ad9d7a1-8c27-4cf7-bb28-c4249ff46a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-a1484cb6-b82e-4323-934b-f5a48ef47cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-0dc04a07-1dfd-45b2-ae73-fe6cd6b08196,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-429a1c85-8462-455b-b4f9-2bdf9a307835,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-d7c566b9-8a59-4227-8841-fb7ffb0efbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-0364c9e3-6f18-44c7-a375-40cea7c178c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443124481-172.17.0.4-1597696752437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39906,DS-7d0bc4d0-bf6f-452c-b508-e6d80f5c3a56,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-1e4283bc-8f18-4a67-8005-58f11eeb43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-4047848c-711f-4988-bb32-4b82daf3004d,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-ce245736-5c70-4ca4-8797-ff0644e4c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-703718e2-76b9-4146-abf2-423c41f23ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-2180cf47-d6dd-49ca-85ba-d60e6d876991,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-173a6918-fc15-4c3f-af38-9dce6bae422c,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-fd2f8265-1525-45b1-8110-088541fe5851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443124481-172.17.0.4-1597696752437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39906,DS-7d0bc4d0-bf6f-452c-b508-e6d80f5c3a56,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-1e4283bc-8f18-4a67-8005-58f11eeb43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-4047848c-711f-4988-bb32-4b82daf3004d,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-ce245736-5c70-4ca4-8797-ff0644e4c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-703718e2-76b9-4146-abf2-423c41f23ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-2180cf47-d6dd-49ca-85ba-d60e6d876991,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-173a6918-fc15-4c3f-af38-9dce6bae422c,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-fd2f8265-1525-45b1-8110-088541fe5851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345348692-172.17.0.4-1597696972015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38662,DS-a3add095-6e03-4858-af00-6399bce86940,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-b23fec6e-a256-4da8-859a-06e8e17595ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-462a4f09-3787-4a97-afab-39d669900450,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-fca3222a-6aee-47e4-aad4-f461381aaaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-5e7d14bc-b99d-4051-b5a8-ec2d707af28a,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-88c9ac3c-6d90-420e-8e65-5a7bb2ed9e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-c223bfa5-eeb2-428a-8f15-858dcbfbc1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-3401aa05-29a7-4c00-9e28-93f5532a3580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345348692-172.17.0.4-1597696972015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38662,DS-a3add095-6e03-4858-af00-6399bce86940,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-b23fec6e-a256-4da8-859a-06e8e17595ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-462a4f09-3787-4a97-afab-39d669900450,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-fca3222a-6aee-47e4-aad4-f461381aaaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-5e7d14bc-b99d-4051-b5a8-ec2d707af28a,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-88c9ac3c-6d90-420e-8e65-5a7bb2ed9e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-c223bfa5-eeb2-428a-8f15-858dcbfbc1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-3401aa05-29a7-4c00-9e28-93f5532a3580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719808931-172.17.0.4-1597697344791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40568,DS-8d4f3461-8a09-454f-943a-7faf9aae1612,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-daf25cc3-3898-4869-88b0-403ceb9a015d,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-a8f8fc81-4dce-4824-9c24-53b6726df842,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-1e7a9f64-d2c1-4680-a951-4d515b96d0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-3afeb99e-4d21-493f-8d63-ecf1a922ba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-8170efc6-1b0e-4441-8a66-afb9565fe6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-45db27a9-0984-4ded-85ae-734fe21687b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-4f67ad26-6861-4304-a7f6-8ccaad5b5414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719808931-172.17.0.4-1597697344791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40568,DS-8d4f3461-8a09-454f-943a-7faf9aae1612,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-daf25cc3-3898-4869-88b0-403ceb9a015d,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-a8f8fc81-4dce-4824-9c24-53b6726df842,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-1e7a9f64-d2c1-4680-a951-4d515b96d0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-3afeb99e-4d21-493f-8d63-ecf1a922ba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-8170efc6-1b0e-4441-8a66-afb9565fe6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-45db27a9-0984-4ded-85ae-734fe21687b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-4f67ad26-6861-4304-a7f6-8ccaad5b5414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918195050-172.17.0.4-1597697736640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38831,DS-0366b02a-b330-4fce-b65a-cc2b4cf8923d,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-4dc34c1c-13d5-46e0-a799-84d41acf7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-c7208bc2-cef0-410d-ba99-70601faf310f,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-8cccf597-d102-448f-b2ed-8290f5a15309,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-d63588a2-6b4c-4d57-87a5-c9dcbbc849dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-b07f9644-f2b3-4373-be8d-f48d925e0bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-a8fd064c-934d-459a-a1fe-8e133316815f,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-e84f0a9c-03bd-4022-af74-7d5c8b6995b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918195050-172.17.0.4-1597697736640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38831,DS-0366b02a-b330-4fce-b65a-cc2b4cf8923d,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-4dc34c1c-13d5-46e0-a799-84d41acf7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-c7208bc2-cef0-410d-ba99-70601faf310f,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-8cccf597-d102-448f-b2ed-8290f5a15309,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-d63588a2-6b4c-4d57-87a5-c9dcbbc849dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-b07f9644-f2b3-4373-be8d-f48d925e0bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-a8fd064c-934d-459a-a1fe-8e133316815f,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-e84f0a9c-03bd-4022-af74-7d5c8b6995b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612354881-172.17.0.4-1597698258657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-b6bed069-05a8-4ff3-98dd-1e6d285f53cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-553635e3-51d9-4aa9-8e75-d13a3981620e,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-f5543b96-bbba-4885-b90e-006ec2e8be54,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-40796c3d-d7d6-415f-9859-5c649dfeea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-63bed75b-3e69-450f-942c-9f63900d3181,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-c4e9f047-4d33-42c1-b2ca-3ea822619fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-79c8377b-6386-4f1f-af26-de9ce9345192,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-942993aa-2345-4ffc-8699-f1e343a0f6c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612354881-172.17.0.4-1597698258657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40023,DS-b6bed069-05a8-4ff3-98dd-1e6d285f53cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-553635e3-51d9-4aa9-8e75-d13a3981620e,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-f5543b96-bbba-4885-b90e-006ec2e8be54,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-40796c3d-d7d6-415f-9859-5c649dfeea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-63bed75b-3e69-450f-942c-9f63900d3181,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-c4e9f047-4d33-42c1-b2ca-3ea822619fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-79c8377b-6386-4f1f-af26-de9ce9345192,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-942993aa-2345-4ffc-8699-f1e343a0f6c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223342133-172.17.0.4-1597698458425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-9dff2da7-0aba-4132-8c1c-21dd25cdb638,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-eee29d96-80bd-4c46-9d45-7d78b87ca291,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-d1125d25-8c68-4689-b059-d8efb4ada11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-dffe95c4-d5ad-4185-8287-6290adb4e65a,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-77f194bc-fc37-4492-b600-8b11875c26df,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-bf1ea13b-cd1a-4690-91ac-8736efa56c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-60772f5e-4fd6-464a-b535-967bdfe6d46f,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-8dc7ae71-3a43-4f02-afa2-b0481d259092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223342133-172.17.0.4-1597698458425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-9dff2da7-0aba-4132-8c1c-21dd25cdb638,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-eee29d96-80bd-4c46-9d45-7d78b87ca291,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-d1125d25-8c68-4689-b059-d8efb4ada11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-dffe95c4-d5ad-4185-8287-6290adb4e65a,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-77f194bc-fc37-4492-b600-8b11875c26df,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-bf1ea13b-cd1a-4690-91ac-8736efa56c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-60772f5e-4fd6-464a-b535-967bdfe6d46f,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-8dc7ae71-3a43-4f02-afa2-b0481d259092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252374926-172.17.0.4-1597698489354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46526,DS-a28c9365-43b9-444d-8daf-ba5fb734522c,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-23463f69-5a88-4823-9996-208225dea82d,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-bc33aa2b-deaa-450d-bdf2-e6b9158a9819,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-5bf2eb74-df7c-42fb-b880-eaef8b4d0d94,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-2884bbff-cdc3-4913-a3d1-f70f3dda377d,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-ad73a852-0104-4ee6-8b69-c0984c3e95c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-11c78e7e-2eb8-4054-b60f-bd0b7c9f02e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-6924408e-71f6-481d-b04b-66a377c93707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252374926-172.17.0.4-1597698489354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46526,DS-a28c9365-43b9-444d-8daf-ba5fb734522c,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-23463f69-5a88-4823-9996-208225dea82d,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-bc33aa2b-deaa-450d-bdf2-e6b9158a9819,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-5bf2eb74-df7c-42fb-b880-eaef8b4d0d94,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-2884bbff-cdc3-4913-a3d1-f70f3dda377d,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-ad73a852-0104-4ee6-8b69-c0984c3e95c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-11c78e7e-2eb8-4054-b60f-bd0b7c9f02e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-6924408e-71f6-481d-b04b-66a377c93707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174192717-172.17.0.4-1597698788669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44115,DS-af32d8a5-8a4c-411c-b056-f584b3a9cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-881a2d30-deaf-46a3-9412-0f2920d1fe26,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-4454a2fe-624e-4a2d-ad87-159f0b89feed,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-3ee8ccd2-fa89-49fe-8412-fab212fb6768,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-595518b8-a808-439a-965e-662f4b0fa5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-a71ac857-704d-41ab-ab03-87e96634a631,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-b58c1c8e-a7cb-407e-a208-6fda4f1988b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-decddc7d-456d-4be2-b72f-7ab16ccc87b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174192717-172.17.0.4-1597698788669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44115,DS-af32d8a5-8a4c-411c-b056-f584b3a9cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-881a2d30-deaf-46a3-9412-0f2920d1fe26,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-4454a2fe-624e-4a2d-ad87-159f0b89feed,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-3ee8ccd2-fa89-49fe-8412-fab212fb6768,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-595518b8-a808-439a-965e-662f4b0fa5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-a71ac857-704d-41ab-ab03-87e96634a631,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-b58c1c8e-a7cb-407e-a208-6fda4f1988b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-decddc7d-456d-4be2-b72f-7ab16ccc87b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216946048-172.17.0.4-1597698998021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39113,DS-3249c7a2-1558-4709-91f1-0a3afc1817c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-831f8458-5a57-4c87-8688-170539433f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-dde85e0d-31d8-4632-9885-172ab384948c,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-886877ff-6258-473d-b07d-e465f492214d,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-171591f0-ef03-4cf4-9fae-6ada81eaaf76,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-ab8610f7-1b67-4959-bb21-5ea6c7ffa5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-d30049f9-fb61-42b2-9528-0a76be283c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-6686fc20-60f3-406b-8886-0ca7a04293d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216946048-172.17.0.4-1597698998021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39113,DS-3249c7a2-1558-4709-91f1-0a3afc1817c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-831f8458-5a57-4c87-8688-170539433f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-dde85e0d-31d8-4632-9885-172ab384948c,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-886877ff-6258-473d-b07d-e465f492214d,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-171591f0-ef03-4cf4-9fae-6ada81eaaf76,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-ab8610f7-1b67-4959-bb21-5ea6c7ffa5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-d30049f9-fb61-42b2-9528-0a76be283c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-6686fc20-60f3-406b-8886-0ca7a04293d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527893079-172.17.0.4-1597699621107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44494,DS-75beecc7-8619-4164-bd40-9ed6e171cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-bc3a2fea-f29c-485d-8f28-c3f8900eb9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-0f0b508b-0803-46d8-8ed7-05b9f44d0456,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-b58e7788-dc51-46dd-8910-c751a9c20f74,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-4a0d2553-abba-4c7d-9f94-b30f9cd2a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-88613659-0304-493f-862b-d169a72e6ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-859d55c2-aade-409b-89af-3231a7434ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-5a6a4687-c5b8-4cee-8785-3ca548adc12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527893079-172.17.0.4-1597699621107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44494,DS-75beecc7-8619-4164-bd40-9ed6e171cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-bc3a2fea-f29c-485d-8f28-c3f8900eb9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-0f0b508b-0803-46d8-8ed7-05b9f44d0456,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-b58e7788-dc51-46dd-8910-c751a9c20f74,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-4a0d2553-abba-4c7d-9f94-b30f9cd2a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-88613659-0304-493f-862b-d169a72e6ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-859d55c2-aade-409b-89af-3231a7434ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-5a6a4687-c5b8-4cee-8785-3ca548adc12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708995383-172.17.0.4-1597699691681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42678,DS-34845414-bb36-47b7-87f9-f9e4e03d78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-d6e34b35-0849-4122-a32f-2b4573c06ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-d4c1cd3f-754e-40b0-8ece-54457334b4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-0dc42ed4-b5bf-4d19-9a0e-523f7cf8ccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-0e1aff11-223e-498d-8a2f-25bdfa7891a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-fa87626a-2e67-4d42-9bfb-636caa008b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-3796fd3c-ccc0-4b09-85d4-48f2b41edcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-44954758-41c2-4952-aa62-5b8694a8738d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708995383-172.17.0.4-1597699691681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42678,DS-34845414-bb36-47b7-87f9-f9e4e03d78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-d6e34b35-0849-4122-a32f-2b4573c06ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-d4c1cd3f-754e-40b0-8ece-54457334b4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-0dc42ed4-b5bf-4d19-9a0e-523f7cf8ccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-0e1aff11-223e-498d-8a2f-25bdfa7891a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-fa87626a-2e67-4d42-9bfb-636caa008b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-3796fd3c-ccc0-4b09-85d4-48f2b41edcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-44954758-41c2-4952-aa62-5b8694a8738d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-440752710-172.17.0.4-1597699879163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-68ba67f5-0939-4a6a-bd4b-a22210e5ff67,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-317d0db6-7967-439a-8964-8abd7b583923,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-2fc1f1e4-2d66-4551-8d8d-29bf17fd25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-7d2c9898-34ef-4edd-b36b-4c5db437a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-deecd871-4f74-4701-b798-a77dbd4b8892,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-d362ec87-721b-4f3e-a2e0-70b02d2535e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-c0937ac4-252e-4387-a2e0-043204e5a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-7742f642-69ae-4576-9543-d51043235bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-440752710-172.17.0.4-1597699879163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-68ba67f5-0939-4a6a-bd4b-a22210e5ff67,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-317d0db6-7967-439a-8964-8abd7b583923,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-2fc1f1e4-2d66-4551-8d8d-29bf17fd25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-7d2c9898-34ef-4edd-b36b-4c5db437a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-deecd871-4f74-4701-b798-a77dbd4b8892,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-d362ec87-721b-4f3e-a2e0-70b02d2535e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-c0937ac4-252e-4387-a2e0-043204e5a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-7742f642-69ae-4576-9543-d51043235bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979532347-172.17.0.4-1597699953533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42452,DS-cca31bf1-c053-4aa7-b6fa-4964db339c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-3e224458-aa9f-4eaa-aa2f-15a50138ff5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-ae3986a3-f854-4e30-9790-85a9e23cc6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-168f7b5e-fae6-4c5c-bc87-eb6faf0212f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-0ebb1053-49ba-40bb-aa77-95641126b948,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-48c3f211-babf-4f1b-9f97-68ee36bb82b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-6f03dfc8-a9c5-4394-bd05-e6281fd26c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-e24f9fd4-c912-473a-9c7c-c99dd539ffc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979532347-172.17.0.4-1597699953533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42452,DS-cca31bf1-c053-4aa7-b6fa-4964db339c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-3e224458-aa9f-4eaa-aa2f-15a50138ff5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-ae3986a3-f854-4e30-9790-85a9e23cc6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-168f7b5e-fae6-4c5c-bc87-eb6faf0212f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-0ebb1053-49ba-40bb-aa77-95641126b948,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-48c3f211-babf-4f1b-9f97-68ee36bb82b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-6f03dfc8-a9c5-4394-bd05-e6281fd26c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-e24f9fd4-c912-473a-9c7c-c99dd539ffc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652463834-172.17.0.4-1597701027449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-2ec13cb9-49a9-4731-8f86-b93215fe4534,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-db767d5f-a47a-409e-ad65-3e6441b3b82f,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-af413771-0f3f-4af4-9cdb-40aefeae0474,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-db6e4596-1f64-48ee-8c37-5b22ca8c9e21,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-8af03a7e-dae4-41d0-8fb1-88e09ff685a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-bc44a2ed-3b4c-4438-941f-f2dbb5d773c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-7069ed1f-462b-4490-b837-e33da29ab2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-712ef290-fc13-4310-8de6-f02ed4679b5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652463834-172.17.0.4-1597701027449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-2ec13cb9-49a9-4731-8f86-b93215fe4534,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-db767d5f-a47a-409e-ad65-3e6441b3b82f,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-af413771-0f3f-4af4-9cdb-40aefeae0474,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-db6e4596-1f64-48ee-8c37-5b22ca8c9e21,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-8af03a7e-dae4-41d0-8fb1-88e09ff685a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-bc44a2ed-3b4c-4438-941f-f2dbb5d773c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-7069ed1f-462b-4490-b837-e33da29ab2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-712ef290-fc13-4310-8de6-f02ed4679b5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5475
