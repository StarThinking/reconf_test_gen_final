reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585427765-172.17.0.15-1597744219330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37007,DS-7a8c7f97-d626-499b-833e-e1755ff674eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-18adaa66-a181-4c76-bca2-2a6d1cc59426,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-211018fc-9c2b-4667-afb1-ceacb7d0910b,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-5d4c65d4-f056-4afd-b5d1-230267fd0efe,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-8b6aa9c9-8ac5-422f-884a-4e095b497532,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-34b6ff89-a976-49d2-8d7e-69ffc6457ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-f24309f3-21f9-4308-a364-e9e57a114c93,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-cd890a7f-30dd-4479-b6e9-47f08db21832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585427765-172.17.0.15-1597744219330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37007,DS-7a8c7f97-d626-499b-833e-e1755ff674eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-18adaa66-a181-4c76-bca2-2a6d1cc59426,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-211018fc-9c2b-4667-afb1-ceacb7d0910b,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-5d4c65d4-f056-4afd-b5d1-230267fd0efe,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-8b6aa9c9-8ac5-422f-884a-4e095b497532,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-34b6ff89-a976-49d2-8d7e-69ffc6457ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-f24309f3-21f9-4308-a364-e9e57a114c93,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-cd890a7f-30dd-4479-b6e9-47f08db21832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117452948-172.17.0.15-1597744250843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38389,DS-82334ad1-b260-4e5d-87f9-67f2212eafec,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-ae78a396-83fd-400c-8d0d-6ce19fb9de31,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-b1d1b288-ebb7-48be-b453-d107c4eb2aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-81be6d31-9dbe-46d0-8275-a553ac69f561,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-e471ffaa-a9d3-4d2a-b2da-05b151388de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-af679188-ab8d-4ce9-b926-61effda74293,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-f8a0beb8-d9ab-46ca-ae8b-b70a8efe11f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-d3f00faf-b790-4a92-b536-a4c775a57254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117452948-172.17.0.15-1597744250843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38389,DS-82334ad1-b260-4e5d-87f9-67f2212eafec,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-ae78a396-83fd-400c-8d0d-6ce19fb9de31,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-b1d1b288-ebb7-48be-b453-d107c4eb2aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-81be6d31-9dbe-46d0-8275-a553ac69f561,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-e471ffaa-a9d3-4d2a-b2da-05b151388de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-af679188-ab8d-4ce9-b926-61effda74293,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-f8a0beb8-d9ab-46ca-ae8b-b70a8efe11f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-d3f00faf-b790-4a92-b536-a4c775a57254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491787850-172.17.0.15-1597744351183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-b765dc5e-6ca7-415e-8255-c05e99f381b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-587bd401-a6db-4cb3-a612-b514e1d95b82,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-2cbdf41a-4bd3-423b-ab8b-f0af08aabd99,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-b64c2c52-1d81-4823-8651-374eec8c6265,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-0f0b5d97-cca0-46b1-8e96-5908f5202cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-c8228206-af5b-4081-b2a3-d74b49a36eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-5444332e-75d3-4161-9346-618d4c02c60e,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-c5649fc6-bb40-46d4-aabb-75e69c908e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491787850-172.17.0.15-1597744351183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-b765dc5e-6ca7-415e-8255-c05e99f381b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-587bd401-a6db-4cb3-a612-b514e1d95b82,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-2cbdf41a-4bd3-423b-ab8b-f0af08aabd99,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-b64c2c52-1d81-4823-8651-374eec8c6265,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-0f0b5d97-cca0-46b1-8e96-5908f5202cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-c8228206-af5b-4081-b2a3-d74b49a36eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-5444332e-75d3-4161-9346-618d4c02c60e,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-c5649fc6-bb40-46d4-aabb-75e69c908e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129233523-172.17.0.15-1597744524079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-d5dae228-a10e-40a5-95ae-ca0dfc39b492,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-d1a9e6b3-a23d-4540-ab99-f97747a5cca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-bee7244c-aaaa-4040-a0bc-73015691252a,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-ffe68ba1-5524-44b4-b213-bfffda929f78,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-10025a29-4b67-4263-ac87-5c6b7788d7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-7322e6fd-87b3-40db-a048-f655510bbbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-2fbfe72f-576e-4476-88f6-c180ef113348,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-db73fbcb-baa3-4dad-9f2f-e41ad979a5d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129233523-172.17.0.15-1597744524079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-d5dae228-a10e-40a5-95ae-ca0dfc39b492,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-d1a9e6b3-a23d-4540-ab99-f97747a5cca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-bee7244c-aaaa-4040-a0bc-73015691252a,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-ffe68ba1-5524-44b4-b213-bfffda929f78,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-10025a29-4b67-4263-ac87-5c6b7788d7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-7322e6fd-87b3-40db-a048-f655510bbbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-2fbfe72f-576e-4476-88f6-c180ef113348,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-db73fbcb-baa3-4dad-9f2f-e41ad979a5d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895902210-172.17.0.15-1597744711922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-ce7748e0-0b5b-44af-8743-53f52b43187c,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-8ea85f02-a78b-4457-9d22-333cf7d9a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-595d29a2-4545-4466-91b3-62db48708948,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-8790c495-f37e-4593-966f-dd368fd4c9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-18964fc9-3da3-4d71-90c5-a8c787aa203a,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-709ff6c2-4510-4929-8921-ba14fa4be65c,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-ef83b81c-cb91-4f3d-8967-ea02ce0f334e,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-87c94e6f-0091-4d0e-a88a-e8431742567c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895902210-172.17.0.15-1597744711922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-ce7748e0-0b5b-44af-8743-53f52b43187c,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-8ea85f02-a78b-4457-9d22-333cf7d9a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-595d29a2-4545-4466-91b3-62db48708948,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-8790c495-f37e-4593-966f-dd368fd4c9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-18964fc9-3da3-4d71-90c5-a8c787aa203a,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-709ff6c2-4510-4929-8921-ba14fa4be65c,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-ef83b81c-cb91-4f3d-8967-ea02ce0f334e,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-87c94e6f-0091-4d0e-a88a-e8431742567c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289745367-172.17.0.15-1597744782576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40157,DS-db79ab01-0ad3-41a2-b586-eee2e7f678b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-b4f56510-7487-4114-b2b0-c3a3c49aa158,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-5546dbbb-0608-4bf7-a5d4-19772cfcc6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-99702cfa-867c-4009-a7b0-7b393d32a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-8c4b0362-9d33-4d7c-80aa-453d9122ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-486fea88-792e-4cb1-8c28-2e1c3c3ff3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-802034a6-4208-4154-8bd8-ae9b2642e86d,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-b0dc09aa-eab9-408c-84f8-7c6401021657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289745367-172.17.0.15-1597744782576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40157,DS-db79ab01-0ad3-41a2-b586-eee2e7f678b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-b4f56510-7487-4114-b2b0-c3a3c49aa158,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-5546dbbb-0608-4bf7-a5d4-19772cfcc6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-99702cfa-867c-4009-a7b0-7b393d32a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-8c4b0362-9d33-4d7c-80aa-453d9122ae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-486fea88-792e-4cb1-8c28-2e1c3c3ff3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-802034a6-4208-4154-8bd8-ae9b2642e86d,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-b0dc09aa-eab9-408c-84f8-7c6401021657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002705782-172.17.0.15-1597745524525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-9a7d7172-6e52-4867-b93b-b631323b1c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-25d077ee-f61f-4c87-9d9c-43ca483c9632,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-5cd25857-ebca-41b8-bc0f-ca98f1e833dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-482a35de-176f-4292-a4c4-266358ce31d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-c4f92a28-dcb6-4a84-b296-126b8cb6f987,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-04eedb3e-1ef9-457c-889e-ee3cf9a6e52c,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-1be96f39-6d64-4570-86e4-54b41f4401e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-d6db62f0-3483-4794-a43b-9914ad42d4b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002705782-172.17.0.15-1597745524525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42265,DS-9a7d7172-6e52-4867-b93b-b631323b1c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-25d077ee-f61f-4c87-9d9c-43ca483c9632,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-5cd25857-ebca-41b8-bc0f-ca98f1e833dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-482a35de-176f-4292-a4c4-266358ce31d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-c4f92a28-dcb6-4a84-b296-126b8cb6f987,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-04eedb3e-1ef9-457c-889e-ee3cf9a6e52c,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-1be96f39-6d64-4570-86e4-54b41f4401e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-d6db62f0-3483-4794-a43b-9914ad42d4b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996319966-172.17.0.15-1597745847474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-2c4c5ae9-d7ec-4377-a29e-c20f0f4e5912,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-8397eecb-a8b5-48ab-997b-85d1679d8085,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-df880d33-2418-44e9-907a-3e5d64bd8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-a6217351-0f49-462c-bc25-e34b2ae2f9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-945d511f-11fe-48c9-8416-2b93be53763b,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-8b00f670-5372-4a37-9e17-0d879724d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-407150e4-d723-42ee-b318-76fa2eef0190,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-8ed75d02-bfa4-49bd-95d1-6e5a692c7a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996319966-172.17.0.15-1597745847474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-2c4c5ae9-d7ec-4377-a29e-c20f0f4e5912,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-8397eecb-a8b5-48ab-997b-85d1679d8085,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-df880d33-2418-44e9-907a-3e5d64bd8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-a6217351-0f49-462c-bc25-e34b2ae2f9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-945d511f-11fe-48c9-8416-2b93be53763b,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-8b00f670-5372-4a37-9e17-0d879724d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-407150e4-d723-42ee-b318-76fa2eef0190,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-8ed75d02-bfa4-49bd-95d1-6e5a692c7a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267372005-172.17.0.15-1597746522441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45014,DS-c0b9cc19-d005-4699-a433-650e93e1df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-8cf6bb91-f514-4e2f-977e-e02d3a4fd023,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-bd7b27ac-9d56-4362-b446-255f5c086182,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-5df32cdd-f0c8-4659-97d1-53f6ee4b817c,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-9c979e79-2a5f-4763-8a88-bb1a2297d860,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-551b1f20-1dad-402f-878c-7698c987fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-d539cda9-835c-4a4b-b575-01b6d755e611,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-56c7bcdc-f4f6-4a60-a76e-7457cc0deffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267372005-172.17.0.15-1597746522441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45014,DS-c0b9cc19-d005-4699-a433-650e93e1df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-8cf6bb91-f514-4e2f-977e-e02d3a4fd023,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-bd7b27ac-9d56-4362-b446-255f5c086182,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-5df32cdd-f0c8-4659-97d1-53f6ee4b817c,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-9c979e79-2a5f-4763-8a88-bb1a2297d860,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-551b1f20-1dad-402f-878c-7698c987fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-d539cda9-835c-4a4b-b575-01b6d755e611,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-56c7bcdc-f4f6-4a60-a76e-7457cc0deffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804611050-172.17.0.15-1597746662951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-3cffe39c-ea74-4d7f-97f7-932ad46c9a21,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-659a8fc9-6289-4fdb-9811-55ae44412ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-dcf3af6b-7181-4e1e-b9e5-3dbd9ea6325b,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-b568141b-c43b-46f2-934c-53db7b0146b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-a68d8da5-1c06-4d4b-a99d-27bce9312672,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-f6678451-61fc-4ff5-84b1-428553ea835f,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-37f5815a-8ba8-4c1a-8080-66a552a1646e,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-8574902e-601e-44ee-8b2c-2db011022e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804611050-172.17.0.15-1597746662951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-3cffe39c-ea74-4d7f-97f7-932ad46c9a21,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-659a8fc9-6289-4fdb-9811-55ae44412ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-dcf3af6b-7181-4e1e-b9e5-3dbd9ea6325b,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-b568141b-c43b-46f2-934c-53db7b0146b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-a68d8da5-1c06-4d4b-a99d-27bce9312672,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-f6678451-61fc-4ff5-84b1-428553ea835f,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-37f5815a-8ba8-4c1a-8080-66a552a1646e,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-8574902e-601e-44ee-8b2c-2db011022e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598008022-172.17.0.15-1597746911351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-d36507b5-e8f3-42d7-baef-fd2925ac5dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-24ebe127-327c-4f3d-82bb-fb1588894d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-2bcbb03a-2299-449b-9531-1ddf119e72d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-a908c04f-0165-4b05-afca-1f50e83f76b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-dcfbb205-ef99-4b9e-b100-1e6499bc1c68,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-00cd694f-7666-4d4a-b580-03c3c03ea643,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-ea469fac-5409-4a16-aa8c-270570623f57,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-51e3fa16-5015-4069-a214-0efdbf6bde0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598008022-172.17.0.15-1597746911351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-d36507b5-e8f3-42d7-baef-fd2925ac5dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-24ebe127-327c-4f3d-82bb-fb1588894d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-2bcbb03a-2299-449b-9531-1ddf119e72d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-a908c04f-0165-4b05-afca-1f50e83f76b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-dcfbb205-ef99-4b9e-b100-1e6499bc1c68,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-00cd694f-7666-4d4a-b580-03c3c03ea643,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-ea469fac-5409-4a16-aa8c-270570623f57,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-51e3fa16-5015-4069-a214-0efdbf6bde0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597956792-172.17.0.15-1597747759154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34288,DS-ea15e7c9-18cf-4050-8763-23b5c44be23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-76216f4b-6a10-4a41-9d25-b328f5ef45a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-a6fd0342-9fea-4b71-b535-52b37b9f0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-58582aac-2e22-4d2a-90f7-a346dd383dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-1d4981e3-23b0-4392-b0e6-fa41a7fc84d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-fef74286-e5d5-4a80-8904-f164bd994574,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-5fb4535d-261b-4584-860d-2c82a530677e,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-34ad524e-c07e-4979-a26f-5cbd6bf46f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597956792-172.17.0.15-1597747759154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34288,DS-ea15e7c9-18cf-4050-8763-23b5c44be23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-76216f4b-6a10-4a41-9d25-b328f5ef45a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-a6fd0342-9fea-4b71-b535-52b37b9f0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-58582aac-2e22-4d2a-90f7-a346dd383dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-1d4981e3-23b0-4392-b0e6-fa41a7fc84d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-fef74286-e5d5-4a80-8904-f164bd994574,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-5fb4535d-261b-4584-860d-2c82a530677e,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-34ad524e-c07e-4979-a26f-5cbd6bf46f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843715646-172.17.0.15-1597747872508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34637,DS-76e1a79c-22c3-483b-8e35-c0b14712ad07,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-5dc5dcf0-3714-44af-a6bc-cb7025f16cff,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-5c8748d3-a28c-43b7-bff6-c573be8c3b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-5137cc46-bc05-4d25-af43-f98c9193fb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-3c3fa932-a070-45d4-aaac-81cbeef3cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-f8697047-ee59-4c36-bf7e-3a5d024262fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-32f51c6c-3d57-4a36-96c2-823f375f37cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-b0cf2b88-cc1d-4bc0-ba41-eaa000bd6577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843715646-172.17.0.15-1597747872508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34637,DS-76e1a79c-22c3-483b-8e35-c0b14712ad07,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-5dc5dcf0-3714-44af-a6bc-cb7025f16cff,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-5c8748d3-a28c-43b7-bff6-c573be8c3b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-5137cc46-bc05-4d25-af43-f98c9193fb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-3c3fa932-a070-45d4-aaac-81cbeef3cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-f8697047-ee59-4c36-bf7e-3a5d024262fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-32f51c6c-3d57-4a36-96c2-823f375f37cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-b0cf2b88-cc1d-4bc0-ba41-eaa000bd6577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104500707-172.17.0.15-1597748058989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39848,DS-dde75dc3-cd07-468a-8147-c1504e069d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-574aa1e8-540e-4d3d-a875-90879de07b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-a8d5b27f-2c9b-4cb4-8714-0d8a147e3d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-7ef5e27e-8a5f-475f-baf4-66d4f570a3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-f84885ea-1011-4884-8126-dec4f19604e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-6a1a4ba1-edeb-47f5-a6ea-c4ecb4ccc895,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-3e65b82c-3136-421f-8d0a-682b35cf56fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-dea2228d-f06a-4c23-babe-67de04263555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104500707-172.17.0.15-1597748058989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39848,DS-dde75dc3-cd07-468a-8147-c1504e069d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-574aa1e8-540e-4d3d-a875-90879de07b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-a8d5b27f-2c9b-4cb4-8714-0d8a147e3d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-7ef5e27e-8a5f-475f-baf4-66d4f570a3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-f84885ea-1011-4884-8126-dec4f19604e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-6a1a4ba1-edeb-47f5-a6ea-c4ecb4ccc895,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-3e65b82c-3136-421f-8d0a-682b35cf56fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-dea2228d-f06a-4c23-babe-67de04263555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134947771-172.17.0.15-1597748291303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41478,DS-aae6aea5-48ee-4e98-a167-459df127354c,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-2b83c28f-f776-45e5-9e5b-4969c7614dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-f9578bd1-dbfb-4d8d-833d-f60a8b431411,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-72585d17-f9f0-428c-82a0-6ccffbd07e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-c3395fe6-dfef-4b19-a137-887eb7ed9226,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-ba40cb42-475f-461f-9703-902a24371495,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-32432c15-27f6-49c7-8c94-67315eba2e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-e159daa2-8ed5-44be-a4ad-2a6ebb4166d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134947771-172.17.0.15-1597748291303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41478,DS-aae6aea5-48ee-4e98-a167-459df127354c,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-2b83c28f-f776-45e5-9e5b-4969c7614dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-f9578bd1-dbfb-4d8d-833d-f60a8b431411,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-72585d17-f9f0-428c-82a0-6ccffbd07e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-c3395fe6-dfef-4b19-a137-887eb7ed9226,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-ba40cb42-475f-461f-9703-902a24371495,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-32432c15-27f6-49c7-8c94-67315eba2e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-e159daa2-8ed5-44be-a4ad-2a6ebb4166d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52540291-172.17.0.15-1597749115862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35365,DS-35278cd7-ea56-403c-8b35-cf3f46fd7cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-a9d4c5f4-a0b8-427f-a5c6-1cc3618081ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-3b61e3da-ceda-4ad2-9db1-5dd0a13dd7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-4f0f4c52-9582-48bc-955d-bc5aa4dee0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-206b7a2a-28a1-431d-a2c5-c4703d671e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-0749bd17-7059-4694-a9ab-81499f9642bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-6a5a1748-3e75-4a08-87f9-de2390c14772,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-d1203e17-244a-4af7-ba13-9ef8021c44e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52540291-172.17.0.15-1597749115862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35365,DS-35278cd7-ea56-403c-8b35-cf3f46fd7cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-a9d4c5f4-a0b8-427f-a5c6-1cc3618081ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-3b61e3da-ceda-4ad2-9db1-5dd0a13dd7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-4f0f4c52-9582-48bc-955d-bc5aa4dee0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-206b7a2a-28a1-431d-a2c5-c4703d671e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-0749bd17-7059-4694-a9ab-81499f9642bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-6a5a1748-3e75-4a08-87f9-de2390c14772,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-d1203e17-244a-4af7-ba13-9ef8021c44e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5435
