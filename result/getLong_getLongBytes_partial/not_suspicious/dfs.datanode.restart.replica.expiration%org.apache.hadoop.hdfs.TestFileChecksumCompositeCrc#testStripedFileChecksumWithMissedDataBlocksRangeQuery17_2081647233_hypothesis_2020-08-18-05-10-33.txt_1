reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134017644-172.17.0.15-1597727793661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35864,DS-bb3d842c-9e66-454f-8f6e-6e51bf9796a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-5f68be1d-8485-4490-a9a9-1bed6b5f8b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-82bb576e-9e8d-4f48-adba-5ebd61ac1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-0b916225-ec52-4846-8fa3-428eb99b6812,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-b7bb03db-5b2a-4ab1-93a2-7d218beb0998,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-323372a7-6cf0-49c0-bb0a-5cac6e5a06d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-21d89612-1733-400b-9dae-8f6f9021f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-ec8726a8-5a87-4810-a1e2-edfd3fb0e48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134017644-172.17.0.15-1597727793661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35864,DS-bb3d842c-9e66-454f-8f6e-6e51bf9796a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-5f68be1d-8485-4490-a9a9-1bed6b5f8b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-82bb576e-9e8d-4f48-adba-5ebd61ac1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-0b916225-ec52-4846-8fa3-428eb99b6812,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-b7bb03db-5b2a-4ab1-93a2-7d218beb0998,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-323372a7-6cf0-49c0-bb0a-5cac6e5a06d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-21d89612-1733-400b-9dae-8f6f9021f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-ec8726a8-5a87-4810-a1e2-edfd3fb0e48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371778839-172.17.0.15-1597727836838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-5e0030e5-bdcb-4c7d-9231-ebce4c241520,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-eb0a0546-8887-4669-8e0a-9ded97f39e03,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-30922881-b3fb-48f7-81b8-4ecb2e0447d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-a43dd023-8743-47a7-b9e6-609120985029,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-8bde7e82-fa48-4ebe-a739-7186c214772c,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-5cfef31e-54ce-4d75-acf3-261721b6d583,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-3dc602d0-50f9-43dc-8fdc-ab756e1e020f,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-296a0538-2a0b-471c-b62c-8fb322a9a71b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371778839-172.17.0.15-1597727836838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43984,DS-5e0030e5-bdcb-4c7d-9231-ebce4c241520,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-eb0a0546-8887-4669-8e0a-9ded97f39e03,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-30922881-b3fb-48f7-81b8-4ecb2e0447d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-a43dd023-8743-47a7-b9e6-609120985029,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-8bde7e82-fa48-4ebe-a739-7186c214772c,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-5cfef31e-54ce-4d75-acf3-261721b6d583,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-3dc602d0-50f9-43dc-8fdc-ab756e1e020f,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-296a0538-2a0b-471c-b62c-8fb322a9a71b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386985527-172.17.0.15-1597728104855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45960,DS-4cbc47c6-f25a-44c9-a1f0-1e489ce52540,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-bc42c5fb-aaef-4ec9-8b48-fa5c2e43b1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-afabfae2-ba57-4694-a525-02aae17947dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-698b631b-e310-4364-b6e8-35acbe46547c,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-9d9b548f-cc5e-4d92-aa62-19aa0d837e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e09e0199-6715-466c-ba18-8978ff51fc86,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-a796ce88-0cf1-4a70-a65e-b1344c034b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-e848b3ac-ae69-40e6-9f9e-6ef0bc8c39ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386985527-172.17.0.15-1597728104855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45960,DS-4cbc47c6-f25a-44c9-a1f0-1e489ce52540,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-bc42c5fb-aaef-4ec9-8b48-fa5c2e43b1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-afabfae2-ba57-4694-a525-02aae17947dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-698b631b-e310-4364-b6e8-35acbe46547c,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-9d9b548f-cc5e-4d92-aa62-19aa0d837e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-e09e0199-6715-466c-ba18-8978ff51fc86,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-a796ce88-0cf1-4a70-a65e-b1344c034b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-e848b3ac-ae69-40e6-9f9e-6ef0bc8c39ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198337575-172.17.0.15-1597728471532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42052,DS-8fb1b7e1-bfec-467e-b4b6-f63778d2fc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-8cea196c-b5b6-45a0-b088-b4822294d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-ad4a392a-01dc-4383-b0d9-62bbff80a7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-d6c87fac-b096-476b-b3eb-7113c438b781,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-f873ea2b-5d6c-42ab-821d-ec70d074f194,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-99d83984-7dc0-45fb-b519-a0b98659da1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-696d7a7a-eaf2-472c-9c22-26cc49ed372e,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-881f502e-0612-45eb-bc18-c0552a6a34e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198337575-172.17.0.15-1597728471532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42052,DS-8fb1b7e1-bfec-467e-b4b6-f63778d2fc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-8cea196c-b5b6-45a0-b088-b4822294d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-ad4a392a-01dc-4383-b0d9-62bbff80a7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-d6c87fac-b096-476b-b3eb-7113c438b781,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-f873ea2b-5d6c-42ab-821d-ec70d074f194,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-99d83984-7dc0-45fb-b519-a0b98659da1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-696d7a7a-eaf2-472c-9c22-26cc49ed372e,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-881f502e-0612-45eb-bc18-c0552a6a34e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120418095-172.17.0.15-1597728513135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45705,DS-213e723f-00b9-434e-9a3f-f647066497d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-82c49c81-cd16-424d-b299-c28cbe4f7303,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-4a02d3f5-9dc6-441d-a2cf-e9152c86d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-1d469b94-87fc-490e-8ce2-3925a9b8ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-29dc3261-c83e-49f7-9fce-701d40d45daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-1f1b94f1-4240-48b6-9d89-5182ac2c3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-2c39d520-744a-4ace-8329-51f1f2d49bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-b52b1878-e07f-423f-a3ab-8683ae0e09ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120418095-172.17.0.15-1597728513135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45705,DS-213e723f-00b9-434e-9a3f-f647066497d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-82c49c81-cd16-424d-b299-c28cbe4f7303,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-4a02d3f5-9dc6-441d-a2cf-e9152c86d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-1d469b94-87fc-490e-8ce2-3925a9b8ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-29dc3261-c83e-49f7-9fce-701d40d45daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-1f1b94f1-4240-48b6-9d89-5182ac2c3a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-2c39d520-744a-4ace-8329-51f1f2d49bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-b52b1878-e07f-423f-a3ab-8683ae0e09ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505225484-172.17.0.15-1597728637455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41603,DS-32b69512-cea3-42aa-bc94-c637393481ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-0ba8eed3-a530-4cf9-9559-7d1e48197d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-5e198fb6-6135-4fec-bc2e-2fc4721967d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-b0ad341f-366c-48a9-a7c4-2cea56b54c65,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-4e16ecdf-c6fe-4134-b8c2-29b391471fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-7c83f287-5ee8-4b7d-8724-9cacf4f7daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-b90c9783-aa9a-46ee-ab8e-ac923f76d7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-580282f7-cb43-4f3f-804f-fa55788adebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505225484-172.17.0.15-1597728637455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41603,DS-32b69512-cea3-42aa-bc94-c637393481ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-0ba8eed3-a530-4cf9-9559-7d1e48197d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-5e198fb6-6135-4fec-bc2e-2fc4721967d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-b0ad341f-366c-48a9-a7c4-2cea56b54c65,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-4e16ecdf-c6fe-4134-b8c2-29b391471fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-7c83f287-5ee8-4b7d-8724-9cacf4f7daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-b90c9783-aa9a-46ee-ab8e-ac923f76d7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-580282f7-cb43-4f3f-804f-fa55788adebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459299150-172.17.0.15-1597728691304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-e692e0c7-72cc-4486-9fa2-2e2e7aba7ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-024305d8-dd42-42cc-b614-2905fa7938d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-253954b4-2fb9-4380-9a10-bfd54d365304,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-69f88c00-363e-4efe-8c6a-ab947c85b731,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-85caedd3-f175-4a2f-a3e5-0600cd3a7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-2dc23bf7-dfb4-4273-9f91-d26c99d3ccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-1f6ae7d7-441c-48df-ac3c-7f719e9d65c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-df2bcaff-bdd7-421c-b7a8-a0a1caa0a07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459299150-172.17.0.15-1597728691304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-e692e0c7-72cc-4486-9fa2-2e2e7aba7ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-024305d8-dd42-42cc-b614-2905fa7938d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-253954b4-2fb9-4380-9a10-bfd54d365304,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-69f88c00-363e-4efe-8c6a-ab947c85b731,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-85caedd3-f175-4a2f-a3e5-0600cd3a7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-2dc23bf7-dfb4-4273-9f91-d26c99d3ccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-1f6ae7d7-441c-48df-ac3c-7f719e9d65c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-df2bcaff-bdd7-421c-b7a8-a0a1caa0a07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162196435-172.17.0.15-1597729153024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37402,DS-84873f3a-1ed3-4f22-900c-36d9275f2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-3d0308d7-6076-44cc-8c6e-5d4b96dd0517,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-87a55945-ab12-430a-96f9-1f4250b3e399,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-4d40fbf2-ebba-41f1-bc64-c22d56c5f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-ec6baae8-7cc9-4b7e-a20f-bd301e2ac9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-75ac5c55-0b86-42bf-a563-ffa5c130ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-94134f63-d4c6-4f96-aaff-be9871b25ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-ab413a94-7cc6-4489-abd0-98213836da3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162196435-172.17.0.15-1597729153024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37402,DS-84873f3a-1ed3-4f22-900c-36d9275f2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-3d0308d7-6076-44cc-8c6e-5d4b96dd0517,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-87a55945-ab12-430a-96f9-1f4250b3e399,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-4d40fbf2-ebba-41f1-bc64-c22d56c5f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-ec6baae8-7cc9-4b7e-a20f-bd301e2ac9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-75ac5c55-0b86-42bf-a563-ffa5c130ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-94134f63-d4c6-4f96-aaff-be9871b25ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-ab413a94-7cc6-4489-abd0-98213836da3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110010087-172.17.0.15-1597729233476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-59328c71-3fab-4d7f-9d10-fc7a0e800d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-a7de0324-8a68-47e0-a9eb-be88fa8369d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-1a17b46a-7754-4efe-ba48-9469680bed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-f2cedc19-ec25-432f-bd17-df53a10ac552,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-a2998198-cb79-4e26-a3ac-a864d409b23f,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-2b877cf8-279f-44ef-853e-564a7bb231b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-e3b9b376-c1e4-4e7b-b8ab-e43acb01a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-48a731d3-4276-48e7-b0f4-14ec49522409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110010087-172.17.0.15-1597729233476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-59328c71-3fab-4d7f-9d10-fc7a0e800d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-a7de0324-8a68-47e0-a9eb-be88fa8369d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-1a17b46a-7754-4efe-ba48-9469680bed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-f2cedc19-ec25-432f-bd17-df53a10ac552,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-a2998198-cb79-4e26-a3ac-a864d409b23f,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-2b877cf8-279f-44ef-853e-564a7bb231b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-e3b9b376-c1e4-4e7b-b8ab-e43acb01a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-48a731d3-4276-48e7-b0f4-14ec49522409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686185011-172.17.0.15-1597729270440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39633,DS-16153cf7-5af8-451b-bd9d-837f42407201,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-5419cae9-8253-4025-b03d-b26bada297c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-e5562b04-76dd-4a88-86e1-57d21c6c71e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-75743c94-1ca4-4521-826c-ee98d3251dab,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-75962e27-1e67-45fa-a154-1fda259e1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-8785a6ef-bcae-4488-a75e-bcfd7165bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-51cbba6b-a2d6-4d59-a64d-17f89f504836,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-7ef0a4f7-3a33-4d3c-94c6-e926da2ea624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686185011-172.17.0.15-1597729270440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39633,DS-16153cf7-5af8-451b-bd9d-837f42407201,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-5419cae9-8253-4025-b03d-b26bada297c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-e5562b04-76dd-4a88-86e1-57d21c6c71e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-75743c94-1ca4-4521-826c-ee98d3251dab,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-75962e27-1e67-45fa-a154-1fda259e1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-8785a6ef-bcae-4488-a75e-bcfd7165bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-51cbba6b-a2d6-4d59-a64d-17f89f504836,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-7ef0a4f7-3a33-4d3c-94c6-e926da2ea624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898448085-172.17.0.15-1597729546595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-e0b643c1-0ffd-4e40-9dc5-0e953d7fb78d,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-3c2582a2-1ec0-4868-8d39-cebf4450cfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-a7c5ff6b-5f5b-45fe-bd90-16d224c3a274,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-16f23246-f2c2-4f5a-8dcc-09052841afff,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-f0de991b-7a15-4439-8c5f-7162f26e9950,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-b95d6937-916f-4070-8662-0b2f0aa8c3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-ac2d994d-4906-41be-a467-7c8f9ef3cb60,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-233ad343-c9f7-4f74-b9db-40846badf7bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898448085-172.17.0.15-1597729546595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-e0b643c1-0ffd-4e40-9dc5-0e953d7fb78d,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-3c2582a2-1ec0-4868-8d39-cebf4450cfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-a7c5ff6b-5f5b-45fe-bd90-16d224c3a274,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-16f23246-f2c2-4f5a-8dcc-09052841afff,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-f0de991b-7a15-4439-8c5f-7162f26e9950,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-b95d6937-916f-4070-8662-0b2f0aa8c3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-ac2d994d-4906-41be-a467-7c8f9ef3cb60,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-233ad343-c9f7-4f74-b9db-40846badf7bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700027707-172.17.0.15-1597730223204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35585,DS-1d6b5d9a-847f-4b44-872f-6d117a6f46f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-3d0c4dbc-636c-4bb8-8057-48beb70e5dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-58822aaf-6b1a-4fb4-ae45-f24e787cce88,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-ecf07ffb-3db5-4e64-9ef0-a8120c3d063c,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-789b65e8-c03a-4118-ae0a-de04224fe357,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-0d530cd1-ac79-43b5-becf-6fd33f36d562,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-70a8d2eb-3500-4ba4-a748-5e0e3283ef01,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-9fe0ab80-ecc1-42b1-9bd3-7bd8520e366a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700027707-172.17.0.15-1597730223204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35585,DS-1d6b5d9a-847f-4b44-872f-6d117a6f46f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-3d0c4dbc-636c-4bb8-8057-48beb70e5dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-58822aaf-6b1a-4fb4-ae45-f24e787cce88,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-ecf07ffb-3db5-4e64-9ef0-a8120c3d063c,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-789b65e8-c03a-4118-ae0a-de04224fe357,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-0d530cd1-ac79-43b5-becf-6fd33f36d562,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-70a8d2eb-3500-4ba4-a748-5e0e3283ef01,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-9fe0ab80-ecc1-42b1-9bd3-7bd8520e366a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822723795-172.17.0.15-1597730419729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45292,DS-2efaa8cb-0532-4f6a-b81b-b61289c3b59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-b447c3f2-0a22-48e6-a564-dfce14060038,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-1a378cb8-aa7f-4299-b888-f6fffa600010,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-44d432fb-6e03-427a-844b-504fcc0a4346,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-27d14408-95df-41c8-8a45-b16d83a903bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-b1a9e9ac-eb96-4db7-ab66-6eeae9039762,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-0a035a1a-9b1d-42f7-b70c-b75b09b9c58d,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-21c9aee7-451a-4a45-9143-a950cbfdc0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822723795-172.17.0.15-1597730419729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45292,DS-2efaa8cb-0532-4f6a-b81b-b61289c3b59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-b447c3f2-0a22-48e6-a564-dfce14060038,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-1a378cb8-aa7f-4299-b888-f6fffa600010,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-44d432fb-6e03-427a-844b-504fcc0a4346,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-27d14408-95df-41c8-8a45-b16d83a903bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-b1a9e9ac-eb96-4db7-ab66-6eeae9039762,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-0a035a1a-9b1d-42f7-b70c-b75b09b9c58d,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-21c9aee7-451a-4a45-9143-a950cbfdc0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719959524-172.17.0.15-1597730516591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-7d1cd51d-7b84-4671-ba43-921a4fb34aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-87aac7d4-78d7-4805-8cb9-838ce81760e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-4aebee4c-e8d9-4cb7-a5df-97f11406eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-f4722d1a-8bfb-402c-a924-4f149c1d743f,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-46466641-6fc5-4c8b-a9b0-036ab648ef62,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-4c93bd70-8834-4f9c-8219-91edbcdc6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-2bf0a5fb-7ddc-4f4a-9849-56d7f5c861ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-a1517910-32ed-4de1-bf0b-f0ca632e365d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719959524-172.17.0.15-1597730516591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-7d1cd51d-7b84-4671-ba43-921a4fb34aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-87aac7d4-78d7-4805-8cb9-838ce81760e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-4aebee4c-e8d9-4cb7-a5df-97f11406eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-f4722d1a-8bfb-402c-a924-4f149c1d743f,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-46466641-6fc5-4c8b-a9b0-036ab648ef62,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-4c93bd70-8834-4f9c-8219-91edbcdc6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-2bf0a5fb-7ddc-4f4a-9849-56d7f5c861ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-a1517910-32ed-4de1-bf0b-f0ca632e365d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182828176-172.17.0.15-1597730607098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34201,DS-c2098f67-68d3-43ef-b516-688399013ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-715e0e52-2ade-42d9-b2c7-1986c439f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-334576c8-8356-4547-ac12-e58b5fdfe1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-42052e9b-8a04-412a-8925-66eba310375a,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-b7cac5ad-36c9-4f1f-8475-a9b8314291b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-d863d646-79e3-4c51-bb50-18e5074b627f,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-17498913-0990-4151-87dc-b6de983fdb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-73d21e31-b023-4424-9d92-07b27c370d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182828176-172.17.0.15-1597730607098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34201,DS-c2098f67-68d3-43ef-b516-688399013ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-715e0e52-2ade-42d9-b2c7-1986c439f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-334576c8-8356-4547-ac12-e58b5fdfe1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-42052e9b-8a04-412a-8925-66eba310375a,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-b7cac5ad-36c9-4f1f-8475-a9b8314291b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-d863d646-79e3-4c51-bb50-18e5074b627f,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-17498913-0990-4151-87dc-b6de983fdb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-73d21e31-b023-4424-9d92-07b27c370d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657302011-172.17.0.15-1597731528429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35567,DS-c83753e2-8124-414e-9d16-799130d224ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-17a74c0d-8db1-45c6-959b-ceeff5687aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-1f63b7c3-9993-4201-aac6-9ca4f1ed6e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-2c3552b4-c3cc-4994-a7fb-9590ed25cbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-b04d34c1-99fc-4f09-ab89-48ffcb9cf1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-5d06f0f9-9c37-46f8-a9a1-4e5a1e97b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-c85c4537-4f97-46d2-856a-918d0a72b093,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-39340420-262b-4541-b589-da68a544fc40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657302011-172.17.0.15-1597731528429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35567,DS-c83753e2-8124-414e-9d16-799130d224ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-17a74c0d-8db1-45c6-959b-ceeff5687aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-1f63b7c3-9993-4201-aac6-9ca4f1ed6e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-2c3552b4-c3cc-4994-a7fb-9590ed25cbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-b04d34c1-99fc-4f09-ab89-48ffcb9cf1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-5d06f0f9-9c37-46f8-a9a1-4e5a1e97b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-c85c4537-4f97-46d2-856a-918d0a72b093,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-39340420-262b-4541-b589-da68a544fc40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680634847-172.17.0.15-1597731667926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-c3284657-c66a-486d-957c-dc3177361eba,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-1e7c2f7f-53b7-4484-a0b6-2cff076cd3df,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-0ad5f762-b500-4dd7-8143-55680eef0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-263e66c1-3224-4c2b-abf4-34415da70e89,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-cb37af62-17c3-428c-b25b-75758dcfdd80,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-cc180f1f-49b2-49d0-9d86-7efe151cbd81,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-ada3c6f5-1289-4d5a-9e6c-6a97d0dc017a,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-0a1283a1-497c-42ff-ba22-7e937a622617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680634847-172.17.0.15-1597731667926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-c3284657-c66a-486d-957c-dc3177361eba,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-1e7c2f7f-53b7-4484-a0b6-2cff076cd3df,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-0ad5f762-b500-4dd7-8143-55680eef0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-263e66c1-3224-4c2b-abf4-34415da70e89,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-cb37af62-17c3-428c-b25b-75758dcfdd80,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-cc180f1f-49b2-49d0-9d86-7efe151cbd81,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-ada3c6f5-1289-4d5a-9e6c-6a97d0dc017a,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-0a1283a1-497c-42ff-ba22-7e937a622617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142527759-172.17.0.15-1597731986976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37882,DS-89d63921-ee5d-4217-b6e4-3220d459e23d,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-e5692d78-c7ba-45ec-ba64-bf83d7be3f99,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-c7f22348-948a-45ea-bce8-f6eedcd22d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-969af290-c08a-4e3f-bd6a-d53e6f3143b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-53216f51-7b3c-44d1-90e7-5b8b9057e545,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-3a202fef-8490-4438-a4d0-9c0b16a4ce42,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-4960c798-afc5-4f54-a26a-53135a2a9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-f356506c-72f7-4618-8f91-76d8f95e9db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142527759-172.17.0.15-1597731986976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37882,DS-89d63921-ee5d-4217-b6e4-3220d459e23d,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-e5692d78-c7ba-45ec-ba64-bf83d7be3f99,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-c7f22348-948a-45ea-bce8-f6eedcd22d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-969af290-c08a-4e3f-bd6a-d53e6f3143b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-53216f51-7b3c-44d1-90e7-5b8b9057e545,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-3a202fef-8490-4438-a4d0-9c0b16a4ce42,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-4960c798-afc5-4f54-a26a-53135a2a9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-f356506c-72f7-4618-8f91-76d8f95e9db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325396734-172.17.0.15-1597732670778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42599,DS-9988f449-9c5e-4a9d-a039-981614c317ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-f3003389-d556-4f52-8cf2-be2bb32a7a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-81b1a9c7-c60f-4ac9-9bf2-3d9b49cf6fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-433ca912-500e-4ca9-b044-d3e1e855f42e,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-3ea258ed-981d-4ecc-8373-dba9ae490d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-38233f6e-460a-48d9-a475-a08e7377d078,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-4a24fa2a-fc88-4d13-9cd8-40e85b051905,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-8ddc9ca0-e832-43f3-aecb-ea6ad4431137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325396734-172.17.0.15-1597732670778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42599,DS-9988f449-9c5e-4a9d-a039-981614c317ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-f3003389-d556-4f52-8cf2-be2bb32a7a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-81b1a9c7-c60f-4ac9-9bf2-3d9b49cf6fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-433ca912-500e-4ca9-b044-d3e1e855f42e,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-3ea258ed-981d-4ecc-8373-dba9ae490d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-38233f6e-460a-48d9-a475-a08e7377d078,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-4a24fa2a-fc88-4d13-9cd8-40e85b051905,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-8ddc9ca0-e832-43f3-aecb-ea6ad4431137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271875009-172.17.0.15-1597732894265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-a76f24f7-2b66-45cf-ae88-5cd38e19357e,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-0fab5ec9-19ef-4a98-9a34-cbd0460a5dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-2c5a8fd0-72d5-41b2-a887-3227d85ecada,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-ddea58c3-8c7c-4f4e-8cb2-2574bc13f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-44594974-f488-4b31-b50f-4ae4a723f0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-1bd97cd3-f282-47e8-8877-de81c6d24d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-6ccf8ab0-00f3-4398-af44-c221bb46d261,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-45751418-9742-4245-8936-fba7c743468a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271875009-172.17.0.15-1597732894265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-a76f24f7-2b66-45cf-ae88-5cd38e19357e,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-0fab5ec9-19ef-4a98-9a34-cbd0460a5dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-2c5a8fd0-72d5-41b2-a887-3227d85ecada,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-ddea58c3-8c7c-4f4e-8cb2-2574bc13f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-44594974-f488-4b31-b50f-4ae4a723f0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-1bd97cd3-f282-47e8-8877-de81c6d24d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-6ccf8ab0-00f3-4398-af44-c221bb46d261,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-45751418-9742-4245-8936-fba7c743468a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336606992-172.17.0.15-1597733833759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39393,DS-20de0019-cfeb-4976-9172-070a42b62bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-0f4f1017-2df5-40d7-a9c3-2eae7aaaf289,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-a20bbedf-7cd8-4fc6-ad71-edc8a9b28ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-9e25f42e-7980-49b7-aa1e-9f1cb2cf7c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-dc861599-4f88-49d3-a626-3a653f107ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-2dc95e19-81b0-423a-abac-756c726d1863,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-9131cfcf-321c-4e9b-aa0c-07c1b44a2f64,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-96cee442-082a-44f7-911c-062790644d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336606992-172.17.0.15-1597733833759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39393,DS-20de0019-cfeb-4976-9172-070a42b62bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-0f4f1017-2df5-40d7-a9c3-2eae7aaaf289,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-a20bbedf-7cd8-4fc6-ad71-edc8a9b28ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-9e25f42e-7980-49b7-aa1e-9f1cb2cf7c08,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-dc861599-4f88-49d3-a626-3a653f107ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-2dc95e19-81b0-423a-abac-756c726d1863,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-9131cfcf-321c-4e9b-aa0c-07c1b44a2f64,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-96cee442-082a-44f7-911c-062790644d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815826486-172.17.0.15-1597734206697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-ca5e8696-95a6-4686-86ed-b9da1cf1d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-8e6f2071-70c2-4d10-832a-2849f4c9c976,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-0eb9657f-44b2-4801-8c5a-4d57b8c4aba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-788d1df0-96d0-41b6-a768-80869b533c01,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-fff38095-b274-4dc8-8531-4858c2b6944e,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-3277a64a-ac31-461f-9a56-72971ae17707,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-23ffc327-95f7-4918-b6aa-b2fd984947a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-c08face3-a11d-4335-93d3-c41d3e440680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815826486-172.17.0.15-1597734206697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-ca5e8696-95a6-4686-86ed-b9da1cf1d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-8e6f2071-70c2-4d10-832a-2849f4c9c976,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-0eb9657f-44b2-4801-8c5a-4d57b8c4aba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-788d1df0-96d0-41b6-a768-80869b533c01,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-fff38095-b274-4dc8-8531-4858c2b6944e,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-3277a64a-ac31-461f-9a56-72971ae17707,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-23ffc327-95f7-4918-b6aa-b2fd984947a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-c08face3-a11d-4335-93d3-c41d3e440680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6893
