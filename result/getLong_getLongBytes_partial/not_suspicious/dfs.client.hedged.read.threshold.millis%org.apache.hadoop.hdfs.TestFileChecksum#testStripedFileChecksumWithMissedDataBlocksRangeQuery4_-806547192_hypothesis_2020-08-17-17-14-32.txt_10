reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622892834-172.17.0.5-1597684880947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44079,DS-bd910eab-f506-485d-b9c1-6085ec2cffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-ab27f1ad-b6c2-4e2d-9425-76a00f0d46ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-07a39c58-8261-4ed3-9f66-a2a7bc6ad035,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-a18b000d-c248-4a81-af43-d51edee2d362,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-069553bb-da00-44f1-ad0b-e09f6c9b1cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-f714ce42-3710-4fed-a08a-c90315c925f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-a1a7fd58-49ae-44ad-b202-1cd92da5abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-baf07b77-65f0-44dd-a0e4-d0086cc21cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622892834-172.17.0.5-1597684880947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44079,DS-bd910eab-f506-485d-b9c1-6085ec2cffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-ab27f1ad-b6c2-4e2d-9425-76a00f0d46ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-07a39c58-8261-4ed3-9f66-a2a7bc6ad035,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-a18b000d-c248-4a81-af43-d51edee2d362,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-069553bb-da00-44f1-ad0b-e09f6c9b1cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-f714ce42-3710-4fed-a08a-c90315c925f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-a1a7fd58-49ae-44ad-b202-1cd92da5abdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-baf07b77-65f0-44dd-a0e4-d0086cc21cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732439046-172.17.0.5-1597684953836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41760,DS-c28d95e0-45b3-4218-9337-4c59e70419d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-e5a4ff59-34ff-4497-a87f-15ec59a00443,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-d6956f3a-2e46-453a-99a2-bd1b3c6c0fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-ba9b3fda-85a1-4eac-8fc5-9dfccaab9484,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-4e721c5e-7ae7-413e-83ce-85d61d1d522f,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-37023ba2-b6cd-44e4-b131-fdf029b08e05,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-22904855-6cce-4cd1-89e5-d82c66fa957e,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-fb17dd29-c6d5-493a-abf1-945847783e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732439046-172.17.0.5-1597684953836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41760,DS-c28d95e0-45b3-4218-9337-4c59e70419d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-e5a4ff59-34ff-4497-a87f-15ec59a00443,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-d6956f3a-2e46-453a-99a2-bd1b3c6c0fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-ba9b3fda-85a1-4eac-8fc5-9dfccaab9484,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-4e721c5e-7ae7-413e-83ce-85d61d1d522f,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-37023ba2-b6cd-44e4-b131-fdf029b08e05,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-22904855-6cce-4cd1-89e5-d82c66fa957e,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-fb17dd29-c6d5-493a-abf1-945847783e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184946723-172.17.0.5-1597685145027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33240,DS-7e7745a1-df34-4bd6-b144-c2c53ec41187,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-b2bf3ae4-32d9-482d-885c-a4d513e933e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-866c7eb3-0973-4fab-bb5f-beeef6d49767,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-c940f155-107a-458a-954e-8831e2a65687,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-b10279b5-1e5f-44a0-8fa0-a5298eb04ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-9f92c5f6-f92b-4745-8a67-61ed9d3404fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-b824c218-40b4-4983-859a-b4b271f0bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-21f933ec-577c-4f9a-8d38-378b401a2c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184946723-172.17.0.5-1597685145027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33240,DS-7e7745a1-df34-4bd6-b144-c2c53ec41187,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-b2bf3ae4-32d9-482d-885c-a4d513e933e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-866c7eb3-0973-4fab-bb5f-beeef6d49767,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-c940f155-107a-458a-954e-8831e2a65687,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-b10279b5-1e5f-44a0-8fa0-a5298eb04ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-9f92c5f6-f92b-4745-8a67-61ed9d3404fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-b824c218-40b4-4983-859a-b4b271f0bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-21f933ec-577c-4f9a-8d38-378b401a2c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47306022-172.17.0.5-1597686028394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-32d2a84e-2002-463b-859a-58424b52ae50,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-e6be5193-2a1a-4a3b-b510-3b02a675d880,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-283cee0d-ec4e-421b-a8c9-471893777a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-86889b9b-1f3f-473d-bed3-0c37f6551dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-51c48329-0cee-4edd-b943-48b3a551dd75,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-7d4b8e5d-8abd-44cf-87a5-e5b8f1e0eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-0758d9fa-36ee-46cf-91af-bbb16248c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-06463c74-da51-4b77-a9df-cfd6909bf6e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47306022-172.17.0.5-1597686028394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-32d2a84e-2002-463b-859a-58424b52ae50,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-e6be5193-2a1a-4a3b-b510-3b02a675d880,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-283cee0d-ec4e-421b-a8c9-471893777a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-86889b9b-1f3f-473d-bed3-0c37f6551dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-51c48329-0cee-4edd-b943-48b3a551dd75,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-7d4b8e5d-8abd-44cf-87a5-e5b8f1e0eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-0758d9fa-36ee-46cf-91af-bbb16248c2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-06463c74-da51-4b77-a9df-cfd6909bf6e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812358115-172.17.0.5-1597686376889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40802,DS-9830ca91-bf35-48ad-8750-b15a92713740,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-c9597933-6157-4f3a-921e-d7b967f8a583,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-3a2c49c9-9be6-4a08-9f60-d9911c277a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-5296ec80-8b9d-4b01-9ee7-edffd9ed2f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-20116580-69fd-4588-9777-5ee4edd84e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-c0b5acaa-49e2-4c1b-b7d7-85a9ea2d8a30,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-d33a8011-44f8-4ebf-af62-fe06efe042b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-a76660a2-4a40-4a19-a803-a4e555c7acfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812358115-172.17.0.5-1597686376889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40802,DS-9830ca91-bf35-48ad-8750-b15a92713740,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-c9597933-6157-4f3a-921e-d7b967f8a583,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-3a2c49c9-9be6-4a08-9f60-d9911c277a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-5296ec80-8b9d-4b01-9ee7-edffd9ed2f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-20116580-69fd-4588-9777-5ee4edd84e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-c0b5acaa-49e2-4c1b-b7d7-85a9ea2d8a30,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-d33a8011-44f8-4ebf-af62-fe06efe042b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-a76660a2-4a40-4a19-a803-a4e555c7acfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459891913-172.17.0.5-1597686793756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36274,DS-e3958444-6a3a-45ae-814f-f32fbd3c205a,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-a60076a9-37a2-4495-a627-ccff6aaef3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-5cb38d31-0a03-4f40-b28b-abe501f66e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-476b6189-9d65-49d1-9a92-0fa44a383625,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-7edb18f7-7b7f-434c-afa2-c90a375d3b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-b0e9323d-8abf-4566-9bb3-53f010091010,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-6b0519b5-12e0-404c-9b6a-c7ab16d53d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-4c34b41a-7d3a-4963-bd97-d8b1ff99d509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459891913-172.17.0.5-1597686793756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36274,DS-e3958444-6a3a-45ae-814f-f32fbd3c205a,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-a60076a9-37a2-4495-a627-ccff6aaef3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-5cb38d31-0a03-4f40-b28b-abe501f66e23,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-476b6189-9d65-49d1-9a92-0fa44a383625,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-7edb18f7-7b7f-434c-afa2-c90a375d3b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-b0e9323d-8abf-4566-9bb3-53f010091010,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-6b0519b5-12e0-404c-9b6a-c7ab16d53d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-4c34b41a-7d3a-4963-bd97-d8b1ff99d509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844056686-172.17.0.5-1597686864484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46865,DS-e0b31785-93b8-4c48-8cc7-4be06cd79da0,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-16b4c76d-b884-4d53-816b-dc3f440cc1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-f7b44396-53bf-41c6-97f8-06b48e14808f,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-f8215153-184a-495a-a222-1233f783764a,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-1a53e6be-20d4-49c1-ba22-c08d68b37641,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-ecfb39f2-140d-497f-b812-58e360a7f107,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-8d0e2871-c774-4b79-8659-21fe77b8b1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-a2d09c84-3d84-4c2a-be25-c4ce3646aae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844056686-172.17.0.5-1597686864484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46865,DS-e0b31785-93b8-4c48-8cc7-4be06cd79da0,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-16b4c76d-b884-4d53-816b-dc3f440cc1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-f7b44396-53bf-41c6-97f8-06b48e14808f,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-f8215153-184a-495a-a222-1233f783764a,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-1a53e6be-20d4-49c1-ba22-c08d68b37641,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-ecfb39f2-140d-497f-b812-58e360a7f107,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-8d0e2871-c774-4b79-8659-21fe77b8b1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-a2d09c84-3d84-4c2a-be25-c4ce3646aae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752371440-172.17.0.5-1597687684847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-e88ee259-e6b3-43ec-ac40-bee9b2694d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-bc0c3e8e-1be7-4aac-9139-c8d416727a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-ec8803f2-a541-4d96-a710-ca6c3833e573,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-ce718b68-bf90-43ed-9acf-8e11d9d120c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-6aaeecfe-c006-4222-88e8-907471409c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-c9e14bc6-8011-4112-b792-f8dcdf697481,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-aef56507-51d2-47e0-8b8c-b68f1397afb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-79ee91a4-cb73-419c-878d-0373930a161b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752371440-172.17.0.5-1597687684847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-e88ee259-e6b3-43ec-ac40-bee9b2694d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-bc0c3e8e-1be7-4aac-9139-c8d416727a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-ec8803f2-a541-4d96-a710-ca6c3833e573,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-ce718b68-bf90-43ed-9acf-8e11d9d120c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-6aaeecfe-c006-4222-88e8-907471409c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-c9e14bc6-8011-4112-b792-f8dcdf697481,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-aef56507-51d2-47e0-8b8c-b68f1397afb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-79ee91a4-cb73-419c-878d-0373930a161b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011686333-172.17.0.5-1597687806647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-50f1360f-efe5-4250-aec3-b300edc0258f,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-b3858d5a-1429-4acf-8e66-ffdd3f44596f,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-9fafee12-5735-4897-ba08-6a2a150b2525,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-66000917-1f97-43db-b330-6299a7f9d485,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-4bd99712-de7c-4a1d-aecb-83a20aeb8e43,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-eb47aa3b-186d-486e-ab7e-6fd41ead8e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-0b729f5a-a442-4b8b-aa7a-faf2ef4811ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-f7b052f8-32fa-4d4d-b541-2b17f061d03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011686333-172.17.0.5-1597687806647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-50f1360f-efe5-4250-aec3-b300edc0258f,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-b3858d5a-1429-4acf-8e66-ffdd3f44596f,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-9fafee12-5735-4897-ba08-6a2a150b2525,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-66000917-1f97-43db-b330-6299a7f9d485,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-4bd99712-de7c-4a1d-aecb-83a20aeb8e43,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-eb47aa3b-186d-486e-ab7e-6fd41ead8e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-0b729f5a-a442-4b8b-aa7a-faf2ef4811ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-f7b052f8-32fa-4d4d-b541-2b17f061d03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53265742-172.17.0.5-1597687882261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37259,DS-a5f93943-91d7-4c4a-a660-04c936078729,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-50a26564-6324-47d1-b52d-12200da5d296,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-16f5271d-809f-4285-a0dc-137ac3f4b7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-07cd711b-2dcc-46cb-846f-881bc502f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-5d13b26a-42ad-4f59-abb2-01c95fb47aff,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-f72aa4bc-716a-459f-b476-623b83db0b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-817a7d5f-e168-4630-a7b4-db0528b50827,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-292d23cb-1007-442a-8b5a-0c49cfe7662c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53265742-172.17.0.5-1597687882261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37259,DS-a5f93943-91d7-4c4a-a660-04c936078729,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-50a26564-6324-47d1-b52d-12200da5d296,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-16f5271d-809f-4285-a0dc-137ac3f4b7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-07cd711b-2dcc-46cb-846f-881bc502f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-5d13b26a-42ad-4f59-abb2-01c95fb47aff,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-f72aa4bc-716a-459f-b476-623b83db0b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-817a7d5f-e168-4630-a7b4-db0528b50827,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-292d23cb-1007-442a-8b5a-0c49cfe7662c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542177162-172.17.0.5-1597688165656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36721,DS-53c75fc0-78e7-4ea1-88fb-8f84a8cc012c,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-7c857550-6580-4ce5-9b0a-de5961cf24d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-9ebb558a-24fb-46ab-bc95-4f171e18982d,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-6b5989ec-433a-4cf3-aef1-acdd61ba5dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-7af6e662-3f75-4ee0-a67a-2fb1ddea9e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-111587b0-a958-4462-99b0-f39bf3c37d41,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-ab6b3596-5bf6-4177-8ad4-9e49fc69acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-c7c529ed-3a19-446c-81c3-bd96c778cc80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542177162-172.17.0.5-1597688165656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36721,DS-53c75fc0-78e7-4ea1-88fb-8f84a8cc012c,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-7c857550-6580-4ce5-9b0a-de5961cf24d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-9ebb558a-24fb-46ab-bc95-4f171e18982d,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-6b5989ec-433a-4cf3-aef1-acdd61ba5dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-7af6e662-3f75-4ee0-a67a-2fb1ddea9e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-111587b0-a958-4462-99b0-f39bf3c37d41,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-ab6b3596-5bf6-4177-8ad4-9e49fc69acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-c7c529ed-3a19-446c-81c3-bd96c778cc80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647689863-172.17.0.5-1597688364661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45217,DS-eaf4e40e-4b48-4460-862e-8b61fa11face,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-d119fb5d-6d13-4727-9d9d-76b87bf94264,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-f0e764ff-849e-4a82-8cfb-c16e09fb33b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-8f61f1d7-9612-4c05-bcb1-0e4fae5f88df,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-bc2b1f90-b6f7-45d6-a568-b04749783642,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-9c257788-7204-480f-92f2-ffabd739f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-e86ee2cd-fb5f-45cc-aa60-a49a248b2ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-2675e979-b972-4e2e-83ea-bc370c039f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647689863-172.17.0.5-1597688364661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45217,DS-eaf4e40e-4b48-4460-862e-8b61fa11face,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-d119fb5d-6d13-4727-9d9d-76b87bf94264,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-f0e764ff-849e-4a82-8cfb-c16e09fb33b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-8f61f1d7-9612-4c05-bcb1-0e4fae5f88df,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-bc2b1f90-b6f7-45d6-a568-b04749783642,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-9c257788-7204-480f-92f2-ffabd739f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-e86ee2cd-fb5f-45cc-aa60-a49a248b2ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-2675e979-b972-4e2e-83ea-bc370c039f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978937992-172.17.0.5-1597688556477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-58778647-72e9-4526-afd6-6c05692a18b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-52226635-f730-4030-80a0-c4673ff64004,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-67051ed8-134b-42ec-a546-6d597caefa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-3c54a262-6878-4ae4-a1af-d3527ae76483,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-94ca7bb9-3b74-485d-a9f8-a2d3da56ce2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-a612ec71-180b-4679-b1b6-56f209665ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-0a6bea22-465f-4032-9129-f10248553e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-eaf02d49-bef4-4956-ba94-545c4b174879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978937992-172.17.0.5-1597688556477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-58778647-72e9-4526-afd6-6c05692a18b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-52226635-f730-4030-80a0-c4673ff64004,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-67051ed8-134b-42ec-a546-6d597caefa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-3c54a262-6878-4ae4-a1af-d3527ae76483,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-94ca7bb9-3b74-485d-a9f8-a2d3da56ce2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-a612ec71-180b-4679-b1b6-56f209665ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-0a6bea22-465f-4032-9129-f10248553e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-eaf02d49-bef4-4956-ba94-545c4b174879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337323786-172.17.0.5-1597689348586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-c3938a6a-8821-4e79-b06d-63a332f215e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-4cb3935c-6217-417f-9f06-ea93ea129347,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-78d99600-63a1-4831-b7ab-4a8dd97181dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-136c7f81-de98-42ed-976c-9d2804bb2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-18139911-96c6-417f-8f74-ad42f7e4571a,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-5840f97a-b6c3-4db2-9466-106fb5b3b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-f18be855-ce09-43ef-a11b-66a96067dd98,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-ca69d0cb-9437-49f1-890a-2acd88185f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337323786-172.17.0.5-1597689348586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-c3938a6a-8821-4e79-b06d-63a332f215e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-4cb3935c-6217-417f-9f06-ea93ea129347,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-78d99600-63a1-4831-b7ab-4a8dd97181dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-136c7f81-de98-42ed-976c-9d2804bb2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-18139911-96c6-417f-8f74-ad42f7e4571a,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-5840f97a-b6c3-4db2-9466-106fb5b3b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-f18be855-ce09-43ef-a11b-66a96067dd98,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-ca69d0cb-9437-49f1-890a-2acd88185f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026228323-172.17.0.5-1597689467791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-4754c525-5e4b-4c25-b637-7f5ea053c4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-a355df7c-d052-43b1-95d9-31ca69e8c87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-37d4e3a5-d19f-42d1-aa44-8b96e91e7161,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-5f300de0-f375-4291-88ee-456f091d1d12,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-adb4b749-8457-4361-ac4e-46d755fa9da6,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-f14aec50-5b83-4ce7-9e55-64e7d3a813e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-bc5a99bc-06f8-4623-8964-14f6825a1a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-18c77906-270d-4e38-864d-2a49bbd9fb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026228323-172.17.0.5-1597689467791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-4754c525-5e4b-4c25-b637-7f5ea053c4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-a355df7c-d052-43b1-95d9-31ca69e8c87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-37d4e3a5-d19f-42d1-aa44-8b96e91e7161,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-5f300de0-f375-4291-88ee-456f091d1d12,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-adb4b749-8457-4361-ac4e-46d755fa9da6,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-f14aec50-5b83-4ce7-9e55-64e7d3a813e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-bc5a99bc-06f8-4623-8964-14f6825a1a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-18c77906-270d-4e38-864d-2a49bbd9fb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68031440-172.17.0.5-1597689502162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36109,DS-c3d79e93-c3f6-4df4-b81c-6c12d471ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-f6daba76-7c53-48b3-a890-388da4bfbd09,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-cf0b8af2-2252-4219-bf8e-99d30bf9424e,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-e61919ea-87d8-4673-be2c-1add09cf31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-c81d7de1-ca03-49c1-a203-6241bc48d31b,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-c2fc7879-7666-4560-b92c-8bc99e104309,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-0c9f0d3d-9646-4029-b3d0-c391c89ae35a,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-4aeffb95-b2a9-4d80-88a7-07d1b6f55308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68031440-172.17.0.5-1597689502162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36109,DS-c3d79e93-c3f6-4df4-b81c-6c12d471ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-f6daba76-7c53-48b3-a890-388da4bfbd09,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-cf0b8af2-2252-4219-bf8e-99d30bf9424e,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-e61919ea-87d8-4673-be2c-1add09cf31ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-c81d7de1-ca03-49c1-a203-6241bc48d31b,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-c2fc7879-7666-4560-b92c-8bc99e104309,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-0c9f0d3d-9646-4029-b3d0-c391c89ae35a,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-4aeffb95-b2a9-4d80-88a7-07d1b6f55308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807035080-172.17.0.5-1597689856138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41907,DS-aadc85a1-3fa9-466f-8fdb-6f95da58e749,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-1ef0d31c-e49d-4d98-9d17-138c83041a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-65672ee5-f626-4e6f-80cd-fc7bedc8c275,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-412278d5-8add-4f88-a03c-3a6788424c76,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-1298bf1c-9e50-40ad-b35c-fed6c1ab579e,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-5b602ee8-ee09-49de-98ba-872519b8af06,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-29ed4409-a5f5-43c4-8bd7-2d10704ae698,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-cd6aa716-1965-4516-b18a-e09d0cfcecab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807035080-172.17.0.5-1597689856138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41907,DS-aadc85a1-3fa9-466f-8fdb-6f95da58e749,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-1ef0d31c-e49d-4d98-9d17-138c83041a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-65672ee5-f626-4e6f-80cd-fc7bedc8c275,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-412278d5-8add-4f88-a03c-3a6788424c76,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-1298bf1c-9e50-40ad-b35c-fed6c1ab579e,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-5b602ee8-ee09-49de-98ba-872519b8af06,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-29ed4409-a5f5-43c4-8bd7-2d10704ae698,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-cd6aa716-1965-4516-b18a-e09d0cfcecab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5730
