reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524674451-172.17.0.8-1597715270778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-44e927b0-a37b-483e-9d24-add2e547a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-e55157ef-5043-4555-b6c4-c9b6ffb27528,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-201bcce3-bb9d-427e-b421-af9e9e461ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-dba176df-50fc-496c-905e-beee2124ef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-70af8543-e2ed-4e00-b725-00c4e8e66d62,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-c6ddd929-78f8-44e7-ba94-9dce11147cec,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-2460450f-4758-42e9-b198-752b6285aba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-d1c09386-b93f-4266-8231-e9092f71e791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524674451-172.17.0.8-1597715270778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-44e927b0-a37b-483e-9d24-add2e547a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-e55157ef-5043-4555-b6c4-c9b6ffb27528,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-201bcce3-bb9d-427e-b421-af9e9e461ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-dba176df-50fc-496c-905e-beee2124ef5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-70af8543-e2ed-4e00-b725-00c4e8e66d62,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-c6ddd929-78f8-44e7-ba94-9dce11147cec,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-2460450f-4758-42e9-b198-752b6285aba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-d1c09386-b93f-4266-8231-e9092f71e791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344160929-172.17.0.8-1597715860477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35699,DS-9e90d729-950f-4be7-b17c-c2250c9de935,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-fbf66aed-ea8b-4138-b216-8539e6fe1e23,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-e70f5b16-0824-471c-84b0-573a11888349,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-9cd763dd-e916-4bd4-80d2-5243eaf67ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-a6c3cef8-a4cc-4c76-8819-91a3589d3f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-ae0e4f1e-3da5-4507-9a4f-f579136558df,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-cb45e506-ff1a-41b5-8a1d-116b6138ee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-b340cf39-e2b5-4032-835b-31ff9b305a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344160929-172.17.0.8-1597715860477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35699,DS-9e90d729-950f-4be7-b17c-c2250c9de935,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-fbf66aed-ea8b-4138-b216-8539e6fe1e23,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-e70f5b16-0824-471c-84b0-573a11888349,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-9cd763dd-e916-4bd4-80d2-5243eaf67ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-a6c3cef8-a4cc-4c76-8819-91a3589d3f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-ae0e4f1e-3da5-4507-9a4f-f579136558df,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-cb45e506-ff1a-41b5-8a1d-116b6138ee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-b340cf39-e2b5-4032-835b-31ff9b305a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986504523-172.17.0.8-1597716186221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39268,DS-ed39f0f4-12d9-409d-a7f0-07fc36903fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-aef84b4a-f210-4512-b1d5-09a0234b674d,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-5fe31236-f161-4dcb-83ed-b0d4ea91a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-6309f738-6224-4b88-b6c2-f0548ccfdc11,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-cf141ef7-8c96-4314-bf6e-3a8630b0cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-92ea5cf9-17e8-4745-95bd-7e2a31b1a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-ed919c9f-2034-422d-a6c4-d99f591ac9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-2a570528-15dd-4baf-b253-f6ef01d67783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986504523-172.17.0.8-1597716186221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39268,DS-ed39f0f4-12d9-409d-a7f0-07fc36903fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-aef84b4a-f210-4512-b1d5-09a0234b674d,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-5fe31236-f161-4dcb-83ed-b0d4ea91a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-6309f738-6224-4b88-b6c2-f0548ccfdc11,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-cf141ef7-8c96-4314-bf6e-3a8630b0cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-92ea5cf9-17e8-4745-95bd-7e2a31b1a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-ed919c9f-2034-422d-a6c4-d99f591ac9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-2a570528-15dd-4baf-b253-f6ef01d67783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10851516-172.17.0.8-1597716370131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-8f735457-2519-4c90-bad9-42e17aaa8959,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-a2c5027e-eeb3-413f-b86a-4cdc66aa7054,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-7e9a768c-ca41-47cb-a7e1-622f7be5e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-9e445e1f-5a02-47d5-b554-5451ca43189f,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-23cf1a42-07d7-4274-ab11-7446ab27c3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-bcf45d9b-0493-4cd8-9533-6e536100b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-e9f354d8-6c2d-4324-8792-673255e0f6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-75775b5c-8548-40e2-8922-de272d1bf9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10851516-172.17.0.8-1597716370131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-8f735457-2519-4c90-bad9-42e17aaa8959,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-a2c5027e-eeb3-413f-b86a-4cdc66aa7054,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-7e9a768c-ca41-47cb-a7e1-622f7be5e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-9e445e1f-5a02-47d5-b554-5451ca43189f,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-23cf1a42-07d7-4274-ab11-7446ab27c3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-bcf45d9b-0493-4cd8-9533-6e536100b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-e9f354d8-6c2d-4324-8792-673255e0f6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-75775b5c-8548-40e2-8922-de272d1bf9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614902918-172.17.0.8-1597716437365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35348,DS-dfbd8ff5-26c5-4490-8b34-f8f9bb15ac36,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-e3eefc62-6e94-4c62-8be4-d509a7c9f452,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-92561a71-b3f5-462c-bc9e-9e22ca587ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-046c244c-4be3-43ae-a2ba-0ca64ca918b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-9bc9850a-a4b0-4034-a616-d7816192927e,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d8af3d64-5a56-4835-b22d-76af3794a56b,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-f7e5c3e6-5ed5-49d9-8b08-5615efbe1d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-136d9ea8-9651-4c2d-89b1-f6e64d40e3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614902918-172.17.0.8-1597716437365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35348,DS-dfbd8ff5-26c5-4490-8b34-f8f9bb15ac36,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-e3eefc62-6e94-4c62-8be4-d509a7c9f452,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-92561a71-b3f5-462c-bc9e-9e22ca587ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-046c244c-4be3-43ae-a2ba-0ca64ca918b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-9bc9850a-a4b0-4034-a616-d7816192927e,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d8af3d64-5a56-4835-b22d-76af3794a56b,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-f7e5c3e6-5ed5-49d9-8b08-5615efbe1d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-136d9ea8-9651-4c2d-89b1-f6e64d40e3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315824156-172.17.0.8-1597716522636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-70ffc65d-4986-4303-9f46-f46c51e52355,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-9a03a6dc-2f14-44cc-8229-9a24e9c0199a,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-40faf1f6-d276-4a60-9d1c-848dd760a79d,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-5d38138b-8d1f-48c9-b1e9-d550f691573e,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-bf60b958-7003-46de-8e37-0bd95dd96005,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-7e488588-1291-499f-bce2-77ae797437fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-67ac4ac5-9aa0-4fac-ad36-2157e9a78484,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-2b2c3dfb-93a3-441d-82a6-7dca1bd22ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315824156-172.17.0.8-1597716522636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-70ffc65d-4986-4303-9f46-f46c51e52355,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-9a03a6dc-2f14-44cc-8229-9a24e9c0199a,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-40faf1f6-d276-4a60-9d1c-848dd760a79d,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-5d38138b-8d1f-48c9-b1e9-d550f691573e,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-bf60b958-7003-46de-8e37-0bd95dd96005,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-7e488588-1291-499f-bce2-77ae797437fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-67ac4ac5-9aa0-4fac-ad36-2157e9a78484,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-2b2c3dfb-93a3-441d-82a6-7dca1bd22ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978517306-172.17.0.8-1597716624967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41243,DS-be6342c5-7a96-4a66-a972-0b001f33a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-3cd7079a-c83d-436f-8d73-710b8aba4128,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-04b53582-e6bd-42ae-9e25-2968aa7974fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-bd041dc4-b8d9-44f9-a8ee-0117fe8fd786,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-202c07a7-20ef-4966-880c-6f16632402dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-9ec00832-59e3-4e7e-af5c-b169c3ecc6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-a153d9d7-d7f4-437a-b772-82b1827b4b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-7e3c0671-ae6c-44c8-a969-e62856336594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978517306-172.17.0.8-1597716624967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41243,DS-be6342c5-7a96-4a66-a972-0b001f33a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-3cd7079a-c83d-436f-8d73-710b8aba4128,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-04b53582-e6bd-42ae-9e25-2968aa7974fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-bd041dc4-b8d9-44f9-a8ee-0117fe8fd786,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-202c07a7-20ef-4966-880c-6f16632402dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-9ec00832-59e3-4e7e-af5c-b169c3ecc6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-a153d9d7-d7f4-437a-b772-82b1827b4b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-7e3c0671-ae6c-44c8-a969-e62856336594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167696811-172.17.0.8-1597716699321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-6271a51a-894c-499b-bcdd-078bad9ab297,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ebe0005b-dff5-4a73-8e67-588445ca6019,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-d9dc4481-c577-4089-9fd8-348d9f961ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-b5319156-aac1-4195-bb54-d11198cf9400,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-60d4a44f-9003-4149-a61b-ffde44addf01,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-36cc25cc-5b4e-4f64-8049-c9dbaaec73cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-13dad85e-25ff-479c-a07a-1dd7221bfb54,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-fed03b29-ba8d-491c-a31c-f43e497e5097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167696811-172.17.0.8-1597716699321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-6271a51a-894c-499b-bcdd-078bad9ab297,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ebe0005b-dff5-4a73-8e67-588445ca6019,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-d9dc4481-c577-4089-9fd8-348d9f961ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-b5319156-aac1-4195-bb54-d11198cf9400,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-60d4a44f-9003-4149-a61b-ffde44addf01,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-36cc25cc-5b4e-4f64-8049-c9dbaaec73cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-13dad85e-25ff-479c-a07a-1dd7221bfb54,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-fed03b29-ba8d-491c-a31c-f43e497e5097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49627022-172.17.0.8-1597716948901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37556,DS-d61cdcbb-a087-4696-9dd0-f5d0998ab45e,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-316db40a-623c-4ee6-81cc-bc87ed087e98,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-d8e110c1-69ca-4ed8-b2ee-fd8aed120f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-5bf2e196-0d94-4c1e-997a-d594ec39900b,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-7d7c76b3-57e9-45f9-8f89-d680227670ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-c75c2a81-af94-4fd2-a45c-761a2c3423ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-12f2bd71-0744-4972-9a9e-af089c7ce6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-5d19b6fa-1ab6-45f0-ace1-2627472d7bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49627022-172.17.0.8-1597716948901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37556,DS-d61cdcbb-a087-4696-9dd0-f5d0998ab45e,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-316db40a-623c-4ee6-81cc-bc87ed087e98,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-d8e110c1-69ca-4ed8-b2ee-fd8aed120f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-5bf2e196-0d94-4c1e-997a-d594ec39900b,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-7d7c76b3-57e9-45f9-8f89-d680227670ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-c75c2a81-af94-4fd2-a45c-761a2c3423ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-12f2bd71-0744-4972-9a9e-af089c7ce6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-5d19b6fa-1ab6-45f0-ace1-2627472d7bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63936013-172.17.0.8-1597717089599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41033,DS-bbcc40cc-6d21-4a46-aa98-e4655a5d6f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-e9f90701-5840-44d2-bcdc-0aef68aff66e,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-65e236ac-4cc3-4354-892d-195428822fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-6ee6a0c4-6358-4057-8737-e2987cc212cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-6e46bee6-6955-41d6-a43b-c7a473617835,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-409d8f05-01c0-4994-8515-48623c54c848,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-ef727eca-55a8-4648-b4ab-47aff08a7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-9951bd5b-bbfc-495a-af24-2455c9947263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63936013-172.17.0.8-1597717089599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41033,DS-bbcc40cc-6d21-4a46-aa98-e4655a5d6f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-e9f90701-5840-44d2-bcdc-0aef68aff66e,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-65e236ac-4cc3-4354-892d-195428822fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-6ee6a0c4-6358-4057-8737-e2987cc212cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-6e46bee6-6955-41d6-a43b-c7a473617835,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-409d8f05-01c0-4994-8515-48623c54c848,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-ef727eca-55a8-4648-b4ab-47aff08a7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-9951bd5b-bbfc-495a-af24-2455c9947263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695952809-172.17.0.8-1597717479777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-6db384a6-768a-47eb-971e-ed7388866db0,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-4fa22938-3952-4f14-a571-41e2405ecf47,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-44773faf-50d5-4dfc-aa83-bce95e4fe4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-4d8277e4-7ef3-4bad-8ca8-d07b606a46e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-cb6ba7dd-6fc8-40f9-8bc8-693da9d747c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-bbef49ab-38c6-432f-a73e-e1e75d591134,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-b4e7bc58-43b4-46a9-9875-9ab135620ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-6cd9d5f2-9468-4d2d-8b5a-e49387faf14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695952809-172.17.0.8-1597717479777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-6db384a6-768a-47eb-971e-ed7388866db0,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-4fa22938-3952-4f14-a571-41e2405ecf47,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-44773faf-50d5-4dfc-aa83-bce95e4fe4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-4d8277e4-7ef3-4bad-8ca8-d07b606a46e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-cb6ba7dd-6fc8-40f9-8bc8-693da9d747c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-bbef49ab-38c6-432f-a73e-e1e75d591134,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-b4e7bc58-43b4-46a9-9875-9ab135620ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-6cd9d5f2-9468-4d2d-8b5a-e49387faf14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899785616-172.17.0.8-1597718204489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36046,DS-aa119a51-0337-4f8a-9783-f9e4d75f4c14,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-3298ef6a-a779-4201-afaa-bbd96ebea997,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-170d4889-d999-49e1-a796-ce4bd56c1560,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-48f6381c-6e0b-4c89-b2de-48032c81bfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-279672ad-3e84-4ea7-8299-ca25a585c369,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-78db8c29-5b13-4be4-b74a-4dd000a5f95b,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-88f9c86d-cb17-4c26-9859-c9e3d960d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-9886f5f8-fe08-4818-8af0-aee66fa284ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899785616-172.17.0.8-1597718204489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36046,DS-aa119a51-0337-4f8a-9783-f9e4d75f4c14,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-3298ef6a-a779-4201-afaa-bbd96ebea997,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-170d4889-d999-49e1-a796-ce4bd56c1560,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-48f6381c-6e0b-4c89-b2de-48032c81bfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-279672ad-3e84-4ea7-8299-ca25a585c369,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-78db8c29-5b13-4be4-b74a-4dd000a5f95b,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-88f9c86d-cb17-4c26-9859-c9e3d960d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-9886f5f8-fe08-4818-8af0-aee66fa284ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019887838-172.17.0.8-1597718286319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40962,DS-7bf04c41-b9c0-4ba7-b68a-0e77d66f6cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-61951849-65da-46a9-824f-13173b3d2db2,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-4ae3b92f-80a3-4a0f-93a4-8a96b6cbfe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-bf1075e1-df48-42b8-8164-e9d01bd63661,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-77cab1d7-68d0-432e-b114-425ffdefd0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-61c6cd5d-3d48-49bc-a06b-efaf9e6b5ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-998e132f-c2d8-46a9-abab-c4beb2ec95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-ae4cd045-8ce7-45d0-9d16-ecda2c04233c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019887838-172.17.0.8-1597718286319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40962,DS-7bf04c41-b9c0-4ba7-b68a-0e77d66f6cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-61951849-65da-46a9-824f-13173b3d2db2,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-4ae3b92f-80a3-4a0f-93a4-8a96b6cbfe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-bf1075e1-df48-42b8-8164-e9d01bd63661,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-77cab1d7-68d0-432e-b114-425ffdefd0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-61c6cd5d-3d48-49bc-a06b-efaf9e6b5ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-998e132f-c2d8-46a9-abab-c4beb2ec95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-ae4cd045-8ce7-45d0-9d16-ecda2c04233c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483380430-172.17.0.8-1597718362022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33387,DS-fcf51179-5cd9-40e0-b27b-5c32e437a855,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-e3a6b21d-8d7e-48f1-b458-8c0bf477aabe,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-d274758a-ce2b-444b-ad42-dc5dcba102ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-387decc1-3396-48be-b237-6baf92446762,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-ec954209-f7a8-4559-9cd3-86299131c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-23f08b29-e188-48fe-af68-56c0e32214cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b6b7ac91-4195-4daa-b8d0-d0a3871781c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-8c2461bc-ad4c-4508-88c4-e6186667eb55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483380430-172.17.0.8-1597718362022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33387,DS-fcf51179-5cd9-40e0-b27b-5c32e437a855,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-e3a6b21d-8d7e-48f1-b458-8c0bf477aabe,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-d274758a-ce2b-444b-ad42-dc5dcba102ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-387decc1-3396-48be-b237-6baf92446762,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-ec954209-f7a8-4559-9cd3-86299131c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-23f08b29-e188-48fe-af68-56c0e32214cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b6b7ac91-4195-4daa-b8d0-d0a3871781c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-8c2461bc-ad4c-4508-88c4-e6186667eb55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169016167-172.17.0.8-1597718826055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-ee1e9e76-73a0-4861-adba-fb4f5d80b536,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-276b8ac3-57d3-4630-8349-441f01aca7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-fe80d059-38e8-45a9-86e2-bef79c37de40,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-6eedf0c1-6571-46eb-adaa-66a01367d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-c94a72d9-32aa-4b5d-aabe-dc3ea586821c,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-1378b360-384e-44d3-af2e-4838314f4f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-46734b0e-b625-4d3a-be01-11ea43a749fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-d596a134-6964-4652-aca5-abcdac33f760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169016167-172.17.0.8-1597718826055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-ee1e9e76-73a0-4861-adba-fb4f5d80b536,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-276b8ac3-57d3-4630-8349-441f01aca7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-fe80d059-38e8-45a9-86e2-bef79c37de40,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-6eedf0c1-6571-46eb-adaa-66a01367d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-c94a72d9-32aa-4b5d-aabe-dc3ea586821c,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-1378b360-384e-44d3-af2e-4838314f4f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-46734b0e-b625-4d3a-be01-11ea43a749fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-d596a134-6964-4652-aca5-abcdac33f760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82702902-172.17.0.8-1597718949102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38426,DS-70030117-d759-434a-85bd-1bb2d00bc880,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-f8effaa9-8a25-4a63-92d5-3e62c5e62d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-3e453cf8-5ee6-4876-ae65-3e060c162906,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-f322e243-eb78-434b-a8e4-2d53d2374b00,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-b11032ca-d4cd-4cc4-bd02-7e67d333392b,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-ed425bea-b142-41db-8baa-c2f070fdbf62,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-ae05ae2c-ac90-4e01-9288-11089fa392ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-9bff8fe4-bde6-4c62-93bd-97e738fa4dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82702902-172.17.0.8-1597718949102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38426,DS-70030117-d759-434a-85bd-1bb2d00bc880,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-f8effaa9-8a25-4a63-92d5-3e62c5e62d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-3e453cf8-5ee6-4876-ae65-3e060c162906,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-f322e243-eb78-434b-a8e4-2d53d2374b00,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-b11032ca-d4cd-4cc4-bd02-7e67d333392b,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-ed425bea-b142-41db-8baa-c2f070fdbf62,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-ae05ae2c-ac90-4e01-9288-11089fa392ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-9bff8fe4-bde6-4c62-93bd-97e738fa4dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860853646-172.17.0.8-1597719670429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-e6a5cc24-66fb-4210-9f94-816666a0cd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-66401344-639f-4e28-8a20-ff4bc910c565,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-11625787-9909-4885-8535-5cca98204dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-83dc9b6d-192a-4d96-b928-9ef4e7d6b20c,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-c9be01a5-b05f-45c8-8c5a-cbd57c9abc72,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-9646936e-dc5d-46b4-9722-b949811b8b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-e15c422e-4eef-4eaf-ad96-46a039c53c55,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-cd54962f-20d0-4884-814e-61ba4f835289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860853646-172.17.0.8-1597719670429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-e6a5cc24-66fb-4210-9f94-816666a0cd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-66401344-639f-4e28-8a20-ff4bc910c565,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-11625787-9909-4885-8535-5cca98204dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-83dc9b6d-192a-4d96-b928-9ef4e7d6b20c,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-c9be01a5-b05f-45c8-8c5a-cbd57c9abc72,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-9646936e-dc5d-46b4-9722-b949811b8b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-e15c422e-4eef-4eaf-ad96-46a039c53c55,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-cd54962f-20d0-4884-814e-61ba4f835289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163193066-172.17.0.8-1597719748939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45734,DS-05d80792-00cf-415c-8d31-44f0b45f7ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-b20b4d25-bc7d-4b41-8480-781f12809b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-9b27fa62-2e15-4a91-9482-6d975b9c9120,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-f37b072e-9362-4608-9021-52b266d8fb13,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-a9619bb3-09df-4ec1-9954-68c31ca6aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-2c70ebb5-cc4b-4984-a17e-e5d5bf438302,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-b53973a5-67b5-4433-b8e4-943e5d4104f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-0203e3cd-68fa-4f06-ba77-5634df6a2685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163193066-172.17.0.8-1597719748939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45734,DS-05d80792-00cf-415c-8d31-44f0b45f7ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-b20b4d25-bc7d-4b41-8480-781f12809b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-9b27fa62-2e15-4a91-9482-6d975b9c9120,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-f37b072e-9362-4608-9021-52b266d8fb13,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-a9619bb3-09df-4ec1-9954-68c31ca6aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-2c70ebb5-cc4b-4984-a17e-e5d5bf438302,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-b53973a5-67b5-4433-b8e4-943e5d4104f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-0203e3cd-68fa-4f06-ba77-5634df6a2685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994109862-172.17.0.8-1597720445003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-ad15bf42-d123-44cf-a0d5-77cede582957,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-a0fa3019-93b6-4295-b0f1-c299296afcea,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-3d82d898-9064-4729-b390-1a859f469e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-597f5e36-2f2f-4b9f-9805-308e98f4a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-2e3a0733-325d-45cd-8296-89baa3fcebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-6b62210f-e8f6-40fb-8598-41361aefcd57,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-e9e261d0-5fca-4866-94bb-adca4a41fce5,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-baf2192e-4e67-449a-b225-a8944e8962cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994109862-172.17.0.8-1597720445003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-ad15bf42-d123-44cf-a0d5-77cede582957,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-a0fa3019-93b6-4295-b0f1-c299296afcea,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-3d82d898-9064-4729-b390-1a859f469e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-597f5e36-2f2f-4b9f-9805-308e98f4a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-2e3a0733-325d-45cd-8296-89baa3fcebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-6b62210f-e8f6-40fb-8598-41361aefcd57,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-e9e261d0-5fca-4866-94bb-adca4a41fce5,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-baf2192e-4e67-449a-b225-a8944e8962cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693929835-172.17.0.8-1597720485239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38312,DS-0488628a-c66c-415c-b4ad-144e23be9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-69af3435-521a-453e-9bd8-f0432b58403c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-d22ddca4-a9f1-4b18-9211-5aefca7259b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-91478ed1-0547-4ec0-8e95-7fc3ee3ceea0,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-69d49fe0-567e-4551-932c-5903caa8196e,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-fd5d577a-55d3-4c7c-b206-2d24e66d5a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-3ccbbb04-4e30-4e61-aa9f-1ffaf5c03df7,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-61e429c6-81d0-49d4-89ce-a965ea8ac06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693929835-172.17.0.8-1597720485239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38312,DS-0488628a-c66c-415c-b4ad-144e23be9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-69af3435-521a-453e-9bd8-f0432b58403c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-d22ddca4-a9f1-4b18-9211-5aefca7259b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-91478ed1-0547-4ec0-8e95-7fc3ee3ceea0,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-69d49fe0-567e-4551-932c-5903caa8196e,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-fd5d577a-55d3-4c7c-b206-2d24e66d5a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-3ccbbb04-4e30-4e61-aa9f-1ffaf5c03df7,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-61e429c6-81d0-49d4-89ce-a965ea8ac06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912095827-172.17.0.8-1597720766133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42404,DS-5d7ea5b6-8dac-4b93-9cfc-7d0f02201892,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-eeaa3b00-68e0-445b-b263-64f7b7574fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-46bed79c-0f3d-4b2f-9cc3-a9c9a8f0c151,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-f5a03451-0fe7-4dda-bfb9-2010d0947c81,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-3a91fcdf-b610-4d0f-bbcd-c9edff41835c,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-06e0e909-fd92-4913-a346-d319b2fbb110,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-42e131cf-b160-4393-9715-cc74ba0c9f50,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-73d10e0a-f606-4b59-8c99-592e2606f9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912095827-172.17.0.8-1597720766133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42404,DS-5d7ea5b6-8dac-4b93-9cfc-7d0f02201892,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-eeaa3b00-68e0-445b-b263-64f7b7574fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-46bed79c-0f3d-4b2f-9cc3-a9c9a8f0c151,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-f5a03451-0fe7-4dda-bfb9-2010d0947c81,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-3a91fcdf-b610-4d0f-bbcd-c9edff41835c,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-06e0e909-fd92-4913-a346-d319b2fbb110,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-42e131cf-b160-4393-9715-cc74ba0c9f50,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-73d10e0a-f606-4b59-8c99-592e2606f9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5644
