reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99181480-172.17.0.4-1597410750371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37002,DS-6d515ed9-c24d-4b84-bd21-8708b362700d,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-749c29e8-e08d-4993-b2f8-e26eeba19dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-f57d577c-97cb-45ea-adca-4bd0ebf7f852,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-6322653a-cb70-403b-ab84-9a96ed821c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-e6dc945f-27fc-4419-9af3-878c773caacf,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-80bded44-4830-4f16-bfc2-223812b93780,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-287d6e90-0bd2-49c1-b407-e409e43fb088,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-616544ba-bdd3-4770-9561-a65b92d307af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99181480-172.17.0.4-1597410750371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37002,DS-6d515ed9-c24d-4b84-bd21-8708b362700d,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-749c29e8-e08d-4993-b2f8-e26eeba19dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-f57d577c-97cb-45ea-adca-4bd0ebf7f852,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-6322653a-cb70-403b-ab84-9a96ed821c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-e6dc945f-27fc-4419-9af3-878c773caacf,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-80bded44-4830-4f16-bfc2-223812b93780,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-287d6e90-0bd2-49c1-b407-e409e43fb088,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-616544ba-bdd3-4770-9561-a65b92d307af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064111514-172.17.0.4-1597410832704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44387,DS-cdc3868e-5d63-449c-8b74-83da4d30a7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-aefa3668-651e-4a32-ad86-045fddd3939a,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-9fa22c14-fccd-4a2a-8d35-84933064bd81,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-9be6120c-758e-4ca9-8a61-bf5143a9d27a,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-897dd063-e120-4443-b51b-7d8843964f01,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-2a756ae7-77eb-4db3-a2a1-cf61713b883f,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-61c4d2b9-c3e8-482c-91bd-120715e8c010,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-6b1a5662-044d-4680-bc16-2a59117193bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064111514-172.17.0.4-1597410832704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44387,DS-cdc3868e-5d63-449c-8b74-83da4d30a7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-aefa3668-651e-4a32-ad86-045fddd3939a,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-9fa22c14-fccd-4a2a-8d35-84933064bd81,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-9be6120c-758e-4ca9-8a61-bf5143a9d27a,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-897dd063-e120-4443-b51b-7d8843964f01,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-2a756ae7-77eb-4db3-a2a1-cf61713b883f,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-61c4d2b9-c3e8-482c-91bd-120715e8c010,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-6b1a5662-044d-4680-bc16-2a59117193bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057680174-172.17.0.4-1597410953032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38416,DS-70d3b16f-5606-491a-8e36-28f05e203dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-be278cb0-eb10-4ddf-a6a1-7036240d22b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-a7992f29-7fca-46e2-9140-8e8db002917d,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-ee4c62d0-91ca-4998-8b0f-9733759114c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-d3846af5-ad16-4d60-ad8d-cd1a9f29c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-d01f8e65-12f6-477f-8ea3-d03c33bf998a,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-2b1a4578-0ead-46d3-9f5b-74eac08c15ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-7f448acc-80f1-4431-91b1-f35c94bdadfe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057680174-172.17.0.4-1597410953032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38416,DS-70d3b16f-5606-491a-8e36-28f05e203dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-be278cb0-eb10-4ddf-a6a1-7036240d22b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-a7992f29-7fca-46e2-9140-8e8db002917d,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-ee4c62d0-91ca-4998-8b0f-9733759114c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-d3846af5-ad16-4d60-ad8d-cd1a9f29c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-d01f8e65-12f6-477f-8ea3-d03c33bf998a,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-2b1a4578-0ead-46d3-9f5b-74eac08c15ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-7f448acc-80f1-4431-91b1-f35c94bdadfe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920876091-172.17.0.4-1597411156006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-b8654083-d039-43db-acad-96950b9d1251,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-5f0c95d6-335f-4afe-94ce-7c5140e3cc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-329b46d8-acf7-4633-9f7b-a04095aa1242,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-2b1efade-f51e-413b-bc0d-90331d750479,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-4a342466-b3d4-4eac-93ea-7371b8eb0692,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-dfaeddfc-4b4c-48bc-8bf8-f9910d149f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-73de7515-8134-4e63-98d3-30cb2cbfce4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-07d309e0-dd52-4300-9b7b-858311a41f56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920876091-172.17.0.4-1597411156006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-b8654083-d039-43db-acad-96950b9d1251,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-5f0c95d6-335f-4afe-94ce-7c5140e3cc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-329b46d8-acf7-4633-9f7b-a04095aa1242,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-2b1efade-f51e-413b-bc0d-90331d750479,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-4a342466-b3d4-4eac-93ea-7371b8eb0692,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-dfaeddfc-4b4c-48bc-8bf8-f9910d149f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-73de7515-8134-4e63-98d3-30cb2cbfce4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-07d309e0-dd52-4300-9b7b-858311a41f56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060154780-172.17.0.4-1597411279051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-676c3f60-ad22-4e37-be21-6c20af314bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-7bf2994a-b141-44d1-b748-b558deedd8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-5c30aa11-28f7-4503-ab8a-34d8f4f87f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-81401d07-4f70-415c-a916-2a03f60e808a,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-d98d0f50-0f74-4d8a-8dcf-5136e243ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-993b982b-2c13-4399-85cd-aebac8e5fe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-70dae5a4-d564-484b-bf82-6697a329880d,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-d674a25a-8d20-40b1-89dc-7706c7dff598,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060154780-172.17.0.4-1597411279051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-676c3f60-ad22-4e37-be21-6c20af314bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-7bf2994a-b141-44d1-b748-b558deedd8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-5c30aa11-28f7-4503-ab8a-34d8f4f87f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-81401d07-4f70-415c-a916-2a03f60e808a,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-d98d0f50-0f74-4d8a-8dcf-5136e243ce4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-993b982b-2c13-4399-85cd-aebac8e5fe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-70dae5a4-d564-484b-bf82-6697a329880d,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-d674a25a-8d20-40b1-89dc-7706c7dff598,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059414611-172.17.0.4-1597411318372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33752,DS-02f770f0-770d-4143-b5b5-d344cf448c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-83b379d5-2f82-4f37-87b3-cfdd199bbc64,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-88a52320-cf17-4666-8c4a-3245d4e1ab8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-0cef7edf-9787-4008-9070-08821e65d2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-57d6caea-1eb4-430f-91a5-7d68aaccc0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ac68a33d-b811-445b-90bc-f7511e0d6cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-3eafcb72-1e15-4daa-a6be-fd281cc4e89e,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-301d23e7-4ae7-432d-863c-9ec81be08dfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059414611-172.17.0.4-1597411318372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33752,DS-02f770f0-770d-4143-b5b5-d344cf448c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-83b379d5-2f82-4f37-87b3-cfdd199bbc64,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-88a52320-cf17-4666-8c4a-3245d4e1ab8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-0cef7edf-9787-4008-9070-08821e65d2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-57d6caea-1eb4-430f-91a5-7d68aaccc0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ac68a33d-b811-445b-90bc-f7511e0d6cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-3eafcb72-1e15-4daa-a6be-fd281cc4e89e,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-301d23e7-4ae7-432d-863c-9ec81be08dfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410957472-172.17.0.4-1597411600917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44510,DS-acc8f654-a166-43dd-ad65-fcc89558b3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-fc316e01-2895-46ea-b30e-28bb662ca237,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-92064a14-4e0f-4806-b6c2-7ccb8e25a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-e1d37e8e-e0b1-4bff-b9c6-05bfd7244478,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-27ab6d02-0999-454c-8154-93d08ee69d48,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-9efda5e4-816b-4d8e-9259-84d22ed5e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-137de478-1441-4a10-9c7a-f7e88d617c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-7605c288-8702-40d1-8547-749994e455d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410957472-172.17.0.4-1597411600917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44510,DS-acc8f654-a166-43dd-ad65-fcc89558b3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-fc316e01-2895-46ea-b30e-28bb662ca237,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-92064a14-4e0f-4806-b6c2-7ccb8e25a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-e1d37e8e-e0b1-4bff-b9c6-05bfd7244478,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-27ab6d02-0999-454c-8154-93d08ee69d48,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-9efda5e4-816b-4d8e-9259-84d22ed5e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-137de478-1441-4a10-9c7a-f7e88d617c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-7605c288-8702-40d1-8547-749994e455d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757826851-172.17.0.4-1597411641413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-29e7d45e-daa6-422e-b780-1a2451034487,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-130394f5-a599-4d3c-9907-0bb123d14aef,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-3ec11e1c-3db6-431d-aac9-ad0f7a88205e,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-96a1d940-236d-4615-abfe-023b270e4dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-ac3afcdf-9383-49b7-8368-a60714adffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-958ab52a-3532-4bff-baad-7eb080073636,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-b78e6096-da6d-4188-b14b-8a30310ace78,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-f3c383da-5275-4dd0-b254-2c3459ea6eed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757826851-172.17.0.4-1597411641413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-29e7d45e-daa6-422e-b780-1a2451034487,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-130394f5-a599-4d3c-9907-0bb123d14aef,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-3ec11e1c-3db6-431d-aac9-ad0f7a88205e,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-96a1d940-236d-4615-abfe-023b270e4dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-ac3afcdf-9383-49b7-8368-a60714adffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-958ab52a-3532-4bff-baad-7eb080073636,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-b78e6096-da6d-4188-b14b-8a30310ace78,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-f3c383da-5275-4dd0-b254-2c3459ea6eed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837378482-172.17.0.4-1597411689927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-2030d887-a5e4-493b-8313-cbf1bedbc5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-05fbef9d-db9e-4ed7-92c0-3884ab81d215,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-46285f1c-ba10-4282-9031-a7cf7bb5dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-92e90717-285b-4a75-bf5c-d9ba18bbe018,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-83401931-32bf-46c7-8fd8-1bba79cd92a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-816d7dc6-d467-4512-a128-327c66374a32,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-cc0b9963-ce18-46a2-8c34-fcb412f77f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-11556235-f395-433f-bd93-d58dfc026e4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837378482-172.17.0.4-1597411689927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-2030d887-a5e4-493b-8313-cbf1bedbc5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-05fbef9d-db9e-4ed7-92c0-3884ab81d215,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-46285f1c-ba10-4282-9031-a7cf7bb5dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-92e90717-285b-4a75-bf5c-d9ba18bbe018,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-83401931-32bf-46c7-8fd8-1bba79cd92a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-816d7dc6-d467-4512-a128-327c66374a32,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-cc0b9963-ce18-46a2-8c34-fcb412f77f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-11556235-f395-433f-bd93-d58dfc026e4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109430753-172.17.0.4-1597411774334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33334,DS-11da0868-1e84-4a46-bdf6-b7d62bd68776,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-da59625e-061a-4a55-8da8-b4627a37c0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-c0320a2f-2ac3-4789-9f5e-b36440cbecb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-da10fbbe-efc2-4cee-94aa-1c45bcb9ced3,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-76393cd4-6d36-4e03-bb4c-c3d9ea969ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-25d36115-3d44-4a06-bb3e-478ae0ca7fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-cb616f7c-701a-4b84-8337-60751f0cf036,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-ff78086d-a5d8-453b-9d5a-9a5d59faf410,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109430753-172.17.0.4-1597411774334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33334,DS-11da0868-1e84-4a46-bdf6-b7d62bd68776,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-da59625e-061a-4a55-8da8-b4627a37c0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-c0320a2f-2ac3-4789-9f5e-b36440cbecb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-da10fbbe-efc2-4cee-94aa-1c45bcb9ced3,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-76393cd4-6d36-4e03-bb4c-c3d9ea969ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-25d36115-3d44-4a06-bb3e-478ae0ca7fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-cb616f7c-701a-4b84-8337-60751f0cf036,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-ff78086d-a5d8-453b-9d5a-9a5d59faf410,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597846453-172.17.0.4-1597412148928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-ecb5ee2f-ce51-4692-b528-82c9b8251ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-1c360509-b36a-418c-81d8-d234fa6e1e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-69b37aa7-505e-4d30-8926-9f46e6f938cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-5b48b609-e2a7-43e5-a9a4-30d5342a502c,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-6da17bd1-7cae-4d64-8648-24e1e1c961a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-2d9e1b0e-87e1-4546-8586-85f654599362,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cde25614-a1fd-4b48-9bfd-0842931479a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-10f8e7f9-acb6-4281-b989-199ed10d9170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597846453-172.17.0.4-1597412148928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-ecb5ee2f-ce51-4692-b528-82c9b8251ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-1c360509-b36a-418c-81d8-d234fa6e1e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-69b37aa7-505e-4d30-8926-9f46e6f938cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-5b48b609-e2a7-43e5-a9a4-30d5342a502c,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-6da17bd1-7cae-4d64-8648-24e1e1c961a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-2d9e1b0e-87e1-4546-8586-85f654599362,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cde25614-a1fd-4b48-9bfd-0842931479a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-10f8e7f9-acb6-4281-b989-199ed10d9170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720816123-172.17.0.4-1597412342338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46717,DS-520562c8-d879-405d-a549-64a19e6da622,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-d3141b2c-b2ee-4151-8c82-cd16eb0b2c43,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-2b53c2dc-4f79-407f-814a-bc5acc2f5529,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-9247ada0-6993-4cbb-a458-5b7675fc9263,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-f1e5bf4b-5018-4443-afd7-ededfec08cce,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-d1c1ee9f-84b6-4456-9275-49e49e5f41d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-27638b34-a364-4a40-8366-16ac89cc3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e9cb0a76-59e1-4b68-810b-f512b00b93a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720816123-172.17.0.4-1597412342338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46717,DS-520562c8-d879-405d-a549-64a19e6da622,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-d3141b2c-b2ee-4151-8c82-cd16eb0b2c43,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-2b53c2dc-4f79-407f-814a-bc5acc2f5529,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-9247ada0-6993-4cbb-a458-5b7675fc9263,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-f1e5bf4b-5018-4443-afd7-ededfec08cce,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-d1c1ee9f-84b6-4456-9275-49e49e5f41d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-27638b34-a364-4a40-8366-16ac89cc3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-e9cb0a76-59e1-4b68-810b-f512b00b93a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728818392-172.17.0.4-1597412866946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-081dc363-d0c9-4eec-9bb4-148ee3aac189,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-20b7f16a-9683-44f9-96ce-b399cabf88ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-109ba5b1-bed1-4cdd-8a59-625fe3333081,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-b556e431-8fc0-444e-b577-a48980b8e595,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-147ffb6d-496f-4923-8a42-d54498a4ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-750f2ac5-5198-4117-9aef-42b8b4b17e30,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-c0500781-d7f4-41f4-87c1-c9af6293be76,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-164eb88c-a713-4757-b0a0-51009ce9f441,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728818392-172.17.0.4-1597412866946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-081dc363-d0c9-4eec-9bb4-148ee3aac189,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-20b7f16a-9683-44f9-96ce-b399cabf88ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-109ba5b1-bed1-4cdd-8a59-625fe3333081,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-b556e431-8fc0-444e-b577-a48980b8e595,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-147ffb6d-496f-4923-8a42-d54498a4ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-750f2ac5-5198-4117-9aef-42b8b4b17e30,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-c0500781-d7f4-41f4-87c1-c9af6293be76,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-164eb88c-a713-4757-b0a0-51009ce9f441,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037494895-172.17.0.4-1597413121354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36530,DS-3d99f513-4cd5-44fd-a8f9-1824612fcadd,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-bb6c0c75-c018-4f38-b198-17675a78b13d,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-619279d8-2eed-42ca-b33f-5ce2e2ff3e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-ae9bd37e-e391-4df5-9904-23f565ca63c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-36eba6d2-63bf-49fe-88e4-c4050e2f33ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-beb963ad-4c8f-4bec-bcec-b7ee0d87f504,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-b5e3eecf-3939-48ea-a98d-1251675dde2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-2ff1e0a1-69a6-4f4c-8598-a9ad7445a92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037494895-172.17.0.4-1597413121354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36530,DS-3d99f513-4cd5-44fd-a8f9-1824612fcadd,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-bb6c0c75-c018-4f38-b198-17675a78b13d,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-619279d8-2eed-42ca-b33f-5ce2e2ff3e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-ae9bd37e-e391-4df5-9904-23f565ca63c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-36eba6d2-63bf-49fe-88e4-c4050e2f33ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-beb963ad-4c8f-4bec-bcec-b7ee0d87f504,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-b5e3eecf-3939-48ea-a98d-1251675dde2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-2ff1e0a1-69a6-4f4c-8598-a9ad7445a92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775280109-172.17.0.4-1597413155815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45307,DS-edbc4898-c1bc-4bf5-88ef-54bef5f4b09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-2f35e367-d3c4-440d-946b-1334baec25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-ef2b90d0-ac54-4234-979d-39dbdba9dd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-58a46c59-2785-4d15-bc4d-f4e60dd6f457,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-576f430e-de13-4f2d-a059-708fd8ab25a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-f2846a4d-72f7-4371-9e74-7e537f1f122e,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-5cf5a4cc-e12f-4c6a-ac9c-e673377b1af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-cdecb056-e22f-4b6d-b03b-a23152bd2057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775280109-172.17.0.4-1597413155815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45307,DS-edbc4898-c1bc-4bf5-88ef-54bef5f4b09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-2f35e367-d3c4-440d-946b-1334baec25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-ef2b90d0-ac54-4234-979d-39dbdba9dd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-58a46c59-2785-4d15-bc4d-f4e60dd6f457,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-576f430e-de13-4f2d-a059-708fd8ab25a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-f2846a4d-72f7-4371-9e74-7e537f1f122e,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-5cf5a4cc-e12f-4c6a-ac9c-e673377b1af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-cdecb056-e22f-4b6d-b03b-a23152bd2057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316703000-172.17.0.4-1597413319180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-2a55ca5b-0b62-4ee6-a631-9e04050ed4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-ee824d4c-4cc1-4802-a16a-1cbbb1bdc244,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-33b71574-7074-4387-b0f2-09a9c3b0d64f,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-46ed5ebf-f34e-4e35-b838-191763ec64cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-a0ce4019-08d3-4b67-b11b-93f8021fb129,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-0d2fbfb8-306a-4831-a25a-bfbb30a9d123,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-80e2e5bb-2b2b-4168-9b63-8433185fda4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-92866036-f1b5-46ad-8ced-94093d3060df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316703000-172.17.0.4-1597413319180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-2a55ca5b-0b62-4ee6-a631-9e04050ed4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-ee824d4c-4cc1-4802-a16a-1cbbb1bdc244,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-33b71574-7074-4387-b0f2-09a9c3b0d64f,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-46ed5ebf-f34e-4e35-b838-191763ec64cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-a0ce4019-08d3-4b67-b11b-93f8021fb129,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-0d2fbfb8-306a-4831-a25a-bfbb30a9d123,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-80e2e5bb-2b2b-4168-9b63-8433185fda4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-92866036-f1b5-46ad-8ced-94093d3060df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509489609-172.17.0.4-1597413680470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33350,DS-f947f790-a2c5-4d23-9536-4b8691c51aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-a7e034c7-c755-47ac-be51-cb9672372503,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-9a8099c3-3a63-48aa-97e4-4bc8c1c494c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-fbae66c0-2d7a-4acd-b512-d9d6abf217e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-c8dfcd2e-11f1-45ce-9d3e-3f9806e9c567,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-4ff4c175-da3d-4901-ac28-d79733288da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-131cfb2b-6f8a-4d62-8bc3-04c8e7264ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-cdbf10a2-1d3f-4073-8d87-8791a1277dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509489609-172.17.0.4-1597413680470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33350,DS-f947f790-a2c5-4d23-9536-4b8691c51aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-a7e034c7-c755-47ac-be51-cb9672372503,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-9a8099c3-3a63-48aa-97e4-4bc8c1c494c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-fbae66c0-2d7a-4acd-b512-d9d6abf217e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-c8dfcd2e-11f1-45ce-9d3e-3f9806e9c567,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-4ff4c175-da3d-4901-ac28-d79733288da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-131cfb2b-6f8a-4d62-8bc3-04c8e7264ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-cdbf10a2-1d3f-4073-8d87-8791a1277dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029056886-172.17.0.4-1597413808425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-1996c574-4f9e-404e-991e-daf3ab9f7b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-f93e6061-0924-4118-af72-929e8b52c945,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-93f61970-ea5c-40a3-b2e2-750d9463e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-0c6fc57d-a665-428a-abfe-d77e9e29b997,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-26998df3-3a67-433a-b47f-37af32adc6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-f6003c2d-d89a-4173-b767-df8de43506ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-9bb5c8bb-516a-4c71-9f6c-6966e8a6d8de,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-37b4da1d-b7fd-41bd-bad3-897ab9868366,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029056886-172.17.0.4-1597413808425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-1996c574-4f9e-404e-991e-daf3ab9f7b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-f93e6061-0924-4118-af72-929e8b52c945,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-93f61970-ea5c-40a3-b2e2-750d9463e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-0c6fc57d-a665-428a-abfe-d77e9e29b997,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-26998df3-3a67-433a-b47f-37af32adc6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-f6003c2d-d89a-4173-b767-df8de43506ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-9bb5c8bb-516a-4c71-9f6c-6966e8a6d8de,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-37b4da1d-b7fd-41bd-bad3-897ab9868366,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332758527-172.17.0.4-1597414004110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43206,DS-78e5b05e-e206-453e-ae2b-b097206e96c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-3d45ac4f-a07e-4ca1-ba24-a8378dc70a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-b5082e53-e262-496d-9715-cccb766711f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-0568b6de-0e1e-4d02-869c-74a39ba9775b,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-74969048-a9cc-4937-af99-3db06ff6cb18,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-d4b023ec-e300-4353-8511-e99eaa6b50e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-6b8d7e6f-874f-493c-b798-71d80f29bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-84b1a39d-2169-42b9-b621-58ec995e6a95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332758527-172.17.0.4-1597414004110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43206,DS-78e5b05e-e206-453e-ae2b-b097206e96c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-3d45ac4f-a07e-4ca1-ba24-a8378dc70a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-b5082e53-e262-496d-9715-cccb766711f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-0568b6de-0e1e-4d02-869c-74a39ba9775b,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-74969048-a9cc-4937-af99-3db06ff6cb18,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-d4b023ec-e300-4353-8511-e99eaa6b50e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-6b8d7e6f-874f-493c-b798-71d80f29bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-84b1a39d-2169-42b9-b621-58ec995e6a95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272376227-172.17.0.4-1597414134916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-0c711245-ef49-4513-a514-2a666004f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-0215aabc-30a1-4baa-893e-41a8840cc25f,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-e66f2e5d-f736-4c7b-bffd-5337cf2f40cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-341ef2bc-5414-4fa5-a642-841316afa958,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-193bfcf4-59ee-4f54-be32-459218b0d8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-5bf1850f-ef00-4fd0-b776-8e4bdea4d583,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-d6c9df4d-2deb-4743-a496-6558ee49ac68,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-48a08e7b-f7ba-4403-b27e-c6bfc8abb81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272376227-172.17.0.4-1597414134916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-0c711245-ef49-4513-a514-2a666004f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-0215aabc-30a1-4baa-893e-41a8840cc25f,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-e66f2e5d-f736-4c7b-bffd-5337cf2f40cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-341ef2bc-5414-4fa5-a642-841316afa958,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-193bfcf4-59ee-4f54-be32-459218b0d8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-5bf1850f-ef00-4fd0-b776-8e4bdea4d583,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-d6c9df4d-2deb-4743-a496-6558ee49ac68,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-48a08e7b-f7ba-4403-b27e-c6bfc8abb81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329409555-172.17.0.4-1597414303079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34623,DS-f5206b8b-b622-4082-8143-e95fb9b56c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-2ae6abaf-9d15-418f-965c-4a046edf57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-367efdb9-e370-4e36-a0ce-37fefdc1d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-68128bd0-af19-45c9-b2d3-0fd9e7092878,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-2e9fa2d0-47ac-4f67-9501-ba056bbc6b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-c91c01a4-478d-4112-9f67-fcd14fceec94,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-1f64df75-be36-48a2-9234-7fe4b6a00a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-3c955418-808e-46b3-acef-dd0b33b49dd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329409555-172.17.0.4-1597414303079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34623,DS-f5206b8b-b622-4082-8143-e95fb9b56c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-2ae6abaf-9d15-418f-965c-4a046edf57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-367efdb9-e370-4e36-a0ce-37fefdc1d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-68128bd0-af19-45c9-b2d3-0fd9e7092878,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-2e9fa2d0-47ac-4f67-9501-ba056bbc6b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-c91c01a4-478d-4112-9f67-fcd14fceec94,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-1f64df75-be36-48a2-9234-7fe4b6a00a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-3c955418-808e-46b3-acef-dd0b33b49dd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721357607-172.17.0.4-1597414501319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-8d72d77e-1ec5-4200-8a46-bba2b3560766,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-78692ac3-0b6c-42d2-a61e-2c6cc49a1f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-86cbf477-059b-4125-bbfa-8287a8726174,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-11264d98-5d8a-4d45-b655-189cc39fd3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-ae2c315e-db52-4657-af46-15760769d76a,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-4964c42e-2368-474d-8076-3b92cc096476,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-b0781230-e005-4901-8857-f2884ff11a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-88afb70c-17cb-4cd2-b35c-6acb201531ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721357607-172.17.0.4-1597414501319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-8d72d77e-1ec5-4200-8a46-bba2b3560766,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-78692ac3-0b6c-42d2-a61e-2c6cc49a1f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-86cbf477-059b-4125-bbfa-8287a8726174,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-11264d98-5d8a-4d45-b655-189cc39fd3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-ae2c315e-db52-4657-af46-15760769d76a,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-4964c42e-2368-474d-8076-3b92cc096476,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-b0781230-e005-4901-8857-f2884ff11a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-88afb70c-17cb-4cd2-b35c-6acb201531ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191370638-172.17.0.4-1597414781733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-423d26c0-e08b-40c3-a800-e5c37e41ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-8b672d58-d0e0-481e-b6a4-197e3351f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-6185c88a-b75a-40cf-86d3-05ec43bfaddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-e83a1629-f6e4-40af-95c6-196f6ed1d608,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-75695874-9440-476f-b3db-a1d8c55e75bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-92f8dffb-c4bf-466e-87b5-c2d56df9a7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-da100555-2cb3-4f6e-b327-775a0d3c194c,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-807cb500-1ae5-4040-aa98-da3d25ab27ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191370638-172.17.0.4-1597414781733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-423d26c0-e08b-40c3-a800-e5c37e41ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-8b672d58-d0e0-481e-b6a4-197e3351f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-6185c88a-b75a-40cf-86d3-05ec43bfaddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-e83a1629-f6e4-40af-95c6-196f6ed1d608,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-75695874-9440-476f-b3db-a1d8c55e75bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-92f8dffb-c4bf-466e-87b5-c2d56df9a7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-da100555-2cb3-4f6e-b327-775a0d3c194c,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-807cb500-1ae5-4040-aa98-da3d25ab27ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879061230-172.17.0.4-1597415288285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-dea2d3b4-52f8-4205-a5a9-516236fa1719,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-a3a26d20-397f-4ff6-b5b1-1e59627cd1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-e3ada396-2e1b-4e52-824e-dc93bf4ceed2,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-ef52c15e-e75c-46bc-94df-9f292d499d23,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-049ea434-bd0d-4afa-a72b-5557663b84ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-a55021e3-fd18-42b1-b131-231e4cbfe288,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-c48cd0b1-0fad-459f-94c7-264cfbf0e5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-6ceb2e21-1bdd-4eb0-9426-4d09bfca700e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879061230-172.17.0.4-1597415288285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-dea2d3b4-52f8-4205-a5a9-516236fa1719,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-a3a26d20-397f-4ff6-b5b1-1e59627cd1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-e3ada396-2e1b-4e52-824e-dc93bf4ceed2,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-ef52c15e-e75c-46bc-94df-9f292d499d23,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-049ea434-bd0d-4afa-a72b-5557663b84ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-a55021e3-fd18-42b1-b131-231e4cbfe288,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-c48cd0b1-0fad-459f-94c7-264cfbf0e5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-6ceb2e21-1bdd-4eb0-9426-4d09bfca700e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063727880-172.17.0.4-1597415601313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34439,DS-6a6745c6-e63b-458d-b8f9-94afd5de5a78,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-4453236a-5293-49e1-aacf-9485ade3fb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-89ab23fe-7883-40c4-b720-167086131fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cf6f42a2-6111-410b-a070-9a4c6a827740,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-0cd17e88-2b94-49b5-8092-ccf9ee0c76be,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-812c3b8f-1895-4259-9511-1c9e3ff22969,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-3499fa30-f612-4c91-98b8-a1cfd1ac3d71,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-7e9a738d-736e-43cc-8724-792f33cd6985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063727880-172.17.0.4-1597415601313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34439,DS-6a6745c6-e63b-458d-b8f9-94afd5de5a78,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-4453236a-5293-49e1-aacf-9485ade3fb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-89ab23fe-7883-40c4-b720-167086131fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cf6f42a2-6111-410b-a070-9a4c6a827740,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-0cd17e88-2b94-49b5-8092-ccf9ee0c76be,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-812c3b8f-1895-4259-9511-1c9e3ff22969,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-3499fa30-f612-4c91-98b8-a1cfd1ac3d71,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-7e9a738d-736e-43cc-8724-792f33cd6985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366622768-172.17.0.4-1597415759078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-8ffefad1-56fe-4481-91ed-33ff116520a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-a188804a-6680-4fca-987b-05d669a5f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-2073f289-60fe-42a9-a9a8-c31bf1f02c82,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-6423be3e-7bd3-421d-a308-16818083c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-4bef9cff-7788-4ef4-84b7-07ecc4dcc7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-80e8caf2-4ca8-452e-9993-e935832ef791,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-06aaf643-8c91-43fa-b975-8a860468306e,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-93919ad6-be23-4930-9cff-c78048c23737,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1366622768-172.17.0.4-1597415759078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-8ffefad1-56fe-4481-91ed-33ff116520a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-a188804a-6680-4fca-987b-05d669a5f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-2073f289-60fe-42a9-a9a8-c31bf1f02c82,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-6423be3e-7bd3-421d-a308-16818083c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-4bef9cff-7788-4ef4-84b7-07ecc4dcc7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-80e8caf2-4ca8-452e-9993-e935832ef791,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-06aaf643-8c91-43fa-b975-8a860468306e,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-93919ad6-be23-4930-9cff-c78048c23737,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970673126-172.17.0.4-1597415794289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-b715565a-e756-41d3-af81-71d2a6132a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-9366ad5a-7aa6-4309-9818-bea89e2f524d,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-7e06ed20-ab86-41a3-bf54-904c5361edfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-b73ea1cf-95b1-458c-87d0-e0c1c8bdbaec,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-c485a7d0-78d3-46f8-aae3-deff42dde533,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-f6dec031-1821-4f62-ae0c-3435fb416329,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-3230c462-a76f-4136-bdab-16a15b7f6920,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-e0ded8e6-819f-4ebc-85da-c91a7c37ae4b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970673126-172.17.0.4-1597415794289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-b715565a-e756-41d3-af81-71d2a6132a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-9366ad5a-7aa6-4309-9818-bea89e2f524d,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-7e06ed20-ab86-41a3-bf54-904c5361edfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-b73ea1cf-95b1-458c-87d0-e0c1c8bdbaec,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-c485a7d0-78d3-46f8-aae3-deff42dde533,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-f6dec031-1821-4f62-ae0c-3435fb416329,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-3230c462-a76f-4136-bdab-16a15b7f6920,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-e0ded8e6-819f-4ebc-85da-c91a7c37ae4b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765918803-172.17.0.4-1597415982526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33186,DS-4aa901af-ccbf-40cf-a742-cc5ec5ff9e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-d56cc1ba-3080-4bb1-8506-cfb538b3bc87,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-c62cb68b-af85-4252-8466-b5ec919a1fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-d340dd58-270a-4b93-ac34-742cf124fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-dc99da74-26fc-4f6f-9fd2-9906f742f82c,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-fbf5dcb3-4c1b-4b57-9737-a7a3759917c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-fd70fa23-d6a6-4e4f-8e5b-9c7c6697c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-33c5831f-9d5d-4d05-bdfc-a53b652fc721,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765918803-172.17.0.4-1597415982526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33186,DS-4aa901af-ccbf-40cf-a742-cc5ec5ff9e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-d56cc1ba-3080-4bb1-8506-cfb538b3bc87,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-c62cb68b-af85-4252-8466-b5ec919a1fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-d340dd58-270a-4b93-ac34-742cf124fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-dc99da74-26fc-4f6f-9fd2-9906f742f82c,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-fbf5dcb3-4c1b-4b57-9737-a7a3759917c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-fd70fa23-d6a6-4e4f-8e5b-9c7c6697c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-33c5831f-9d5d-4d05-bdfc-a53b652fc721,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729594030-172.17.0.4-1597416022279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-db2fda25-b2f1-481c-a7fd-a5f9d8cd2e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-5a127ddf-e5cf-4142-b44a-699a260ad9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-5783c173-2184-497a-b441-943c82746dae,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-40d4d1de-2ad8-4316-8737-79ecc44c3d79,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-7524ced8-a59f-405e-ad66-66c95fce4571,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-a9c44ad8-658d-467b-bdbe-7e241d71bfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-632922ad-d4f8-47e8-8122-4549216fed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-c2709487-fe93-4e6f-87a9-945b87ac4edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729594030-172.17.0.4-1597416022279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-db2fda25-b2f1-481c-a7fd-a5f9d8cd2e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-5a127ddf-e5cf-4142-b44a-699a260ad9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-5783c173-2184-497a-b441-943c82746dae,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-40d4d1de-2ad8-4316-8737-79ecc44c3d79,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-7524ced8-a59f-405e-ad66-66c95fce4571,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-a9c44ad8-658d-467b-bdbe-7e241d71bfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-632922ad-d4f8-47e8-8122-4549216fed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-c2709487-fe93-4e6f-87a9-945b87ac4edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090923496-172.17.0.4-1597416066092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34695,DS-4d16f92c-05a8-485b-8817-e1090e26c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-e263025d-89c3-4716-bba7-88a8e9fc66b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-11f6d700-2da6-4530-bf26-3d07c7648ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-f541676d-ba68-4576-8dac-de9ed7cb59dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-cb036fff-3eae-496d-ad9b-b68efb3dee10,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-1cc85b7e-0b0c-4104-bea1-a54fbd968a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-c692f322-e285-446a-92f1-7739a7e1e558,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-402227f5-f0cc-4def-a022-7b039c67ff33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090923496-172.17.0.4-1597416066092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34695,DS-4d16f92c-05a8-485b-8817-e1090e26c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-e263025d-89c3-4716-bba7-88a8e9fc66b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-11f6d700-2da6-4530-bf26-3d07c7648ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-f541676d-ba68-4576-8dac-de9ed7cb59dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-cb036fff-3eae-496d-ad9b-b68efb3dee10,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-1cc85b7e-0b0c-4104-bea1-a54fbd968a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-c692f322-e285-446a-92f1-7739a7e1e558,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-402227f5-f0cc-4def-a022-7b039c67ff33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395865126-172.17.0.4-1597416106750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40044,DS-c72de0a1-cf8b-44d0-aea1-86c13df253c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-741e1949-105c-41bb-932e-e179dec20744,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-997f3efa-0a55-43b8-82bd-2eaeb4a931c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-df194a07-683c-4778-9b38-e25a3bac0b22,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-fc5f56eb-1084-4402-bd7b-e504db8cffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-81a032fb-9a23-439e-849a-5547287eb6af,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-422daa70-809d-4922-9f34-88732816929c,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-43ca019a-cf23-4181-b563-c5d9ba0c2bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395865126-172.17.0.4-1597416106750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40044,DS-c72de0a1-cf8b-44d0-aea1-86c13df253c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-741e1949-105c-41bb-932e-e179dec20744,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-997f3efa-0a55-43b8-82bd-2eaeb4a931c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-df194a07-683c-4778-9b38-e25a3bac0b22,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-fc5f56eb-1084-4402-bd7b-e504db8cffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-81a032fb-9a23-439e-849a-5547287eb6af,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-422daa70-809d-4922-9f34-88732816929c,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-43ca019a-cf23-4181-b563-c5d9ba0c2bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695231675-172.17.0.4-1597416150864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33188,DS-bec816ef-1740-43ee-af37-f26d9b3a8528,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-f208b3f2-6f9b-4763-ae68-fb339d17eaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-5a2d5137-db39-4197-9a82-87f0cead2427,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-180a3538-bf3a-4066-8892-774f22bfbfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-e10c00a4-e63b-4648-895b-2590deab3cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-a83198e5-9061-459e-91b2-ebe21738b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-9037314e-3d65-4750-ab03-d6e4ca2cb064,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-4fb989a9-0e6a-4d62-a4a2-7da05cde8f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695231675-172.17.0.4-1597416150864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33188,DS-bec816ef-1740-43ee-af37-f26d9b3a8528,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-f208b3f2-6f9b-4763-ae68-fb339d17eaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-5a2d5137-db39-4197-9a82-87f0cead2427,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-180a3538-bf3a-4066-8892-774f22bfbfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-e10c00a4-e63b-4648-895b-2590deab3cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-a83198e5-9061-459e-91b2-ebe21738b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-9037314e-3d65-4750-ab03-d6e4ca2cb064,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-4fb989a9-0e6a-4d62-a4a2-7da05cde8f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371377320-172.17.0.4-1597416298909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36239,DS-6570c65c-672f-48ba-b0d7-083c3da15cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-22b085ce-ce33-4a95-8542-a53dbd0836c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-3113f01c-4233-4cec-a66b-d2f565d74a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-e261c713-cc8f-4103-8172-1f86cb3905a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-2f7b0567-af18-410e-aae3-b41178baef21,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-c5133459-7e8c-4976-8d71-035123bcd684,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-edd710ff-666b-4e2e-82df-7c0630a657da,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-419f97bb-dbca-40f8-b290-2a30665709b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371377320-172.17.0.4-1597416298909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36239,DS-6570c65c-672f-48ba-b0d7-083c3da15cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-22b085ce-ce33-4a95-8542-a53dbd0836c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-3113f01c-4233-4cec-a66b-d2f565d74a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-e261c713-cc8f-4103-8172-1f86cb3905a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-2f7b0567-af18-410e-aae3-b41178baef21,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-c5133459-7e8c-4976-8d71-035123bcd684,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-edd710ff-666b-4e2e-82df-7c0630a657da,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-419f97bb-dbca-40f8-b290-2a30665709b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278467008-172.17.0.4-1597416613766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-9aa01765-0332-438a-8066-ff9a568ae083,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-7695c29c-6e3d-44dc-9e60-dfd1f773fc70,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-8cecacc9-1a78-4674-b1ee-72fecff57797,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-7cde47d6-7bc3-4b43-9e31-b9879a999326,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-424d6e6e-cd83-497a-afb5-f79a332995c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-017bb73d-ebcb-458f-831a-843fee2bb073,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-8f89ac94-c55a-4f82-aae3-a97cd7ef196c,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-9e725d5d-5d2d-4e25-a97f-753ca299111a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278467008-172.17.0.4-1597416613766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-9aa01765-0332-438a-8066-ff9a568ae083,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-7695c29c-6e3d-44dc-9e60-dfd1f773fc70,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-8cecacc9-1a78-4674-b1ee-72fecff57797,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-7cde47d6-7bc3-4b43-9e31-b9879a999326,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-424d6e6e-cd83-497a-afb5-f79a332995c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-017bb73d-ebcb-458f-831a-843fee2bb073,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-8f89ac94-c55a-4f82-aae3-a97cd7ef196c,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-9e725d5d-5d2d-4e25-a97f-753ca299111a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5976
