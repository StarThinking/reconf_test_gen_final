reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345700638-172.17.0.14-1597650049636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37031,DS-850e1328-2254-4ed0-9157-3036990e56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-35bf2e7a-cf10-4445-bdd7-f58a635de3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-cb091004-54f6-459c-91b0-2b175015d00c,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-5dc3c9e2-ffa9-4d22-938f-23c2a1d4d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-2f0e6cdb-4689-4057-8b4e-f4957aa176e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-d41957e1-8cd8-4dc6-8909-d26b192a8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-dbe4fc61-3b9f-4dc2-a11d-4ecfd696bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-70aaf1c9-5939-42ba-b026-93d18d72c24b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345700638-172.17.0.14-1597650049636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37031,DS-850e1328-2254-4ed0-9157-3036990e56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-35bf2e7a-cf10-4445-bdd7-f58a635de3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-cb091004-54f6-459c-91b0-2b175015d00c,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-5dc3c9e2-ffa9-4d22-938f-23c2a1d4d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-2f0e6cdb-4689-4057-8b4e-f4957aa176e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-d41957e1-8cd8-4dc6-8909-d26b192a8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-dbe4fc61-3b9f-4dc2-a11d-4ecfd696bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-70aaf1c9-5939-42ba-b026-93d18d72c24b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631940397-172.17.0.14-1597650680184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45589,DS-d234be5e-553b-48cb-8196-c8f35a90b122,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-0d503edd-3f35-4019-b9bd-e125a73d47c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-5ca21659-2244-497e-9706-3d08af90a451,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-c8889670-a5c2-40d6-bdbc-707c3127b5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-d8f94255-9be0-4983-9db2-85f23bb4eb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-ad0bd2a2-dc0b-4342-83a9-df846f181518,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-27d99031-3a8d-4af4-8b42-2c51cfc7b685,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-cf3d2bd7-4293-4615-94b1-4a05d53ea31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631940397-172.17.0.14-1597650680184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45589,DS-d234be5e-553b-48cb-8196-c8f35a90b122,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-0d503edd-3f35-4019-b9bd-e125a73d47c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-5ca21659-2244-497e-9706-3d08af90a451,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-c8889670-a5c2-40d6-bdbc-707c3127b5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-d8f94255-9be0-4983-9db2-85f23bb4eb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-ad0bd2a2-dc0b-4342-83a9-df846f181518,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-27d99031-3a8d-4af4-8b42-2c51cfc7b685,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-cf3d2bd7-4293-4615-94b1-4a05d53ea31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192165235-172.17.0.14-1597650756142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-54f4fb04-ea12-4371-97dc-269c3c23b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-66259d22-9852-4996-a35a-52775ef4f8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-dca4d1f6-dd49-4d55-ba51-a0cc2ec93592,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-993ca2a2-76a7-4b3c-9f8b-d224f83303d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-26651e39-7cf4-492e-81c3-3ccaf00e0e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-7acde6bf-87c0-457c-ad21-60335cd5a3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-7925b0aa-6c3f-4f6e-8b41-43a45426e998,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-216eaec3-b78b-43f0-a352-342663e5a5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192165235-172.17.0.14-1597650756142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46321,DS-54f4fb04-ea12-4371-97dc-269c3c23b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-66259d22-9852-4996-a35a-52775ef4f8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-dca4d1f6-dd49-4d55-ba51-a0cc2ec93592,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-993ca2a2-76a7-4b3c-9f8b-d224f83303d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-26651e39-7cf4-492e-81c3-3ccaf00e0e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-7acde6bf-87c0-457c-ad21-60335cd5a3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-7925b0aa-6c3f-4f6e-8b41-43a45426e998,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-216eaec3-b78b-43f0-a352-342663e5a5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454757569-172.17.0.14-1597651163564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39183,DS-bb27a27d-e7ed-448a-9e3e-e13d5b388596,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-e5d0ade0-9078-4c1c-8edf-8828bdcba8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-9fc030a7-eb47-4083-b202-02028351f867,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-8c824031-61a7-4357-9158-ea0c61ea3498,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-0c3d0ebe-d5ff-47b4-9d28-98d0d110fd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-bd3d9391-718e-481a-bd33-e05795d00d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-006d7257-faf1-40e3-8b22-4da3d1f6ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-661e6775-87bc-40e4-940c-d95f4dcb68a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454757569-172.17.0.14-1597651163564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39183,DS-bb27a27d-e7ed-448a-9e3e-e13d5b388596,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-e5d0ade0-9078-4c1c-8edf-8828bdcba8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-9fc030a7-eb47-4083-b202-02028351f867,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-8c824031-61a7-4357-9158-ea0c61ea3498,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-0c3d0ebe-d5ff-47b4-9d28-98d0d110fd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-bd3d9391-718e-481a-bd33-e05795d00d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-006d7257-faf1-40e3-8b22-4da3d1f6ade4,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-661e6775-87bc-40e4-940c-d95f4dcb68a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972453732-172.17.0.14-1597651467399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-51eb33a0-fe25-446d-904e-e23bf6eb2246,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-4415f5fa-9ee9-402d-b48d-a2cd1519d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-d6e68238-49e2-40b1-bc15-42f9431d6fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-98dc14a3-508a-4c4b-ad0b-97cca47230e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-9d46f4fa-01ad-4756-b51d-52d597964e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-46267f1b-cf24-4c0c-9c2f-5ce2c13f0a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-b70df312-882b-43a3-b6e8-ffb5f786b373,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-d63c229b-8e91-40aa-b943-6997b21b8c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972453732-172.17.0.14-1597651467399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-51eb33a0-fe25-446d-904e-e23bf6eb2246,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-4415f5fa-9ee9-402d-b48d-a2cd1519d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-d6e68238-49e2-40b1-bc15-42f9431d6fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-98dc14a3-508a-4c4b-ad0b-97cca47230e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-9d46f4fa-01ad-4756-b51d-52d597964e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-46267f1b-cf24-4c0c-9c2f-5ce2c13f0a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-b70df312-882b-43a3-b6e8-ffb5f786b373,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-d63c229b-8e91-40aa-b943-6997b21b8c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144360498-172.17.0.14-1597651707654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40505,DS-f23814aa-590b-4bfc-9a85-29d4ca2a8124,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-cbb78f16-e3d2-4401-bd47-a8d5faccf162,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-a86a73d0-c747-40ba-826f-dd6a20295c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-482c1103-e67f-47e6-b6ed-48a1dfd13967,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-2871515f-de3f-47b3-9b32-cec49e4887f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-8e323f66-0ec0-47a9-9d30-f5c8d5081515,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-7c94c0d8-c596-483a-aae8-260415ad6788,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-29eb113e-27d4-429f-9805-57de4472e0f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144360498-172.17.0.14-1597651707654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40505,DS-f23814aa-590b-4bfc-9a85-29d4ca2a8124,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-cbb78f16-e3d2-4401-bd47-a8d5faccf162,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-a86a73d0-c747-40ba-826f-dd6a20295c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-482c1103-e67f-47e6-b6ed-48a1dfd13967,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-2871515f-de3f-47b3-9b32-cec49e4887f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-8e323f66-0ec0-47a9-9d30-f5c8d5081515,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-7c94c0d8-c596-483a-aae8-260415ad6788,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-29eb113e-27d4-429f-9805-57de4472e0f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731406783-172.17.0.14-1597651745126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37055,DS-4ef117f1-e943-4069-9c0f-638c369efb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-dc7ed5a4-0701-4860-8df8-2b6788baa656,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-7fb02c51-4b01-460e-8e24-043d4111a7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-2020af75-02d3-4d8a-b671-2293058c6d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-f10ea0d4-2538-43a3-8a80-dbb82e683c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-6eeb431d-8ddf-4c80-b154-a3fe6656ddb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-78afe5ff-9085-4696-886f-ed3238a617fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-02abcc97-0480-4dc3-8782-4e07ff1de4dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731406783-172.17.0.14-1597651745126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37055,DS-4ef117f1-e943-4069-9c0f-638c369efb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-dc7ed5a4-0701-4860-8df8-2b6788baa656,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-7fb02c51-4b01-460e-8e24-043d4111a7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-2020af75-02d3-4d8a-b671-2293058c6d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-f10ea0d4-2538-43a3-8a80-dbb82e683c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-6eeb431d-8ddf-4c80-b154-a3fe6656ddb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-78afe5ff-9085-4696-886f-ed3238a617fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-02abcc97-0480-4dc3-8782-4e07ff1de4dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867579132-172.17.0.14-1597651818493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32848,DS-73ac82c9-24d8-4955-a65d-1978d2eaae15,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-a7bb3835-3e33-4fbd-ba20-ed921851db98,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-cecb67a7-5407-4659-9f3d-d4ac132a9791,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-46d17850-9b9d-4fff-b5e8-c442e60c1458,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-d6cb5a0c-a49b-4111-8ad0-2da16314a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-d69608f2-1d3a-4a82-be9d-82519c094161,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-21259211-f0b7-4b46-ad67-3ab7f8dc4577,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-0158bdfb-e243-4ce4-bf99-12bd437d875a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867579132-172.17.0.14-1597651818493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32848,DS-73ac82c9-24d8-4955-a65d-1978d2eaae15,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-a7bb3835-3e33-4fbd-ba20-ed921851db98,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-cecb67a7-5407-4659-9f3d-d4ac132a9791,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-46d17850-9b9d-4fff-b5e8-c442e60c1458,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-d6cb5a0c-a49b-4111-8ad0-2da16314a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-d69608f2-1d3a-4a82-be9d-82519c094161,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-21259211-f0b7-4b46-ad67-3ab7f8dc4577,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-0158bdfb-e243-4ce4-bf99-12bd437d875a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216689321-172.17.0.14-1597651893181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40772,DS-786988c9-992e-4b8b-b481-5a305dd2ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-4bc419fd-fd7c-42f1-99e6-15654615f28c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-3ecc45d4-e81b-42da-95a6-3c9ad87a87fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-381cd01b-fc98-4db9-962c-1891ef76e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-9fe2419d-c874-4ed2-b5b5-0e9b1541b331,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-8bf1a851-7070-4b26-b910-f85667b6f6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-206c3d07-c918-4a20-b779-65db4cb32fed,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-973d92fd-7429-4804-85c8-bcbf92e92402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216689321-172.17.0.14-1597651893181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40772,DS-786988c9-992e-4b8b-b481-5a305dd2ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-4bc419fd-fd7c-42f1-99e6-15654615f28c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-3ecc45d4-e81b-42da-95a6-3c9ad87a87fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-381cd01b-fc98-4db9-962c-1891ef76e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-9fe2419d-c874-4ed2-b5b5-0e9b1541b331,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-8bf1a851-7070-4b26-b910-f85667b6f6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-206c3d07-c918-4a20-b779-65db4cb32fed,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-973d92fd-7429-4804-85c8-bcbf92e92402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446123707-172.17.0.14-1597651929448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35661,DS-2733bb04-0189-4a3d-a3de-464b65d2524d,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-ae4ffd52-ecb1-4922-9366-cb5c6351034d,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-95d2833b-6877-461e-8c4d-c09b07650e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-d9f41c23-c251-4b2d-b4e3-bf5875d74164,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-14194a43-5a41-4740-acbf-498dd4403ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-e29effa4-0ff2-4fe6-ad4d-3318e1deda32,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-864575fc-1fdd-45b4-afa9-809ab83d0186,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-e4bafa56-f68e-4891-902f-c3a0e14552c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446123707-172.17.0.14-1597651929448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35661,DS-2733bb04-0189-4a3d-a3de-464b65d2524d,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-ae4ffd52-ecb1-4922-9366-cb5c6351034d,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-95d2833b-6877-461e-8c4d-c09b07650e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-d9f41c23-c251-4b2d-b4e3-bf5875d74164,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-14194a43-5a41-4740-acbf-498dd4403ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-e29effa4-0ff2-4fe6-ad4d-3318e1deda32,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-864575fc-1fdd-45b4-afa9-809ab83d0186,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-e4bafa56-f68e-4891-902f-c3a0e14552c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669240522-172.17.0.14-1597652797557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34522,DS-6211825f-db3b-4d2e-bbd7-4991f004d168,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-c6e3bad1-b204-4e68-ace4-efaacf45ee02,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-00ed76e4-e7e1-4d25-b32d-29c848cb459a,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-8641f378-77c9-40a0-a001-40994f37dd40,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-dabeaa6f-1e6e-4ed4-98f7-0fa733a56bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-c1dff6be-bb9f-479d-94b5-e1effdac16b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-07a3b2c3-bb8f-4e64-8a43-b5c3f225206b,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-db27387d-e9c0-4df5-9f47-aa9a1acc48bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669240522-172.17.0.14-1597652797557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34522,DS-6211825f-db3b-4d2e-bbd7-4991f004d168,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-c6e3bad1-b204-4e68-ace4-efaacf45ee02,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-00ed76e4-e7e1-4d25-b32d-29c848cb459a,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-8641f378-77c9-40a0-a001-40994f37dd40,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-dabeaa6f-1e6e-4ed4-98f7-0fa733a56bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-c1dff6be-bb9f-479d-94b5-e1effdac16b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-07a3b2c3-bb8f-4e64-8a43-b5c3f225206b,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-db27387d-e9c0-4df5-9f47-aa9a1acc48bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081063124-172.17.0.14-1597652872593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39237,DS-2739d8ce-42c2-4637-a5ef-1e6c1d41cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-89a9e12b-d489-4319-bda0-377243d00b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-57b6f29e-2266-4f36-91e1-1c82f9a22e70,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-52b152c8-2490-44f6-801c-63e4a89a9592,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-a4cf57cf-58ac-450f-b565-0564dd545504,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-0c0f6ae7-a163-4700-bb23-89e48ffd82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-a3476378-d4f9-42b5-bb22-a7f2b9a66cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-c22bb107-9066-4f48-bacb-568a6d1ab18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081063124-172.17.0.14-1597652872593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39237,DS-2739d8ce-42c2-4637-a5ef-1e6c1d41cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-89a9e12b-d489-4319-bda0-377243d00b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-57b6f29e-2266-4f36-91e1-1c82f9a22e70,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-52b152c8-2490-44f6-801c-63e4a89a9592,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-a4cf57cf-58ac-450f-b565-0564dd545504,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-0c0f6ae7-a163-4700-bb23-89e48ffd82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-a3476378-d4f9-42b5-bb22-a7f2b9a66cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-c22bb107-9066-4f48-bacb-568a6d1ab18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252602603-172.17.0.14-1597653364349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-cf92a38f-4149-4623-ac9a-4ccac18871d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-7f1f6c1e-65a1-4b1e-a9c3-707ab3b4fd83,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-fbd30b79-1db0-477b-bec6-9543075a7a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-45f56eb8-9c83-4721-aae2-c2ebb2de5361,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-9960debe-5972-4d1f-8e3d-3f28304e8d31,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-98a296ae-d274-4484-afb5-99ed847854a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-5a1ea187-6e48-457c-bcf2-5f32e91c1aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-e010cb1f-b544-4f1f-b157-8ee4f5dd49d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252602603-172.17.0.14-1597653364349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-cf92a38f-4149-4623-ac9a-4ccac18871d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-7f1f6c1e-65a1-4b1e-a9c3-707ab3b4fd83,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-fbd30b79-1db0-477b-bec6-9543075a7a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-45f56eb8-9c83-4721-aae2-c2ebb2de5361,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-9960debe-5972-4d1f-8e3d-3f28304e8d31,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-98a296ae-d274-4484-afb5-99ed847854a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-5a1ea187-6e48-457c-bcf2-5f32e91c1aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-e010cb1f-b544-4f1f-b157-8ee4f5dd49d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395754016-172.17.0.14-1597654374153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38427,DS-efb5b923-41c7-4f18-a8fa-947cfd3515c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-df84c18d-c7d0-4c39-96e3-b95769296fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-02d5890c-7b65-4540-8a5e-ad73bc415821,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-5c3d0390-b6e6-4f72-8351-b92806a31846,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-3b68110e-3c8a-4de2-9e51-786166086b44,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-72892145-6302-4d16-96f4-f86ce8bb2ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-ff7623c4-749a-400e-a088-5b0459040b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-a5b70b99-b39b-42de-9303-246b0bd01dbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395754016-172.17.0.14-1597654374153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38427,DS-efb5b923-41c7-4f18-a8fa-947cfd3515c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-df84c18d-c7d0-4c39-96e3-b95769296fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-02d5890c-7b65-4540-8a5e-ad73bc415821,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-5c3d0390-b6e6-4f72-8351-b92806a31846,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-3b68110e-3c8a-4de2-9e51-786166086b44,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-72892145-6302-4d16-96f4-f86ce8bb2ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-ff7623c4-749a-400e-a088-5b0459040b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-a5b70b99-b39b-42de-9303-246b0bd01dbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230770577-172.17.0.14-1597654708220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-3e8d6ec2-a5e4-40cc-972b-a56b2d5d5631,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-7dc98f07-064e-49bb-b5e8-352022718493,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-798ae82f-9957-49f3-9c34-4ea658f295f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-05db8ea5-d1a5-4f50-8889-bea998016c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-e85f6cb1-1cf3-4e17-b549-73f391176f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-d7489fe9-26af-4d56-9701-4fa82d11f950,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-29534ea8-7a3e-40cf-8bd6-275d02c230ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-790c2c1b-166d-41b3-979c-5219a371c219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230770577-172.17.0.14-1597654708220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-3e8d6ec2-a5e4-40cc-972b-a56b2d5d5631,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-7dc98f07-064e-49bb-b5e8-352022718493,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-798ae82f-9957-49f3-9c34-4ea658f295f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-05db8ea5-d1a5-4f50-8889-bea998016c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-e85f6cb1-1cf3-4e17-b549-73f391176f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-d7489fe9-26af-4d56-9701-4fa82d11f950,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-29534ea8-7a3e-40cf-8bd6-275d02c230ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-790c2c1b-166d-41b3-979c-5219a371c219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903061467-172.17.0.14-1597654865391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-9c6e15c1-5d53-40a7-ba32-2d6ce6c028de,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-cb2dfdd2-9a13-4f71-b7a2-1148b24eea84,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-9e6fa133-f08a-42ca-b5e8-74aeecc6e5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-6147220c-a15f-433c-af13-db3f14cfa36d,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-89cb1cff-10d3-428e-80e0-a27559e8d64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-df296c71-e121-45ae-900c-e8f2943966c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-29feb9b5-fbe1-4861-8b84-f31aa81beff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-eb6091b1-41ec-4685-a261-494d0736ef29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903061467-172.17.0.14-1597654865391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-9c6e15c1-5d53-40a7-ba32-2d6ce6c028de,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-cb2dfdd2-9a13-4f71-b7a2-1148b24eea84,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-9e6fa133-f08a-42ca-b5e8-74aeecc6e5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-6147220c-a15f-433c-af13-db3f14cfa36d,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-89cb1cff-10d3-428e-80e0-a27559e8d64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-df296c71-e121-45ae-900c-e8f2943966c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-29feb9b5-fbe1-4861-8b84-f31aa81beff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-eb6091b1-41ec-4685-a261-494d0736ef29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5576
