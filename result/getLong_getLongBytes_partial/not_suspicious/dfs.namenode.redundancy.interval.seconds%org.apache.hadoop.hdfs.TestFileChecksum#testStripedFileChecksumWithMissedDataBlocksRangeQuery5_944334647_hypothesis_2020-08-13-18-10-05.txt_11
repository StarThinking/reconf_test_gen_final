reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223002285-172.17.0.20-1597342262238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34465,DS-19776200-52ec-4cb0-8ddf-3cc9c5c64222,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-9c8560dd-9ece-4b08-aff8-fa19448b3b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-74582bc4-6618-482f-be64-7e51d0d4f49b,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-806f6dbf-0f75-493f-820c-572a32c9865c,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-c71b0614-d2f5-4bdd-b757-fc1a68b91f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-420c11c1-4836-42ab-8379-3f45acd2a1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-8dbeefca-bbf5-4a12-9c29-b9a764273089,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-e6495965-afbb-4328-ba1b-137a83f093af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223002285-172.17.0.20-1597342262238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34465,DS-19776200-52ec-4cb0-8ddf-3cc9c5c64222,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-9c8560dd-9ece-4b08-aff8-fa19448b3b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-74582bc4-6618-482f-be64-7e51d0d4f49b,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-806f6dbf-0f75-493f-820c-572a32c9865c,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-c71b0614-d2f5-4bdd-b757-fc1a68b91f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-420c11c1-4836-42ab-8379-3f45acd2a1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-8dbeefca-bbf5-4a12-9c29-b9a764273089,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-e6495965-afbb-4328-ba1b-137a83f093af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167311112-172.17.0.20-1597342857626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40442,DS-304374c8-863e-4f85-a9c5-36484217ef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-0db644c8-950e-4d60-8717-9713b3039483,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-b38cd55e-fe7c-4151-8865-248a792b99c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-48b8de0f-3502-473c-9b73-93602b9aa16e,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-2e66af28-3a03-462d-a040-d349073a74bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-03cedec7-4eb0-4ac2-aa54-c74aee90ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-5cbc1914-86b9-45ec-9dd2-fb6e65eb54b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-a1012f7d-88f7-45d7-aaf7-b02bcd9df3f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167311112-172.17.0.20-1597342857626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40442,DS-304374c8-863e-4f85-a9c5-36484217ef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-0db644c8-950e-4d60-8717-9713b3039483,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-b38cd55e-fe7c-4151-8865-248a792b99c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-48b8de0f-3502-473c-9b73-93602b9aa16e,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-2e66af28-3a03-462d-a040-d349073a74bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-03cedec7-4eb0-4ac2-aa54-c74aee90ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-5cbc1914-86b9-45ec-9dd2-fb6e65eb54b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-a1012f7d-88f7-45d7-aaf7-b02bcd9df3f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198228183-172.17.0.20-1597343933327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36450,DS-6403252c-81fc-4514-ac5a-dc3441a73a40,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-abdea754-67b1-4cb5-bf05-eea71d9d6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-797228cd-62e2-4396-b9cf-a30ed0800174,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-06a5c36b-38ec-474a-8415-07bdd88a1c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-b6ee7244-9e7e-4491-95be-b175d9414c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-1c67f6b2-43f0-4baf-80f7-e06263c7d731,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-16f8f7f8-649a-4598-aaff-1dbc566a8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-946945ee-89b7-4692-8750-37c0a3fc6d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198228183-172.17.0.20-1597343933327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36450,DS-6403252c-81fc-4514-ac5a-dc3441a73a40,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-abdea754-67b1-4cb5-bf05-eea71d9d6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-797228cd-62e2-4396-b9cf-a30ed0800174,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-06a5c36b-38ec-474a-8415-07bdd88a1c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-b6ee7244-9e7e-4491-95be-b175d9414c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-1c67f6b2-43f0-4baf-80f7-e06263c7d731,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-16f8f7f8-649a-4598-aaff-1dbc566a8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-946945ee-89b7-4692-8750-37c0a3fc6d46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442512912-172.17.0.20-1597344085149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33074,DS-68e4b5b9-e292-4dd5-9377-39552ff763f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-7521e6cc-3300-480e-9b21-88ddcade8580,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-5270a40e-a89e-4f02-9fd4-c1417080a88c,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-0b5cfa5b-085c-4516-b5c8-a9463b171d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-305cbd73-ea5b-4f74-bc72-fcb198ae7785,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-60d9e84e-afc6-4097-b9de-09d3cf985edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-a6da5595-a85a-41c1-99cb-5277b25abc25,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-5c312df1-d385-43cd-8fbb-108b53b6beb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442512912-172.17.0.20-1597344085149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33074,DS-68e4b5b9-e292-4dd5-9377-39552ff763f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-7521e6cc-3300-480e-9b21-88ddcade8580,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-5270a40e-a89e-4f02-9fd4-c1417080a88c,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-0b5cfa5b-085c-4516-b5c8-a9463b171d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-305cbd73-ea5b-4f74-bc72-fcb198ae7785,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-60d9e84e-afc6-4097-b9de-09d3cf985edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-a6da5595-a85a-41c1-99cb-5277b25abc25,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-5c312df1-d385-43cd-8fbb-108b53b6beb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339189499-172.17.0.20-1597344174963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-871368cb-e1f1-4e10-a9e6-547b8a3acab1,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-c4f9cbfc-3452-4126-9a26-8e7ffb1ae704,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-387b728d-b4be-4b69-b1b9-52591d07928c,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-ed5af2b2-047a-48c2-a5c6-80137741d254,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-032a7a67-9b09-495d-9c3a-4469bc789690,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-f410a6bf-e13c-4e07-ba49-098a1334db46,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-f78fd99e-c799-4344-b1d3-21d13d644b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-75622556-71b0-434a-adc9-29759878d53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339189499-172.17.0.20-1597344174963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-871368cb-e1f1-4e10-a9e6-547b8a3acab1,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-c4f9cbfc-3452-4126-9a26-8e7ffb1ae704,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-387b728d-b4be-4b69-b1b9-52591d07928c,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-ed5af2b2-047a-48c2-a5c6-80137741d254,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-032a7a67-9b09-495d-9c3a-4469bc789690,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-f410a6bf-e13c-4e07-ba49-098a1334db46,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-f78fd99e-c799-4344-b1d3-21d13d644b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-75622556-71b0-434a-adc9-29759878d53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917976528-172.17.0.20-1597344327901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-f21d3722-04c1-4036-b9b7-6bc9fd496b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-f9360f43-4582-4e5f-9158-2b99dd41c4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-f54bc82a-b802-484a-b10b-57f0c5ae3154,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-a94258fe-f855-4e14-beda-fc7ea9b888fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-8b78eee0-7d43-4a54-84ae-622f611b9612,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-857b3153-866f-40a7-af24-c3835f0baba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-12c9ef8f-3496-4d85-bd63-75d290b1cc59,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-984f710e-f703-4765-9582-1adc0db1ae83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917976528-172.17.0.20-1597344327901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-f21d3722-04c1-4036-b9b7-6bc9fd496b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-f9360f43-4582-4e5f-9158-2b99dd41c4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-f54bc82a-b802-484a-b10b-57f0c5ae3154,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-a94258fe-f855-4e14-beda-fc7ea9b888fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-8b78eee0-7d43-4a54-84ae-622f611b9612,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-857b3153-866f-40a7-af24-c3835f0baba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-12c9ef8f-3496-4d85-bd63-75d290b1cc59,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-984f710e-f703-4765-9582-1adc0db1ae83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541721411-172.17.0.20-1597344744378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32960,DS-892f408a-0c79-4368-a223-4795b3775f45,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-3d91129c-4912-47e2-bb5f-c8210354e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-c93b2a8a-d928-46f0-ba58-b8ff2c017a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-b545049f-2546-4fe8-8d12-7eb996df03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-37d6c407-a92d-474f-b3cb-ba443497e33c,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-9c8bcad3-6315-42d7-8648-34ffa981b8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-89050b28-cdee-4ebb-9281-aca66a31abbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-c6b14811-b49d-440a-8436-2330f97a9fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541721411-172.17.0.20-1597344744378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32960,DS-892f408a-0c79-4368-a223-4795b3775f45,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-3d91129c-4912-47e2-bb5f-c8210354e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-c93b2a8a-d928-46f0-ba58-b8ff2c017a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-b545049f-2546-4fe8-8d12-7eb996df03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-37d6c407-a92d-474f-b3cb-ba443497e33c,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-9c8bcad3-6315-42d7-8648-34ffa981b8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-89050b28-cdee-4ebb-9281-aca66a31abbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-c6b14811-b49d-440a-8436-2330f97a9fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632870896-172.17.0.20-1597345200084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39657,DS-c9dfd2e0-11bf-432c-8a1c-bb98af21b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-e2814953-bb39-4f21-8554-64e5ce6ef7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-6dd1abe4-b4cf-4e38-ab2c-310b7cfa75a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-147e94b3-ca4b-4ed2-af84-ada0bff629c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-1bee912b-3c97-43d3-88ed-ec82929b619a,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-1c28025b-bd8f-4e94-8b14-432be499dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-fd7bc460-9b2d-41aa-afee-a9b0a2a93ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-c55f020e-bb1d-4f11-97b7-3a9fa0256c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632870896-172.17.0.20-1597345200084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39657,DS-c9dfd2e0-11bf-432c-8a1c-bb98af21b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-e2814953-bb39-4f21-8554-64e5ce6ef7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-6dd1abe4-b4cf-4e38-ab2c-310b7cfa75a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-147e94b3-ca4b-4ed2-af84-ada0bff629c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-1bee912b-3c97-43d3-88ed-ec82929b619a,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-1c28025b-bd8f-4e94-8b14-432be499dbea,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-fd7bc460-9b2d-41aa-afee-a9b0a2a93ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-c55f020e-bb1d-4f11-97b7-3a9fa0256c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541870873-172.17.0.20-1597345241702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-e7d92fa0-f24a-4405-9c46-84dfd1497001,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-2add8743-bf5d-4ad5-acbe-fe412fd4df76,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-ddc7c45a-9f30-4342-a4e8-9157b042f351,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-a237aa15-a042-45a9-ac37-9f77d7564ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-f4f38e8a-057d-4a0f-9701-34565aa44871,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-df99432c-9b02-455b-ab4a-35511c34b9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-df0ab5dc-0121-43df-b5e9-0031ac1a60e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-d746d28b-eb6e-4266-bc53-ffddb1f9ca42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541870873-172.17.0.20-1597345241702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-e7d92fa0-f24a-4405-9c46-84dfd1497001,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-2add8743-bf5d-4ad5-acbe-fe412fd4df76,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-ddc7c45a-9f30-4342-a4e8-9157b042f351,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-a237aa15-a042-45a9-ac37-9f77d7564ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-f4f38e8a-057d-4a0f-9701-34565aa44871,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-df99432c-9b02-455b-ab4a-35511c34b9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-df0ab5dc-0121-43df-b5e9-0031ac1a60e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-d746d28b-eb6e-4266-bc53-ffddb1f9ca42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14415952-172.17.0.20-1597345279872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43466,DS-4e952372-5895-4f7b-9b5a-f081db8169f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-1eefbfe3-2f0f-438b-94d8-9461cfe0cb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-c4c227ea-1ebf-49b0-8f59-1d2998ccf372,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-3b49b9f6-cb07-4b68-afd3-180ddf73b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-2bab3f91-3844-497f-9b16-b0cf1e2f137f,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-02389b65-363c-48a1-9f71-b26af76def15,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-509b7ed9-7125-49d0-838f-efb94715cc70,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-83622377-85e1-4fca-9b13-1acf83f53a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14415952-172.17.0.20-1597345279872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43466,DS-4e952372-5895-4f7b-9b5a-f081db8169f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-1eefbfe3-2f0f-438b-94d8-9461cfe0cb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-c4c227ea-1ebf-49b0-8f59-1d2998ccf372,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-3b49b9f6-cb07-4b68-afd3-180ddf73b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-2bab3f91-3844-497f-9b16-b0cf1e2f137f,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-02389b65-363c-48a1-9f71-b26af76def15,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-509b7ed9-7125-49d0-838f-efb94715cc70,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-83622377-85e1-4fca-9b13-1acf83f53a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659729514-172.17.0.20-1597345397017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45042,DS-7cae31bb-c00a-4a31-a090-b26dfc116d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-018f266a-4ee2-47c3-a083-721f801180fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-f40d9a47-8f09-4b0b-af54-475ad9793df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-92107920-9b95-4b65-85aa-e891e36f28c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-aeefc3fb-d99e-4519-83ef-cd1258087852,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-ba8217e2-b43b-4640-a9e5-71da553c26f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-e4800be4-ba8f-41ac-a7a9-c1393ca10090,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-5d9510f7-c7fc-4a1b-90f8-2c520359a7bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659729514-172.17.0.20-1597345397017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45042,DS-7cae31bb-c00a-4a31-a090-b26dfc116d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-018f266a-4ee2-47c3-a083-721f801180fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-f40d9a47-8f09-4b0b-af54-475ad9793df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-92107920-9b95-4b65-85aa-e891e36f28c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-aeefc3fb-d99e-4519-83ef-cd1258087852,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-ba8217e2-b43b-4640-a9e5-71da553c26f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-e4800be4-ba8f-41ac-a7a9-c1393ca10090,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-5d9510f7-c7fc-4a1b-90f8-2c520359a7bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103354069-172.17.0.20-1597345440702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45432,DS-0343af4f-fcea-48c3-851b-c5d279908272,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-e08e4d1b-aa6e-44e7-911c-2b8965db6563,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-0815a02d-bfb6-4d0d-8d0f-7baff8f69a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-19eb7fde-4b3f-4708-8c93-14c15adfc4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-b3d7be22-2d0d-4183-a16a-1ff438645fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-3e23010e-9b13-47dd-9bc0-4c34c0429fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-af273842-013c-429c-a9c1-23159710b301,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-76a89cc4-dabd-4ed7-97ef-d7f8b69e1620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103354069-172.17.0.20-1597345440702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45432,DS-0343af4f-fcea-48c3-851b-c5d279908272,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-e08e4d1b-aa6e-44e7-911c-2b8965db6563,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-0815a02d-bfb6-4d0d-8d0f-7baff8f69a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-19eb7fde-4b3f-4708-8c93-14c15adfc4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-b3d7be22-2d0d-4183-a16a-1ff438645fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-3e23010e-9b13-47dd-9bc0-4c34c0429fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-af273842-013c-429c-a9c1-23159710b301,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-76a89cc4-dabd-4ed7-97ef-d7f8b69e1620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126357781-172.17.0.20-1597345637217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45473,DS-eddb9587-a840-4c7c-b02c-ebfd3e22981f,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-43e74f4a-1810-4bb5-a046-6fb1d1d29971,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-af93d9a3-dfe8-49b0-8113-8be2f684c718,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-b91b3998-1da8-44a1-8f21-063d41dad2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-6e0cf622-5da9-4fc1-bd93-bda686daed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-687c719a-ec89-4360-a897-447225238b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-56c3dc0c-e55c-463d-9d73-05f185b3da4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-741d15f8-e532-4d53-a764-e449fc3bec8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126357781-172.17.0.20-1597345637217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45473,DS-eddb9587-a840-4c7c-b02c-ebfd3e22981f,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-43e74f4a-1810-4bb5-a046-6fb1d1d29971,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-af93d9a3-dfe8-49b0-8113-8be2f684c718,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-b91b3998-1da8-44a1-8f21-063d41dad2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-6e0cf622-5da9-4fc1-bd93-bda686daed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-687c719a-ec89-4360-a897-447225238b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-56c3dc0c-e55c-463d-9d73-05f185b3da4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-741d15f8-e532-4d53-a764-e449fc3bec8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296296702-172.17.0.20-1597345711686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43174,DS-10f5b4fd-b03a-4164-9842-248e046df66c,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-f0888981-c6c1-4944-a39f-d122de072d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-b6d4e504-dc4a-46f6-bbc2-f2314536bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-546ea4ee-809c-4512-8fd7-946303447cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-7e7aed30-7a41-4e59-bd0c-bfdfe15f0c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-089e1f80-2021-45a7-8235-c05892c24697,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-9fe6feef-d508-409c-b80a-563f3599f0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-2bc72805-69e3-4960-9571-f9df69c3f9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296296702-172.17.0.20-1597345711686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43174,DS-10f5b4fd-b03a-4164-9842-248e046df66c,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-f0888981-c6c1-4944-a39f-d122de072d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-b6d4e504-dc4a-46f6-bbc2-f2314536bb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-546ea4ee-809c-4512-8fd7-946303447cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-7e7aed30-7a41-4e59-bd0c-bfdfe15f0c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-089e1f80-2021-45a7-8235-c05892c24697,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-9fe6feef-d508-409c-b80a-563f3599f0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-2bc72805-69e3-4960-9571-f9df69c3f9d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736738564-172.17.0.20-1597346256487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35061,DS-5a22c393-562f-4fc0-be4d-36ccaf22c19d,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-91e72e14-6943-4d35-bd02-027c2e76ce27,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-b842115e-16b2-4a85-bf26-867d012a16d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-7aaa510e-376f-4a88-8bce-09f71725793c,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-a8f793ea-79ff-4e24-adef-3575452f64fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-b5f8ee60-f4df-4638-b92e-557dc662a358,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-3aeeb2b9-39dd-422c-a743-82a374a571e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-a7a3ccc6-61b1-4924-959e-eab4a6601259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736738564-172.17.0.20-1597346256487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35061,DS-5a22c393-562f-4fc0-be4d-36ccaf22c19d,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-91e72e14-6943-4d35-bd02-027c2e76ce27,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-b842115e-16b2-4a85-bf26-867d012a16d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-7aaa510e-376f-4a88-8bce-09f71725793c,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-a8f793ea-79ff-4e24-adef-3575452f64fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-b5f8ee60-f4df-4638-b92e-557dc662a358,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-3aeeb2b9-39dd-422c-a743-82a374a571e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-a7a3ccc6-61b1-4924-959e-eab4a6601259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579778115-172.17.0.20-1597346443865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-a0962abc-8367-47e4-88d2-142d03a12d03,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-7abda576-c07d-4be2-b099-51d411d41c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-ad89b30b-bfcd-41e9-92ab-b0fcdb96034e,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-4a60b052-62f7-4612-a853-e917736bcdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-c98dc84f-26c0-498a-b9bd-3a80a419250e,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-33e0a8b0-9735-4d1e-9206-5bb999d5347f,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-1eed8594-14d4-4f67-8ef9-ff1f545a0459,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-29df14ce-e5da-481f-9feb-31ea8e31d7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579778115-172.17.0.20-1597346443865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-a0962abc-8367-47e4-88d2-142d03a12d03,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-7abda576-c07d-4be2-b099-51d411d41c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-ad89b30b-bfcd-41e9-92ab-b0fcdb96034e,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-4a60b052-62f7-4612-a853-e917736bcdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-c98dc84f-26c0-498a-b9bd-3a80a419250e,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-33e0a8b0-9735-4d1e-9206-5bb999d5347f,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-1eed8594-14d4-4f67-8ef9-ff1f545a0459,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-29df14ce-e5da-481f-9feb-31ea8e31d7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009530375-172.17.0.20-1597346553694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-2db8da8c-abe2-42b8-b757-18c729f2fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-7ab25a9e-a81c-4c5a-b39c-5acb6b1ed095,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-89107e96-4a7d-42ac-a38b-b425e129f579,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-a5ed839c-4603-4c89-b8a7-7b8188f55151,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-20746d93-6ee9-48a5-a948-ebc2030d60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-cf663e2b-957c-4c56-b5c5-b349b3dc1fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-fe7cd44b-900b-491f-96a0-741e67db0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-87f0e26a-ea06-4609-bc74-49ce37bb649e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009530375-172.17.0.20-1597346553694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-2db8da8c-abe2-42b8-b757-18c729f2fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-7ab25a9e-a81c-4c5a-b39c-5acb6b1ed095,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-89107e96-4a7d-42ac-a38b-b425e129f579,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-a5ed839c-4603-4c89-b8a7-7b8188f55151,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-20746d93-6ee9-48a5-a948-ebc2030d60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-cf663e2b-957c-4c56-b5c5-b349b3dc1fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-fe7cd44b-900b-491f-96a0-741e67db0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-87f0e26a-ea06-4609-bc74-49ce37bb649e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560784815-172.17.0.20-1597347020065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-6c676f6b-a92c-464c-a97c-4b2d2f528d73,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-c93aaa02-6291-4dbd-8506-9f93e6ff9008,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-d97e9615-6919-45ed-9cb4-232913e7d321,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-0b53a0e7-1b03-4207-b66b-4c14506f4b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-f9f285b6-4612-4179-b71b-0915a1161531,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-feec59b6-ef29-4e84-bca8-f15e74029a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-f26cd9e6-dd42-4a30-898a-188c192b0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-8a4ef2a6-80ef-4aa7-acb0-fca9e45e4037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560784815-172.17.0.20-1597347020065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-6c676f6b-a92c-464c-a97c-4b2d2f528d73,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-c93aaa02-6291-4dbd-8506-9f93e6ff9008,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-d97e9615-6919-45ed-9cb4-232913e7d321,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-0b53a0e7-1b03-4207-b66b-4c14506f4b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-f9f285b6-4612-4179-b71b-0915a1161531,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-feec59b6-ef29-4e84-bca8-f15e74029a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-f26cd9e6-dd42-4a30-898a-188c192b0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-8a4ef2a6-80ef-4aa7-acb0-fca9e45e4037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012924448-172.17.0.20-1597347219944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34705,DS-3c7ca818-681e-4b43-81f0-57479de2897c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-c2fa7498-1d88-4465-8a1e-1a4381ab0924,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-122b8c29-80f0-49ca-ba01-eb7f119f67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-997ad04d-f5cb-436c-bde4-d4a2c8db7d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-da400d14-bb19-4aad-ae00-59d24f9c357b,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-fed918f9-8534-4642-9564-6efab4ee1fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-042c3969-3e04-44c6-9682-caa3251388fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-f3af80fd-1556-44fd-a55e-f21f1b90e112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012924448-172.17.0.20-1597347219944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34705,DS-3c7ca818-681e-4b43-81f0-57479de2897c,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-c2fa7498-1d88-4465-8a1e-1a4381ab0924,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-122b8c29-80f0-49ca-ba01-eb7f119f67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-997ad04d-f5cb-436c-bde4-d4a2c8db7d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-da400d14-bb19-4aad-ae00-59d24f9c357b,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-fed918f9-8534-4642-9564-6efab4ee1fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-042c3969-3e04-44c6-9682-caa3251388fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-f3af80fd-1556-44fd-a55e-f21f1b90e112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517869475-172.17.0.20-1597347300096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-067f8065-2be9-4bb2-a48f-201bf0aa36f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-2fd82ce4-196f-48f1-b15c-2205396a882e,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-4252bc35-7dc4-4bb6-95d3-d8a1d6fa33e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-f86e25c0-e82d-4c19-b972-cfbd1392dbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-ab5bae71-c040-4781-b323-5cb8eb15e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-cb55caf9-ec6a-4de0-bc51-f15f4a1fb8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-a6f1651f-bf07-420c-bbfb-c58b734d7222,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-f424bbd3-7cb3-4108-a897-a312403ead1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517869475-172.17.0.20-1597347300096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-067f8065-2be9-4bb2-a48f-201bf0aa36f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-2fd82ce4-196f-48f1-b15c-2205396a882e,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-4252bc35-7dc4-4bb6-95d3-d8a1d6fa33e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-f86e25c0-e82d-4c19-b972-cfbd1392dbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-ab5bae71-c040-4781-b323-5cb8eb15e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-cb55caf9-ec6a-4de0-bc51-f15f4a1fb8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-a6f1651f-bf07-420c-bbfb-c58b734d7222,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-f424bbd3-7cb3-4108-a897-a312403ead1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 300s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333068638-172.17.0.20-1597347821595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44367,DS-276fa2fb-1023-4c5d-8f92-6031600a023b,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-76e1eddd-4763-431d-966b-99f3bc62d405,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-5d5e3676-87b2-4a85-91e0-4b42f292f672,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-c4138203-810c-4526-8fab-3127aa7c0db7,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-07c7dd82-364e-4acf-aca2-2cf042e051f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-7a4c39df-a9ea-4cca-b41d-93118dfdfdec,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-401ef1eb-0f21-4f0c-aeb4-9dff4a6c25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-91afbb70-c326-448d-bf4b-bd9f16f11c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333068638-172.17.0.20-1597347821595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44367,DS-276fa2fb-1023-4c5d-8f92-6031600a023b,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-76e1eddd-4763-431d-966b-99f3bc62d405,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-5d5e3676-87b2-4a85-91e0-4b42f292f672,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-c4138203-810c-4526-8fab-3127aa7c0db7,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-07c7dd82-364e-4acf-aca2-2cf042e051f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-7a4c39df-a9ea-4cca-b41d-93118dfdfdec,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-401ef1eb-0f21-4f0c-aeb4-9dff4a6c25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-91afbb70-c326-448d-bf4b-bd9f16f11c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5757
