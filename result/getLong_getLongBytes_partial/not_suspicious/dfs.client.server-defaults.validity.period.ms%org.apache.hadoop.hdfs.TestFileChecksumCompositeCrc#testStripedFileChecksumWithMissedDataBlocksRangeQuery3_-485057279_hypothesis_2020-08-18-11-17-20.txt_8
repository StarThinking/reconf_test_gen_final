reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500512845-172.17.0.14-1597749491984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42731,DS-d273f8a4-fde0-4c32-ad06-61b13fc22628,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-62154b8f-12b2-44be-af8f-6e584128ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-bceb6470-0e97-42bb-bcb9-29cb7f647804,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-8558a76e-bd90-4e7c-9d0a-7c81e549182a,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-6855e4eb-a942-4fc9-82dd-2f796c3360aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-6ae110c9-b67b-4be9-8fb0-4d50e2ad04b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-7f4911ac-f863-46a6-adc8-0bfc8820fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-adebc727-c6aa-4eb2-92db-78cc8e10e12b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500512845-172.17.0.14-1597749491984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42731,DS-d273f8a4-fde0-4c32-ad06-61b13fc22628,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-62154b8f-12b2-44be-af8f-6e584128ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-bceb6470-0e97-42bb-bcb9-29cb7f647804,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-8558a76e-bd90-4e7c-9d0a-7c81e549182a,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-6855e4eb-a942-4fc9-82dd-2f796c3360aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-6ae110c9-b67b-4be9-8fb0-4d50e2ad04b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-7f4911ac-f863-46a6-adc8-0bfc8820fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-adebc727-c6aa-4eb2-92db-78cc8e10e12b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339738895-172.17.0.14-1597749759679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-072ba74b-61d8-4852-9988-af3c3372ce02,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-05006759-e58e-4f13-8fa2-db2b38b725bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-2f8aeece-5ba2-41a1-88c1-361ae174814c,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-07d61bda-855d-4d0a-a762-9a3c6b6a0dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-d311e45d-7e58-46c1-a002-a17eff452856,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-384a28e3-0572-44f6-88d3-d64c81520906,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-47977343-0c56-4c8b-b730-6c4d8272af8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-0efd427f-19f4-4d45-af46-aeea2efe1586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339738895-172.17.0.14-1597749759679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-072ba74b-61d8-4852-9988-af3c3372ce02,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-05006759-e58e-4f13-8fa2-db2b38b725bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-2f8aeece-5ba2-41a1-88c1-361ae174814c,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-07d61bda-855d-4d0a-a762-9a3c6b6a0dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-d311e45d-7e58-46c1-a002-a17eff452856,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-384a28e3-0572-44f6-88d3-d64c81520906,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-47977343-0c56-4c8b-b730-6c4d8272af8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-0efd427f-19f4-4d45-af46-aeea2efe1586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659753124-172.17.0.14-1597750088225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-de517a5b-1ea3-4ab4-b5e0-55d31da4038a,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-106836ed-66f0-47cb-a94e-4e64835a53cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-c71ceaa5-c1fc-4ee9-9a5c-845a8783a586,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-56d9c8b4-87db-4f11-8885-624f169125bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-95599add-1834-4c92-81a2-e8b98f6fe8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-1f352269-276d-415e-be08-59440bc364e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-ff06f037-5f92-4956-9796-b35aba3a926a,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-8b0f0b33-bcca-41be-9c31-e91ed26868a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659753124-172.17.0.14-1597750088225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-de517a5b-1ea3-4ab4-b5e0-55d31da4038a,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-106836ed-66f0-47cb-a94e-4e64835a53cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-c71ceaa5-c1fc-4ee9-9a5c-845a8783a586,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-56d9c8b4-87db-4f11-8885-624f169125bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-95599add-1834-4c92-81a2-e8b98f6fe8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-1f352269-276d-415e-be08-59440bc364e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-ff06f037-5f92-4956-9796-b35aba3a926a,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-8b0f0b33-bcca-41be-9c31-e91ed26868a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139317191-172.17.0.14-1597750125510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45137,DS-79da3349-1472-4f45-a183-c140e5829933,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-ffcb4e79-1556-4874-9fa7-6ad270ce786e,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-b3a930fc-91fb-467d-8c45-e119eef124a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-957085df-dd55-4ced-ac6a-aaa09296403f,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-e42cfb2c-7998-4d13-94ff-859e17c95842,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-1275c872-b795-444e-abfe-be8bbded9b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-21f6ce4c-7090-4521-923d-2e02d982a169,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-172d9093-8240-4fb0-9759-64118f040dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139317191-172.17.0.14-1597750125510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45137,DS-79da3349-1472-4f45-a183-c140e5829933,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-ffcb4e79-1556-4874-9fa7-6ad270ce786e,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-b3a930fc-91fb-467d-8c45-e119eef124a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-957085df-dd55-4ced-ac6a-aaa09296403f,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-e42cfb2c-7998-4d13-94ff-859e17c95842,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-1275c872-b795-444e-abfe-be8bbded9b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-21f6ce4c-7090-4521-923d-2e02d982a169,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-172d9093-8240-4fb0-9759-64118f040dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170952698-172.17.0.14-1597750519860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35179,DS-1581c43d-d01b-468b-a68e-2fe42495f653,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-91bfaeab-4400-4b7a-8ed9-4ee8eae8c7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-c28664c9-b595-4de4-b446-6cff4a3af80a,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-24bb6d95-b76e-440b-9669-b108df26f216,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-344c2294-6014-49c3-be58-ff3da09a5908,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-7f933f54-8a9b-4b2a-8a69-e8c216c3732b,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-23f3f8e1-7d99-48dc-a59a-9ca3216743d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-2f979a9e-dbba-4df7-9e8b-23288f966fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170952698-172.17.0.14-1597750519860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35179,DS-1581c43d-d01b-468b-a68e-2fe42495f653,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-91bfaeab-4400-4b7a-8ed9-4ee8eae8c7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-c28664c9-b595-4de4-b446-6cff4a3af80a,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-24bb6d95-b76e-440b-9669-b108df26f216,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-344c2294-6014-49c3-be58-ff3da09a5908,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-7f933f54-8a9b-4b2a-8a69-e8c216c3732b,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-23f3f8e1-7d99-48dc-a59a-9ca3216743d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-2f979a9e-dbba-4df7-9e8b-23288f966fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382443650-172.17.0.14-1597750662330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-2c463825-1ca1-4a41-84d7-f9fa47a28ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-e47095e9-8f79-4d2b-8ee9-661170b092be,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-7c94389f-af14-4870-b799-159da0fecfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-2c1eb68d-4fd6-4a7a-a18d-3295b1adc98c,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-22b3bcc2-86b7-4004-9d39-727364cb3ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-b34a0b26-e6e2-4eab-adc2-bfd864f60b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-adc6d4f7-2859-4ed0-b77e-6fb7d33f84b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-06d38242-a411-4b41-aebd-1be3e0f0f88e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382443650-172.17.0.14-1597750662330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-2c463825-1ca1-4a41-84d7-f9fa47a28ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-e47095e9-8f79-4d2b-8ee9-661170b092be,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-7c94389f-af14-4870-b799-159da0fecfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-2c1eb68d-4fd6-4a7a-a18d-3295b1adc98c,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-22b3bcc2-86b7-4004-9d39-727364cb3ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-b34a0b26-e6e2-4eab-adc2-bfd864f60b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-adc6d4f7-2859-4ed0-b77e-6fb7d33f84b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-06d38242-a411-4b41-aebd-1be3e0f0f88e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130058777-172.17.0.14-1597750996953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-336bdaca-0053-4c8e-a2ee-27ee3b9293b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-34cb04e5-3d4e-4c91-9396-b25d2dc0e4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-ca6d0b4d-1511-4fe1-8e19-07cfb56abb38,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-fe6b3f7c-2a84-4b46-b0b0-ad81edac3142,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-359b4cb7-80ad-4b6a-ba16-05cf43ae6a98,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-b24f88ee-5cee-4242-b94d-a2a68767d440,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-f09f4b8d-5a2e-4e4b-80b4-174e5099295f,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-e6433e0f-5d82-4bd8-824f-a855f4468a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130058777-172.17.0.14-1597750996953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-336bdaca-0053-4c8e-a2ee-27ee3b9293b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-34cb04e5-3d4e-4c91-9396-b25d2dc0e4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-ca6d0b4d-1511-4fe1-8e19-07cfb56abb38,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-fe6b3f7c-2a84-4b46-b0b0-ad81edac3142,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-359b4cb7-80ad-4b6a-ba16-05cf43ae6a98,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-b24f88ee-5cee-4242-b94d-a2a68767d440,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-f09f4b8d-5a2e-4e4b-80b4-174e5099295f,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-e6433e0f-5d82-4bd8-824f-a855f4468a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11241458-172.17.0.14-1597751338092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43275,DS-909b3249-138e-431c-a4b7-c7ef7a9b529f,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-9655245a-d4c0-4f98-98b3-4781472201d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-29ff0e53-63a7-46f1-9abd-ebc302897e78,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-35c5a1b0-be70-4117-a11a-dd0d435e28f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-79268da5-3c57-42f9-a0b5-f8e9764a9677,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-26c7da4f-557d-492a-a563-42fd803877ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-502af241-b6fa-4979-9844-dc19889e8115,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-28b934b4-6382-467e-97a3-1bfaadf3acce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11241458-172.17.0.14-1597751338092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43275,DS-909b3249-138e-431c-a4b7-c7ef7a9b529f,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-9655245a-d4c0-4f98-98b3-4781472201d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-29ff0e53-63a7-46f1-9abd-ebc302897e78,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-35c5a1b0-be70-4117-a11a-dd0d435e28f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-79268da5-3c57-42f9-a0b5-f8e9764a9677,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-26c7da4f-557d-492a-a563-42fd803877ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-502af241-b6fa-4979-9844-dc19889e8115,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-28b934b4-6382-467e-97a3-1bfaadf3acce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493216108-172.17.0.14-1597751531472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39125,DS-dd9c05f7-6b8f-4801-a654-06dad23ca2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-844528ca-3600-4c06-98d2-11dc774b8cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-bd929fe4-a490-4f46-9418-0690db0d8754,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-c57090b0-a30e-40aa-bc30-685b65939dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-cd70a3d7-70cf-4082-b9a6-727e2fecfe11,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-73d6f3cd-7d67-4f2e-8cca-a5f3854dec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-b9061a1d-d15f-4e9f-aac5-b40309292988,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-157177cf-7558-4480-91d7-f109be4fbfc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493216108-172.17.0.14-1597751531472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39125,DS-dd9c05f7-6b8f-4801-a654-06dad23ca2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-844528ca-3600-4c06-98d2-11dc774b8cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-bd929fe4-a490-4f46-9418-0690db0d8754,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-c57090b0-a30e-40aa-bc30-685b65939dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-cd70a3d7-70cf-4082-b9a6-727e2fecfe11,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-73d6f3cd-7d67-4f2e-8cca-a5f3854dec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-b9061a1d-d15f-4e9f-aac5-b40309292988,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-157177cf-7558-4480-91d7-f109be4fbfc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756702624-172.17.0.14-1597751749017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36616,DS-534076a0-08c4-4510-836d-e10bf1879d68,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-1443c727-3682-4b74-9373-4aa7c6a8e330,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-3468e996-f977-4d50-b62d-483ffa260db5,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-564dd5c1-d1be-4420-9178-4d8a7226e662,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-effad326-afb9-416a-b12e-797fffce8a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-22c5a692-6ddc-44bf-93ca-d823ad0264bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-bc930c70-e7cb-46c5-a294-5c729bf76797,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-3fbd5755-2455-49be-a292-15f45ae9798d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756702624-172.17.0.14-1597751749017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36616,DS-534076a0-08c4-4510-836d-e10bf1879d68,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-1443c727-3682-4b74-9373-4aa7c6a8e330,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-3468e996-f977-4d50-b62d-483ffa260db5,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-564dd5c1-d1be-4420-9178-4d8a7226e662,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-effad326-afb9-416a-b12e-797fffce8a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-22c5a692-6ddc-44bf-93ca-d823ad0264bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-bc930c70-e7cb-46c5-a294-5c729bf76797,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-3fbd5755-2455-49be-a292-15f45ae9798d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227065258-172.17.0.14-1597751934354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40907,DS-53e94d87-da07-4e4b-93e6-edbeddb600b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-000d7062-4fde-43ea-8622-c811fd1ed70b,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-6b9923e9-1ed8-4f0c-b30c-de10e04c876f,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-c1e69e33-b79a-4da7-9afb-e18290ebb198,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-2e78a18a-9fb2-4f5d-9430-9fe173e539a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-3ac2183a-37c9-41aa-a25a-d6a2c0df7bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-5d9b64b2-2c76-4c63-92c5-a1b9a0ce6e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-7e111879-b848-4965-90e5-b51988c51712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227065258-172.17.0.14-1597751934354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40907,DS-53e94d87-da07-4e4b-93e6-edbeddb600b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-000d7062-4fde-43ea-8622-c811fd1ed70b,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-6b9923e9-1ed8-4f0c-b30c-de10e04c876f,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-c1e69e33-b79a-4da7-9afb-e18290ebb198,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-2e78a18a-9fb2-4f5d-9430-9fe173e539a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-3ac2183a-37c9-41aa-a25a-d6a2c0df7bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-5d9b64b2-2c76-4c63-92c5-a1b9a0ce6e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-7e111879-b848-4965-90e5-b51988c51712,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533810787-172.17.0.14-1597752113980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-102df8b8-75fa-4834-bf56-7f8502610781,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-95aaa1b5-f830-40ff-966b-fae3fbabf276,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-8603a748-4d9a-44c9-ab64-fba36de44e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-03105519-fb94-4168-9e14-38e35930ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-f1814e67-c4f5-4ac4-8612-43514d30ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-a617450c-5226-45a8-b38e-490a5bfb88ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-f87d6d14-7da7-4b2d-8ee3-16b054e7dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-f297764c-51f5-4ec3-b6c2-36485648d56b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533810787-172.17.0.14-1597752113980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38673,DS-102df8b8-75fa-4834-bf56-7f8502610781,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-95aaa1b5-f830-40ff-966b-fae3fbabf276,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-8603a748-4d9a-44c9-ab64-fba36de44e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-03105519-fb94-4168-9e14-38e35930ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-f1814e67-c4f5-4ac4-8612-43514d30ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-a617450c-5226-45a8-b38e-490a5bfb88ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-f87d6d14-7da7-4b2d-8ee3-16b054e7dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-f297764c-51f5-4ec3-b6c2-36485648d56b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614080617-172.17.0.14-1597752553805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-15ebe3c3-2b9c-45b7-8a95-58323e54645b,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-47f2f2c0-ee66-4a2c-b340-053a9ffe5ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-3d993daa-e57f-4fe9-8eb3-1a584e415ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-748723a9-6d9b-40c5-912f-b713b7e1a8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-72a0a663-71bb-4867-bbb7-9bfab642e0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-9c9e8df4-d798-4ec4-a670-16fae6c83ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-89d49b7e-58d2-4182-9792-3cc0d6be72e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-776d5b74-8ef5-4a16-a162-96b130acd8f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614080617-172.17.0.14-1597752553805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-15ebe3c3-2b9c-45b7-8a95-58323e54645b,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-47f2f2c0-ee66-4a2c-b340-053a9ffe5ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-3d993daa-e57f-4fe9-8eb3-1a584e415ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-748723a9-6d9b-40c5-912f-b713b7e1a8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-72a0a663-71bb-4867-bbb7-9bfab642e0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-9c9e8df4-d798-4ec4-a670-16fae6c83ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-89d49b7e-58d2-4182-9792-3cc0d6be72e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-776d5b74-8ef5-4a16-a162-96b130acd8f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835197746-172.17.0.14-1597753211754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-86d7c19b-9bf6-41dc-a032-45981db3d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-87fc1174-ea99-40e2-add7-004966f0dcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-8af7168b-73f9-4c02-9b30-bd9424a3af63,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-0c9e3fb6-855c-4236-afed-df8f38e90b34,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-f7b99eb1-41ad-4339-b727-dc8a4e115ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-45db9286-e11d-41df-a2de-4d8f0ae67a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-636b19f3-c337-47b5-a19b-17b47d32172c,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-bf15d603-3790-4c39-81b8-073e5a37a8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835197746-172.17.0.14-1597753211754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-86d7c19b-9bf6-41dc-a032-45981db3d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-87fc1174-ea99-40e2-add7-004966f0dcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-8af7168b-73f9-4c02-9b30-bd9424a3af63,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-0c9e3fb6-855c-4236-afed-df8f38e90b34,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-f7b99eb1-41ad-4339-b727-dc8a4e115ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-45db9286-e11d-41df-a2de-4d8f0ae67a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-636b19f3-c337-47b5-a19b-17b47d32172c,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-bf15d603-3790-4c39-81b8-073e5a37a8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982385753-172.17.0.14-1597753772208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-eff6957d-0fb0-4923-bf5f-aa3ab75dbba9,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-323824a8-2d0d-4e39-b74f-c0ca9b902ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-8d050ef9-fa0b-4bb8-97cd-3037f3b797c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-f6560c41-0465-48c1-9cec-f063f645c03e,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-8784f2c8-39ba-4727-880a-c57ee9e0a41e,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-924da173-8c11-42c7-862b-6df1cdf88939,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-2311e0bb-b46d-42c4-a66e-96522b0f5eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-428d4797-34f6-421e-b70e-46ea5ee6d9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982385753-172.17.0.14-1597753772208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-eff6957d-0fb0-4923-bf5f-aa3ab75dbba9,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-323824a8-2d0d-4e39-b74f-c0ca9b902ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-8d050ef9-fa0b-4bb8-97cd-3037f3b797c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-f6560c41-0465-48c1-9cec-f063f645c03e,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-8784f2c8-39ba-4727-880a-c57ee9e0a41e,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-924da173-8c11-42c7-862b-6df1cdf88939,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-2311e0bb-b46d-42c4-a66e-96522b0f5eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-428d4797-34f6-421e-b70e-46ea5ee6d9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139640601-172.17.0.14-1597754932421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45758,DS-25111c25-55c1-4368-8494-4e830afec6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-0f2008fe-4f0b-475f-bbc0-28d624626850,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-aadebab5-c8c6-4284-9d68-2343d1fa89e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-0bb0578c-1f45-46f6-a958-e3d5d5a6fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-7dc73995-e19b-4a5c-a5f9-8660013b431f,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-2d65b015-8eb3-4569-b3d5-b99d02277eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-5b3cd577-289b-4a7f-8096-2951b1a3c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-6bc525c6-bf0f-48b0-9715-2f8cec307833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139640601-172.17.0.14-1597754932421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45758,DS-25111c25-55c1-4368-8494-4e830afec6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-0f2008fe-4f0b-475f-bbc0-28d624626850,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-aadebab5-c8c6-4284-9d68-2343d1fa89e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-0bb0578c-1f45-46f6-a958-e3d5d5a6fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-7dc73995-e19b-4a5c-a5f9-8660013b431f,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-2d65b015-8eb3-4569-b3d5-b99d02277eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-5b3cd577-289b-4a7f-8096-2951b1a3c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-6bc525c6-bf0f-48b0-9715-2f8cec307833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5546
