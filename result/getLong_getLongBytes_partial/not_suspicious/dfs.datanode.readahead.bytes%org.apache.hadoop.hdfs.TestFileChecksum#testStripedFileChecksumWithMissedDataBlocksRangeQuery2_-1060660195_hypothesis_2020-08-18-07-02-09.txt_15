reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551309728-172.17.0.3-1597734635021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-cf2114e2-775b-458a-970e-3e8b3a5929be,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-3cf237b4-96e9-4837-b1d7-537e3770606c,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-e96c67f7-0895-4375-8d19-0137dc80983a,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-fed90534-b881-4b9f-a3fb-31eba75e11ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-559df73d-e9aa-47b2-a229-e267a3360ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-77e6cf95-1d57-4cdc-ae60-8e15f94afb04,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-bf9e2ea7-5911-4e5f-836f-9e354f5b19ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-72b0fc95-0d63-44c7-b7da-8924df4cd493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551309728-172.17.0.3-1597734635021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-cf2114e2-775b-458a-970e-3e8b3a5929be,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-3cf237b4-96e9-4837-b1d7-537e3770606c,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-e96c67f7-0895-4375-8d19-0137dc80983a,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-fed90534-b881-4b9f-a3fb-31eba75e11ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-559df73d-e9aa-47b2-a229-e267a3360ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-77e6cf95-1d57-4cdc-ae60-8e15f94afb04,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-bf9e2ea7-5911-4e5f-836f-9e354f5b19ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-72b0fc95-0d63-44c7-b7da-8924df4cd493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506306805-172.17.0.3-1597734743487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-b88ae8b2-92c4-4e72-b42d-708c5c58a625,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-ce6c8153-3f71-4078-8557-8dadca16c807,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-37fb2a0a-5ed5-4da6-9875-cf39be9fc417,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-7ac0a02b-685c-48c3-8d2f-dd4a9e65bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-898f40ee-fbdb-4bcb-a26e-2ee2046fc56e,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-ba4daf5d-c73f-4b92-a5df-d3588dd8f5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-e924c70e-b204-4f14-8ea8-14e230f12e73,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-66003f65-2360-4a9c-85ee-717d6711aa4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506306805-172.17.0.3-1597734743487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-b88ae8b2-92c4-4e72-b42d-708c5c58a625,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-ce6c8153-3f71-4078-8557-8dadca16c807,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-37fb2a0a-5ed5-4da6-9875-cf39be9fc417,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-7ac0a02b-685c-48c3-8d2f-dd4a9e65bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-898f40ee-fbdb-4bcb-a26e-2ee2046fc56e,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-ba4daf5d-c73f-4b92-a5df-d3588dd8f5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-e924c70e-b204-4f14-8ea8-14e230f12e73,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-66003f65-2360-4a9c-85ee-717d6711aa4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29670802-172.17.0.3-1597735254183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-6594d031-a52b-4cd2-8c04-08729ea79293,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-ae9e9ac6-7bbf-4289-aedf-184ecf9f6dff,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-2c08d545-eb00-41f5-9467-cb3447069a58,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-5b556cf3-b42f-46d1-a0ef-d4e10a78cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-1758f78d-4a83-41ff-9a23-bf5866fb37f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-4c50c181-53d9-41e4-a539-01382a0f72b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-19274d08-42be-4a18-8f62-d50c34b6fbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-4b207906-5a87-4b91-b4e2-379454fa9316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29670802-172.17.0.3-1597735254183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38295,DS-6594d031-a52b-4cd2-8c04-08729ea79293,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-ae9e9ac6-7bbf-4289-aedf-184ecf9f6dff,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-2c08d545-eb00-41f5-9467-cb3447069a58,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-5b556cf3-b42f-46d1-a0ef-d4e10a78cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-1758f78d-4a83-41ff-9a23-bf5866fb37f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-4c50c181-53d9-41e4-a539-01382a0f72b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-19274d08-42be-4a18-8f62-d50c34b6fbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-4b207906-5a87-4b91-b4e2-379454fa9316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636284291-172.17.0.3-1597735472822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-f0178271-ec19-4a45-abac-cffdd0d8b933,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-674b094a-fbaf-4a90-aff4-a1f594fd2b45,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-45700dd3-c4c8-4816-81fe-f4fbe923edcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-7ccfc42c-57af-4947-86c2-647f6139a140,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-bb101c23-7d47-44bc-ae76-b3c735ed83ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-b1b59730-87cf-4317-a578-72cdbff3ba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-f5c96cb9-7e0e-41bc-a94b-3b9c566d1b62,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-0ed1fb5e-5b87-4459-91dd-2542e7b8e624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636284291-172.17.0.3-1597735472822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-f0178271-ec19-4a45-abac-cffdd0d8b933,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-674b094a-fbaf-4a90-aff4-a1f594fd2b45,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-45700dd3-c4c8-4816-81fe-f4fbe923edcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-7ccfc42c-57af-4947-86c2-647f6139a140,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-bb101c23-7d47-44bc-ae76-b3c735ed83ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-b1b59730-87cf-4317-a578-72cdbff3ba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-f5c96cb9-7e0e-41bc-a94b-3b9c566d1b62,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-0ed1fb5e-5b87-4459-91dd-2542e7b8e624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210440458-172.17.0.3-1597735636469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-647c5c0e-dc32-4f3d-8614-e49b0c474200,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-f1572008-8654-46d7-8d1b-7cabf9b1302c,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-c5b7ed91-e26e-431b-a85d-527a659a15f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-4f991ee1-1da0-4f8d-a3a1-dea5fbad4e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-4e5b620b-1694-4def-ac04-74f1d2741c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-376b0bff-fef8-43f6-adba-a6901ab18755,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-66488d4b-5f61-46db-9ef4-3abaae318130,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-998348c7-6b39-4b89-a0d6-c803c9bd6766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210440458-172.17.0.3-1597735636469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34826,DS-647c5c0e-dc32-4f3d-8614-e49b0c474200,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-f1572008-8654-46d7-8d1b-7cabf9b1302c,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-c5b7ed91-e26e-431b-a85d-527a659a15f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-4f991ee1-1da0-4f8d-a3a1-dea5fbad4e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-4e5b620b-1694-4def-ac04-74f1d2741c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-376b0bff-fef8-43f6-adba-a6901ab18755,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-66488d4b-5f61-46db-9ef4-3abaae318130,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-998348c7-6b39-4b89-a0d6-c803c9bd6766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342640140-172.17.0.3-1597735856847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39439,DS-7d4e6626-b3e7-4a51-b4f1-7f4f9b29f88c,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-a4306e79-5d95-451e-817b-197919c90234,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-d7e92063-e267-4359-865f-47dfaffa16b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-25b3c5bf-14d3-4bc2-b04b-db03a9e7e541,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-89877188-e367-48c9-bf55-13cdfbb216f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-6d34b67c-c91b-465d-b0e6-7ef230aefc17,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-5d3d1c1c-8f3f-4ccb-bcc5-dacc21bf08fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-d0aae58e-9001-4f26-863d-12c1ee97f4e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342640140-172.17.0.3-1597735856847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39439,DS-7d4e6626-b3e7-4a51-b4f1-7f4f9b29f88c,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-a4306e79-5d95-451e-817b-197919c90234,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-d7e92063-e267-4359-865f-47dfaffa16b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-25b3c5bf-14d3-4bc2-b04b-db03a9e7e541,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-89877188-e367-48c9-bf55-13cdfbb216f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-6d34b67c-c91b-465d-b0e6-7ef230aefc17,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-5d3d1c1c-8f3f-4ccb-bcc5-dacc21bf08fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-d0aae58e-9001-4f26-863d-12c1ee97f4e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895250827-172.17.0.3-1597735928163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-04e41ce5-c255-46bb-845b-f7fa4fa8f456,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-b3cd7908-163c-4874-b34a-5a2757b6b203,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-1cfefcc2-6742-4482-b8d4-7563a4c84dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-60d48994-e140-40c0-826d-1bd990b9772b,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-6f4010e4-761d-432a-9dae-3cdc0d8658e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-40f8610b-78b9-463a-b843-9e5f12dc8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-3d77ec18-0653-4c30-ae92-a98dbaeba225,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-ead195bf-dd55-4c13-98ad-231bbd1e1271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895250827-172.17.0.3-1597735928163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-04e41ce5-c255-46bb-845b-f7fa4fa8f456,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-b3cd7908-163c-4874-b34a-5a2757b6b203,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-1cfefcc2-6742-4482-b8d4-7563a4c84dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-60d48994-e140-40c0-826d-1bd990b9772b,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-6f4010e4-761d-432a-9dae-3cdc0d8658e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-40f8610b-78b9-463a-b843-9e5f12dc8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-3d77ec18-0653-4c30-ae92-a98dbaeba225,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-ead195bf-dd55-4c13-98ad-231bbd1e1271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857558234-172.17.0.3-1597736077546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34623,DS-55b7ec69-c0da-4a3b-82f0-69561093b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-3c20b160-d089-4603-9db3-ef3c6f773abc,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-4c05268a-10dc-4c22-9def-410453aae74e,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-7aef97d0-74bd-4f42-8c0b-9e5acdca9e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-47bafdfb-52b3-4961-bd7b-8e60f33f12a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-5f681581-e77c-41d6-bafa-da032eac4498,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-74c57101-04ba-45d6-b0f6-0d7be0eff9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-130e6275-c866-43b8-a7be-0b60830c871d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857558234-172.17.0.3-1597736077546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34623,DS-55b7ec69-c0da-4a3b-82f0-69561093b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-3c20b160-d089-4603-9db3-ef3c6f773abc,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-4c05268a-10dc-4c22-9def-410453aae74e,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-7aef97d0-74bd-4f42-8c0b-9e5acdca9e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-47bafdfb-52b3-4961-bd7b-8e60f33f12a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-5f681581-e77c-41d6-bafa-da032eac4498,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-74c57101-04ba-45d6-b0f6-0d7be0eff9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-130e6275-c866-43b8-a7be-0b60830c871d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178603471-172.17.0.3-1597736227903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-aef9b176-1b27-4fdb-8d11-d22326fd404d,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-5ccca76c-7122-4665-8cb7-1af8ebd1afb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-ff36ade4-2a31-46c9-a593-9cbeaf480f81,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-d65b3ec2-1c20-41e7-aff9-071d86162852,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-d4a82b8e-c70a-4fde-8e42-96e739e308eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-c4b4d197-5a4b-423b-a4c7-9629d82189a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-f5326101-e778-415c-aa9c-26140c1cabff,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-40adc940-8cc1-49d8-b1cd-37d260dce1f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178603471-172.17.0.3-1597736227903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-aef9b176-1b27-4fdb-8d11-d22326fd404d,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-5ccca76c-7122-4665-8cb7-1af8ebd1afb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-ff36ade4-2a31-46c9-a593-9cbeaf480f81,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-d65b3ec2-1c20-41e7-aff9-071d86162852,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-d4a82b8e-c70a-4fde-8e42-96e739e308eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-c4b4d197-5a4b-423b-a4c7-9629d82189a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-f5326101-e778-415c-aa9c-26140c1cabff,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-40adc940-8cc1-49d8-b1cd-37d260dce1f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408851467-172.17.0.3-1597736375196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34024,DS-f883190a-5e95-42d9-be34-af8f7a210b84,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-abd36c0a-5fd6-47a6-b287-6ff94e8eafef,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-e7762021-9b21-497a-9e3c-d2fd2b97f052,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-c6d638d3-f7f0-43d2-8bcb-84af32cebba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-76b7f8c2-0421-41bf-b671-a93edb97cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-f293045a-5bfb-49e1-8b6c-2a845f37f650,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-cc50df31-7e6d-4116-84ed-8ad32b9ff41f,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-c9e6f321-a803-45b9-8107-0bb31b1ff7e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408851467-172.17.0.3-1597736375196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34024,DS-f883190a-5e95-42d9-be34-af8f7a210b84,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-abd36c0a-5fd6-47a6-b287-6ff94e8eafef,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-e7762021-9b21-497a-9e3c-d2fd2b97f052,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-c6d638d3-f7f0-43d2-8bcb-84af32cebba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-76b7f8c2-0421-41bf-b671-a93edb97cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-f293045a-5bfb-49e1-8b6c-2a845f37f650,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-cc50df31-7e6d-4116-84ed-8ad32b9ff41f,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-c9e6f321-a803-45b9-8107-0bb31b1ff7e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5785277-172.17.0.3-1597736924516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39320,DS-de97c3ab-6b83-48d4-8d5a-3dae250e3e77,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-b8e3913b-18c0-4645-8daf-c38ea10f0088,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-c351ef92-46a4-4919-b927-8483b27542c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-58dfa5a1-219f-4c30-820f-8d6a8aea4345,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-f03d2ad2-725d-405d-94a4-5e64e14c01da,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-8910fae0-f64c-473d-ac2f-2b72150d88ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-e156a86d-1de6-484a-a19a-2b51d5429480,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-1cc5d66d-9e0f-489a-b754-c721588afc26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5785277-172.17.0.3-1597736924516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39320,DS-de97c3ab-6b83-48d4-8d5a-3dae250e3e77,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-b8e3913b-18c0-4645-8daf-c38ea10f0088,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-c351ef92-46a4-4919-b927-8483b27542c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-58dfa5a1-219f-4c30-820f-8d6a8aea4345,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-f03d2ad2-725d-405d-94a4-5e64e14c01da,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-8910fae0-f64c-473d-ac2f-2b72150d88ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-e156a86d-1de6-484a-a19a-2b51d5429480,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-1cc5d66d-9e0f-489a-b754-c721588afc26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166062710-172.17.0.3-1597738063304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-cf1d319a-2f34-4b77-a775-84c52fa64225,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-e166f16f-eee7-4dc3-b826-0d72e1cdb544,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-fc39149d-ac54-4059-bda2-3d164755c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-e1802b0a-1d2f-44c0-be34-21068dd84f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-d79b720c-5b13-4049-8160-f0f41513dc35,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-04cf0176-f332-4ebe-b8e2-ddf387cc3660,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-2bcc5a73-09e4-4734-93f2-5f302c2cd1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-96f54c0c-5032-4de8-ab2a-91052812e704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166062710-172.17.0.3-1597738063304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43893,DS-cf1d319a-2f34-4b77-a775-84c52fa64225,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-e166f16f-eee7-4dc3-b826-0d72e1cdb544,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-fc39149d-ac54-4059-bda2-3d164755c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-e1802b0a-1d2f-44c0-be34-21068dd84f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-d79b720c-5b13-4049-8160-f0f41513dc35,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-04cf0176-f332-4ebe-b8e2-ddf387cc3660,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-2bcc5a73-09e4-4734-93f2-5f302c2cd1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-96f54c0c-5032-4de8-ab2a-91052812e704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373047099-172.17.0.3-1597738176661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-810f3d09-320f-413a-8644-4a1975e844a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-fb12c452-942c-4c35-b3c9-bdc215c9cd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-f811d664-50f1-49b6-8d1f-d94767db0c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-cbb5c060-3890-4d3e-9598-187036a35c02,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-b308b08a-0a24-489a-b7f0-632a0d528cba,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-cb805c88-c09c-4b1e-8811-92e3331f1fba,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-fa63ad77-6244-435e-8f1e-38efef332b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-c38b8a66-f73b-406e-9b20-b15887ba0954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373047099-172.17.0.3-1597738176661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-810f3d09-320f-413a-8644-4a1975e844a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-fb12c452-942c-4c35-b3c9-bdc215c9cd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-f811d664-50f1-49b6-8d1f-d94767db0c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-cbb5c060-3890-4d3e-9598-187036a35c02,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-b308b08a-0a24-489a-b7f0-632a0d528cba,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-cb805c88-c09c-4b1e-8811-92e3331f1fba,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-fa63ad77-6244-435e-8f1e-38efef332b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-c38b8a66-f73b-406e-9b20-b15887ba0954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575672288-172.17.0.3-1597738516269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41712,DS-e0a15e4c-0ee1-49f8-bfda-beca12f82f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-2b8cd80f-07aa-4eba-a181-71b515722737,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-4076faff-57a1-4ae8-baa3-50715a8af95b,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-ba8a6e16-bcce-448a-b70c-4148f121384e,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-415503b7-a655-490d-8c26-fd0a6cbcae24,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-6f74fca6-3fb7-41ad-b4cf-c47a8bd1aaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-b1aa55c1-874e-48b2-825b-0b8086857ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-17adb498-da69-4076-bd4f-dc63166ed81f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575672288-172.17.0.3-1597738516269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41712,DS-e0a15e4c-0ee1-49f8-bfda-beca12f82f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-2b8cd80f-07aa-4eba-a181-71b515722737,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-4076faff-57a1-4ae8-baa3-50715a8af95b,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-ba8a6e16-bcce-448a-b70c-4148f121384e,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-415503b7-a655-490d-8c26-fd0a6cbcae24,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-6f74fca6-3fb7-41ad-b4cf-c47a8bd1aaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-b1aa55c1-874e-48b2-825b-0b8086857ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-17adb498-da69-4076-bd4f-dc63166ed81f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840363789-172.17.0.3-1597738555223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-29e248d6-8ae1-44ec-ab9c-f42d44fd1a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-1aa39457-9186-47d5-9fad-c52f63923d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-434e6ba6-79d4-43bb-9e13-7e0d9d49a0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-9c39187a-37ef-4a44-a637-6294602fb8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-691896b3-51f9-48b9-8be8-5ef6a8b17020,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-41a80e6c-b92a-4f54-8fa7-d6b3bc69f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-0c82d80b-17b5-409d-80ff-b4907f1fa1df,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-7ff3412d-97d1-4fd1-9241-775fd4384f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840363789-172.17.0.3-1597738555223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-29e248d6-8ae1-44ec-ab9c-f42d44fd1a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-1aa39457-9186-47d5-9fad-c52f63923d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-434e6ba6-79d4-43bb-9e13-7e0d9d49a0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-9c39187a-37ef-4a44-a637-6294602fb8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-691896b3-51f9-48b9-8be8-5ef6a8b17020,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-41a80e6c-b92a-4f54-8fa7-d6b3bc69f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-0c82d80b-17b5-409d-80ff-b4907f1fa1df,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-7ff3412d-97d1-4fd1-9241-775fd4384f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267224195-172.17.0.3-1597738618245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-3113c63b-f960-431b-9784-270b6faf20b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-f5b1d03b-7db6-40e1-8770-e5977d44012b,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-56182ce7-b97d-4772-aeb4-f6b888140b56,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-9fe937a8-35a5-40fb-bb99-77be5f10c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-8dca97ca-fe16-48f3-8969-6f2fce00dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-2e88ee35-a17a-4388-8c00-ccb77c625c08,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-2c6e5354-f38d-48d0-b15b-39f50ab224d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-2845cfd3-fbdf-434f-83a6-246515f0713c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267224195-172.17.0.3-1597738618245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-3113c63b-f960-431b-9784-270b6faf20b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-f5b1d03b-7db6-40e1-8770-e5977d44012b,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-56182ce7-b97d-4772-aeb4-f6b888140b56,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-9fe937a8-35a5-40fb-bb99-77be5f10c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-8dca97ca-fe16-48f3-8969-6f2fce00dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-2e88ee35-a17a-4388-8c00-ccb77c625c08,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-2c6e5354-f38d-48d0-b15b-39f50ab224d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-2845cfd3-fbdf-434f-83a6-246515f0713c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910066781-172.17.0.3-1597738769574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34232,DS-f793911b-1dce-4046-a610-0352b3c907de,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-f72f75a9-79ac-4343-a63a-90fb4db05f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-98909d59-c1f3-4fdf-b422-333b1cab8271,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-7a75f308-2110-4ee1-9cd8-fe47bee1c101,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-966b575e-3a76-4761-b0e1-bc32e17627fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-ad7fe75f-fd7e-40bc-af03-e4f524948a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-5c361643-4642-42d3-a53e-2cad405fe23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-37929252-c002-4feb-a636-c9f01f1a6c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910066781-172.17.0.3-1597738769574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34232,DS-f793911b-1dce-4046-a610-0352b3c907de,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-f72f75a9-79ac-4343-a63a-90fb4db05f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-98909d59-c1f3-4fdf-b422-333b1cab8271,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-7a75f308-2110-4ee1-9cd8-fe47bee1c101,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-966b575e-3a76-4761-b0e1-bc32e17627fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-ad7fe75f-fd7e-40bc-af03-e4f524948a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-5c361643-4642-42d3-a53e-2cad405fe23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-37929252-c002-4feb-a636-c9f01f1a6c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7346185-172.17.0.3-1597738809030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-27cee067-193c-430f-aada-50fc97761431,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-db039154-545d-47ea-9cad-4ca6afe0b166,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-8d585e36-db7f-4fac-b567-6a3c0893605e,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-4078462b-6a2b-47a9-9a3f-f2511af4010c,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-0494a66f-ac1a-4649-8647-67d03d126f54,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-1f1fe55f-b2c2-4caf-90f0-494c45a8a6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-27a1ee03-8f93-41be-8d64-352119a1a807,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-7472a2d1-589b-4187-b8b1-4a85883d0532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7346185-172.17.0.3-1597738809030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-27cee067-193c-430f-aada-50fc97761431,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-db039154-545d-47ea-9cad-4ca6afe0b166,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-8d585e36-db7f-4fac-b567-6a3c0893605e,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-4078462b-6a2b-47a9-9a3f-f2511af4010c,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-0494a66f-ac1a-4649-8647-67d03d126f54,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-1f1fe55f-b2c2-4caf-90f0-494c45a8a6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-27a1ee03-8f93-41be-8d64-352119a1a807,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-7472a2d1-589b-4187-b8b1-4a85883d0532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045080233-172.17.0.3-1597738848286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-a6455700-77fa-4cd5-be31-767acd35bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-6eb55ed2-12b0-452b-9375-0455f23c0b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-3f564325-3294-4a1d-a243-58c8ebb9ec13,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-52f1b1a7-fbf4-4db3-b024-6368b6b6ad51,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-6d37b6eb-7717-4916-aeb9-e339bc2c993b,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-45c4228d-8d10-453e-a77b-7953b055f9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-29468760-f905-47ca-b9d2-5c1f76ae1324,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-070c63d6-f9bf-4722-8a90-8bf84d9a5cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045080233-172.17.0.3-1597738848286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-a6455700-77fa-4cd5-be31-767acd35bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-6eb55ed2-12b0-452b-9375-0455f23c0b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-3f564325-3294-4a1d-a243-58c8ebb9ec13,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-52f1b1a7-fbf4-4db3-b024-6368b6b6ad51,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-6d37b6eb-7717-4916-aeb9-e339bc2c993b,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-45c4228d-8d10-453e-a77b-7953b055f9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-29468760-f905-47ca-b9d2-5c1f76ae1324,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-070c63d6-f9bf-4722-8a90-8bf84d9a5cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5572
