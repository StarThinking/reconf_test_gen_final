reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202458914-172.17.0.17-1597721756464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36453,DS-35555930-f148-4206-970c-bb6491c9eff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-1831ae5b-5c5f-4be1-9705-6d66c779a269,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-15b083d5-5a8e-4787-8c87-036b014fa7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-54895bbb-aaf1-4749-a2e8-9f5728cd5753,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-0fd465aa-4008-4036-9208-6223fcfb8e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-4ab43699-0d47-4338-bb5b-080b7ca3f31a,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-e0b8ccef-0335-42ca-a1af-95e480040ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-994b2e2e-95bb-4067-bab1-2452c28bcbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202458914-172.17.0.17-1597721756464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36453,DS-35555930-f148-4206-970c-bb6491c9eff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-1831ae5b-5c5f-4be1-9705-6d66c779a269,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-15b083d5-5a8e-4787-8c87-036b014fa7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-54895bbb-aaf1-4749-a2e8-9f5728cd5753,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-0fd465aa-4008-4036-9208-6223fcfb8e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-4ab43699-0d47-4338-bb5b-080b7ca3f31a,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-e0b8ccef-0335-42ca-a1af-95e480040ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-994b2e2e-95bb-4067-bab1-2452c28bcbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077636566-172.17.0.17-1597722186771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-1eca9e9e-cfdc-4803-a4f5-f1d9849d33dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-1f2155b6-d316-4012-bc8b-13b5bc3a2e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-7a2e94fe-546b-4ead-8bbd-c6867e12a4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-1d861dfc-a88d-4c09-8e84-702f6ceb2ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-72a2e280-9935-4699-80f1-af8b3994edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-978882d1-205b-417c-a8a7-8bffe115b953,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-bd31aa84-dc61-428a-9688-412160df5e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1b555708-027c-4956-98e6-a02d3fa00161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077636566-172.17.0.17-1597722186771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-1eca9e9e-cfdc-4803-a4f5-f1d9849d33dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-1f2155b6-d316-4012-bc8b-13b5bc3a2e37,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-7a2e94fe-546b-4ead-8bbd-c6867e12a4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-1d861dfc-a88d-4c09-8e84-702f6ceb2ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-72a2e280-9935-4699-80f1-af8b3994edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-978882d1-205b-417c-a8a7-8bffe115b953,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-bd31aa84-dc61-428a-9688-412160df5e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1b555708-027c-4956-98e6-a02d3fa00161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298262392-172.17.0.17-1597722327708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44491,DS-5f84d1b9-24c1-4bd6-861d-90aa6eb38110,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-273a7f88-fabc-4722-8481-0d2fc351d668,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-5291b64c-a0e1-4205-ade2-d8a2c4905e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-78d74992-8714-458c-8229-5a6fae2b0245,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-0e689139-7b39-4270-a3f2-5ef2b982f0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-ecc2f77d-5899-4662-84a2-d7f6d3a53252,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-6004f6fd-a3aa-44d6-a86f-3abd23363edf,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-104128ba-04d7-4c23-bfab-63be03710ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298262392-172.17.0.17-1597722327708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44491,DS-5f84d1b9-24c1-4bd6-861d-90aa6eb38110,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-273a7f88-fabc-4722-8481-0d2fc351d668,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-5291b64c-a0e1-4205-ade2-d8a2c4905e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-78d74992-8714-458c-8229-5a6fae2b0245,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-0e689139-7b39-4270-a3f2-5ef2b982f0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-ecc2f77d-5899-4662-84a2-d7f6d3a53252,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-6004f6fd-a3aa-44d6-a86f-3abd23363edf,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-104128ba-04d7-4c23-bfab-63be03710ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526889503-172.17.0.17-1597722953860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-1cca907d-f069-42de-839e-7df993302c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-1a0bb374-95fa-4056-855a-375c83031272,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-efcc4be9-ffaf-4a5d-a8db-410162d3da57,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-951a6254-bef2-457a-b010-7a83c053023d,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-966211c1-1fd0-4072-9ec1-c7b2f48b85c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-87798d99-524b-4fc5-8a01-758d0e2b6053,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-5e123fee-9074-46f4-9687-3d84bf9e6f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-41a5fd5c-ce8a-49b5-94fc-fbfc10b77a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526889503-172.17.0.17-1597722953860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-1cca907d-f069-42de-839e-7df993302c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-1a0bb374-95fa-4056-855a-375c83031272,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-efcc4be9-ffaf-4a5d-a8db-410162d3da57,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-951a6254-bef2-457a-b010-7a83c053023d,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-966211c1-1fd0-4072-9ec1-c7b2f48b85c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-87798d99-524b-4fc5-8a01-758d0e2b6053,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-5e123fee-9074-46f4-9687-3d84bf9e6f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-41a5fd5c-ce8a-49b5-94fc-fbfc10b77a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344521900-172.17.0.17-1597723414605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44251,DS-5247069b-230c-45dd-8f2d-3178e2dc56d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-f1f8ed5d-5e84-474e-ae56-246abbcf76ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-8fa92487-b30b-4ce8-8776-dc4d96163dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-395eec57-b80a-455a-82d8-960635fdfdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-0cd78ba6-b0f6-40b7-b1cd-93c126cfcb87,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-5108978c-174c-4917-b0cb-378af178430c,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-94adffcf-5f18-4962-9e05-b80435658603,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-08a907f6-dec3-460e-ae57-2e0ff7ffb486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344521900-172.17.0.17-1597723414605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44251,DS-5247069b-230c-45dd-8f2d-3178e2dc56d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-f1f8ed5d-5e84-474e-ae56-246abbcf76ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-8fa92487-b30b-4ce8-8776-dc4d96163dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-395eec57-b80a-455a-82d8-960635fdfdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-0cd78ba6-b0f6-40b7-b1cd-93c126cfcb87,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-5108978c-174c-4917-b0cb-378af178430c,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-94adffcf-5f18-4962-9e05-b80435658603,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-08a907f6-dec3-460e-ae57-2e0ff7ffb486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296421154-172.17.0.17-1597723916767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-caeea338-2523-4146-b027-79be36f0806a,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-2b5d103c-6f54-4293-bbed-adba162662e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-bee236f1-6bf1-41c6-946e-ca5ef7b4057d,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-ce7b4297-d32e-4ebc-90ce-3c66117fe9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-89d6ced9-4679-4ade-b36f-035fbb41033d,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-cb42595d-1716-4fdd-ae12-17d92b0f6e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-993ae26b-695b-4c24-8c2e-84e201159648,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-823eab89-5742-4964-a286-66bf95d18a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296421154-172.17.0.17-1597723916767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-caeea338-2523-4146-b027-79be36f0806a,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-2b5d103c-6f54-4293-bbed-adba162662e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-bee236f1-6bf1-41c6-946e-ca5ef7b4057d,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-ce7b4297-d32e-4ebc-90ce-3c66117fe9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-89d6ced9-4679-4ade-b36f-035fbb41033d,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-cb42595d-1716-4fdd-ae12-17d92b0f6e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-993ae26b-695b-4c24-8c2e-84e201159648,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-823eab89-5742-4964-a286-66bf95d18a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159712569-172.17.0.17-1597724161550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39174,DS-75b454a1-82e6-4f23-94ef-ea41a731fe7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-de0ea5a7-8a9b-426b-b4e9-928f0955a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-dcd88020-9a45-4962-b19d-478b69b6d150,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-7294b2ab-4610-47de-8ba4-e812b1834c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-beea8cfa-dbd8-4c36-8276-d9480b9f2601,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-b45ae6af-55e9-4d5d-9c6a-22ede2ea9b57,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-c80277d6-4bed-475b-a7a1-0e2ee3d4848f,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-b972081c-2db8-4fc5-84a3-1e877fd245d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159712569-172.17.0.17-1597724161550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39174,DS-75b454a1-82e6-4f23-94ef-ea41a731fe7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-de0ea5a7-8a9b-426b-b4e9-928f0955a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-dcd88020-9a45-4962-b19d-478b69b6d150,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-7294b2ab-4610-47de-8ba4-e812b1834c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-beea8cfa-dbd8-4c36-8276-d9480b9f2601,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-b45ae6af-55e9-4d5d-9c6a-22ede2ea9b57,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-c80277d6-4bed-475b-a7a1-0e2ee3d4848f,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-b972081c-2db8-4fc5-84a3-1e877fd245d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480009829-172.17.0.17-1597724193209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-ac6ebde7-50a1-424d-8f86-a31ee40c32b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-1ccea4b9-7c25-482a-8172-5b105ed542be,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-b7afe638-8691-4981-a65d-887d32ebd1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-c2e11eb8-e4e7-4f8c-8799-186f00c14305,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-eb750b0c-814a-4a85-85b7-3cc8f9bcbce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-2a98afeb-f814-4b55-976e-59b4d4ef3e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-a8b04dac-8cf3-4e71-8d8c-f1d1bdc9f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-805709cf-3f89-4f78-bfaa-2f47c5cc54e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480009829-172.17.0.17-1597724193209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-ac6ebde7-50a1-424d-8f86-a31ee40c32b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-1ccea4b9-7c25-482a-8172-5b105ed542be,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-b7afe638-8691-4981-a65d-887d32ebd1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-c2e11eb8-e4e7-4f8c-8799-186f00c14305,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-eb750b0c-814a-4a85-85b7-3cc8f9bcbce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-2a98afeb-f814-4b55-976e-59b4d4ef3e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-a8b04dac-8cf3-4e71-8d8c-f1d1bdc9f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-805709cf-3f89-4f78-bfaa-2f47c5cc54e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609071694-172.17.0.17-1597724661159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41449,DS-06ff9809-4eeb-4576-aac2-5fc476119bac,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-420013ae-7def-4b4a-b13f-fb6ffb941d58,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-732f886e-606b-40c3-8f25-400631ea3243,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-070e4a07-139c-4c74-83e5-f657134b3a92,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-3b46dd9e-c664-49c0-8886-cab68da4551a,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-c45cf209-3ec0-4764-891d-cd6791bb0033,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-63984b7c-7577-4c10-811e-faede59ca871,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-0f86bbfa-3a93-456f-b3fe-bff9375c13fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609071694-172.17.0.17-1597724661159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41449,DS-06ff9809-4eeb-4576-aac2-5fc476119bac,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-420013ae-7def-4b4a-b13f-fb6ffb941d58,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-732f886e-606b-40c3-8f25-400631ea3243,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-070e4a07-139c-4c74-83e5-f657134b3a92,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-3b46dd9e-c664-49c0-8886-cab68da4551a,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-c45cf209-3ec0-4764-891d-cd6791bb0033,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-63984b7c-7577-4c10-811e-faede59ca871,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-0f86bbfa-3a93-456f-b3fe-bff9375c13fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734841982-172.17.0.17-1597725265784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45862,DS-135cae8d-ac40-4d10-985f-6a95b4aeed18,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-9c73968d-6bbb-429e-8f44-6de60fee5857,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-97226381-5ba1-4bbf-a78e-1bc72deafabe,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-a6e0b113-32c0-4ff9-9ea3-e8a415bf1699,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-73799487-4fec-41f0-872a-a47f40cec513,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-7cd58a97-6dc9-4e2c-9a83-f44a09a6aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-91d373b5-e8be-4035-ba93-3c7438b36c85,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-4a0e9330-be9a-4ef9-8f23-fe636ac29cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734841982-172.17.0.17-1597725265784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45862,DS-135cae8d-ac40-4d10-985f-6a95b4aeed18,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-9c73968d-6bbb-429e-8f44-6de60fee5857,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-97226381-5ba1-4bbf-a78e-1bc72deafabe,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-a6e0b113-32c0-4ff9-9ea3-e8a415bf1699,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-73799487-4fec-41f0-872a-a47f40cec513,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-7cd58a97-6dc9-4e2c-9a83-f44a09a6aa42,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-91d373b5-e8be-4035-ba93-3c7438b36c85,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-4a0e9330-be9a-4ef9-8f23-fe636ac29cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032429677-172.17.0.17-1597725334312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-49382435-88f1-4f49-8828-c26c5be0053b,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e9818de6-f6c6-4f7a-8608-1a47d450933f,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-b1473d57-91de-4e8a-a4c9-9ae5e48ea6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-836a8fd8-ad30-457e-970c-df2899ee33ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-7640786d-360b-4722-84d4-6a99a924eb59,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-4dadc8cd-ab82-488d-8281-0b09d0fdf1df,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-b5c020ee-d291-4028-8ea0-1411d4394b38,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-8e21b304-f19b-4cb4-9dfc-f66610f91e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032429677-172.17.0.17-1597725334312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-49382435-88f1-4f49-8828-c26c5be0053b,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e9818de6-f6c6-4f7a-8608-1a47d450933f,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-b1473d57-91de-4e8a-a4c9-9ae5e48ea6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-836a8fd8-ad30-457e-970c-df2899ee33ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-7640786d-360b-4722-84d4-6a99a924eb59,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-4dadc8cd-ab82-488d-8281-0b09d0fdf1df,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-b5c020ee-d291-4028-8ea0-1411d4394b38,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-8e21b304-f19b-4cb4-9dfc-f66610f91e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645159059-172.17.0.17-1597725563678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-6536a15f-1e8c-4d40-a61c-e4cefceee729,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-6ec183e9-c00d-4e81-a23b-654055750bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-38ce3925-88de-4ce4-b4fc-784ea3cea4af,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-2a44d3fa-2cd6-4ec7-b527-f7c9ee4067c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-8d4257f8-5465-4718-bd85-16213906af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-cf0e65b3-514f-4902-9684-2202bdb95ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-31ad8b37-88a1-4c07-bf44-442441a096c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-f9cfbf10-b439-426f-84d2-3e0c3a9da206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645159059-172.17.0.17-1597725563678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-6536a15f-1e8c-4d40-a61c-e4cefceee729,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-6ec183e9-c00d-4e81-a23b-654055750bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-38ce3925-88de-4ce4-b4fc-784ea3cea4af,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-2a44d3fa-2cd6-4ec7-b527-f7c9ee4067c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-8d4257f8-5465-4718-bd85-16213906af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-cf0e65b3-514f-4902-9684-2202bdb95ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-31ad8b37-88a1-4c07-bf44-442441a096c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-f9cfbf10-b439-426f-84d2-3e0c3a9da206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336071164-172.17.0.17-1597725802700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-86fcdde9-7bec-4151-bf86-4b1f236ab630,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-f7a81b58-2964-4d84-9d8d-8317710725f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-0c2f290d-a348-439c-9d4a-5cb8f33e030d,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-78c1ac5c-10dd-43a3-b47c-914938b80f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-a8f6c29e-f3ee-4197-ad81-e226094f9896,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-810c5a16-427f-4b50-bc8c-e9960f4338ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-5ed57fb0-9717-4094-a856-7032a6130236,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-11f4aad2-2740-405f-9016-50fd46629728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336071164-172.17.0.17-1597725802700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-86fcdde9-7bec-4151-bf86-4b1f236ab630,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-f7a81b58-2964-4d84-9d8d-8317710725f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-0c2f290d-a348-439c-9d4a-5cb8f33e030d,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-78c1ac5c-10dd-43a3-b47c-914938b80f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-a8f6c29e-f3ee-4197-ad81-e226094f9896,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-810c5a16-427f-4b50-bc8c-e9960f4338ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-5ed57fb0-9717-4094-a856-7032a6130236,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-11f4aad2-2740-405f-9016-50fd46629728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974197708-172.17.0.17-1597726143513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-5dcc8774-dab7-4251-93fb-ee03a3cde583,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-17e7c4bd-13ae-4c36-973a-35fc31a796c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-8f137de0-b5c6-4cd7-84ab-914acfa7ed17,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-7f3ac4ee-cd3a-4e28-a68f-fe5abad66f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-0f75f970-aa7f-4a94-9763-702fda14c200,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-81df4733-f4ec-47b7-8604-02870794e72f,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-7370e0df-b04f-4e70-bce1-d5dbf65cfb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-8dcde92b-eb81-41fd-89f8-4b2db7a6fbec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974197708-172.17.0.17-1597726143513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-5dcc8774-dab7-4251-93fb-ee03a3cde583,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-17e7c4bd-13ae-4c36-973a-35fc31a796c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-8f137de0-b5c6-4cd7-84ab-914acfa7ed17,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-7f3ac4ee-cd3a-4e28-a68f-fe5abad66f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-0f75f970-aa7f-4a94-9763-702fda14c200,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-81df4733-f4ec-47b7-8604-02870794e72f,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-7370e0df-b04f-4e70-bce1-d5dbf65cfb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-8dcde92b-eb81-41fd-89f8-4b2db7a6fbec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 5m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516836264-172.17.0.17-1597726686443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-0eb8d84a-f73c-4fe0-92f9-9bf925f2fa59,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-833aad26-d436-40a0-bb12-de5cf4393ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-25f8cadd-875d-4527-8ded-a73bb5542af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-3b9f77bd-cc11-4844-ac52-cb10a50842df,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-f8cce964-c816-4b5d-94a6-d0544cd19d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-236400a8-99d1-485c-bd0b-2c339446dac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-370c0aad-32a6-4599-b660-1937cd801ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-2a63f5a8-8107-43b6-acdd-9cc0eb172f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516836264-172.17.0.17-1597726686443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-0eb8d84a-f73c-4fe0-92f9-9bf925f2fa59,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-833aad26-d436-40a0-bb12-de5cf4393ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-25f8cadd-875d-4527-8ded-a73bb5542af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-3b9f77bd-cc11-4844-ac52-cb10a50842df,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-f8cce964-c816-4b5d-94a6-d0544cd19d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-236400a8-99d1-485c-bd0b-2c339446dac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-370c0aad-32a6-4599-b660-1937cd801ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-2a63f5a8-8107-43b6-acdd-9cc0eb172f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5337
