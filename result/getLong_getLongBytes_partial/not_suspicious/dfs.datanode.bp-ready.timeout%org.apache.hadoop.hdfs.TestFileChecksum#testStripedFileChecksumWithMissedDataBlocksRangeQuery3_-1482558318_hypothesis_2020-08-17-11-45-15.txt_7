reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186643405-172.17.0.6-1597665038983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36539,DS-b4d1a889-2821-4944-be5f-963ec70373af,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-e8123fe6-731e-48f8-929b-c355f551a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-f0b33417-e5a0-44aa-83e5-d863d042ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-24269503-5519-4636-8409-92fbcb945625,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-8466b60a-c304-4acf-9ec9-d2f6859799a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-d0c1534f-27a4-4ec0-a019-b2210f5bc310,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-53641798-a920-4288-acd4-f0f0aa0fa8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-19c97cad-6654-4b52-a3da-49fbcd7473ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186643405-172.17.0.6-1597665038983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36539,DS-b4d1a889-2821-4944-be5f-963ec70373af,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-e8123fe6-731e-48f8-929b-c355f551a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-f0b33417-e5a0-44aa-83e5-d863d042ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-24269503-5519-4636-8409-92fbcb945625,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-8466b60a-c304-4acf-9ec9-d2f6859799a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-d0c1534f-27a4-4ec0-a019-b2210f5bc310,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-53641798-a920-4288-acd4-f0f0aa0fa8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-19c97cad-6654-4b52-a3da-49fbcd7473ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342721246-172.17.0.6-1597665111582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-cfcad126-28ba-43d2-97e7-749177778c29,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-db487097-b266-4570-b868-53c9b605f2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-e6d2d815-3fbc-47f7-b2ad-0986aba77368,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-91642cde-54e9-4c9a-b24c-902669b09dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-21a7eb36-4d95-4a5b-97e6-34761ae2b54a,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-187bf7de-78b8-4f30-8b65-e3a22ff941a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-78a5088f-3617-4637-bf96-f1c39dc7d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-98c1d1ec-d518-4f84-90ee-e0a49d6979fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342721246-172.17.0.6-1597665111582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-cfcad126-28ba-43d2-97e7-749177778c29,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-db487097-b266-4570-b868-53c9b605f2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-e6d2d815-3fbc-47f7-b2ad-0986aba77368,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-91642cde-54e9-4c9a-b24c-902669b09dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-21a7eb36-4d95-4a5b-97e6-34761ae2b54a,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-187bf7de-78b8-4f30-8b65-e3a22ff941a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-78a5088f-3617-4637-bf96-f1c39dc7d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-98c1d1ec-d518-4f84-90ee-e0a49d6979fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428736446-172.17.0.6-1597665451039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-2fad3f3f-7209-46e3-b1e6-1916292afb35,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-a13318ef-3ed7-4f12-ac89-16ec798ee7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-6c68a740-f43f-4cd2-b7be-c725578ace7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-f499783b-e8b8-49e7-bf38-9ab0b4123c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-cf5186ac-e28d-4174-ac44-489e66ad6f36,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-df662ba7-5fc5-4a0f-898a-f6b9deec782c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-90dc94f9-b7e2-43a1-b2e5-a9bc1360a656,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-6ff0bebb-417b-4e18-b1c7-472cba9c09b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428736446-172.17.0.6-1597665451039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-2fad3f3f-7209-46e3-b1e6-1916292afb35,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-a13318ef-3ed7-4f12-ac89-16ec798ee7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-6c68a740-f43f-4cd2-b7be-c725578ace7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-f499783b-e8b8-49e7-bf38-9ab0b4123c44,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-cf5186ac-e28d-4174-ac44-489e66ad6f36,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-df662ba7-5fc5-4a0f-898a-f6b9deec782c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-90dc94f9-b7e2-43a1-b2e5-a9bc1360a656,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-6ff0bebb-417b-4e18-b1c7-472cba9c09b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602596283-172.17.0.6-1597665649451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43441,DS-476e5846-5b2e-46ae-b11e-599f6e53aedd,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-cda87d24-ee8b-4e74-a9c5-aba4001e7cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-2572a04d-9980-4521-bb70-016d21ab2705,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-e8f5aafd-c768-4032-be86-c68e2363ea96,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-3fadb62a-320b-4b89-abe3-8380319a61ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-d6c0fcd3-ca4c-4316-bf6c-a1503610c264,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-9c46b07b-9f78-4222-bce1-49ec7f63ab63,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-dd83f447-73d6-47e6-b873-49fe20ec5e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602596283-172.17.0.6-1597665649451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43441,DS-476e5846-5b2e-46ae-b11e-599f6e53aedd,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-cda87d24-ee8b-4e74-a9c5-aba4001e7cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-2572a04d-9980-4521-bb70-016d21ab2705,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-e8f5aafd-c768-4032-be86-c68e2363ea96,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-3fadb62a-320b-4b89-abe3-8380319a61ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-d6c0fcd3-ca4c-4316-bf6c-a1503610c264,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-9c46b07b-9f78-4222-bce1-49ec7f63ab63,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-dd83f447-73d6-47e6-b873-49fe20ec5e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822556580-172.17.0.6-1597665984006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34655,DS-fabc82b2-e1db-4203-9e60-09e107827d57,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-4b7d136a-9631-4dd0-b2fc-fbbb167daefa,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-32aa6223-200b-4a90-81c8-ea0f705a4071,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-f570f760-ed33-4667-b356-8a3efa9e6528,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-eb528c29-287c-47ab-bdb9-0b38c181a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-c4811431-d02a-424a-a40f-b6ce2138a061,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-b8dda10d-af4c-4df2-a808-e7ab87fefda6,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-be601f99-60f2-4da4-9325-0ea46e36edb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822556580-172.17.0.6-1597665984006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34655,DS-fabc82b2-e1db-4203-9e60-09e107827d57,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-4b7d136a-9631-4dd0-b2fc-fbbb167daefa,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-32aa6223-200b-4a90-81c8-ea0f705a4071,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-f570f760-ed33-4667-b356-8a3efa9e6528,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-eb528c29-287c-47ab-bdb9-0b38c181a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-c4811431-d02a-424a-a40f-b6ce2138a061,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-b8dda10d-af4c-4df2-a808-e7ab87fefda6,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-be601f99-60f2-4da4-9325-0ea46e36edb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134674440-172.17.0.6-1597667259055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-04575da3-b92e-49a8-a7b5-29b9262489f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-801af7e0-db4d-4ed6-ad1b-e4473ac00c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-981770aa-5139-4587-a4c4-8b1bfa23030b,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-da897b1c-44db-492b-ae7e-a980ba580227,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-3da70f9a-05fd-43bb-bd3a-af7ea42f3c80,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-b78a181d-6cc5-4e83-8030-fe30dfc1140a,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-f2cb4986-9915-4407-9849-0a1340faa8db,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-15210f25-d0c3-44fb-937d-1048e27ac9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134674440-172.17.0.6-1597667259055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-04575da3-b92e-49a8-a7b5-29b9262489f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-801af7e0-db4d-4ed6-ad1b-e4473ac00c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-981770aa-5139-4587-a4c4-8b1bfa23030b,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-da897b1c-44db-492b-ae7e-a980ba580227,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-3da70f9a-05fd-43bb-bd3a-af7ea42f3c80,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-b78a181d-6cc5-4e83-8030-fe30dfc1140a,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-f2cb4986-9915-4407-9849-0a1340faa8db,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-15210f25-d0c3-44fb-937d-1048e27ac9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837924641-172.17.0.6-1597667621631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43232,DS-b05d5377-f026-42af-9a63-b626cbd05956,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-01c3fea3-014e-468d-9129-67b71549386a,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-40750395-9580-4609-b10d-02c4eb6f6ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-db8b5a1d-daac-46e1-a1eb-8409d199fa21,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-8f637cb4-3aab-41c0-9f3f-09cf2ad7565f,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-841e2c8c-1648-44b1-866f-1d54500205b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-7ba75a88-54f1-4877-a4ff-22e4a9b64f97,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-11fb7e1c-e237-4843-a3b3-438b3d135754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837924641-172.17.0.6-1597667621631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43232,DS-b05d5377-f026-42af-9a63-b626cbd05956,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-01c3fea3-014e-468d-9129-67b71549386a,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-40750395-9580-4609-b10d-02c4eb6f6ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-db8b5a1d-daac-46e1-a1eb-8409d199fa21,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-8f637cb4-3aab-41c0-9f3f-09cf2ad7565f,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-841e2c8c-1648-44b1-866f-1d54500205b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-7ba75a88-54f1-4877-a4ff-22e4a9b64f97,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-11fb7e1c-e237-4843-a3b3-438b3d135754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785603611-172.17.0.6-1597668259965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-25411592-9da8-48e4-8516-a37650bd6979,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-29a464aa-d16d-4d06-933e-e43cc1fef1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-d358942b-aee8-4327-b600-e1743c0e40b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-a8dcf89e-705e-482e-8ebc-a27c0967878e,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-0bff4792-a257-49c5-bbc0-1be7e96ff990,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-b8068649-f2e1-4fd8-a888-e65ed0d30b43,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-00c1f30b-fa1b-4214-9eff-cda8bb12fde8,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-9048618d-e739-4f2f-a2c3-e78ebc02879b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785603611-172.17.0.6-1597668259965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-25411592-9da8-48e4-8516-a37650bd6979,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-29a464aa-d16d-4d06-933e-e43cc1fef1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-d358942b-aee8-4327-b600-e1743c0e40b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-a8dcf89e-705e-482e-8ebc-a27c0967878e,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-0bff4792-a257-49c5-bbc0-1be7e96ff990,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-b8068649-f2e1-4fd8-a888-e65ed0d30b43,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-00c1f30b-fa1b-4214-9eff-cda8bb12fde8,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-9048618d-e739-4f2f-a2c3-e78ebc02879b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778263583-172.17.0.6-1597669047403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-67c6402f-faf9-4fd1-84ee-309f2fc18fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-bfaa0191-aa34-4147-b819-9dcd77cebe36,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-906eb1d0-9fde-42bc-b144-21a82f3ccdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-0cef26be-57b5-4a25-9551-c07358dce0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-53b4a65f-41e5-46c3-b6cf-df628bd6a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-b7eb3b47-c64e-404f-90a1-f8fd3d9d3857,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-1a3a133a-35a9-4c24-bb24-27b526a7edce,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-bf8e7894-3167-4f32-a244-20dd96a8758a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778263583-172.17.0.6-1597669047403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-67c6402f-faf9-4fd1-84ee-309f2fc18fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-bfaa0191-aa34-4147-b819-9dcd77cebe36,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-906eb1d0-9fde-42bc-b144-21a82f3ccdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-0cef26be-57b5-4a25-9551-c07358dce0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-53b4a65f-41e5-46c3-b6cf-df628bd6a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-b7eb3b47-c64e-404f-90a1-f8fd3d9d3857,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-1a3a133a-35a9-4c24-bb24-27b526a7edce,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-bf8e7894-3167-4f32-a244-20dd96a8758a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237256662-172.17.0.6-1597669116359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42072,DS-59d064d7-945e-4cbe-9f42-ab822cf4ffba,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-a80d342c-dc7b-4948-842f-df35537d137c,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-bc31d632-0b54-4fa3-a471-c7bea1eccd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-dc3cf6ab-59d7-44d2-b682-7c2cfeaca5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-26724ecd-71c4-423a-802e-bfea8fafc76a,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-c5e4720c-2f3a-47fb-8f4c-371fc3536d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-0aa0a6a1-c239-4ac2-a7ab-51faa5d480bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-91d1f14f-0809-45d2-99a4-55d80c9d680a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237256662-172.17.0.6-1597669116359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42072,DS-59d064d7-945e-4cbe-9f42-ab822cf4ffba,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-a80d342c-dc7b-4948-842f-df35537d137c,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-bc31d632-0b54-4fa3-a471-c7bea1eccd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-dc3cf6ab-59d7-44d2-b682-7c2cfeaca5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-26724ecd-71c4-423a-802e-bfea8fafc76a,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-c5e4720c-2f3a-47fb-8f4c-371fc3536d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-0aa0a6a1-c239-4ac2-a7ab-51faa5d480bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-91d1f14f-0809-45d2-99a4-55d80c9d680a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331119156-172.17.0.6-1597669478112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35860,DS-2affc3de-8185-4a4d-9d69-752cd55b69db,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-ac93fe2c-f479-4a1a-ae08-dae9d85a9132,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-e4a9026e-c8f5-4eff-a085-0c0fc6fd72ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-bf3977c9-5023-410b-aaff-589a45926524,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-015530bc-0ccd-4529-82aa-4530b320393b,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-ee58c90d-ca2c-4234-80b5-a8070fe0c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-3b786965-edf0-4665-a5ac-e026b8b7bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-d713bb35-8125-432d-90f3-3ff631eeb0f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331119156-172.17.0.6-1597669478112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35860,DS-2affc3de-8185-4a4d-9d69-752cd55b69db,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-ac93fe2c-f479-4a1a-ae08-dae9d85a9132,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-e4a9026e-c8f5-4eff-a085-0c0fc6fd72ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-bf3977c9-5023-410b-aaff-589a45926524,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-015530bc-0ccd-4529-82aa-4530b320393b,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-ee58c90d-ca2c-4234-80b5-a8070fe0c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-3b786965-edf0-4665-a5ac-e026b8b7bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-d713bb35-8125-432d-90f3-3ff631eeb0f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140085452-172.17.0.6-1597669639582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-5edfb56b-b5f2-4048-ac6f-9595d865b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-c138d759-f13e-4e08-a54c-62f4ee0e4732,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-118db087-f0d6-42ed-a63f-5ff89364dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-1f91f2e6-3180-4c7b-b97f-689b33f2ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-b98c8a79-3c29-421e-8691-a4031a856b58,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-cff70a20-7f23-43d6-a421-665091a271c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-d668992b-d31b-4627-8f77-96e5d28cefb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-dbc8b167-e050-4fab-90df-bc4c965c33c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140085452-172.17.0.6-1597669639582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-5edfb56b-b5f2-4048-ac6f-9595d865b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-c138d759-f13e-4e08-a54c-62f4ee0e4732,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-118db087-f0d6-42ed-a63f-5ff89364dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-1f91f2e6-3180-4c7b-b97f-689b33f2ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-b98c8a79-3c29-421e-8691-a4031a856b58,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-cff70a20-7f23-43d6-a421-665091a271c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-d668992b-d31b-4627-8f77-96e5d28cefb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-dbc8b167-e050-4fab-90df-bc4c965c33c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834655925-172.17.0.6-1597670219798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39409,DS-b848cf28-28ef-40b2-83c2-7b64d2f58fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-24208660-04ff-4bb5-9cd2-0094e2cfd6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-61202f94-1991-45b2-a65b-840646fe78ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-133a17a6-896c-49a8-b265-3d2f450f9628,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-aae3037d-4441-4553-9792-b09f5c797fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-cfbb890b-42b3-40c5-b1d1-1b2a0ba87080,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-d37e9f76-9039-4519-b1bc-0cd34fbf4d97,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-c9b66c3e-5812-4a25-a396-1bdb68a4bcaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834655925-172.17.0.6-1597670219798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39409,DS-b848cf28-28ef-40b2-83c2-7b64d2f58fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-24208660-04ff-4bb5-9cd2-0094e2cfd6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-61202f94-1991-45b2-a65b-840646fe78ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-133a17a6-896c-49a8-b265-3d2f450f9628,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-aae3037d-4441-4553-9792-b09f5c797fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-cfbb890b-42b3-40c5-b1d1-1b2a0ba87080,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-d37e9f76-9039-4519-b1bc-0cd34fbf4d97,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-c9b66c3e-5812-4a25-a396-1bdb68a4bcaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5637
