reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145114803-172.17.0.14-1597723404649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35208,DS-49aae772-ae58-4a7d-88f7-7ddd82a840fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-15e8698f-cd7a-419e-819c-c02966ae7a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-fc25fef5-55f2-45e0-bcdf-5304b2aa0465,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-becce949-a7de-4d85-ae6f-06c8946b2cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-b5ad814b-b3ef-41e0-a65d-f872e76dc316,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-015f7bb6-1e94-4e12-8921-fc9f0ca34305,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-089debcf-5ee7-423c-9b94-81006fa257fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-06880ed8-961f-4e12-8db7-7feca5537c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145114803-172.17.0.14-1597723404649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35208,DS-49aae772-ae58-4a7d-88f7-7ddd82a840fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-15e8698f-cd7a-419e-819c-c02966ae7a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-fc25fef5-55f2-45e0-bcdf-5304b2aa0465,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-becce949-a7de-4d85-ae6f-06c8946b2cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-b5ad814b-b3ef-41e0-a65d-f872e76dc316,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-015f7bb6-1e94-4e12-8921-fc9f0ca34305,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-089debcf-5ee7-423c-9b94-81006fa257fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-06880ed8-961f-4e12-8db7-7feca5537c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140208899-172.17.0.14-1597723678396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42450,DS-5fdba890-bb16-48db-9545-107828b28d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-0dbc542f-70cb-43e6-afee-6492d7bb5344,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-b8a45548-5a5d-47da-a02d-1b4017848453,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-1449a9d3-ed3a-4784-b04d-ccc9b2770e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-7bd21494-dc78-42ac-b3be-c7b450af7dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-197bcc4b-3898-42f9-9d3b-c10bd8299a45,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-3b5625e9-f31c-4467-8131-11ab4bebd8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-193b363e-1edb-40d0-85e6-b07201f29a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140208899-172.17.0.14-1597723678396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42450,DS-5fdba890-bb16-48db-9545-107828b28d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-0dbc542f-70cb-43e6-afee-6492d7bb5344,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-b8a45548-5a5d-47da-a02d-1b4017848453,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-1449a9d3-ed3a-4784-b04d-ccc9b2770e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-7bd21494-dc78-42ac-b3be-c7b450af7dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-197bcc4b-3898-42f9-9d3b-c10bd8299a45,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-3b5625e9-f31c-4467-8131-11ab4bebd8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-193b363e-1edb-40d0-85e6-b07201f29a1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599698390-172.17.0.14-1597724237190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36650,DS-8956c2bb-7578-4fa0-b1bd-bb104c2357ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-0fd21022-4c3a-4fad-9449-6e4902d29368,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-a4364845-6c37-486b-a28c-7fd9427bc529,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-fde24418-5714-4e15-acb6-274caf4bbf67,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-8eaf070b-962f-4be9-8771-4fd43bf1f0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-993370db-62da-475a-9a58-01ff3bc4ee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-eba581cc-1b81-4382-86c9-0c5ee0a701ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-4ae386c1-2b1c-4e93-ac47-096bcfe32afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599698390-172.17.0.14-1597724237190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36650,DS-8956c2bb-7578-4fa0-b1bd-bb104c2357ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-0fd21022-4c3a-4fad-9449-6e4902d29368,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-a4364845-6c37-486b-a28c-7fd9427bc529,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-fde24418-5714-4e15-acb6-274caf4bbf67,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-8eaf070b-962f-4be9-8771-4fd43bf1f0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-993370db-62da-475a-9a58-01ff3bc4ee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-eba581cc-1b81-4382-86c9-0c5ee0a701ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-4ae386c1-2b1c-4e93-ac47-096bcfe32afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628473908-172.17.0.14-1597724528062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-bdf1c445-1e60-4c9d-9439-d7d6c20d3226,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-4a4d7c98-9930-4a76-8634-5c70f8287552,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-47bd05b3-484f-4db3-942c-5783e2730358,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-59e2c40e-6a95-4123-a8c5-74b15aa34698,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-a821274e-11f5-46f9-87fb-d03a263091dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-71728f95-c44a-45fa-aa30-85482cdfbf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-270a4e9e-fea3-433a-8f68-d3eac7c9c9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-6c65cbd6-e6c9-421f-873e-290dc781a284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628473908-172.17.0.14-1597724528062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-bdf1c445-1e60-4c9d-9439-d7d6c20d3226,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-4a4d7c98-9930-4a76-8634-5c70f8287552,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-47bd05b3-484f-4db3-942c-5783e2730358,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-59e2c40e-6a95-4123-a8c5-74b15aa34698,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-a821274e-11f5-46f9-87fb-d03a263091dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-71728f95-c44a-45fa-aa30-85482cdfbf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-270a4e9e-fea3-433a-8f68-d3eac7c9c9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-6c65cbd6-e6c9-421f-873e-290dc781a284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23859790-172.17.0.14-1597724757417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46661,DS-3f08c221-9ba2-4c12-86b7-52a84bab2d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-cbd55b36-6b3a-4c34-b235-3cc05399765f,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-5c1c5477-28f0-4b2c-a7c4-e622c1ac8e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-7ee74200-80a8-4f93-ae37-8de8796c0460,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-1e3ae94f-2513-43e4-916f-a13d59f381a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-6a052727-3f8e-4db1-af6d-3e157130d044,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-fbe461aa-8894-4ef9-9d82-d0692468e619,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-7e1915bc-751d-437b-8b06-cf55fe73289b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23859790-172.17.0.14-1597724757417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46661,DS-3f08c221-9ba2-4c12-86b7-52a84bab2d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-cbd55b36-6b3a-4c34-b235-3cc05399765f,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-5c1c5477-28f0-4b2c-a7c4-e622c1ac8e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-7ee74200-80a8-4f93-ae37-8de8796c0460,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-1e3ae94f-2513-43e4-916f-a13d59f381a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-6a052727-3f8e-4db1-af6d-3e157130d044,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-fbe461aa-8894-4ef9-9d82-d0692468e619,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-7e1915bc-751d-437b-8b06-cf55fe73289b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093082815-172.17.0.14-1597724798356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-860f9347-dabf-470c-be62-ab0b49c21814,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-71a92568-7f40-4154-a07d-087319c5ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-23bd63f1-ebd9-4931-94f1-75b049e79865,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-02c54b90-8c6d-48e7-9028-afaa57afbfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-e3d74737-db4e-424e-a568-048f62ceb5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-c1533833-4974-467c-815c-3f1f0d773738,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-a02e35a4-46d0-46ea-877f-238ad5ba2b69,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-3d82a5ea-9f88-4121-a0eb-b6d411dd2906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093082815-172.17.0.14-1597724798356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-860f9347-dabf-470c-be62-ab0b49c21814,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-71a92568-7f40-4154-a07d-087319c5ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-23bd63f1-ebd9-4931-94f1-75b049e79865,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-02c54b90-8c6d-48e7-9028-afaa57afbfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-e3d74737-db4e-424e-a568-048f62ceb5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-c1533833-4974-467c-815c-3f1f0d773738,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-a02e35a4-46d0-46ea-877f-238ad5ba2b69,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-3d82a5ea-9f88-4121-a0eb-b6d411dd2906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832512793-172.17.0.14-1597725667034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-2be7b01e-e2e4-497c-b825-bd766d0b943a,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-eb91c1a9-2cdd-4b71-9e7c-d4fdff3be014,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-e8c7d35a-57cd-4217-8635-380bac08f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-5dc1ec83-2659-458a-8bdc-800cb597ec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-326b7dc0-bdd5-4a3c-9040-f71608a67b84,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-a874f77a-3d82-4675-a4c8-17b660921b33,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-3679d7a9-596e-457d-837f-47c642532358,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-89106a86-460e-40f4-997c-effa1b31f17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832512793-172.17.0.14-1597725667034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-2be7b01e-e2e4-497c-b825-bd766d0b943a,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-eb91c1a9-2cdd-4b71-9e7c-d4fdff3be014,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-e8c7d35a-57cd-4217-8635-380bac08f06d,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-5dc1ec83-2659-458a-8bdc-800cb597ec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-326b7dc0-bdd5-4a3c-9040-f71608a67b84,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-a874f77a-3d82-4675-a4c8-17b660921b33,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-3679d7a9-596e-457d-837f-47c642532358,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-89106a86-460e-40f4-997c-effa1b31f17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734596722-172.17.0.14-1597725774081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37246,DS-5218024a-fd74-45d2-9dfc-f73e6ceeb204,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-81025a0d-054e-4403-aa02-aca0762bb9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-5f3aa050-3be7-4f1b-9f76-0d1fa5ec6189,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-d3211e24-2c71-4fba-bf8a-ea0f6ed73907,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-47339984-9a41-4eee-bf7c-dcbbc758b5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-263c80b0-8190-467e-92a0-92a33f150f18,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-d9bf4958-c586-4d72-ad52-d7005bf3610f,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-8dfa254b-68a2-4182-8908-017c0771da4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734596722-172.17.0.14-1597725774081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37246,DS-5218024a-fd74-45d2-9dfc-f73e6ceeb204,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-81025a0d-054e-4403-aa02-aca0762bb9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-5f3aa050-3be7-4f1b-9f76-0d1fa5ec6189,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-d3211e24-2c71-4fba-bf8a-ea0f6ed73907,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-47339984-9a41-4eee-bf7c-dcbbc758b5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-263c80b0-8190-467e-92a0-92a33f150f18,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-d9bf4958-c586-4d72-ad52-d7005bf3610f,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-8dfa254b-68a2-4182-8908-017c0771da4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981495889-172.17.0.14-1597725812014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36347,DS-1ed05f3d-7a37-47b0-82f8-a7eb06934ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-4e88efb6-c209-40df-8c39-598f5904f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-7e7cb0e5-3f2e-439a-9bef-16d5e44f073d,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-5d5169b5-a9cf-45e7-a6bd-4ffdc7c1bc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-600e47ae-354d-4a99-a9ee-4c0af3cb5995,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-9b79324f-de5e-4a04-9ff9-6da10cd1f1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-5afbbba7-e423-42d9-afdc-62e6cee95d85,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-b3fbfe43-79e8-4a18-b29b-5b915ae50ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981495889-172.17.0.14-1597725812014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36347,DS-1ed05f3d-7a37-47b0-82f8-a7eb06934ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-4e88efb6-c209-40df-8c39-598f5904f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-7e7cb0e5-3f2e-439a-9bef-16d5e44f073d,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-5d5169b5-a9cf-45e7-a6bd-4ffdc7c1bc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-600e47ae-354d-4a99-a9ee-4c0af3cb5995,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-9b79324f-de5e-4a04-9ff9-6da10cd1f1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-5afbbba7-e423-42d9-afdc-62e6cee95d85,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-b3fbfe43-79e8-4a18-b29b-5b915ae50ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143590051-172.17.0.14-1597725848343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-39ae31d4-1302-4410-b426-956ed35e491b,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-d7d7135c-0a98-421e-8325-5322b48da82a,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-cfcc6d79-4b94-4b48-a7cb-985b54ff2dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-0e44e416-e93c-42bb-9ee1-863dd955f76d,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-b507c045-1667-4dcc-83a9-b5c319c44c45,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-f81d7443-e157-4b86-bae6-6088ef339d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-b9cc3aa7-6172-4306-acc4-e00c9847f109,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-e5af3ac2-1f28-401c-bb8c-088e7a373957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143590051-172.17.0.14-1597725848343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-39ae31d4-1302-4410-b426-956ed35e491b,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-d7d7135c-0a98-421e-8325-5322b48da82a,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-cfcc6d79-4b94-4b48-a7cb-985b54ff2dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-0e44e416-e93c-42bb-9ee1-863dd955f76d,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-b507c045-1667-4dcc-83a9-b5c319c44c45,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-f81d7443-e157-4b86-bae6-6088ef339d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-b9cc3aa7-6172-4306-acc4-e00c9847f109,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-e5af3ac2-1f28-401c-bb8c-088e7a373957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047229036-172.17.0.14-1597725934568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-843c8df8-97af-4e32-b9cd-1a3180a88a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-e7dc764f-c053-4991-aba8-6ac20d29ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-664b4faf-ce29-4503-9a6a-268e619fccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-df501c0c-90c7-48cf-8e46-81839189b534,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-f972590a-8913-4e4f-89f7-2071852b87f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-6fdf98b8-204c-401e-a866-ffd5bbddbdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-032f3394-5720-458a-b3c9-09c050537bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-ee319141-b10c-43a7-af9e-eacf59b677b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047229036-172.17.0.14-1597725934568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-843c8df8-97af-4e32-b9cd-1a3180a88a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-e7dc764f-c053-4991-aba8-6ac20d29ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-664b4faf-ce29-4503-9a6a-268e619fccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-df501c0c-90c7-48cf-8e46-81839189b534,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-f972590a-8913-4e4f-89f7-2071852b87f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-6fdf98b8-204c-401e-a866-ffd5bbddbdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-032f3394-5720-458a-b3c9-09c050537bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-ee319141-b10c-43a7-af9e-eacf59b677b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404483260-172.17.0.14-1597726483353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-774d666c-74c3-47ef-94aa-688063468757,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-e32fd07d-5c90-44d1-8504-9ed8fdae9797,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-8413db70-61d8-43c4-adf6-b399c5cfe929,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-7c776c93-1f00-450a-aed0-133bb0c39724,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-7458f5a5-a1ab-4ad1-8dd8-26ba5d724f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-60ae142c-0006-498e-8f70-cfc58fb6b454,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-ead6fac1-7ebe-408a-b6e7-6bc9e944594f,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-4a2ced20-5e40-4c76-8cbe-045c7ae1fd0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404483260-172.17.0.14-1597726483353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-774d666c-74c3-47ef-94aa-688063468757,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-e32fd07d-5c90-44d1-8504-9ed8fdae9797,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-8413db70-61d8-43c4-adf6-b399c5cfe929,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-7c776c93-1f00-450a-aed0-133bb0c39724,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-7458f5a5-a1ab-4ad1-8dd8-26ba5d724f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-60ae142c-0006-498e-8f70-cfc58fb6b454,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-ead6fac1-7ebe-408a-b6e7-6bc9e944594f,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-4a2ced20-5e40-4c76-8cbe-045c7ae1fd0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170386166-172.17.0.14-1597726876827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37216,DS-5a66e73a-50b3-4163-9e66-5d5b45fb27c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-ae9340f2-8b90-4997-918b-3113daf59f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-8bc1df10-19f3-421f-ab54-5f0044169344,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-20b18adf-aaae-4607-82fe-1d4fd3407bda,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-8fced51b-6170-41d0-b040-2af4e8352122,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-22f2940b-f1c6-4812-adc5-5093c9d05f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-4a27e118-4a91-4449-aaa5-d5d26fcd0a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-99c7905e-22e4-44cf-9b67-0da4e3f23b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170386166-172.17.0.14-1597726876827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37216,DS-5a66e73a-50b3-4163-9e66-5d5b45fb27c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-ae9340f2-8b90-4997-918b-3113daf59f05,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-8bc1df10-19f3-421f-ab54-5f0044169344,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-20b18adf-aaae-4607-82fe-1d4fd3407bda,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-8fced51b-6170-41d0-b040-2af4e8352122,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-22f2940b-f1c6-4812-adc5-5093c9d05f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-4a27e118-4a91-4449-aaa5-d5d26fcd0a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-99c7905e-22e4-44cf-9b67-0da4e3f23b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85827198-172.17.0.14-1597727003585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32964,DS-45351b29-6a30-472a-978b-48e0c71a8fca,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-af88883b-440b-4b58-8e3a-882104ff70e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-13178ad7-f05c-49f3-bf37-dd18fb602c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-799c642b-d965-4775-a386-13f824f75a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-711ae3b4-affc-4c2f-ba1e-80c5dd1fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-7983e654-aa6f-4a52-85d6-6d83d8384e16,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-bf4d9899-485b-415d-a889-da2699563b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-67017c89-977a-44a2-a786-8b86d7e27fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85827198-172.17.0.14-1597727003585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32964,DS-45351b29-6a30-472a-978b-48e0c71a8fca,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-af88883b-440b-4b58-8e3a-882104ff70e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-13178ad7-f05c-49f3-bf37-dd18fb602c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-799c642b-d965-4775-a386-13f824f75a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-711ae3b4-affc-4c2f-ba1e-80c5dd1fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-7983e654-aa6f-4a52-85d6-6d83d8384e16,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-bf4d9899-485b-415d-a889-da2699563b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-67017c89-977a-44a2-a786-8b86d7e27fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090803464-172.17.0.14-1597727575517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42534,DS-2195eb48-9b56-47a0-b8ed-ffc44236b265,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-a7e61e4f-6ea3-49ba-87ab-068e419dc850,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-25061496-a804-4889-a2ba-35994625c1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-469511be-db91-4b1b-9574-65a5d6bbbb25,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-0e2d5d73-89fc-4ab3-a506-f6295d10032f,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-f72e2282-ae01-4411-8ddd-ceeca79ccbac,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-46d6ebe5-d97e-4168-9bd8-dc0a66e2d88d,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-d2ac7c2a-75ad-47dc-8da0-4df6cc3e79cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090803464-172.17.0.14-1597727575517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42534,DS-2195eb48-9b56-47a0-b8ed-ffc44236b265,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-a7e61e4f-6ea3-49ba-87ab-068e419dc850,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-25061496-a804-4889-a2ba-35994625c1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-469511be-db91-4b1b-9574-65a5d6bbbb25,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-0e2d5d73-89fc-4ab3-a506-f6295d10032f,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-f72e2282-ae01-4411-8ddd-ceeca79ccbac,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-46d6ebe5-d97e-4168-9bd8-dc0a66e2d88d,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-d2ac7c2a-75ad-47dc-8da0-4df6cc3e79cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264154818-172.17.0.14-1597728212079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45786,DS-3d7180c9-96fc-417e-bdc1-51a98d806bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-6155df86-8640-4821-bc67-af69750f5eee,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-f1111e30-c47a-4b04-b172-96edf52ac3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-70a92da5-21e6-47ab-8f80-690f6e209218,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-2531edc4-2036-4369-a2b1-e9cd0709dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-022a87d7-8e00-4b96-b34f-c64e48830332,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-9cf53c9b-84ce-45d0-b2f5-4253d69b9941,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-18e359e8-ef28-40a0-978b-bf6e75fd034b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264154818-172.17.0.14-1597728212079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45786,DS-3d7180c9-96fc-417e-bdc1-51a98d806bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-6155df86-8640-4821-bc67-af69750f5eee,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-f1111e30-c47a-4b04-b172-96edf52ac3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-70a92da5-21e6-47ab-8f80-690f6e209218,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-2531edc4-2036-4369-a2b1-e9cd0709dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-022a87d7-8e00-4b96-b34f-c64e48830332,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-9cf53c9b-84ce-45d0-b2f5-4253d69b9941,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-18e359e8-ef28-40a0-978b-bf6e75fd034b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117945554-172.17.0.14-1597728322610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33212,DS-93622751-a88c-4c82-ab8b-c8dd8ffa2ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-da9775f5-24a0-45b6-b556-a4651762758a,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d25761c3-318c-4b21-a6b7-eb169f301909,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-4f5e666a-8e10-419f-834f-b66deaf2a1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-64b7bf6a-3006-44a8-bee9-09956c31fd10,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-46c851fb-1c20-4b75-bf4a-ab06053198d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-a033a15a-0c3c-4c79-bca4-76904235dd80,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-a8d1ad3e-9dd5-4f56-8707-9746cfe93ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117945554-172.17.0.14-1597728322610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33212,DS-93622751-a88c-4c82-ab8b-c8dd8ffa2ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-da9775f5-24a0-45b6-b556-a4651762758a,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d25761c3-318c-4b21-a6b7-eb169f301909,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-4f5e666a-8e10-419f-834f-b66deaf2a1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-64b7bf6a-3006-44a8-bee9-09956c31fd10,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-46c851fb-1c20-4b75-bf4a-ab06053198d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-a033a15a-0c3c-4c79-bca4-76904235dd80,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-a8d1ad3e-9dd5-4f56-8707-9746cfe93ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497536070-172.17.0.14-1597728482712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38204,DS-d59d33ad-797d-46f9-b411-039021469846,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-6ff54601-771c-4c72-b0b0-40b119b82c89,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-df1cb87a-ef6d-41df-9ffb-a5bfdafa6df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-50e2ea5f-eb8e-4a67-b7c4-117434b14076,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-1842beca-7206-456f-be2d-8ff5b26a8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-3445e3c6-47f5-42c7-9ee1-2d398bee82dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-abdf6f38-29cc-402c-9d13-d7d9e84d3aea,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-e990102a-06d4-49c8-b5bb-578f11df3fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497536070-172.17.0.14-1597728482712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38204,DS-d59d33ad-797d-46f9-b411-039021469846,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-6ff54601-771c-4c72-b0b0-40b119b82c89,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-df1cb87a-ef6d-41df-9ffb-a5bfdafa6df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-50e2ea5f-eb8e-4a67-b7c4-117434b14076,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-1842beca-7206-456f-be2d-8ff5b26a8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-3445e3c6-47f5-42c7-9ee1-2d398bee82dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-abdf6f38-29cc-402c-9d13-d7d9e84d3aea,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-e990102a-06d4-49c8-b5bb-578f11df3fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488425738-172.17.0.14-1597728600358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40896,DS-f0c7a680-c5b4-4602-8fe5-b04236180837,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-1a3bdefe-ebaf-474a-83c6-bce8be460717,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-083673ef-83d9-4093-94d4-6050ff5807e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-713ca195-69b8-43d0-a1e5-a634fb194662,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-95a98a97-d6ce-4667-8c67-389bd736792e,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-2520b07b-2694-4444-8556-16859fbc5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-43297c75-67a8-40c0-9920-44751be7f875,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-162ffc8e-2eb8-40ef-b196-e9018221a4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488425738-172.17.0.14-1597728600358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40896,DS-f0c7a680-c5b4-4602-8fe5-b04236180837,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-1a3bdefe-ebaf-474a-83c6-bce8be460717,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-083673ef-83d9-4093-94d4-6050ff5807e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-713ca195-69b8-43d0-a1e5-a634fb194662,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-95a98a97-d6ce-4667-8c67-389bd736792e,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-2520b07b-2694-4444-8556-16859fbc5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-43297c75-67a8-40c0-9920-44751be7f875,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-162ffc8e-2eb8-40ef-b196-e9018221a4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224142572-172.17.0.14-1597728636956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-d168e1d8-100f-4d5e-9ae4-fcfac60ae9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-e32af182-29bf-42dd-b3ba-935f5456e815,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-06d50d63-2d6e-4e81-bc09-bec8717198f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-a586f1c5-f651-4049-9e57-1d0a043de002,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-f8ace3d6-5331-4bcb-99cb-f868f7fe8d09,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-7c41b74d-2a82-4b6c-b5fb-5fa9e6ff5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-4651fe48-8b49-4ceb-a83d-fd1e5722e467,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-f9b06257-1e25-44da-b6bd-dc61c76753ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224142572-172.17.0.14-1597728636956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-d168e1d8-100f-4d5e-9ae4-fcfac60ae9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-e32af182-29bf-42dd-b3ba-935f5456e815,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-06d50d63-2d6e-4e81-bc09-bec8717198f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-a586f1c5-f651-4049-9e57-1d0a043de002,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-f8ace3d6-5331-4bcb-99cb-f868f7fe8d09,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-7c41b74d-2a82-4b6c-b5fb-5fa9e6ff5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-4651fe48-8b49-4ceb-a83d-fd1e5722e467,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-f9b06257-1e25-44da-b6bd-dc61c76753ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5828
