reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082735029-172.17.0.18-1597747567876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39111,DS-4c116aeb-cccb-4cce-b4b3-e0ee5401bcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-8e5936e2-2a74-4e65-bed7-26f9b8958ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-b5e09853-e938-419a-b123-d82d9256b9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-6eb0b559-68a8-4bd8-ba85-3723f95ff44a,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-e546525f-7330-4291-969a-5790d20c73d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-fdc640f7-6b13-4820-85f3-b2edb73a7f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-34bd73f0-d031-4a37-88eb-2b7691ae7348,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-b361e423-86c6-4b59-b4ef-cc0b8f10ec15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082735029-172.17.0.18-1597747567876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39111,DS-4c116aeb-cccb-4cce-b4b3-e0ee5401bcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-8e5936e2-2a74-4e65-bed7-26f9b8958ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-b5e09853-e938-419a-b123-d82d9256b9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-6eb0b559-68a8-4bd8-ba85-3723f95ff44a,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-e546525f-7330-4291-969a-5790d20c73d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-fdc640f7-6b13-4820-85f3-b2edb73a7f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-34bd73f0-d031-4a37-88eb-2b7691ae7348,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-b361e423-86c6-4b59-b4ef-cc0b8f10ec15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663931452-172.17.0.18-1597747947362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44747,DS-5f635353-55e9-480f-a70d-1127a8bd94ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-68112725-8d67-46b7-bed7-79261802a3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-7eb25332-c8e8-4aef-a048-0a16de73bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-ad31d434-ae6c-4e5a-9d92-02b28f61e47a,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-a3aa1211-4f57-45d9-b486-8e3fe96db5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-3639b0f1-2638-4318-b614-6b27ef6ed5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-2eacc197-f721-44c8-aaf6-474129a4a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-e952f651-ac5d-4954-b438-e54627b7efb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663931452-172.17.0.18-1597747947362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44747,DS-5f635353-55e9-480f-a70d-1127a8bd94ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-68112725-8d67-46b7-bed7-79261802a3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-7eb25332-c8e8-4aef-a048-0a16de73bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-ad31d434-ae6c-4e5a-9d92-02b28f61e47a,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-a3aa1211-4f57-45d9-b486-8e3fe96db5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-3639b0f1-2638-4318-b614-6b27ef6ed5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-2eacc197-f721-44c8-aaf6-474129a4a27f,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-e952f651-ac5d-4954-b438-e54627b7efb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199171191-172.17.0.18-1597748030340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-8acc08f8-2c49-40b3-8dc3-3e3d37ec6eca,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-cdba2bc2-bb2a-4e67-8173-c2f64a1c58cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-66f584cb-3144-40cf-8619-85934927809e,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-a64cc400-4833-4eb6-911f-e7820d4372dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-64150dc0-29c3-4b31-b26f-b3a72ad38c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-f7b0cdd4-4492-4f48-b5b0-08c158661dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-1fe69606-abd9-4863-a7fb-2b05c9f67215,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-de1cf208-8640-4244-8aad-2f23b5d38c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199171191-172.17.0.18-1597748030340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-8acc08f8-2c49-40b3-8dc3-3e3d37ec6eca,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-cdba2bc2-bb2a-4e67-8173-c2f64a1c58cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-66f584cb-3144-40cf-8619-85934927809e,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-a64cc400-4833-4eb6-911f-e7820d4372dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-64150dc0-29c3-4b31-b26f-b3a72ad38c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-f7b0cdd4-4492-4f48-b5b0-08c158661dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-1fe69606-abd9-4863-a7fb-2b05c9f67215,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-de1cf208-8640-4244-8aad-2f23b5d38c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228110113-172.17.0.18-1597748114015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45551,DS-3821a245-6228-4200-8127-c434e454adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-7bde0a63-f8c5-481d-a565-9873cbbbeb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-fdb313d9-5ac2-45fc-b6f1-1476c368fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-66a18b7b-6b02-4bd0-ba1a-912f5261246d,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-52ea1841-6603-48bc-8076-a0701995dc18,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-809a1ebd-9776-48a5-b118-0ce097c1490f,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-8a90751d-466b-43b6-8ce8-6896d081d244,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-d02937e2-16e3-46e9-a0bd-7fc1ac8c9410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228110113-172.17.0.18-1597748114015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45551,DS-3821a245-6228-4200-8127-c434e454adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-7bde0a63-f8c5-481d-a565-9873cbbbeb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-fdb313d9-5ac2-45fc-b6f1-1476c368fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-66a18b7b-6b02-4bd0-ba1a-912f5261246d,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-52ea1841-6603-48bc-8076-a0701995dc18,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-809a1ebd-9776-48a5-b118-0ce097c1490f,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-8a90751d-466b-43b6-8ce8-6896d081d244,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-d02937e2-16e3-46e9-a0bd-7fc1ac8c9410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040252041-172.17.0.18-1597748472143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-5a566625-2479-4d16-b308-84e02b75208a,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-129f38e8-4ce2-4767-8acd-ab0b9cc61abb,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-69793f8e-d0c7-43f1-b973-4a1ab89f8e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e020ab97-334f-456d-b545-3705c00ba435,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-0418b124-75b4-470a-9304-316ee6ecaa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-0b75883c-fab6-4bb6-8c6b-493c6324aebb,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-82c73804-8eee-4c2a-8d1f-7da140f64d52,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-9eca4685-d1ee-4cd3-aa1e-f605813a537b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040252041-172.17.0.18-1597748472143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-5a566625-2479-4d16-b308-84e02b75208a,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-129f38e8-4ce2-4767-8acd-ab0b9cc61abb,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-69793f8e-d0c7-43f1-b973-4a1ab89f8e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e020ab97-334f-456d-b545-3705c00ba435,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-0418b124-75b4-470a-9304-316ee6ecaa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-0b75883c-fab6-4bb6-8c6b-493c6324aebb,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-82c73804-8eee-4c2a-8d1f-7da140f64d52,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-9eca4685-d1ee-4cd3-aa1e-f605813a537b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062893500-172.17.0.18-1597749335214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-d94870d6-2984-4b16-80b6-63920957c22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-b743e0f1-97ec-491f-9fe1-2196a13b974c,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-8c3fd8a7-65b9-43b0-b6ce-be480d4f146c,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-abe95299-02f8-4048-b3f3-d9666661712d,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-36c6b5b7-491f-4923-b3e2-84162b9f6225,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-c760910a-720c-4f4a-9c3a-e7b516878cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-0a52e0ff-a133-4e28-bdd2-a108e433178f,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-de7e7c82-0094-43fb-b643-232b6dc352ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062893500-172.17.0.18-1597749335214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-d94870d6-2984-4b16-80b6-63920957c22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-b743e0f1-97ec-491f-9fe1-2196a13b974c,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-8c3fd8a7-65b9-43b0-b6ce-be480d4f146c,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-abe95299-02f8-4048-b3f3-d9666661712d,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-36c6b5b7-491f-4923-b3e2-84162b9f6225,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-c760910a-720c-4f4a-9c3a-e7b516878cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-0a52e0ff-a133-4e28-bdd2-a108e433178f,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-de7e7c82-0094-43fb-b643-232b6dc352ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439732616-172.17.0.18-1597751165053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-957e379c-c9ea-4903-b99f-ad20cbf6a243,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-a0951122-b674-4167-9d8b-44d67676a113,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-0226a15b-4db9-4321-a729-11328872fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-ade38b67-a6d9-454a-8233-855ae81b8a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-7da5161a-a848-43f4-8c50-8045084e9f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-a3f1966f-1d46-4a27-8734-5b615640bb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-624cadaa-ba42-4bc7-a5da-a1a99c9b7f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-95e0505f-6d26-4b68-b75a-692376b2e5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439732616-172.17.0.18-1597751165053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-957e379c-c9ea-4903-b99f-ad20cbf6a243,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-a0951122-b674-4167-9d8b-44d67676a113,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-0226a15b-4db9-4321-a729-11328872fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-ade38b67-a6d9-454a-8233-855ae81b8a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-7da5161a-a848-43f4-8c50-8045084e9f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-a3f1966f-1d46-4a27-8734-5b615640bb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-624cadaa-ba42-4bc7-a5da-a1a99c9b7f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-95e0505f-6d26-4b68-b75a-692376b2e5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067623825-172.17.0.18-1597751232444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-bb9b98d6-73a0-4ba3-8d59-285a0be86dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-56534e62-bd82-4cf8-b1d0-5d9124b57ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-99563c23-2c56-4f99-bb2a-c9d8c4650baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-021ef33e-b0fb-425f-ac20-3fb5171347e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-ffe38c66-f601-49bf-80b1-12e3377acb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-1186f602-710d-4a82-afed-40776b96411e,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-b73494b0-38bf-4fd1-b5ea-c9bdfecdc4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-3876242b-9a31-41ab-ae37-9adaee3e291c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067623825-172.17.0.18-1597751232444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-bb9b98d6-73a0-4ba3-8d59-285a0be86dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-56534e62-bd82-4cf8-b1d0-5d9124b57ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-99563c23-2c56-4f99-bb2a-c9d8c4650baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-021ef33e-b0fb-425f-ac20-3fb5171347e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-ffe38c66-f601-49bf-80b1-12e3377acb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-1186f602-710d-4a82-afed-40776b96411e,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-b73494b0-38bf-4fd1-b5ea-c9bdfecdc4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-3876242b-9a31-41ab-ae37-9adaee3e291c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077279828-172.17.0.18-1597751813743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34827,DS-57574bd5-de17-42cd-b6b5-b10544f4299e,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-14f55e20-95d6-4142-ad5e-53e0fa472148,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-6da78903-bc76-4733-9820-d2325cce23e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-69a134d8-5bac-4ae2-b83b-5384d15a8553,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-9250692e-4056-4579-8af2-9fb26c4f3843,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-f8b05d16-347e-4145-aba8-c2bdf9020817,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-fd704fa4-bc93-47cb-8f68-551983954402,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-c2e7429d-e7ca-4130-b644-a0858937bd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077279828-172.17.0.18-1597751813743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34827,DS-57574bd5-de17-42cd-b6b5-b10544f4299e,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-14f55e20-95d6-4142-ad5e-53e0fa472148,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-6da78903-bc76-4733-9820-d2325cce23e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-69a134d8-5bac-4ae2-b83b-5384d15a8553,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-9250692e-4056-4579-8af2-9fb26c4f3843,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-f8b05d16-347e-4145-aba8-c2bdf9020817,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-fd704fa4-bc93-47cb-8f68-551983954402,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-c2e7429d-e7ca-4130-b644-a0858937bd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534994016-172.17.0.18-1597752172271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-2c069409-85a3-4873-946c-75735b7be1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-b70f0cfe-8dfc-4d24-9022-5ea18580e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-0cd477af-12bf-4434-b3aa-c97cfc42d264,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-214ae3d5-22d4-4a52-b4eb-80ab96d64555,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-6e21a72f-e7c3-4bfb-ad96-520d3ddf4589,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-4ebac372-d305-4fd0-a7ca-51668ead81c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-b683696b-7aac-457b-b762-63d9b10129d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-147eb344-94a4-40e9-a700-2b0d5bdf9683,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534994016-172.17.0.18-1597752172271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-2c069409-85a3-4873-946c-75735b7be1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-b70f0cfe-8dfc-4d24-9022-5ea18580e45d,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-0cd477af-12bf-4434-b3aa-c97cfc42d264,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-214ae3d5-22d4-4a52-b4eb-80ab96d64555,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-6e21a72f-e7c3-4bfb-ad96-520d3ddf4589,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-4ebac372-d305-4fd0-a7ca-51668ead81c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-b683696b-7aac-457b-b762-63d9b10129d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-147eb344-94a4-40e9-a700-2b0d5bdf9683,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702394085-172.17.0.18-1597752358860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-8a6c5830-5649-4c84-9b78-de7535dfd01f,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-a947759c-16e4-4aa5-a801-90dc87c294a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-e910360d-d671-4888-b24b-fdcdcd32f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-8a3a10f6-7540-49d2-aca2-0cf528ef9f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-031b0f8e-5ccd-4e6f-8519-5198d3e59d80,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-65206e71-27c4-4223-b544-1aceb26a6d55,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-35c866e8-0d56-4872-afd6-751b05c6cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-86d64f81-a699-4ed5-9c69-d9d0b57bf5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702394085-172.17.0.18-1597752358860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-8a6c5830-5649-4c84-9b78-de7535dfd01f,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-a947759c-16e4-4aa5-a801-90dc87c294a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-e910360d-d671-4888-b24b-fdcdcd32f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-8a3a10f6-7540-49d2-aca2-0cf528ef9f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-031b0f8e-5ccd-4e6f-8519-5198d3e59d80,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-65206e71-27c4-4223-b544-1aceb26a6d55,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-35c866e8-0d56-4872-afd6-751b05c6cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-86d64f81-a699-4ed5-9c69-d9d0b57bf5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382448063-172.17.0.18-1597752803114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36929,DS-5644cdcd-035d-4ee7-8f05-32ea923b9d92,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-bebf8d80-b7d6-4244-a776-3fcb60769912,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-2baa11ce-f229-4f1a-ad2f-d8c880c80d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-db4a3be5-3f87-48e4-8f3e-401af975f1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-966e8ea5-2a90-482c-bd95-ecb4079fbda0,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-bacd3eea-889e-4c75-883f-003bc4233f55,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-53240eb8-bd89-4e97-93e7-e045067d6c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-b9d2b100-3428-475c-bfd0-88de67786eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382448063-172.17.0.18-1597752803114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36929,DS-5644cdcd-035d-4ee7-8f05-32ea923b9d92,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-bebf8d80-b7d6-4244-a776-3fcb60769912,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-2baa11ce-f229-4f1a-ad2f-d8c880c80d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-db4a3be5-3f87-48e4-8f3e-401af975f1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-966e8ea5-2a90-482c-bd95-ecb4079fbda0,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-bacd3eea-889e-4c75-883f-003bc4233f55,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-53240eb8-bd89-4e97-93e7-e045067d6c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-b9d2b100-3428-475c-bfd0-88de67786eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3000s
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934579451-172.17.0.18-1597752946614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34459,DS-2ce3e560-ec57-4b3f-8959-63a37a677e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-904e4cf1-ceb7-48b2-a297-c27282786122,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-7e6acd55-e77a-4256-b4a5-0dbd7fef4637,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-67582020-67c2-4cbd-a12c-d98aafcc2bae,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-607c3c90-d576-4494-9ee8-fe3d74551bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-8770d6b9-978d-4cc7-9981-148f17bcda62,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-e59912d1-db20-4bdc-8395-dadd9ec621b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-f7dc74b3-a4ff-4102-955f-ba446ef201c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934579451-172.17.0.18-1597752946614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34459,DS-2ce3e560-ec57-4b3f-8959-63a37a677e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-904e4cf1-ceb7-48b2-a297-c27282786122,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-7e6acd55-e77a-4256-b4a5-0dbd7fef4637,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-67582020-67c2-4cbd-a12c-d98aafcc2bae,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-607c3c90-d576-4494-9ee8-fe3d74551bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-8770d6b9-978d-4cc7-9981-148f17bcda62,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-e59912d1-db20-4bdc-8395-dadd9ec621b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-f7dc74b3-a4ff-4102-955f-ba446ef201c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5693
