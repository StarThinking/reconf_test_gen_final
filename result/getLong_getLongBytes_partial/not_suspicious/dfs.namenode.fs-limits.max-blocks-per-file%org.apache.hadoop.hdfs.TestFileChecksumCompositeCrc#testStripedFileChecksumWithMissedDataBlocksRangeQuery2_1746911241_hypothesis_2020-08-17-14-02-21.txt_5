reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806824492-172.17.0.2-1597673076079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39753,DS-6a90b9e6-e9eb-419c-b049-ac4e42e3dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-d2ae55d6-8039-4211-b39a-cd64248ec87d,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-42813944-5820-4588-a84a-7489396a993c,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-3d68f357-5b48-46f4-b3d0-9aaf1d529a97,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-4c91956a-eb05-43a6-8907-d13611036cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-89183291-64fc-48c6-98b0-eac951f85e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-2e33b84c-0a7d-4c40-af68-11549ff44682,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-fb7074df-3ea8-4162-aaeb-9e7f5d7e2072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806824492-172.17.0.2-1597673076079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39753,DS-6a90b9e6-e9eb-419c-b049-ac4e42e3dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-d2ae55d6-8039-4211-b39a-cd64248ec87d,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-42813944-5820-4588-a84a-7489396a993c,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-3d68f357-5b48-46f4-b3d0-9aaf1d529a97,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-4c91956a-eb05-43a6-8907-d13611036cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-89183291-64fc-48c6-98b0-eac951f85e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-2e33b84c-0a7d-4c40-af68-11549ff44682,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-fb7074df-3ea8-4162-aaeb-9e7f5d7e2072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449013817-172.17.0.2-1597673220375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-be48bc09-17e4-4498-a597-8e1ac06f63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-f869368f-0dc3-4b50-a990-e715df2cccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-be14666c-3b51-49ff-9dc5-5cb17e9acee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-5317791a-c23a-41db-9444-4705f87a4c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-1d26272d-8b17-4ed3-97dd-8eaa30342496,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-304d5dc6-77de-43c5-a807-61c34af17086,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-1086e97e-0f49-44d9-8345-83fef35462b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-4832dfd7-9571-4097-9605-3eec56679654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449013817-172.17.0.2-1597673220375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-be48bc09-17e4-4498-a597-8e1ac06f63e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-f869368f-0dc3-4b50-a990-e715df2cccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-be14666c-3b51-49ff-9dc5-5cb17e9acee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-5317791a-c23a-41db-9444-4705f87a4c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-1d26272d-8b17-4ed3-97dd-8eaa30342496,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-304d5dc6-77de-43c5-a807-61c34af17086,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-1086e97e-0f49-44d9-8345-83fef35462b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-4832dfd7-9571-4097-9605-3eec56679654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269933895-172.17.0.2-1597673921060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-0d20e58d-d254-44bf-89ea-91b11c148782,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-7a5f52a4-faac-439f-ba60-1dc1c2fd1491,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-63cb3635-4fdd-4c6a-b1c3-965faf053abe,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-6ddd5f60-f29e-4503-b822-8b7490710ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-2ea2881b-4338-4330-ae96-03c4462eea03,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-7771eb56-400d-4dc7-b7b2-bb83b9d765aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-128fa4b4-9fb9-4711-a0f5-bff494eaa011,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-e351f3c7-a346-44a6-8b73-f8dca4839e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269933895-172.17.0.2-1597673921060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38301,DS-0d20e58d-d254-44bf-89ea-91b11c148782,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-7a5f52a4-faac-439f-ba60-1dc1c2fd1491,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-63cb3635-4fdd-4c6a-b1c3-965faf053abe,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-6ddd5f60-f29e-4503-b822-8b7490710ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-2ea2881b-4338-4330-ae96-03c4462eea03,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-7771eb56-400d-4dc7-b7b2-bb83b9d765aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-128fa4b4-9fb9-4711-a0f5-bff494eaa011,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-e351f3c7-a346-44a6-8b73-f8dca4839e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817246580-172.17.0.2-1597674437467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38155,DS-bce10b0e-8158-4829-b40d-f2731945f3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-d25ce4fa-f5d5-44cf-beb5-5d9105bf0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-f66f3c10-f63a-44fc-92e9-8881f8013bca,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-53d4c9af-8200-41d3-a3b3-83fc794694af,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-ee49076f-566c-4a08-a436-2b625b79e5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-02c342d0-64a9-492d-9be7-de3a3a4bc15e,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-c44c69fb-78e5-497a-ae32-0af0de8563bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-b32cd3ea-c732-443e-abee-064b4dde76a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817246580-172.17.0.2-1597674437467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38155,DS-bce10b0e-8158-4829-b40d-f2731945f3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-d25ce4fa-f5d5-44cf-beb5-5d9105bf0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-f66f3c10-f63a-44fc-92e9-8881f8013bca,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-53d4c9af-8200-41d3-a3b3-83fc794694af,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-ee49076f-566c-4a08-a436-2b625b79e5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-02c342d0-64a9-492d-9be7-de3a3a4bc15e,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-c44c69fb-78e5-497a-ae32-0af0de8563bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-b32cd3ea-c732-443e-abee-064b4dde76a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958983283-172.17.0.2-1597674603307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46432,DS-fe7a8c6c-a370-48a0-b94a-de6f7d631420,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-764e842f-d3fb-45ac-9344-7566938f7667,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-d71b519d-01d6-4e62-9427-fe0a8c305912,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-33000bdf-a736-45b3-a509-3008510bc3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-51757f9c-b2b5-40da-8867-0074fe613f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-0392571e-8a0a-4895-a37a-e6cd99c0ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-7351afe0-fe2f-49e6-8d94-67d3d9ef27d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-13ba7d49-ac3f-47e6-aaef-a64cd3cead78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958983283-172.17.0.2-1597674603307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46432,DS-fe7a8c6c-a370-48a0-b94a-de6f7d631420,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-764e842f-d3fb-45ac-9344-7566938f7667,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-d71b519d-01d6-4e62-9427-fe0a8c305912,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-33000bdf-a736-45b3-a509-3008510bc3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-51757f9c-b2b5-40da-8867-0074fe613f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-0392571e-8a0a-4895-a37a-e6cd99c0ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-7351afe0-fe2f-49e6-8d94-67d3d9ef27d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-13ba7d49-ac3f-47e6-aaef-a64cd3cead78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951864040-172.17.0.2-1597674925166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-fe4fce2e-e6f1-4e47-9efa-6261f9b1c908,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-fd0af1b2-0408-42c5-b374-2867e0648e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-e5b48e65-4486-4e4c-b380-79f045d3cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-90ec2ed4-66a7-4e25-9038-5b9f9c4d14c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-510189ba-b59b-47dd-a304-ae62837ad77b,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-32e49af1-b08f-48b5-9776-c4d7bd6c7a98,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-d4e1504b-d4d7-490b-bf0f-d58faeb714bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-2ea9cace-1e12-4dc3-93be-191bf4b0bdfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951864040-172.17.0.2-1597674925166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-fe4fce2e-e6f1-4e47-9efa-6261f9b1c908,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-fd0af1b2-0408-42c5-b374-2867e0648e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-e5b48e65-4486-4e4c-b380-79f045d3cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-90ec2ed4-66a7-4e25-9038-5b9f9c4d14c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-510189ba-b59b-47dd-a304-ae62837ad77b,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-32e49af1-b08f-48b5-9776-c4d7bd6c7a98,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-d4e1504b-d4d7-490b-bf0f-d58faeb714bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-2ea9cace-1e12-4dc3-93be-191bf4b0bdfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709227370-172.17.0.2-1597675064107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-f949f3e4-bb50-4690-b297-b3aed29be554,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-d9ac11e9-779b-4049-81a0-d669350cf28d,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-ec1ff509-b237-4ea7-8117-ad84d121cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-75032002-aa37-4139-a831-ec9afb6e9203,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-f48e6926-f98d-46fb-bc81-d5ca3b5f1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-c27d5d51-cc83-486b-a1a5-6be5ec8fec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-812e88d5-d4c9-482d-8d4e-e25460901cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-dc15499a-9bc4-41e5-b19e-cec648c4469d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709227370-172.17.0.2-1597675064107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35467,DS-f949f3e4-bb50-4690-b297-b3aed29be554,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-d9ac11e9-779b-4049-81a0-d669350cf28d,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-ec1ff509-b237-4ea7-8117-ad84d121cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-75032002-aa37-4139-a831-ec9afb6e9203,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-f48e6926-f98d-46fb-bc81-d5ca3b5f1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-c27d5d51-cc83-486b-a1a5-6be5ec8fec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-812e88d5-d4c9-482d-8d4e-e25460901cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-dc15499a-9bc4-41e5-b19e-cec648c4469d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350608473-172.17.0.2-1597675128069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-9d8688b7-10a8-49e9-9925-9700b24e8b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-2bbf2f06-0616-4853-bc2d-5a738309303b,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-0f293d52-dc8c-4603-ae86-950699699f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-d38c5371-64ab-4e62-a8bb-bb50dc8edca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-9112d068-fcf6-4956-a931-3f3a2caca21b,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-20e4f8ed-0074-4dd1-b27c-f55b28f5e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-35f14fca-4ae0-4a43-b6a5-ba083ae4b521,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-a82545bf-1a7d-497b-8923-ead31397e7f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350608473-172.17.0.2-1597675128069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-9d8688b7-10a8-49e9-9925-9700b24e8b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-2bbf2f06-0616-4853-bc2d-5a738309303b,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-0f293d52-dc8c-4603-ae86-950699699f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-d38c5371-64ab-4e62-a8bb-bb50dc8edca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-9112d068-fcf6-4956-a931-3f3a2caca21b,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-20e4f8ed-0074-4dd1-b27c-f55b28f5e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-35f14fca-4ae0-4a43-b6a5-ba083ae4b521,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-a82545bf-1a7d-497b-8923-ead31397e7f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114572300-172.17.0.2-1597675208634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36333,DS-a2231fe1-eb1c-429f-865a-aab176b81db3,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-0f7fa75a-4b63-4e45-b669-c88e8c2e24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-4aeb8bff-3b95-4009-b739-94e64502464b,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-05857e3d-2f61-40b2-83e3-68185fa3fbad,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-f3215988-8113-4ee8-9448-adadb42026db,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-38215e6b-1666-41d8-86e5-6c2c2a527ada,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-4c16a895-7e6d-4b75-b135-37c76da0a34c,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-0b84f1c7-7dca-43e6-8735-0778fe336268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114572300-172.17.0.2-1597675208634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36333,DS-a2231fe1-eb1c-429f-865a-aab176b81db3,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-0f7fa75a-4b63-4e45-b669-c88e8c2e24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-4aeb8bff-3b95-4009-b739-94e64502464b,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-05857e3d-2f61-40b2-83e3-68185fa3fbad,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-f3215988-8113-4ee8-9448-adadb42026db,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-38215e6b-1666-41d8-86e5-6c2c2a527ada,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-4c16a895-7e6d-4b75-b135-37c76da0a34c,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-0b84f1c7-7dca-43e6-8735-0778fe336268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962557676-172.17.0.2-1597675352287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44030,DS-b33f39e1-d1f8-4849-a503-9b348e808cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-109e267e-5eaf-4625-9b52-05fda1c0b74c,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-18ea56ff-bad0-48ad-9923-443d4673ee1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-535f48ed-2251-4a33-95f4-616340df2bda,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-5c4a6143-5009-4410-a969-93ef4de981f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-6112b5aa-48f2-475f-89ed-33709c102784,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-3d59f10d-42c5-4333-be11-b5f242eb13c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-64d2f7d0-55b6-4aef-bb2a-bd1a2816b89b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962557676-172.17.0.2-1597675352287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44030,DS-b33f39e1-d1f8-4849-a503-9b348e808cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-109e267e-5eaf-4625-9b52-05fda1c0b74c,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-18ea56ff-bad0-48ad-9923-443d4673ee1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-535f48ed-2251-4a33-95f4-616340df2bda,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-5c4a6143-5009-4410-a969-93ef4de981f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-6112b5aa-48f2-475f-89ed-33709c102784,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-3d59f10d-42c5-4333-be11-b5f242eb13c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-64d2f7d0-55b6-4aef-bb2a-bd1a2816b89b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347291842-172.17.0.2-1597675612110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-26beb337-c284-4ae5-9df3-678574ae9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-ec67c619-e0c5-494a-b74f-6cf862e6e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-aa01989b-1823-4854-8518-d36eb37a7e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-2ab6b3b0-7019-4eac-9058-04725ccdd6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-94eb0dc5-e841-4d1e-bfbf-ae59478c2e19,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-d62ad143-6047-443a-9eb5-8b7456e70e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-683130f3-b36f-4159-a220-3f8c43602c46,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-80cbb127-61c0-43aa-ade9-5b8dd6628dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347291842-172.17.0.2-1597675612110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-26beb337-c284-4ae5-9df3-678574ae9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-ec67c619-e0c5-494a-b74f-6cf862e6e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-aa01989b-1823-4854-8518-d36eb37a7e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-2ab6b3b0-7019-4eac-9058-04725ccdd6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-94eb0dc5-e841-4d1e-bfbf-ae59478c2e19,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-d62ad143-6047-443a-9eb5-8b7456e70e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-683130f3-b36f-4159-a220-3f8c43602c46,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-80cbb127-61c0-43aa-ade9-5b8dd6628dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695450020-172.17.0.2-1597676104583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-bfba858c-8b70-47f5-9444-65b2ded81dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-99f82e42-9937-4448-b254-dec536a4a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-c6223488-0bef-467e-833d-8f57d1147a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-af267da6-1c38-4337-9166-69801dd71e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-0d94e1eb-1ceb-4b11-99de-2544f08550cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-02c3e7cc-c05b-4645-9105-bdd6bcf17e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-af3c5360-8e18-4ead-83d3-4dfaaab407cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-f93e16f2-2714-4a10-b970-3e426cde0d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695450020-172.17.0.2-1597676104583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-bfba858c-8b70-47f5-9444-65b2ded81dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-99f82e42-9937-4448-b254-dec536a4a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-c6223488-0bef-467e-833d-8f57d1147a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-af267da6-1c38-4337-9166-69801dd71e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-0d94e1eb-1ceb-4b11-99de-2544f08550cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-02c3e7cc-c05b-4645-9105-bdd6bcf17e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-af3c5360-8e18-4ead-83d3-4dfaaab407cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-f93e16f2-2714-4a10-b970-3e426cde0d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409859199-172.17.0.2-1597676236672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-d87fbdda-edef-40ee-a60f-405fddb05106,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-283ff6b7-c455-4ffe-b307-35712b9d5d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-5fba8dd7-9838-4c03-9e2c-bd9dfa44c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-b39bea30-f38e-4c5e-947c-4778c0779360,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-d54f6b73-1cbc-4540-997e-9a282730fa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-e4cc4aed-a9b4-4f88-b150-7e913ce457bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-17d500ce-0b7a-41b4-885c-d112cd83ec17,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-c2b2729b-6ff6-4a27-b649-f06367550fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409859199-172.17.0.2-1597676236672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-d87fbdda-edef-40ee-a60f-405fddb05106,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-283ff6b7-c455-4ffe-b307-35712b9d5d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-5fba8dd7-9838-4c03-9e2c-bd9dfa44c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-b39bea30-f38e-4c5e-947c-4778c0779360,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-d54f6b73-1cbc-4540-997e-9a282730fa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-e4cc4aed-a9b4-4f88-b150-7e913ce457bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-17d500ce-0b7a-41b4-885c-d112cd83ec17,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-c2b2729b-6ff6-4a27-b649-f06367550fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888883378-172.17.0.2-1597676888017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-8f1cebdb-47a4-43fa-97fb-de1dd670987c,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-7d31f292-e815-495e-96ca-58fbf5a288c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-91143dfd-60f4-46ef-b598-90ad7bdeb342,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-1f695a41-7911-401a-92c8-c149dba259ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-2e6b51a6-488f-4928-9699-651b4cc879ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-c3160519-b016-4511-9c2e-0f94570490e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-85f3ac3e-935f-4528-b0ff-56e39098ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-3ec47c9c-9bf1-4843-94d2-73638a8f0477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888883378-172.17.0.2-1597676888017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-8f1cebdb-47a4-43fa-97fb-de1dd670987c,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-7d31f292-e815-495e-96ca-58fbf5a288c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-91143dfd-60f4-46ef-b598-90ad7bdeb342,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-1f695a41-7911-401a-92c8-c149dba259ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-2e6b51a6-488f-4928-9699-651b4cc879ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-c3160519-b016-4511-9c2e-0f94570490e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-85f3ac3e-935f-4528-b0ff-56e39098ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-3ec47c9c-9bf1-4843-94d2-73638a8f0477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285178285-172.17.0.2-1597677035961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38636,DS-1ac361d0-0139-4031-bc48-49408d849779,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-9cbbb67b-9dde-4fbb-8f6d-d45348439a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-d0bf2506-72ff-4459-bbf6-41899b2f6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-4cbd7ae7-bcc3-4694-b1a4-1dd081efe99c,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-1f770841-713d-4a7d-888c-cc7fcdc0f727,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-338e900a-718d-4ee7-8a1b-629f1ef38312,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-a7a46e6b-2d28-4491-bae4-5f5218cf10a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-60be2bb5-3d21-4514-a2a4-0358be990ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285178285-172.17.0.2-1597677035961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38636,DS-1ac361d0-0139-4031-bc48-49408d849779,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-9cbbb67b-9dde-4fbb-8f6d-d45348439a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-d0bf2506-72ff-4459-bbf6-41899b2f6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-4cbd7ae7-bcc3-4694-b1a4-1dd081efe99c,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-1f770841-713d-4a7d-888c-cc7fcdc0f727,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-338e900a-718d-4ee7-8a1b-629f1ef38312,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-a7a46e6b-2d28-4491-bae4-5f5218cf10a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-60be2bb5-3d21-4514-a2a4-0358be990ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470384176-172.17.0.2-1597677216885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-87477297-09ab-4dcd-b579-ad897a4ead14,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-e8ba5ad7-b00c-4d80-bdc2-bdab290e4b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-7d58b15b-04cf-436c-818e-df3709e23727,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-9d4b8f70-b4b1-4a94-bc14-87641e7cdedf,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-a70faa11-db27-4ca9-9cf8-f23069a6a407,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-0faeb410-bcb4-4249-8ee8-f49244df6f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-8f4ceaf6-1f97-4042-80a1-cb438a4c9ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-dc007b15-b544-4949-a39f-59fd49065968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470384176-172.17.0.2-1597677216885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-87477297-09ab-4dcd-b579-ad897a4ead14,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-e8ba5ad7-b00c-4d80-bdc2-bdab290e4b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-7d58b15b-04cf-436c-818e-df3709e23727,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-9d4b8f70-b4b1-4a94-bc14-87641e7cdedf,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-a70faa11-db27-4ca9-9cf8-f23069a6a407,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-0faeb410-bcb4-4249-8ee8-f49244df6f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-8f4ceaf6-1f97-4042-80a1-cb438a4c9ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-dc007b15-b544-4949-a39f-59fd49065968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740689799-172.17.0.2-1597677685216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33674,DS-ea28e96e-237c-48cf-a23f-d88be9e636c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-b072148e-6d53-49da-b3ba-157b8b40e26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-5477e49e-26dc-4add-9cab-69cbf5ae98e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-947f1e9f-7d56-4151-8a3a-03a4ec21aa07,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-79b9b010-ae7e-47fc-96f0-bae2241f3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-bf2da0ee-8052-45b8-9864-9350bfc67970,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-a42818be-8580-4034-a198-7f44f818d859,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-747ac109-db6b-4a4a-9e3f-72ff79769a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740689799-172.17.0.2-1597677685216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33674,DS-ea28e96e-237c-48cf-a23f-d88be9e636c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-b072148e-6d53-49da-b3ba-157b8b40e26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-5477e49e-26dc-4add-9cab-69cbf5ae98e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-947f1e9f-7d56-4151-8a3a-03a4ec21aa07,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-79b9b010-ae7e-47fc-96f0-bae2241f3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-bf2da0ee-8052-45b8-9864-9350bfc67970,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-a42818be-8580-4034-a198-7f44f818d859,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-747ac109-db6b-4a4a-9e3f-72ff79769a72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80993751-172.17.0.2-1597677997517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-609ef404-a99d-4424-b288-bcb51597a009,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-fe6b9bba-6e91-4066-8abc-c8e4550dc3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-ad2fcee0-1fd2-4879-a6ab-bb3a1194374f,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-fe5b4b91-4b7e-43dc-af28-71fd5b3ca4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-635ebac5-c46d-4e1f-b41d-d559e7150392,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-ee963168-0906-49ff-a9ea-6fb8489e7af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-66dd2432-2fa6-49ec-b03b-f91b2f3a3482,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-9ed3050c-a432-4ce5-891a-7bb8947c499b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80993751-172.17.0.2-1597677997517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-609ef404-a99d-4424-b288-bcb51597a009,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-fe6b9bba-6e91-4066-8abc-c8e4550dc3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-ad2fcee0-1fd2-4879-a6ab-bb3a1194374f,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-fe5b4b91-4b7e-43dc-af28-71fd5b3ca4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-635ebac5-c46d-4e1f-b41d-d559e7150392,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-ee963168-0906-49ff-a9ea-6fb8489e7af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-66dd2432-2fa6-49ec-b03b-f91b2f3a3482,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-9ed3050c-a432-4ce5-891a-7bb8947c499b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5347
