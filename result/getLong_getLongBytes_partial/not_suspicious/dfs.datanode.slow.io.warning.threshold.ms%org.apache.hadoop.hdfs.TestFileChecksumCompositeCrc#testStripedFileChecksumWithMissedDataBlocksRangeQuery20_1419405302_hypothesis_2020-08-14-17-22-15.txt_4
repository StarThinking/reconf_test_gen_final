reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970192235-172.17.0.17-1597425824471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-724b3041-76c3-47e8-948f-8f46553199dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-56df0992-dc5a-430b-9ab2-47f834a6b78d,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-5680b3d1-0e41-43ea-bab2-d43bdad8e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-3b498b50-9a1f-4b59-9f3f-53c6c3debaef,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-737e93b2-13da-4159-9ae1-685abfa239e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-52a35c69-6298-43d5-baf4-4ad112f7c882,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-616e5f71-17e2-4efc-9c85-363e2c511457,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-a1bbfa31-5f0b-40b5-88ab-fb5422b28e48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970192235-172.17.0.17-1597425824471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-724b3041-76c3-47e8-948f-8f46553199dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-56df0992-dc5a-430b-9ab2-47f834a6b78d,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-5680b3d1-0e41-43ea-bab2-d43bdad8e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-3b498b50-9a1f-4b59-9f3f-53c6c3debaef,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-737e93b2-13da-4159-9ae1-685abfa239e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-52a35c69-6298-43d5-baf4-4ad112f7c882,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-616e5f71-17e2-4efc-9c85-363e2c511457,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-a1bbfa31-5f0b-40b5-88ab-fb5422b28e48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463226383-172.17.0.17-1597425923100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-e07e8270-3fe3-4be3-a551-a1ec5d527140,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-e23362f3-ba9e-4bde-9fb6-591b446d8aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-bfe13328-71f0-4188-a53e-a4b64d2e3d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-355c1af0-eaf0-4823-bca9-003935c1cb70,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-dc0fc369-5581-4fc9-acb5-b7760b29f5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-34503b50-23d6-431d-9cf2-ed7754ea6ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-d92838d8-aedb-46c0-b19f-9d4515bfca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-0ce1d02b-2d34-4a24-8fef-918e8783ca50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463226383-172.17.0.17-1597425923100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-e07e8270-3fe3-4be3-a551-a1ec5d527140,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-e23362f3-ba9e-4bde-9fb6-591b446d8aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-bfe13328-71f0-4188-a53e-a4b64d2e3d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-355c1af0-eaf0-4823-bca9-003935c1cb70,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-dc0fc369-5581-4fc9-acb5-b7760b29f5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-34503b50-23d6-431d-9cf2-ed7754ea6ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-d92838d8-aedb-46c0-b19f-9d4515bfca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-0ce1d02b-2d34-4a24-8fef-918e8783ca50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623637707-172.17.0.17-1597426234892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-1273f6bb-c3e4-46eb-ae53-3485a240e4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-f03525c2-709d-4393-879c-9a3495cb189e,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-ed172a1e-1769-4ec2-95af-4de2241e089f,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-71970dd4-3337-47c6-9a08-74169c94f534,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-a9f40f70-bba5-47f1-82d3-d2459531af48,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-acb18c2c-6b13-4047-b297-c962b946648c,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-1886bb0e-712e-4369-b1dd-5c6648467bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-9244e9a9-8b55-4384-be89-825aa53c78b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-623637707-172.17.0.17-1597426234892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-1273f6bb-c3e4-46eb-ae53-3485a240e4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-f03525c2-709d-4393-879c-9a3495cb189e,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-ed172a1e-1769-4ec2-95af-4de2241e089f,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-71970dd4-3337-47c6-9a08-74169c94f534,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-a9f40f70-bba5-47f1-82d3-d2459531af48,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-acb18c2c-6b13-4047-b297-c962b946648c,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-1886bb0e-712e-4369-b1dd-5c6648467bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-9244e9a9-8b55-4384-be89-825aa53c78b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125684235-172.17.0.17-1597426267631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43828,DS-e0ef1c41-dad1-422c-ad5b-cd55a9e76635,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-629ffb47-9c3f-49b4-90c7-a3d7b0e68613,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-f6495b68-8e6d-4671-84a6-7753e312efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-7fdf0673-1652-48e7-b7ca-a47fc1749cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-5798526d-eba2-4cfa-b999-958ddf5c1945,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-c4382554-18b4-4d7f-a95d-b8327b5f58ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-7c5c37e4-3299-4509-93e8-a49192eaa018,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-9f2aa299-16f3-4d3c-8bd9-05ef5263db26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125684235-172.17.0.17-1597426267631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43828,DS-e0ef1c41-dad1-422c-ad5b-cd55a9e76635,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-629ffb47-9c3f-49b4-90c7-a3d7b0e68613,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-f6495b68-8e6d-4671-84a6-7753e312efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-7fdf0673-1652-48e7-b7ca-a47fc1749cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-5798526d-eba2-4cfa-b999-958ddf5c1945,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-c4382554-18b4-4d7f-a95d-b8327b5f58ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-7c5c37e4-3299-4509-93e8-a49192eaa018,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-9f2aa299-16f3-4d3c-8bd9-05ef5263db26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321108964-172.17.0.17-1597426497957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45921,DS-daa1c062-5618-45c7-b01a-ba6abdaad6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-62c0437e-b53b-4040-b9ad-b4a5c1baf549,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-8cfaaeca-08e3-4bbf-a1fb-c811f87511fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-ce409a37-058d-4a71-a68f-6a9eb268a882,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-7007f129-4c18-4abf-a325-abff261e4935,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-f3f0fa85-b21c-408d-af9e-6a91ba59ca34,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-85343149-f5a1-42e4-ae66-b02ce21de0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-0689e9ab-c9fc-41b7-b5f7-3587015e972b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321108964-172.17.0.17-1597426497957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45921,DS-daa1c062-5618-45c7-b01a-ba6abdaad6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-62c0437e-b53b-4040-b9ad-b4a5c1baf549,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-8cfaaeca-08e3-4bbf-a1fb-c811f87511fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-ce409a37-058d-4a71-a68f-6a9eb268a882,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-7007f129-4c18-4abf-a325-abff261e4935,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-f3f0fa85-b21c-408d-af9e-6a91ba59ca34,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-85343149-f5a1-42e4-ae66-b02ce21de0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-0689e9ab-c9fc-41b7-b5f7-3587015e972b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023881045-172.17.0.17-1597426630033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34724,DS-fc706db5-10e6-4037-8e13-1babc702a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-4d4537f6-3b2c-475b-9743-faaba95ce7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-603003e7-52c2-4599-9416-1da8651adc25,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-e02d2225-f7e1-4d7e-92b0-073ba60e7528,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-fba43b66-63bd-4c84-8f4b-4ebe07af9c16,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-28e7ef52-c16d-4190-9b03-79a7c25e4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-d05e4fc7-1621-4e7e-b66d-a6a459596eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-e1561e69-3632-42b9-b0a6-14d7fce43c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023881045-172.17.0.17-1597426630033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34724,DS-fc706db5-10e6-4037-8e13-1babc702a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-4d4537f6-3b2c-475b-9743-faaba95ce7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-603003e7-52c2-4599-9416-1da8651adc25,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-e02d2225-f7e1-4d7e-92b0-073ba60e7528,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-fba43b66-63bd-4c84-8f4b-4ebe07af9c16,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-28e7ef52-c16d-4190-9b03-79a7c25e4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-d05e4fc7-1621-4e7e-b66d-a6a459596eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-e1561e69-3632-42b9-b0a6-14d7fce43c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483292954-172.17.0.17-1597426909297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40456,DS-76dd1244-1d4f-435d-bdaf-29b2c6cc557d,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-be870384-9e62-4cf7-98db-cc528857f175,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-4568c904-10c9-4375-bbd1-7aa5c2dbe27e,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-5424442c-0fbd-41d2-bd7b-5585b770a742,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-57644554-96a4-4476-b972-dab56bccbb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-569d3dac-f32f-4b0c-b7f9-6078dbb1da89,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-507072c0-af8e-4b2c-a89b-77a3ed0d8160,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-4514151b-ab34-4665-aa9f-17c4bf241ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483292954-172.17.0.17-1597426909297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40456,DS-76dd1244-1d4f-435d-bdaf-29b2c6cc557d,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-be870384-9e62-4cf7-98db-cc528857f175,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-4568c904-10c9-4375-bbd1-7aa5c2dbe27e,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-5424442c-0fbd-41d2-bd7b-5585b770a742,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-57644554-96a4-4476-b972-dab56bccbb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-569d3dac-f32f-4b0c-b7f9-6078dbb1da89,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-507072c0-af8e-4b2c-a89b-77a3ed0d8160,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-4514151b-ab34-4665-aa9f-17c4bf241ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082672434-172.17.0.17-1597427056762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41994,DS-6be3b301-527c-4971-a061-5c4dbcb89357,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-fe59fd93-d8ed-4fe0-baa5-57e3739263e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-b527f1d3-bcff-4781-8ee1-f207aeb1c176,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-04b2e8a9-2ad8-448e-b671-2b212aeabde6,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-b96f7d13-9dbb-4f46-9538-9f130da96c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-8958920c-ec25-44bc-a235-0e80a9bb13e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-431eed33-6cc6-4321-8205-2090d67754d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-58d59384-ef4e-4c13-b05a-d8b6f2487685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082672434-172.17.0.17-1597427056762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41994,DS-6be3b301-527c-4971-a061-5c4dbcb89357,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-fe59fd93-d8ed-4fe0-baa5-57e3739263e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-b527f1d3-bcff-4781-8ee1-f207aeb1c176,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-04b2e8a9-2ad8-448e-b671-2b212aeabde6,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-b96f7d13-9dbb-4f46-9538-9f130da96c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-8958920c-ec25-44bc-a235-0e80a9bb13e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-431eed33-6cc6-4321-8205-2090d67754d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-58d59384-ef4e-4c13-b05a-d8b6f2487685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129240985-172.17.0.17-1597427090093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39072,DS-ceef0706-9ba7-4046-918d-0a4b19075651,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-04b783a1-07b6-402f-b2d2-6023f9830907,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-6f053da6-52bb-44fb-99be-4fdefff6b4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-44327772-d1a5-48a0-8002-aa30c4ac73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-55bab252-adc7-424d-9497-e41accd78c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-e24687b7-f599-4623-a880-b442dd3116b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-5c9ce1f7-a461-4085-80da-af664dd16630,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-96614d14-25d6-48cb-8df3-b9187a2ef466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129240985-172.17.0.17-1597427090093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39072,DS-ceef0706-9ba7-4046-918d-0a4b19075651,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-04b783a1-07b6-402f-b2d2-6023f9830907,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-6f053da6-52bb-44fb-99be-4fdefff6b4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-44327772-d1a5-48a0-8002-aa30c4ac73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-55bab252-adc7-424d-9497-e41accd78c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-e24687b7-f599-4623-a880-b442dd3116b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-5c9ce1f7-a461-4085-80da-af664dd16630,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-96614d14-25d6-48cb-8df3-b9187a2ef466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919412184-172.17.0.17-1597427156656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-d747e99a-7537-4669-94c3-10d4bf3a4ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-ffc65e8d-54f5-4114-9262-ddc79193349d,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-507d05d5-d31b-45b6-84d6-660db5e30977,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-7a2d8811-3497-4a72-944e-7c115b86fd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-cac2bedd-4f6c-47d5-8857-558d7fd780ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-57ebf69b-6bc7-4b52-876f-287b6ba94851,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-cf527240-d4ba-496d-a7b2-76bb3cc5e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-6be67a7f-2383-42ef-8c2c-9385fe5a5dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919412184-172.17.0.17-1597427156656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-d747e99a-7537-4669-94c3-10d4bf3a4ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-ffc65e8d-54f5-4114-9262-ddc79193349d,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-507d05d5-d31b-45b6-84d6-660db5e30977,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-7a2d8811-3497-4a72-944e-7c115b86fd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-cac2bedd-4f6c-47d5-8857-558d7fd780ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-57ebf69b-6bc7-4b52-876f-287b6ba94851,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-cf527240-d4ba-496d-a7b2-76bb3cc5e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-6be67a7f-2383-42ef-8c2c-9385fe5a5dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078721690-172.17.0.17-1597427271888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43215,DS-738f07e3-2dcf-4790-95c5-552df90fdc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-b3259e73-9c5f-457d-9a7b-e71f4ef90c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-419e5b64-a93b-46cb-8e77-f8e34947d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-e0c25ae0-12ca-4c05-a742-5b5959dd4d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-df028997-3c97-4a29-b099-d41d94363c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-af8390a1-fc5a-45e6-a625-2bc519b143d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-42efbf24-d512-4376-8700-3ae20a2b55a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-7d7b32d9-9285-4bbb-b765-b012eaf8bda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078721690-172.17.0.17-1597427271888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43215,DS-738f07e3-2dcf-4790-95c5-552df90fdc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-b3259e73-9c5f-457d-9a7b-e71f4ef90c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-419e5b64-a93b-46cb-8e77-f8e34947d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-e0c25ae0-12ca-4c05-a742-5b5959dd4d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-df028997-3c97-4a29-b099-d41d94363c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-af8390a1-fc5a-45e6-a625-2bc519b143d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-42efbf24-d512-4376-8700-3ae20a2b55a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-7d7b32d9-9285-4bbb-b765-b012eaf8bda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129236056-172.17.0.17-1597427321273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-ec3324ed-330f-4f4e-9292-57044d559958,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-8aba3f96-5d1f-4232-afdc-a6b8faa9f85c,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-71253ee6-6788-4b08-952c-3874cc3e3861,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-228c9e89-a4d7-495e-bf76-332f31ef65d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-a76fa839-31e6-4431-b0ea-d14a26d62189,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-6e1749a4-3a97-491b-b2e3-56358c455a54,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-225646e3-178b-46f9-9ff0-4d50b0351ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-d66e9f3e-5283-4781-b494-64e9b0ba90f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129236056-172.17.0.17-1597427321273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-ec3324ed-330f-4f4e-9292-57044d559958,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-8aba3f96-5d1f-4232-afdc-a6b8faa9f85c,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-71253ee6-6788-4b08-952c-3874cc3e3861,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-228c9e89-a4d7-495e-bf76-332f31ef65d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-a76fa839-31e6-4431-b0ea-d14a26d62189,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-6e1749a4-3a97-491b-b2e3-56358c455a54,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-225646e3-178b-46f9-9ff0-4d50b0351ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-d66e9f3e-5283-4781-b494-64e9b0ba90f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608189904-172.17.0.17-1597427797939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38258,DS-3577d4cb-d841-4256-afe8-b21cc582377c,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-5bbebb12-2f1b-47b8-ac70-39338081e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-ab2fb2ea-a90e-4056-a206-128e39f98dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-9ebbc910-fab2-48bd-b724-20ac365af55a,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-a86600a1-f5ff-49d5-aa44-196a4ecc0b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-18b1c51c-f44c-4d81-b025-20fa40f97eff,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-bd01ff5f-82b8-4c63-a2d6-0796f93c275e,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-7c9d2037-0c54-42b9-ac38-b773a4ecc1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608189904-172.17.0.17-1597427797939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38258,DS-3577d4cb-d841-4256-afe8-b21cc582377c,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-5bbebb12-2f1b-47b8-ac70-39338081e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-ab2fb2ea-a90e-4056-a206-128e39f98dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-9ebbc910-fab2-48bd-b724-20ac365af55a,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-a86600a1-f5ff-49d5-aa44-196a4ecc0b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-18b1c51c-f44c-4d81-b025-20fa40f97eff,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-bd01ff5f-82b8-4c63-a2d6-0796f93c275e,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-7c9d2037-0c54-42b9-ac38-b773a4ecc1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315085578-172.17.0.17-1597427995562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-8debf9ec-01b6-4296-a4de-4b26fdec2898,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-a83955df-1325-46e7-9d16-cc5515f15fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-09280576-cf07-4812-a221-6892ac8fd50f,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-18a2776b-d838-47cd-b2b5-da1d807821f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-ba0df9b2-998d-4b22-846a-592553319744,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-d2ff5f95-f6bd-455f-96bf-651cc16ab205,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-28dffa92-0661-4cb7-b56a-3f7ead60e5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d7dd9473-bae0-4aac-bf87-656ff5afcc86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315085578-172.17.0.17-1597427995562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-8debf9ec-01b6-4296-a4de-4b26fdec2898,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-a83955df-1325-46e7-9d16-cc5515f15fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-09280576-cf07-4812-a221-6892ac8fd50f,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-18a2776b-d838-47cd-b2b5-da1d807821f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-ba0df9b2-998d-4b22-846a-592553319744,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-d2ff5f95-f6bd-455f-96bf-651cc16ab205,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-28dffa92-0661-4cb7-b56a-3f7ead60e5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d7dd9473-bae0-4aac-bf87-656ff5afcc86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 2467
