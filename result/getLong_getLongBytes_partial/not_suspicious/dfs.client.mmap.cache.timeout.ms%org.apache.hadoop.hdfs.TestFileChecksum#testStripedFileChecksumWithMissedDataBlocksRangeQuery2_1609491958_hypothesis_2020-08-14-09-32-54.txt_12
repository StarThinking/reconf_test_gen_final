reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221852482-172.17.0.5-1597397630572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-776dafa4-0754-4793-9775-d03aa6b3840c,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-f580bf34-a10c-432d-8f7b-63476df05088,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-54ebdbf2-f66d-425b-b711-b9aa3532ffad,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-5d44463a-6313-4409-86b7-e4d0da358668,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-a5d1df41-67c5-4ec5-a6d8-c6f850204e33,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-4736c426-7152-4250-ae3f-37df38baa5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-8359a2eb-1059-4e10-84fc-f4428098209e,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-34eecac9-9f20-4893-894b-479cbfc452a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221852482-172.17.0.5-1597397630572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-776dafa4-0754-4793-9775-d03aa6b3840c,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-f580bf34-a10c-432d-8f7b-63476df05088,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-54ebdbf2-f66d-425b-b711-b9aa3532ffad,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-5d44463a-6313-4409-86b7-e4d0da358668,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-a5d1df41-67c5-4ec5-a6d8-c6f850204e33,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-4736c426-7152-4250-ae3f-37df38baa5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-8359a2eb-1059-4e10-84fc-f4428098209e,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-34eecac9-9f20-4893-894b-479cbfc452a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414813571-172.17.0.5-1597397938698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-b10bdc65-12a3-4a67-a9ac-72754d7a40a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-aec293ec-a89b-400c-8679-7f31216af61c,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-9a181420-6ef1-4ad2-9567-a8e65de87beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-de75edd8-31e8-444b-80aa-67b208e89808,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-974efc63-70dc-4cc0-b09d-e682b9848744,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-717d652a-72c2-491f-9740-4427552fad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-3264ac99-12d0-4efc-9785-4c9134e89b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-487597d8-952a-4849-bb0a-8ea614cc8134,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414813571-172.17.0.5-1597397938698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41714,DS-b10bdc65-12a3-4a67-a9ac-72754d7a40a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-aec293ec-a89b-400c-8679-7f31216af61c,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-9a181420-6ef1-4ad2-9567-a8e65de87beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-de75edd8-31e8-444b-80aa-67b208e89808,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-974efc63-70dc-4cc0-b09d-e682b9848744,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-717d652a-72c2-491f-9740-4427552fad7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-3264ac99-12d0-4efc-9785-4c9134e89b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-487597d8-952a-4849-bb0a-8ea614cc8134,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923299073-172.17.0.5-1597398171353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-90465131-fcdf-40d6-848a-19a4e2159f16,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-fa213fbb-575a-4c96-a922-1d70e56940ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-d14f55b6-e65e-49f8-8013-7bbb0a904fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-0e842307-bd41-4d1b-a42a-3cadaf0b15de,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-d7f27400-4b66-4bdc-9d5b-e3f6b1088a54,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-68799226-f6ba-44da-90a2-38b4457bb363,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-6f8f65d6-c793-40f6-ad6b-b7b0e66581dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-19bfa48c-6081-44e5-84c6-06510c089825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923299073-172.17.0.5-1597398171353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-90465131-fcdf-40d6-848a-19a4e2159f16,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-fa213fbb-575a-4c96-a922-1d70e56940ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-d14f55b6-e65e-49f8-8013-7bbb0a904fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-0e842307-bd41-4d1b-a42a-3cadaf0b15de,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-d7f27400-4b66-4bdc-9d5b-e3f6b1088a54,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-68799226-f6ba-44da-90a2-38b4457bb363,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-6f8f65d6-c793-40f6-ad6b-b7b0e66581dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-19bfa48c-6081-44e5-84c6-06510c089825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985195942-172.17.0.5-1597398777692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-304c6bfa-79c3-45cc-8a56-d419f2f0da81,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-b5d9dc37-8eb2-4fff-b944-e1f4e345cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-2f90f1d3-09e9-4e4b-b06f-90a575513b38,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-0951ff3c-d56c-437c-a215-8018e042f91c,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-189e4028-8589-4510-befd-54044935e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-a6e7c2b9-35ad-4c1b-b65c-ab0e5d6f6a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-82e37832-2a4e-4d5a-b71c-7493846a7a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-9650f51e-7080-41e7-a91e-e441880c6909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985195942-172.17.0.5-1597398777692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38966,DS-304c6bfa-79c3-45cc-8a56-d419f2f0da81,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-b5d9dc37-8eb2-4fff-b944-e1f4e345cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-2f90f1d3-09e9-4e4b-b06f-90a575513b38,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-0951ff3c-d56c-437c-a215-8018e042f91c,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-189e4028-8589-4510-befd-54044935e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-a6e7c2b9-35ad-4c1b-b65c-ab0e5d6f6a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-82e37832-2a4e-4d5a-b71c-7493846a7a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-9650f51e-7080-41e7-a91e-e441880c6909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196788062-172.17.0.5-1597399293369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34274,DS-6acb28c0-3082-40e9-831c-5f364254f858,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-567027b8-bab9-4b5b-89f7-2486ec376d94,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-6e2d120b-f095-4844-b023-77ee8e4fb00f,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-d5fb818c-f935-4bfa-85c6-8f1cbe911437,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-5e7ad960-8c6f-471f-a634-76890fe81926,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-45d9e960-ee7c-4174-a2b0-301c1575a08a,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-123a008c-a28a-4e05-b8f5-8b77b15d405d,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-4e1fee0a-6690-4cd0-a0d2-6f6727d09190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196788062-172.17.0.5-1597399293369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34274,DS-6acb28c0-3082-40e9-831c-5f364254f858,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-567027b8-bab9-4b5b-89f7-2486ec376d94,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-6e2d120b-f095-4844-b023-77ee8e4fb00f,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-d5fb818c-f935-4bfa-85c6-8f1cbe911437,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-5e7ad960-8c6f-471f-a634-76890fe81926,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-45d9e960-ee7c-4174-a2b0-301c1575a08a,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-123a008c-a28a-4e05-b8f5-8b77b15d405d,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-4e1fee0a-6690-4cd0-a0d2-6f6727d09190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654670756-172.17.0.5-1597399330385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40128,DS-d24ea8df-9345-4a90-a5dc-99760621a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-205d5b8f-1c88-4ad8-a5cc-56ab401336ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-e7d9245c-ff49-4e53-b119-ac9fff0df112,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-6971bcf8-40a9-4b7b-a472-4085e3fc5c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-65c05460-681d-488e-9f34-338c4ae01ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-80f2dd4b-b9b2-45d9-b068-9bb3b35493d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-a182a3ae-8558-452f-b3b4-dd6abd62231c,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-43846d6e-2b5f-473d-bfdb-3c0a190bb60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654670756-172.17.0.5-1597399330385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40128,DS-d24ea8df-9345-4a90-a5dc-99760621a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-205d5b8f-1c88-4ad8-a5cc-56ab401336ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-e7d9245c-ff49-4e53-b119-ac9fff0df112,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-6971bcf8-40a9-4b7b-a472-4085e3fc5c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-65c05460-681d-488e-9f34-338c4ae01ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-80f2dd4b-b9b2-45d9-b068-9bb3b35493d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-a182a3ae-8558-452f-b3b4-dd6abd62231c,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-43846d6e-2b5f-473d-bfdb-3c0a190bb60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920577792-172.17.0.5-1597399404816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45237,DS-48a5f28d-9bef-4c82-9e61-4f0b32f9a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-00389669-0bef-4f0c-93cc-729879bf6434,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-50306fa4-3a8e-4f4c-a95e-cbeca88e6d41,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-567c014e-e7c3-4e44-ac85-30ab53e1f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-963c5f30-945c-4f28-9187-fe4bcae759c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-9b8e1b1a-ce7f-4f4d-9450-ca5ba971464a,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-6e6d4e56-e066-45da-89fb-2a6f9d89a572,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-944d9a2f-0edc-4ba2-999d-5ca4ed0f2983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920577792-172.17.0.5-1597399404816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45237,DS-48a5f28d-9bef-4c82-9e61-4f0b32f9a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-00389669-0bef-4f0c-93cc-729879bf6434,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-50306fa4-3a8e-4f4c-a95e-cbeca88e6d41,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-567c014e-e7c3-4e44-ac85-30ab53e1f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-963c5f30-945c-4f28-9187-fe4bcae759c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-9b8e1b1a-ce7f-4f4d-9450-ca5ba971464a,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-6e6d4e56-e066-45da-89fb-2a6f9d89a572,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-944d9a2f-0edc-4ba2-999d-5ca4ed0f2983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714510022-172.17.0.5-1597399927633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-258dc2c6-aa00-4f5e-8378-088c46e28e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-0cea997b-1de0-45da-9c39-5ff54587f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-e8cd91b4-8ebb-4997-b297-5f0fb5cecde0,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-4611c2d4-8390-4b8a-83d9-4e4ba5d061e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-fa27e781-dc28-4bf0-b481-2e8c4a84ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-04a91112-3f18-40ee-aac1-531ffc235530,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-57b84493-c4e6-41cd-8bdd-60bcbe777376,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-5822e971-ee56-448d-a3b1-e04ba4f87a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714510022-172.17.0.5-1597399927633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-258dc2c6-aa00-4f5e-8378-088c46e28e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-0cea997b-1de0-45da-9c39-5ff54587f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-e8cd91b4-8ebb-4997-b297-5f0fb5cecde0,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-4611c2d4-8390-4b8a-83d9-4e4ba5d061e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-fa27e781-dc28-4bf0-b481-2e8c4a84ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-04a91112-3f18-40ee-aac1-531ffc235530,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-57b84493-c4e6-41cd-8bdd-60bcbe777376,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-5822e971-ee56-448d-a3b1-e04ba4f87a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752012875-172.17.0.5-1597400282518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-b662414e-ae31-487d-b59c-7b408aa9a302,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-d35ea851-a649-417c-92be-f3733c08e572,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-8e2570c1-22ef-4250-925a-7f82c6feec77,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-0d30b119-25b8-479b-bd1f-d4a1c383dc59,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-dabf4ea0-2aed-4883-ba76-59d2cb829f97,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-c4a6fc30-3f54-4f28-b075-76572dcd85a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-235803b2-59b0-4c83-b3e8-6d28d4e8d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-6da3d7c1-05fb-44bd-a06c-7018288f72a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752012875-172.17.0.5-1597400282518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-b662414e-ae31-487d-b59c-7b408aa9a302,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-d35ea851-a649-417c-92be-f3733c08e572,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-8e2570c1-22ef-4250-925a-7f82c6feec77,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-0d30b119-25b8-479b-bd1f-d4a1c383dc59,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-dabf4ea0-2aed-4883-ba76-59d2cb829f97,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-c4a6fc30-3f54-4f28-b075-76572dcd85a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-235803b2-59b0-4c83-b3e8-6d28d4e8d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-6da3d7c1-05fb-44bd-a06c-7018288f72a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737762248-172.17.0.5-1597400367584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42300,DS-1177aefe-0415-4594-8aaa-a38d36ff56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-22f3a811-bfcf-4cd7-8d98-b641dcc2134d,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-d3595693-f8b7-4d5c-a2a6-d2ac9c0e3a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-c00e0946-692c-46b3-a3f0-94f85ad45f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-951e0b88-cacd-46ed-b3c9-0ab36abd9d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-7bc8d009-4d0f-4f5e-a9f3-f851021ca339,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-a747dac5-b29a-4ae7-9096-3ba77111a76e,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-e03c77ec-6ae2-4b8d-91f6-81d594772bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737762248-172.17.0.5-1597400367584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42300,DS-1177aefe-0415-4594-8aaa-a38d36ff56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-22f3a811-bfcf-4cd7-8d98-b641dcc2134d,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-d3595693-f8b7-4d5c-a2a6-d2ac9c0e3a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-c00e0946-692c-46b3-a3f0-94f85ad45f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-951e0b88-cacd-46ed-b3c9-0ab36abd9d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-7bc8d009-4d0f-4f5e-a9f3-f851021ca339,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-a747dac5-b29a-4ae7-9096-3ba77111a76e,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-e03c77ec-6ae2-4b8d-91f6-81d594772bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538113457-172.17.0.5-1597400668592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-78f199e3-54f2-46ba-b5ba-279cf22ce4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-abc3c336-065c-4219-87ff-545e3b06f480,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-49de26aa-713b-4e3d-8d77-df2c6a6b30c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-5f9d04ba-b82a-4776-80c9-2d3c1d5d74ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-bc7a1709-3de1-4fae-8ef3-00627afdbb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-4cb50bef-0f85-41e2-959d-15ed42b989a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-57eda6b2-2370-4bab-900a-ed8e91251dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-723f92ee-d6f8-4d85-83e4-fff5bab667f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538113457-172.17.0.5-1597400668592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-78f199e3-54f2-46ba-b5ba-279cf22ce4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-abc3c336-065c-4219-87ff-545e3b06f480,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-49de26aa-713b-4e3d-8d77-df2c6a6b30c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-5f9d04ba-b82a-4776-80c9-2d3c1d5d74ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-bc7a1709-3de1-4fae-8ef3-00627afdbb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-4cb50bef-0f85-41e2-959d-15ed42b989a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-57eda6b2-2370-4bab-900a-ed8e91251dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-723f92ee-d6f8-4d85-83e4-fff5bab667f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389921314-172.17.0.5-1597400791349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37141,DS-740b9165-a44b-4b9d-b360-d0e973c399e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-dce83c4c-9a23-4b1d-b2d8-77b62baac8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-eced6b21-a278-4d2f-a3fa-444f3e7ac181,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-7188eb81-7198-46aa-bef7-85f00112ff18,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-8dc77b39-6719-451e-bd45-22d93f865584,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-e6e80a24-921b-4ed0-813e-e06841edc746,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-47b044b8-b4e7-4fa2-be51-8d1842c9f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-aa5f6ae9-a2c4-4df9-8ae1-00cc90af76cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389921314-172.17.0.5-1597400791349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37141,DS-740b9165-a44b-4b9d-b360-d0e973c399e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-dce83c4c-9a23-4b1d-b2d8-77b62baac8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-eced6b21-a278-4d2f-a3fa-444f3e7ac181,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-7188eb81-7198-46aa-bef7-85f00112ff18,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-8dc77b39-6719-451e-bd45-22d93f865584,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-e6e80a24-921b-4ed0-813e-e06841edc746,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-47b044b8-b4e7-4fa2-be51-8d1842c9f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-aa5f6ae9-a2c4-4df9-8ae1-00cc90af76cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635345279-172.17.0.5-1597400862689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-be6279cb-632f-471b-889a-06128ab17995,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-8bf1718f-f93c-4495-a1cd-74dc2fce8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-b15dc252-d599-4c74-9b16-f0bd61a0ded8,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-e9d72516-d743-41b1-ac30-831417b6101d,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-50949214-00c6-48c1-b91e-780b93f32036,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-89395e7b-328f-44f4-bee4-3a01dffc6342,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-fa8d8f7b-bc4e-4dde-a729-4feba02e05c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-c191c344-49e3-4ff1-b325-41f1314dec0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635345279-172.17.0.5-1597400862689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-be6279cb-632f-471b-889a-06128ab17995,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-8bf1718f-f93c-4495-a1cd-74dc2fce8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-b15dc252-d599-4c74-9b16-f0bd61a0ded8,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-e9d72516-d743-41b1-ac30-831417b6101d,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-50949214-00c6-48c1-b91e-780b93f32036,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-89395e7b-328f-44f4-bee4-3a01dffc6342,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-fa8d8f7b-bc4e-4dde-a729-4feba02e05c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-c191c344-49e3-4ff1-b325-41f1314dec0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212043864-172.17.0.5-1597401512303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39145,DS-eb76a8fd-217d-4428-b9a6-cd693c0a0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-837adc93-4f9e-45e2-b90b-13bfd4acccd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-c6ad417f-e2fc-497b-b198-8f7c3719cabc,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-0bdb7038-a800-46c7-888b-04d14a391b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-ff7195fe-1099-473f-b330-d51d431b25ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-0e0b536c-c533-4ab6-8200-46cd3447d8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c972629a-7521-41e9-a87c-509af2c484e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-acd04f91-643d-408a-9c43-390eafd0dd98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212043864-172.17.0.5-1597401512303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39145,DS-eb76a8fd-217d-4428-b9a6-cd693c0a0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-837adc93-4f9e-45e2-b90b-13bfd4acccd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-c6ad417f-e2fc-497b-b198-8f7c3719cabc,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-0bdb7038-a800-46c7-888b-04d14a391b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-ff7195fe-1099-473f-b330-d51d431b25ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-0e0b536c-c533-4ab6-8200-46cd3447d8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c972629a-7521-41e9-a87c-509af2c484e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-acd04f91-643d-408a-9c43-390eafd0dd98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626041668-172.17.0.5-1597403083396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-163095cd-cae1-48ae-9e5b-312a6500326d,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-4efd1d92-9c3e-4494-a7da-629409198ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-540bea07-ed00-4791-a5ec-ed914cd486e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-1eb51270-d611-4938-8c04-c69555ccda0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-42901856-984a-433c-ab12-d3af227cb511,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-0f17d2d1-ffcc-4bef-9455-1fd2fd8b2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-2dafc9df-1ecf-4a62-aaa6-17c750129331,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-71f646e9-b0c6-4ce9-8724-c8143b177424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626041668-172.17.0.5-1597403083396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-163095cd-cae1-48ae-9e5b-312a6500326d,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-4efd1d92-9c3e-4494-a7da-629409198ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-540bea07-ed00-4791-a5ec-ed914cd486e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-1eb51270-d611-4938-8c04-c69555ccda0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-42901856-984a-433c-ab12-d3af227cb511,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-0f17d2d1-ffcc-4bef-9455-1fd2fd8b2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-2dafc9df-1ecf-4a62-aaa6-17c750129331,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-71f646e9-b0c6-4ce9-8724-c8143b177424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5948
