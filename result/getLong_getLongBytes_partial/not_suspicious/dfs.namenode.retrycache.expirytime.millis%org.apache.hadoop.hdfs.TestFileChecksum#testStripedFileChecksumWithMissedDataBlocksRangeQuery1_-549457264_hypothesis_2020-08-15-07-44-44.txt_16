reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28813762-172.17.0.4-1597477505511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36045,DS-82f9123f-4a2b-40c8-b9a1-68635097818e,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-7e679c3e-bbb6-42a5-b5a6-8cbdbdc2bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-8019c197-46f7-4238-9e98-72f78bf37904,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-d911785b-afe5-4e0a-baaf-d439c85a8801,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-47a3b519-d07a-4bbf-a125-223125f6d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-a69635a1-f5c2-4cb7-9236-106d00c55f01,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-946bd5f4-503b-443d-a5e2-7746956b5952,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-5a3c4f09-d3e9-4b86-8150-f64c71496f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28813762-172.17.0.4-1597477505511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36045,DS-82f9123f-4a2b-40c8-b9a1-68635097818e,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-7e679c3e-bbb6-42a5-b5a6-8cbdbdc2bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-8019c197-46f7-4238-9e98-72f78bf37904,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-d911785b-afe5-4e0a-baaf-d439c85a8801,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-47a3b519-d07a-4bbf-a125-223125f6d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-a69635a1-f5c2-4cb7-9236-106d00c55f01,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-946bd5f4-503b-443d-a5e2-7746956b5952,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-5a3c4f09-d3e9-4b86-8150-f64c71496f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948456413-172.17.0.4-1597477602093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-13ccdbaa-25a7-49fa-8cab-1265fa654b06,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-64396585-541e-444d-9b04-2745ec25da69,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-45b2a6a7-08c1-47c8-afa4-1706b8e77d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-5dbd5123-e2bd-4201-abec-b40dd36b37ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-defbc5bc-d31e-40e8-b313-a0533f9f6666,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-66bfff8c-c25d-4cd1-83f5-33a3c0451a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-013997b3-b7ad-4b02-81bc-5d1ef5c3fd22,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-89f85bbb-14bb-423c-91b0-b1d125fd9423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948456413-172.17.0.4-1597477602093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37281,DS-13ccdbaa-25a7-49fa-8cab-1265fa654b06,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-64396585-541e-444d-9b04-2745ec25da69,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-45b2a6a7-08c1-47c8-afa4-1706b8e77d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-5dbd5123-e2bd-4201-abec-b40dd36b37ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-defbc5bc-d31e-40e8-b313-a0533f9f6666,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-66bfff8c-c25d-4cd1-83f5-33a3c0451a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-013997b3-b7ad-4b02-81bc-5d1ef5c3fd22,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-89f85bbb-14bb-423c-91b0-b1d125fd9423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002431884-172.17.0.4-1597477735582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45225,DS-bf5ef3a5-bc1d-4fb9-acba-0e2d4005b2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-04100b97-2d4c-46b7-96d6-8901a42ac96a,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-28d75169-d54d-4dd7-8312-263f52e87151,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-d1d8b4f0-0d62-4229-bcdd-d65d51476055,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-0f4f9d09-b2fc-4ea1-8f3c-f74105236f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-b96667f2-5934-4e2f-bea6-5d3d6c0238ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-20c0081e-0c1d-4fd6-9873-cb234ff8ecf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-87f074ca-3a1c-4971-9789-0f810cdf484c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002431884-172.17.0.4-1597477735582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45225,DS-bf5ef3a5-bc1d-4fb9-acba-0e2d4005b2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-04100b97-2d4c-46b7-96d6-8901a42ac96a,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-28d75169-d54d-4dd7-8312-263f52e87151,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-d1d8b4f0-0d62-4229-bcdd-d65d51476055,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-0f4f9d09-b2fc-4ea1-8f3c-f74105236f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-b96667f2-5934-4e2f-bea6-5d3d6c0238ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-20c0081e-0c1d-4fd6-9873-cb234ff8ecf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-87f074ca-3a1c-4971-9789-0f810cdf484c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336885195-172.17.0.4-1597478955804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-399be044-a119-4c2b-872d-a55b1ed1ce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-88f7c1d2-1086-4886-bb4a-72bc3d6f2746,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-6ac52136-2f43-4e0b-98d2-7863c45d9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-2304872d-d7f2-4c6d-bd85-230058939974,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-cb7a306d-3b2c-4aa3-8acf-ff7dc111c3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-d1cd69f7-f952-42f9-b4d1-ac0f811ff92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-d454fbf4-76f3-44a5-b02b-dc51f5dfd083,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-a03099eb-85cd-4644-86df-bb9396003965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336885195-172.17.0.4-1597478955804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-399be044-a119-4c2b-872d-a55b1ed1ce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-88f7c1d2-1086-4886-bb4a-72bc3d6f2746,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-6ac52136-2f43-4e0b-98d2-7863c45d9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-2304872d-d7f2-4c6d-bd85-230058939974,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-cb7a306d-3b2c-4aa3-8acf-ff7dc111c3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-d1cd69f7-f952-42f9-b4d1-ac0f811ff92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-d454fbf4-76f3-44a5-b02b-dc51f5dfd083,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-a03099eb-85cd-4644-86df-bb9396003965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082280074-172.17.0.4-1597479157811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46070,DS-5475eabb-92b0-4aca-8a3f-b6f3dc7c93bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-6e0621cb-50b1-4c6d-bbcf-2a45714623e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-2dd0ce58-2c62-4543-8d74-d7b1a390de70,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-20b131b3-6116-4301-8c5a-2ae037a717ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-4e6823d7-ec28-481a-acc9-19a107bf882b,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-901ebe14-d510-4dc4-9aef-fd6da9748811,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-3eb0870e-f759-47f6-82c7-09eee2e58ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-9ac7fcaf-5ffc-46ae-8db2-0f3a5f15a8a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082280074-172.17.0.4-1597479157811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46070,DS-5475eabb-92b0-4aca-8a3f-b6f3dc7c93bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-6e0621cb-50b1-4c6d-bbcf-2a45714623e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-2dd0ce58-2c62-4543-8d74-d7b1a390de70,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-20b131b3-6116-4301-8c5a-2ae037a717ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-4e6823d7-ec28-481a-acc9-19a107bf882b,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-901ebe14-d510-4dc4-9aef-fd6da9748811,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-3eb0870e-f759-47f6-82c7-09eee2e58ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-9ac7fcaf-5ffc-46ae-8db2-0f3a5f15a8a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346137556-172.17.0.4-1597479312119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45446,DS-50691c8a-d8ac-413b-8f75-a3bdf1c00783,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-b1d2d5ba-06e7-451f-8e42-95bd3f60da26,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-21fc3bec-15a0-4dfc-8ea2-4a4dceb912d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-23cd2ba6-8c31-4b35-bd92-e410629c4ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-e7f4295c-74ef-4e14-ad44-b8e2cd71d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-80a5f2a8-4ae2-4e69-95ae-e6c964e8e441,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-d0707b57-a303-4e55-b626-6932ed9ac613,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-a518aeed-305e-42d5-a253-1fd64c1c9773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346137556-172.17.0.4-1597479312119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45446,DS-50691c8a-d8ac-413b-8f75-a3bdf1c00783,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-b1d2d5ba-06e7-451f-8e42-95bd3f60da26,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-21fc3bec-15a0-4dfc-8ea2-4a4dceb912d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-23cd2ba6-8c31-4b35-bd92-e410629c4ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-e7f4295c-74ef-4e14-ad44-b8e2cd71d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-80a5f2a8-4ae2-4e69-95ae-e6c964e8e441,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-d0707b57-a303-4e55-b626-6932ed9ac613,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-a518aeed-305e-42d5-a253-1fd64c1c9773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595902099-172.17.0.4-1597479502567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-743860a2-8dae-4438-a2c2-31216bc7bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-5d3ac611-14b1-4b31-9c07-ea2265ca6e89,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-11f45771-5c78-4721-bb53-e38bc6e4df96,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-b92e3a59-5291-432c-b7f8-1f2c033ab36f,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-36574308-b2ee-481e-a455-9aaab3fb1c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-72f94074-adfc-4cab-bfb3-6d650e2fdfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-a964fa25-4822-4a75-ab32-e6140300f7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-f35832cb-63bd-4dce-b022-0b7cbcac04ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595902099-172.17.0.4-1597479502567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-743860a2-8dae-4438-a2c2-31216bc7bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-5d3ac611-14b1-4b31-9c07-ea2265ca6e89,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-11f45771-5c78-4721-bb53-e38bc6e4df96,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-b92e3a59-5291-432c-b7f8-1f2c033ab36f,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-36574308-b2ee-481e-a455-9aaab3fb1c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-72f94074-adfc-4cab-bfb3-6d650e2fdfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-a964fa25-4822-4a75-ab32-e6140300f7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-f35832cb-63bd-4dce-b022-0b7cbcac04ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228053734-172.17.0.4-1597479742910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37211,DS-d6886295-7329-408b-b8a9-97a10008827a,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-38bce47c-72ad-433a-9c18-db7a83860b43,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-34524973-5eb4-466e-912c-ba87ac5a5d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-96f8c463-afa8-400a-a4f1-140faf09678f,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-1d8da5fd-fb75-4e43-8df4-db4366f44960,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-be3417b6-01a0-46bc-82e9-dd3bebab67c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-b9afce47-ccb0-47f1-ba78-bf031cae6ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-286e28ce-5933-451b-a017-4991344b7991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228053734-172.17.0.4-1597479742910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37211,DS-d6886295-7329-408b-b8a9-97a10008827a,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-38bce47c-72ad-433a-9c18-db7a83860b43,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-34524973-5eb4-466e-912c-ba87ac5a5d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-96f8c463-afa8-400a-a4f1-140faf09678f,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-1d8da5fd-fb75-4e43-8df4-db4366f44960,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-be3417b6-01a0-46bc-82e9-dd3bebab67c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-b9afce47-ccb0-47f1-ba78-bf031cae6ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-286e28ce-5933-451b-a017-4991344b7991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515456831-172.17.0.4-1597480003689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-0258eef5-a33d-478b-9bc0-8385f7d5318b,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-c4cbf6c9-4b3d-4460-b990-d74198f909ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-3847b7f6-6fc4-4242-9fa5-ff65131fc079,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-9b879364-c6a9-4ebd-944f-5130a2563cec,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-1c98fefd-6ef3-403a-a392-1a844b1606a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-d0ddf975-2174-49b8-8d23-4a4bd041ccf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-188907ce-9e37-4b8a-89a5-800987bf4d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-f34c6448-5000-49c8-a5b5-a3953ce769f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515456831-172.17.0.4-1597480003689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-0258eef5-a33d-478b-9bc0-8385f7d5318b,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-c4cbf6c9-4b3d-4460-b990-d74198f909ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-3847b7f6-6fc4-4242-9fa5-ff65131fc079,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-9b879364-c6a9-4ebd-944f-5130a2563cec,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-1c98fefd-6ef3-403a-a392-1a844b1606a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-d0ddf975-2174-49b8-8d23-4a4bd041ccf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-188907ce-9e37-4b8a-89a5-800987bf4d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-f34c6448-5000-49c8-a5b5-a3953ce769f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491088863-172.17.0.4-1597480418192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-6e3ceaf1-6020-4580-89da-e33a769d599b,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-beadaec9-8e13-4cee-a966-59841c3740d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-1e85c3ef-0e92-4b00-9364-372b7f304c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-bc2bdea1-8d17-464e-b29f-16fa8fcb8df1,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-35678a41-2f16-4ca4-abc0-fc33e116c440,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-3fbef925-6459-41bb-80d5-6403fffc14b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-e1535889-03cc-45b6-9d8e-f16a1dd079da,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-f8d255a9-59dc-441f-8080-e9ad219793eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491088863-172.17.0.4-1597480418192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-6e3ceaf1-6020-4580-89da-e33a769d599b,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-beadaec9-8e13-4cee-a966-59841c3740d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-1e85c3ef-0e92-4b00-9364-372b7f304c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-bc2bdea1-8d17-464e-b29f-16fa8fcb8df1,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-35678a41-2f16-4ca4-abc0-fc33e116c440,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-3fbef925-6459-41bb-80d5-6403fffc14b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-e1535889-03cc-45b6-9d8e-f16a1dd079da,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-f8d255a9-59dc-441f-8080-e9ad219793eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867210943-172.17.0.4-1597480829438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-2629f3f2-5695-4943-bb3f-384792d52597,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-054a5205-0d91-4e1a-bf9d-7c40ccb0eb24,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-42d6621d-5cae-4cda-a060-bd51c8b432c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-eb65c80b-3e2e-43e8-b831-6e660b44f202,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-1ca71d9e-6d68-4ad6-9d88-7c8dcda18af9,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-ec1a9791-b343-439b-84a1-cffca6ee83ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-aedc48cf-fba8-44e5-a2e2-0cdcc10d8b68,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-e5df10f6-771d-4a53-9f12-7857a279cd60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867210943-172.17.0.4-1597480829438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-2629f3f2-5695-4943-bb3f-384792d52597,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-054a5205-0d91-4e1a-bf9d-7c40ccb0eb24,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-42d6621d-5cae-4cda-a060-bd51c8b432c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-eb65c80b-3e2e-43e8-b831-6e660b44f202,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-1ca71d9e-6d68-4ad6-9d88-7c8dcda18af9,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-ec1a9791-b343-439b-84a1-cffca6ee83ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-aedc48cf-fba8-44e5-a2e2-0cdcc10d8b68,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-e5df10f6-771d-4a53-9f12-7857a279cd60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86565604-172.17.0.4-1597480954473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-e70bb7ca-6355-4207-854d-7c3aac15deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-f453b04a-8358-4658-b8d0-172a39def4df,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-a4b02070-299b-439d-b0ad-e9f2d892486b,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-db917973-c39e-4eea-a867-f4f371a1057a,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-5106e920-4ef3-4905-b0d3-2128d430bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-acc68367-545a-46f4-949a-6081cf13b35e,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-9fb9e5b7-1af0-48c9-878d-1f73022b5c54,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-895be568-7caa-484d-a462-5debc5e1d727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86565604-172.17.0.4-1597480954473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-e70bb7ca-6355-4207-854d-7c3aac15deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-f453b04a-8358-4658-b8d0-172a39def4df,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-a4b02070-299b-439d-b0ad-e9f2d892486b,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-db917973-c39e-4eea-a867-f4f371a1057a,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-5106e920-4ef3-4905-b0d3-2128d430bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-acc68367-545a-46f4-949a-6081cf13b35e,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-9fb9e5b7-1af0-48c9-878d-1f73022b5c54,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-895be568-7caa-484d-a462-5debc5e1d727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191251160-172.17.0.4-1597481226576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43530,DS-10984158-4b5d-4e16-b466-1b24b02e4ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-3db0b124-5017-4107-867f-fc923dd5a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-72752764-2be5-4fdc-aef5-6a2cfaf5a696,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-841842e9-0da8-465d-aea9-b1d33caa3a37,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-46806e7d-a909-4e62-9fe2-7be09c1c9e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-694a2aae-2623-4025-ac00-abed1d66a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-cc3a0d63-157e-4f22-8954-d5d1cdabea86,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-8c088119-9f24-408b-8221-8649b28626e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191251160-172.17.0.4-1597481226576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43530,DS-10984158-4b5d-4e16-b466-1b24b02e4ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-3db0b124-5017-4107-867f-fc923dd5a14a,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-72752764-2be5-4fdc-aef5-6a2cfaf5a696,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-841842e9-0da8-465d-aea9-b1d33caa3a37,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-46806e7d-a909-4e62-9fe2-7be09c1c9e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-694a2aae-2623-4025-ac00-abed1d66a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-cc3a0d63-157e-4f22-8954-d5d1cdabea86,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-8c088119-9f24-408b-8221-8649b28626e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594100492-172.17.0.4-1597481365764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-456104a1-9473-415b-8c76-7da815afa1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-a9431402-d140-4cef-b2aa-e0f75bfb25d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-3d076bc6-11d9-439a-aa90-b6c2945a4083,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-4d39a128-ba25-4456-be1d-90dfcbf65283,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-87b5d1fe-a1ca-4bfc-ab08-62df59e5a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-376ab6c4-9eb1-4c8e-af08-72ff0a1fa0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-cc05d17f-88ee-4197-ab36-e9afe3f29a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-8e7ebfcc-a2e6-4a14-ac1c-9e8f25d2d4b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594100492-172.17.0.4-1597481365764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-456104a1-9473-415b-8c76-7da815afa1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-a9431402-d140-4cef-b2aa-e0f75bfb25d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-3d076bc6-11d9-439a-aa90-b6c2945a4083,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-4d39a128-ba25-4456-be1d-90dfcbf65283,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-87b5d1fe-a1ca-4bfc-ab08-62df59e5a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-376ab6c4-9eb1-4c8e-af08-72ff0a1fa0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-cc05d17f-88ee-4197-ab36-e9afe3f29a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-8e7ebfcc-a2e6-4a14-ac1c-9e8f25d2d4b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74738643-172.17.0.4-1597481734950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42559,DS-aa21d94b-7c6a-471f-b53e-3930ebb58ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-4e1b2b02-b8f9-4fd8-941a-7dbb28db011e,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-6c68f0c6-2d4d-44d0-822b-3a433dc9429a,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-bddd201f-d3b5-4193-931a-a5c6ca70d920,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-a834b451-0fc6-4ad7-8223-d358caabdf16,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-13b0e0d3-74ff-470a-bb03-7d0f2e10b67a,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-df9d7f9a-a32b-4d54-ba9c-e68e42564b12,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-85ff6ce6-d9f4-44eb-8c82-879fc5ca2ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74738643-172.17.0.4-1597481734950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42559,DS-aa21d94b-7c6a-471f-b53e-3930ebb58ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-4e1b2b02-b8f9-4fd8-941a-7dbb28db011e,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-6c68f0c6-2d4d-44d0-822b-3a433dc9429a,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-bddd201f-d3b5-4193-931a-a5c6ca70d920,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-a834b451-0fc6-4ad7-8223-d358caabdf16,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-13b0e0d3-74ff-470a-bb03-7d0f2e10b67a,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-df9d7f9a-a32b-4d54-ba9c-e68e42564b12,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-85ff6ce6-d9f4-44eb-8c82-879fc5ca2ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902964960-172.17.0.4-1597481781843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-c1cd57f3-bcd3-4cb0-a577-a227b732f25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-d6b10d42-40da-465b-8d11-67e1dd4648a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-08eb2ecb-81f0-4b20-834e-e993ac712ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-29bcd169-0624-4ce3-b68e-87ee41e46bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-137ef071-0a6b-4c4d-84c9-b328d9c1afa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-b0658af4-320a-4642-b02b-0ae321490cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-bcee63fa-1cc2-415a-b3a5-117718617e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-931cebb5-603e-48a4-9797-69d09134decc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902964960-172.17.0.4-1597481781843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-c1cd57f3-bcd3-4cb0-a577-a227b732f25d,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-d6b10d42-40da-465b-8d11-67e1dd4648a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-08eb2ecb-81f0-4b20-834e-e993ac712ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-29bcd169-0624-4ce3-b68e-87ee41e46bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-137ef071-0a6b-4c4d-84c9-b328d9c1afa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-b0658af4-320a-4642-b02b-0ae321490cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-bcee63fa-1cc2-415a-b3a5-117718617e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-931cebb5-603e-48a4-9797-69d09134decc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446787457-172.17.0.4-1597482023753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38808,DS-e8be151b-c81f-4e90-91a4-46c0e71454e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-957cd0d1-0a43-4ce1-8a66-dbe597575b88,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-dbc5def9-fce8-4bbb-bb04-2596359ea3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-31124aed-0580-4db3-abb2-94d71a894d92,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-e2851c71-f07d-4df8-b98b-f14af250d37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-1b5e9865-ffda-447a-804c-8a6334cd306e,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-ce5f9114-e0bd-4a53-940b-9982c2c8a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-908be798-f276-42e2-b354-1f55e93b14d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446787457-172.17.0.4-1597482023753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38808,DS-e8be151b-c81f-4e90-91a4-46c0e71454e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-957cd0d1-0a43-4ce1-8a66-dbe597575b88,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-dbc5def9-fce8-4bbb-bb04-2596359ea3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-31124aed-0580-4db3-abb2-94d71a894d92,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-e2851c71-f07d-4df8-b98b-f14af250d37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-1b5e9865-ffda-447a-804c-8a6334cd306e,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-ce5f9114-e0bd-4a53-940b-9982c2c8a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-908be798-f276-42e2-b354-1f55e93b14d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.retrycache.expirytime.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684605467-172.17.0.4-1597482593518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-e6c697cc-377d-4d29-9e11-58e0d8d240f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-1877f2c9-fa98-40c2-8d12-ff53fbe70064,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-125b9c49-eb4b-473e-8c0b-10f3464080ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-6f305cb9-003d-42b4-aac5-853aa46ecde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-7818f417-3472-4643-83cc-bd7794e8ae28,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-12efd8be-c1ab-4b8a-9abd-4b0667759f90,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-fe3e8990-f5b2-48f0-beed-7703951c6f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-2eea756b-e301-4b91-99c3-26a97a3e4198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684605467-172.17.0.4-1597482593518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-e6c697cc-377d-4d29-9e11-58e0d8d240f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-1877f2c9-fa98-40c2-8d12-ff53fbe70064,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-125b9c49-eb4b-473e-8c0b-10f3464080ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-6f305cb9-003d-42b4-aac5-853aa46ecde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-7818f417-3472-4643-83cc-bd7794e8ae28,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-12efd8be-c1ab-4b8a-9abd-4b0667759f90,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-fe3e8990-f5b2-48f0-beed-7703951c6f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-2eea756b-e301-4b91-99c3-26a97a3e4198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 6894
