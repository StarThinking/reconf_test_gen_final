reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913270974-172.17.0.12-1597279175803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45002,DS-f3793516-101a-41a7-b5ec-9d25b451d630,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-56526329-bd78-4c81-baf9-114a9b16fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-3af12690-0bd0-4727-b706-5bcd30440ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-01015c14-efd2-4d3a-9735-7a3ccef0cc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-941e69fc-817d-4a20-bff1-28e69e94a87d,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-da6d04a9-5d13-41a7-829d-6500fdb0ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-a2b1c84e-945f-4ea1-aaf7-a24c0608e7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-70d0e310-05c9-4c6f-ad2c-0631ef3a47b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913270974-172.17.0.12-1597279175803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45002,DS-f3793516-101a-41a7-b5ec-9d25b451d630,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-56526329-bd78-4c81-baf9-114a9b16fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-3af12690-0bd0-4727-b706-5bcd30440ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-01015c14-efd2-4d3a-9735-7a3ccef0cc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-941e69fc-817d-4a20-bff1-28e69e94a87d,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-da6d04a9-5d13-41a7-829d-6500fdb0ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-a2b1c84e-945f-4ea1-aaf7-a24c0608e7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-70d0e310-05c9-4c6f-ad2c-0631ef3a47b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636101764-172.17.0.12-1597279789688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34091,DS-ced783f3-7f6c-48f7-8af2-362f252448dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-048e7c92-a0ac-4fe7-becc-37122b37b700,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-40d09252-9ccf-48ee-a574-a758d7994640,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-22212810-9d94-4be4-aaee-49fa0b717518,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-6bab2ed2-d9fa-44d5-af29-14963c245174,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-b9b9f075-c353-444c-bad9-20c4f4edf45f,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-112074ff-9d90-4aa4-a277-cf3611164028,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-7b01e00e-ad15-4e57-9d31-cd01c523f4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636101764-172.17.0.12-1597279789688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34091,DS-ced783f3-7f6c-48f7-8af2-362f252448dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-048e7c92-a0ac-4fe7-becc-37122b37b700,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-40d09252-9ccf-48ee-a574-a758d7994640,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-22212810-9d94-4be4-aaee-49fa0b717518,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-6bab2ed2-d9fa-44d5-af29-14963c245174,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-b9b9f075-c353-444c-bad9-20c4f4edf45f,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-112074ff-9d90-4aa4-a277-cf3611164028,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-7b01e00e-ad15-4e57-9d31-cd01c523f4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402592924-172.17.0.12-1597280025819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-4c89c3e0-b36e-482e-9846-9bfe475d7afc,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-2721d423-8af3-4a05-a516-aa36087eb1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-7214179a-a630-42a3-be82-bac2403c707a,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-849a1e05-082b-48ed-8760-185c83f36954,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-d2fcdc96-14bb-46ac-a417-54d51a43b14f,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-4cec9434-4195-471b-bdba-172fe70da4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-b40e673b-a243-4530-aadb-cc0a714a6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-e14ae8f4-b2a3-48ed-bdd7-6e196995aafb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402592924-172.17.0.12-1597280025819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46105,DS-4c89c3e0-b36e-482e-9846-9bfe475d7afc,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-2721d423-8af3-4a05-a516-aa36087eb1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-7214179a-a630-42a3-be82-bac2403c707a,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-849a1e05-082b-48ed-8760-185c83f36954,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-d2fcdc96-14bb-46ac-a417-54d51a43b14f,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-4cec9434-4195-471b-bdba-172fe70da4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-b40e673b-a243-4530-aadb-cc0a714a6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-e14ae8f4-b2a3-48ed-bdd7-6e196995aafb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030109134-172.17.0.12-1597280160623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-83620fc6-6b86-4f8c-9d52-a7d05cdb518e,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-8193f729-3b90-411b-a7d6-84dfcd6e806c,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-ca60c502-21df-4c7b-ac5d-936f26913f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-86c14826-dc18-4be8-96bc-b9b337cfef7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-94d87713-264c-48d2-a94d-6e6d37e1e4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-4abd2f52-d7ea-4375-bf3f-66f09141d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-ead000e6-4506-4e2e-809d-a2567e375a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-3ed7a548-7630-4508-8ab8-5a01824cc149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030109134-172.17.0.12-1597280160623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-83620fc6-6b86-4f8c-9d52-a7d05cdb518e,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-8193f729-3b90-411b-a7d6-84dfcd6e806c,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-ca60c502-21df-4c7b-ac5d-936f26913f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-86c14826-dc18-4be8-96bc-b9b337cfef7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-94d87713-264c-48d2-a94d-6e6d37e1e4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-4abd2f52-d7ea-4375-bf3f-66f09141d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-ead000e6-4506-4e2e-809d-a2567e375a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-3ed7a548-7630-4508-8ab8-5a01824cc149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677304002-172.17.0.12-1597280701377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-21737ff6-de08-4c5d-b648-9ca5b1553706,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-e3a34be0-bf5a-4945-9d87-dd722aa57789,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-0ed20c67-4ccb-4f78-8440-0cf70370527d,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-ab12c22d-6518-4205-aa02-be6d96c1da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-cac7278d-4744-4ec4-9246-bc5e9e86fce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-e7b734e7-f4d5-4010-9462-1c04c4cc1d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-943fc4c7-597a-4099-87fc-ec2fcd472826,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-1d0aa88a-133e-4c8b-a090-7793e9ecc462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677304002-172.17.0.12-1597280701377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-21737ff6-de08-4c5d-b648-9ca5b1553706,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-e3a34be0-bf5a-4945-9d87-dd722aa57789,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-0ed20c67-4ccb-4f78-8440-0cf70370527d,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-ab12c22d-6518-4205-aa02-be6d96c1da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-cac7278d-4744-4ec4-9246-bc5e9e86fce1,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-e7b734e7-f4d5-4010-9462-1c04c4cc1d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-943fc4c7-597a-4099-87fc-ec2fcd472826,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-1d0aa88a-133e-4c8b-a090-7793e9ecc462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235245920-172.17.0.12-1597281388410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41532,DS-c7e97f27-f1df-4ef3-8d4f-716cb1c8f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-f02fc065-4b27-4532-bf21-2fde69a8926d,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-b4962bc0-411c-4eea-a258-a839acfe02ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-4976db82-4aee-4731-98a8-35f048e8d6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-ef0f3de9-28c3-48f8-934f-17ab0a88a565,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-a91954c0-aea6-428e-8d00-f6b9db8f94c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-0f479060-3a61-409e-9681-bcd9d011ef52,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-2e6c74fa-c8f2-486e-9b4e-ed5dcf731e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235245920-172.17.0.12-1597281388410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41532,DS-c7e97f27-f1df-4ef3-8d4f-716cb1c8f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-f02fc065-4b27-4532-bf21-2fde69a8926d,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-b4962bc0-411c-4eea-a258-a839acfe02ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-4976db82-4aee-4731-98a8-35f048e8d6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-ef0f3de9-28c3-48f8-934f-17ab0a88a565,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-a91954c0-aea6-428e-8d00-f6b9db8f94c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-0f479060-3a61-409e-9681-bcd9d011ef52,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-2e6c74fa-c8f2-486e-9b4e-ed5dcf731e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156249448-172.17.0.12-1597282517839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46164,DS-f0a226fd-27d4-4855-996a-2ccdf1d7c486,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-b4302fb9-c668-4ca5-a386-71093552f580,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-860d5507-6105-4409-b1e3-3dd387ca369d,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-87d30afb-ca73-4bff-970e-31b2471c5dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-64fbcbc5-3e04-4acd-bf14-ebbe0433d494,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-ce46f687-2dba-4a8f-a6ed-961814e09ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8e74c3bc-b1dc-49af-9aaf-cba36f395b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-3f90268d-2d34-4dc8-b51e-d46d2f5fa810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156249448-172.17.0.12-1597282517839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46164,DS-f0a226fd-27d4-4855-996a-2ccdf1d7c486,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-b4302fb9-c668-4ca5-a386-71093552f580,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-860d5507-6105-4409-b1e3-3dd387ca369d,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-87d30afb-ca73-4bff-970e-31b2471c5dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-64fbcbc5-3e04-4acd-bf14-ebbe0433d494,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-ce46f687-2dba-4a8f-a6ed-961814e09ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-8e74c3bc-b1dc-49af-9aaf-cba36f395b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-3f90268d-2d34-4dc8-b51e-d46d2f5fa810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237148078-172.17.0.12-1597283366048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34563,DS-12a197af-4738-4bc5-a917-e15bc4e07428,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-3b789fab-d135-4bcd-9bae-74e44cfe2fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-a629ca6c-5415-4ee7-973b-760a3d6ec842,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-aa4b5115-5be8-4c93-a3c4-9c55bc7c9313,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-55fb731c-540c-46c8-becb-d5443109c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-018ae850-cc89-41b9-acbd-7077fc098801,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ec7cb826-13a8-43ea-b7e7-343eae421380,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-e3d122e1-b0b8-43ee-a49e-8c5003dc327a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237148078-172.17.0.12-1597283366048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34563,DS-12a197af-4738-4bc5-a917-e15bc4e07428,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-3b789fab-d135-4bcd-9bae-74e44cfe2fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-a629ca6c-5415-4ee7-973b-760a3d6ec842,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-aa4b5115-5be8-4c93-a3c4-9c55bc7c9313,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-55fb731c-540c-46c8-becb-d5443109c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-018ae850-cc89-41b9-acbd-7077fc098801,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ec7cb826-13a8-43ea-b7e7-343eae421380,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-e3d122e1-b0b8-43ee-a49e-8c5003dc327a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145939119-172.17.0.12-1597283990658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46798,DS-047c1f3b-c7bf-42fa-938e-46a23352bae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-ed484d97-7c9d-4984-ad1c-bee150108cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-bb0739ca-c7d0-4603-98fe-ea6d583a7e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-69ed58ba-3187-4786-a574-4706c12e7ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-e8e038d9-3df3-403e-88fb-dc1cc78b0a90,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-c15bc157-be3e-408e-94e1-35451c8c41f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-8147b81d-8860-477d-83dd-e6cefc8d1118,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-2aed2edc-fc94-4efd-95b8-44919f58e2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145939119-172.17.0.12-1597283990658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46798,DS-047c1f3b-c7bf-42fa-938e-46a23352bae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-ed484d97-7c9d-4984-ad1c-bee150108cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-bb0739ca-c7d0-4603-98fe-ea6d583a7e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-69ed58ba-3187-4786-a574-4706c12e7ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-e8e038d9-3df3-403e-88fb-dc1cc78b0a90,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-c15bc157-be3e-408e-94e1-35451c8c41f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-8147b81d-8860-477d-83dd-e6cefc8d1118,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-2aed2edc-fc94-4efd-95b8-44919f58e2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923240194-172.17.0.12-1597284218497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-96eedfdd-43e8-4c88-b213-c257af099a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-c7ff39f2-2c1d-4eb3-a397-09e32a05a517,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-1cd8f275-c43b-4ebd-89ba-467bdc2735eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-c81f31ad-dda3-470d-b4bc-0a73b12155b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-4af30bb7-2c23-4a58-9631-fe52a085b364,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-64607191-961e-43e7-88be-b4392d85bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-68f7e242-2e18-4de8-a4b4-eb788563b9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-be7da131-218b-4ab6-acb4-9f9bb6db886d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923240194-172.17.0.12-1597284218497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-96eedfdd-43e8-4c88-b213-c257af099a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-c7ff39f2-2c1d-4eb3-a397-09e32a05a517,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-1cd8f275-c43b-4ebd-89ba-467bdc2735eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-c81f31ad-dda3-470d-b4bc-0a73b12155b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-4af30bb7-2c23-4a58-9631-fe52a085b364,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-64607191-961e-43e7-88be-b4392d85bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-68f7e242-2e18-4de8-a4b4-eb788563b9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-be7da131-218b-4ab6-acb4-9f9bb6db886d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313139813-172.17.0.12-1597284523880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-3acf3699-5304-4739-94fc-6a698d28ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-d27c5106-b2b1-4b54-af12-2cf2a6751bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-e4b04da3-d793-4936-82ca-40e3b58f0a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-c2dc6026-096c-43d2-9b1d-69e415946d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-86041b16-2bfd-460a-a630-c59eb1750345,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-70cbac41-ddfb-4e85-a906-064009c08481,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-d8e018be-48db-4463-85eb-53fe202908b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-47fd424e-2133-4f7d-a092-1700628c58e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313139813-172.17.0.12-1597284523880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-3acf3699-5304-4739-94fc-6a698d28ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-d27c5106-b2b1-4b54-af12-2cf2a6751bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-e4b04da3-d793-4936-82ca-40e3b58f0a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-c2dc6026-096c-43d2-9b1d-69e415946d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-86041b16-2bfd-460a-a630-c59eb1750345,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-70cbac41-ddfb-4e85-a906-064009c08481,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-d8e018be-48db-4463-85eb-53fe202908b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-47fd424e-2133-4f7d-a092-1700628c58e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285350723-172.17.0.12-1597284792822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42591,DS-57200944-8529-46ae-b1c4-cf9442a679ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-0a2543a2-00b0-482c-b277-692f5711d1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-e69b8e7a-6626-4d30-87d5-b796c422679e,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-ff049e16-7086-4262-a0d7-4ddbc29de18f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-d291cd49-0875-4ee2-8e3c-b541aa39aac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-501959ff-41e6-4655-ae06-16fa64e7a7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-159f36c5-956f-4667-847f-cf6f2c0ef09e,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-9c613f43-1d05-4e5b-bc5e-97cece80ad00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285350723-172.17.0.12-1597284792822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42591,DS-57200944-8529-46ae-b1c4-cf9442a679ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-0a2543a2-00b0-482c-b277-692f5711d1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-e69b8e7a-6626-4d30-87d5-b796c422679e,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-ff049e16-7086-4262-a0d7-4ddbc29de18f,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-d291cd49-0875-4ee2-8e3c-b541aa39aac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-501959ff-41e6-4655-ae06-16fa64e7a7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-159f36c5-956f-4667-847f-cf6f2c0ef09e,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-9c613f43-1d05-4e5b-bc5e-97cece80ad00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116138959-172.17.0.12-1597285309459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-161fe713-5832-4364-9a59-120f9ae75bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-ee03ad82-59a2-4c8e-8aba-3af6fc8149a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-3055fb94-51f8-425b-824b-c91277cc450a,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-5b878ad7-9d5d-4463-9c89-097ba8da1248,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-3e2b20c2-8b97-45a9-b459-67dfe024da76,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-c874af0b-cd69-442e-b5aa-ac98fbe1f851,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-bae7ad2f-2d97-4811-bb72-b6d4ee1b2cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-29d9a9f3-72ee-44a1-a36e-cdaf9b29bc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116138959-172.17.0.12-1597285309459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-161fe713-5832-4364-9a59-120f9ae75bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-ee03ad82-59a2-4c8e-8aba-3af6fc8149a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-3055fb94-51f8-425b-824b-c91277cc450a,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-5b878ad7-9d5d-4463-9c89-097ba8da1248,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-3e2b20c2-8b97-45a9-b459-67dfe024da76,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-c874af0b-cd69-442e-b5aa-ac98fbe1f851,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-bae7ad2f-2d97-4811-bb72-b6d4ee1b2cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-29d9a9f3-72ee-44a1-a36e-cdaf9b29bc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 700000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409137948-172.17.0.12-1597285835134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34155,DS-69327088-b911-41fb-b291-b77d0ed912ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-93a0551c-9938-4e61-9654-79344414b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-898c6104-8079-48df-a215-e0f602a4943c,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-6a0dd06b-398c-49b2-ad7c-72f74294cb17,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-b2702676-02bf-4459-814b-7be76f882d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-ad5d9259-e7d0-4236-a450-dacbd9e95296,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-fa0c0307-e522-4c68-915e-a31a2557b282,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-89968a33-c88b-4e37-b3a3-e92fcfe29795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409137948-172.17.0.12-1597285835134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34155,DS-69327088-b911-41fb-b291-b77d0ed912ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-93a0551c-9938-4e61-9654-79344414b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-898c6104-8079-48df-a215-e0f602a4943c,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-6a0dd06b-398c-49b2-ad7c-72f74294cb17,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-b2702676-02bf-4459-814b-7be76f882d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-ad5d9259-e7d0-4236-a450-dacbd9e95296,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-fa0c0307-e522-4c68-915e-a31a2557b282,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-89968a33-c88b-4e37-b3a3-e92fcfe29795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7089
