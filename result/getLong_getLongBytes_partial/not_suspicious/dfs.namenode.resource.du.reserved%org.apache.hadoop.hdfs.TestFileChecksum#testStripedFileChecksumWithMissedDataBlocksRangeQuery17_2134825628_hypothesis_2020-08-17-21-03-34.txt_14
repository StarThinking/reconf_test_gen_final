reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771052605-172.17.0.6-1597698760972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-e1d61da9-5fd4-401a-b3c2-990b1720fdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-27394166-a9cc-4046-be78-ffe715d485d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-71474248-9b5a-4d62-9541-b3bdf9b525df,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-08e5063b-7165-4467-89b1-fcdceaada420,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-f5a0e309-1a13-4046-8b46-e9dec309a494,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-26f389b6-ef61-499e-81a3-3028ec59d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-cf7f71f2-4b17-48bc-9f6e-6ee40e5dd2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-85b4f6eb-4dc3-4e26-acc2-a33c8bac43f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771052605-172.17.0.6-1597698760972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-e1d61da9-5fd4-401a-b3c2-990b1720fdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-27394166-a9cc-4046-be78-ffe715d485d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-71474248-9b5a-4d62-9541-b3bdf9b525df,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-08e5063b-7165-4467-89b1-fcdceaada420,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-f5a0e309-1a13-4046-8b46-e9dec309a494,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-26f389b6-ef61-499e-81a3-3028ec59d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-cf7f71f2-4b17-48bc-9f6e-6ee40e5dd2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-85b4f6eb-4dc3-4e26-acc2-a33c8bac43f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203526014-172.17.0.6-1597698905742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38424,DS-f9dc3761-4b59-415a-a8d8-5566c942962d,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-8a53c590-2a6b-4782-a530-32440b68807a,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-7d586e8e-c1d4-4c7b-8670-d9a2d3c36a85,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-3648bce0-c2e8-47b7-a813-6515547c385a,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-a665e930-3ee4-44c9-b240-c52bd4246eda,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-d400df70-f54b-428e-b50e-d5a20a1174a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-c40f2a95-9712-462e-b1d3-4675e4b2e0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-f0dcd236-bf80-46b9-bbe3-fb6f42d1b00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203526014-172.17.0.6-1597698905742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38424,DS-f9dc3761-4b59-415a-a8d8-5566c942962d,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-8a53c590-2a6b-4782-a530-32440b68807a,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-7d586e8e-c1d4-4c7b-8670-d9a2d3c36a85,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-3648bce0-c2e8-47b7-a813-6515547c385a,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-a665e930-3ee4-44c9-b240-c52bd4246eda,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-d400df70-f54b-428e-b50e-d5a20a1174a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-c40f2a95-9712-462e-b1d3-4675e4b2e0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-f0dcd236-bf80-46b9-bbe3-fb6f42d1b00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262056279-172.17.0.6-1597698984104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-d4f7bbed-d94a-4dda-adce-3e5dd453d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-d800cb09-8749-4cf3-923d-9bcdf7ee761c,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-d4cfbb1f-8a35-40b5-b317-c04e70e61217,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-7e02bb12-1c65-40d0-9955-ad3ca58408f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-5cab1da9-2962-41bd-ba9a-c045a512fabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-88567515-c8e2-43c2-949b-8026abf08779,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-1b841461-618c-4ea2-8612-854f7f34d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-efbf4265-55ce-470e-99c1-9e21c839b519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262056279-172.17.0.6-1597698984104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-d4f7bbed-d94a-4dda-adce-3e5dd453d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-d800cb09-8749-4cf3-923d-9bcdf7ee761c,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-d4cfbb1f-8a35-40b5-b317-c04e70e61217,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-7e02bb12-1c65-40d0-9955-ad3ca58408f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-5cab1da9-2962-41bd-ba9a-c045a512fabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-88567515-c8e2-43c2-949b-8026abf08779,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-1b841461-618c-4ea2-8612-854f7f34d3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-efbf4265-55ce-470e-99c1-9e21c839b519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537425910-172.17.0.6-1597699273456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33453,DS-f4b96c9b-88b0-4a4b-a416-2945d93deaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-333a9a5a-8f25-4b49-ba10-440212634e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-0e2ffd03-f803-45a5-bae7-b99606ea06c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-e542f2b3-8a7f-4ac7-a7fd-eab13cd24d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-2b933535-50df-44e0-a535-1937675e9891,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-896c9baa-c905-4de8-94fa-816bdc8baaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-2e2460e8-994d-4328-8294-b83068f2547e,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-e58f40a7-8c18-459e-9717-5eacbf71370a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537425910-172.17.0.6-1597699273456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33453,DS-f4b96c9b-88b0-4a4b-a416-2945d93deaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-333a9a5a-8f25-4b49-ba10-440212634e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-0e2ffd03-f803-45a5-bae7-b99606ea06c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-e542f2b3-8a7f-4ac7-a7fd-eab13cd24d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-2b933535-50df-44e0-a535-1937675e9891,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-896c9baa-c905-4de8-94fa-816bdc8baaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-2e2460e8-994d-4328-8294-b83068f2547e,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-e58f40a7-8c18-459e-9717-5eacbf71370a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621693643-172.17.0.6-1597699738370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-97fab821-9ba2-4ffa-881a-4c6659fd2295,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-4164b8c2-991c-4cc7-9cca-de69499f3178,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-446b10a3-66aa-4d92-a89b-b6a5d19453d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-b7439b17-1a0a-4227-bc6e-ba9b54f69226,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-373a40a5-ae7b-4f97-bc33-c4364674f019,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-6de43fa1-44df-40c3-90da-1ae60b81ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-2f5267b9-1744-4737-aecc-d5e1c2d98ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-6da2ad92-a43a-475d-8470-077c3578de12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621693643-172.17.0.6-1597699738370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46642,DS-97fab821-9ba2-4ffa-881a-4c6659fd2295,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-4164b8c2-991c-4cc7-9cca-de69499f3178,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-446b10a3-66aa-4d92-a89b-b6a5d19453d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-b7439b17-1a0a-4227-bc6e-ba9b54f69226,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-373a40a5-ae7b-4f97-bc33-c4364674f019,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-6de43fa1-44df-40c3-90da-1ae60b81ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-2f5267b9-1744-4737-aecc-d5e1c2d98ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-6da2ad92-a43a-475d-8470-077c3578de12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633686781-172.17.0.6-1597699768449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-efe09459-2196-4267-b76c-9f8f28980c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-606a33cc-d164-4630-8b15-efb96d2ef73e,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-f68b955e-5a16-4b8f-ae12-e4b1e9979a66,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-d7f472b5-a3e6-47ad-8d90-cc3825ec6663,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-369351ae-61e7-48ad-891e-c3f435c81e74,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-4ac8749b-ba1a-4e7e-8b55-020d685173b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-cdfbead0-103a-47d2-bedc-5e6cb2e5a50a,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-990e1c08-d137-459a-b04c-191326e84d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633686781-172.17.0.6-1597699768449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-efe09459-2196-4267-b76c-9f8f28980c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-606a33cc-d164-4630-8b15-efb96d2ef73e,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-f68b955e-5a16-4b8f-ae12-e4b1e9979a66,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-d7f472b5-a3e6-47ad-8d90-cc3825ec6663,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-369351ae-61e7-48ad-891e-c3f435c81e74,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-4ac8749b-ba1a-4e7e-8b55-020d685173b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-cdfbead0-103a-47d2-bedc-5e6cb2e5a50a,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-990e1c08-d137-459a-b04c-191326e84d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983395581-172.17.0.6-1597699805209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33878,DS-292c582f-1949-4f97-bcc6-8000d8b76f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-bc6096a7-4b7f-4309-acce-51dbe9e274b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-770707e6-0a4b-47b5-a6ba-3ccfbcc38e06,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-5580712b-dab3-4a79-ad6c-75d865aaf935,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-7554fe6f-40a1-4ec0-939f-5640119484a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-eb81fcaa-3257-487d-b031-c3195fc4a72d,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-3d22867b-85ea-453b-be77-83c29b38bd73,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-b9146f4f-6ccf-4cdd-b66b-4b1da922d9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983395581-172.17.0.6-1597699805209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33878,DS-292c582f-1949-4f97-bcc6-8000d8b76f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-bc6096a7-4b7f-4309-acce-51dbe9e274b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-770707e6-0a4b-47b5-a6ba-3ccfbcc38e06,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-5580712b-dab3-4a79-ad6c-75d865aaf935,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-7554fe6f-40a1-4ec0-939f-5640119484a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-eb81fcaa-3257-487d-b031-c3195fc4a72d,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-3d22867b-85ea-453b-be77-83c29b38bd73,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-b9146f4f-6ccf-4cdd-b66b-4b1da922d9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928264311-172.17.0.6-1597699914748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45486,DS-2b79f782-4d4e-4542-b8fe-8319caa725d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-90555b91-af55-4a5d-a710-1c7314c21a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-d6a51ed9-3ff2-48d5-8569-c1c48ee63d41,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-39b48556-0c77-4c81-a6e0-36892fdf2ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-c495e826-7071-47a0-bf73-91dba95b65af,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-22197e79-a0bf-4d2a-97bc-18e204677ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-aa80f04c-a889-403c-8eff-716851939fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-5d50eede-5bde-4c7d-95e5-961889668a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928264311-172.17.0.6-1597699914748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45486,DS-2b79f782-4d4e-4542-b8fe-8319caa725d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-90555b91-af55-4a5d-a710-1c7314c21a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-d6a51ed9-3ff2-48d5-8569-c1c48ee63d41,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-39b48556-0c77-4c81-a6e0-36892fdf2ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-c495e826-7071-47a0-bf73-91dba95b65af,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-22197e79-a0bf-4d2a-97bc-18e204677ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-aa80f04c-a889-403c-8eff-716851939fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-5d50eede-5bde-4c7d-95e5-961889668a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547567061-172.17.0.6-1597700026115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-d09d6a23-5526-48ca-86d9-2173b7e1f287,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-2fe7705a-c169-484a-b510-acee84b42f07,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-4f5784d5-2be4-4c36-8fef-03e0c85de4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-4a59f2cc-7c1a-4cd9-bc3d-92f7c63d4c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-75905042-e746-4a61-97e8-38d4634020c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-61b52a1d-9369-488b-beb5-d17d20c73574,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-b91e514c-0172-47e2-a811-9d95663218c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-c51cc523-e84b-413a-9643-e01ebcf4735b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547567061-172.17.0.6-1597700026115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-d09d6a23-5526-48ca-86d9-2173b7e1f287,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-2fe7705a-c169-484a-b510-acee84b42f07,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-4f5784d5-2be4-4c36-8fef-03e0c85de4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-4a59f2cc-7c1a-4cd9-bc3d-92f7c63d4c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-75905042-e746-4a61-97e8-38d4634020c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-61b52a1d-9369-488b-beb5-d17d20c73574,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-b91e514c-0172-47e2-a811-9d95663218c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-c51cc523-e84b-413a-9643-e01ebcf4735b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501165343-172.17.0.6-1597700167534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43157,DS-eb967a3c-6fc8-4d2e-a28e-98853aabe33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-df65594f-2e77-4218-8635-b226c7e37e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-8d3b7f86-0fdb-46fd-b74b-16895cd09c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-54c890f9-2993-4761-b01d-7ca042372570,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-158a3041-04b3-47ea-8b91-17ccbdc78bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-5ffe49b5-eea8-4685-9047-f2688c72f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-a003f66c-65eb-473e-b660-dd7ce0792bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-6377f153-3efa-45fa-83fa-586e4b4e361a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501165343-172.17.0.6-1597700167534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43157,DS-eb967a3c-6fc8-4d2e-a28e-98853aabe33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-df65594f-2e77-4218-8635-b226c7e37e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-8d3b7f86-0fdb-46fd-b74b-16895cd09c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-54c890f9-2993-4761-b01d-7ca042372570,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-158a3041-04b3-47ea-8b91-17ccbdc78bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-5ffe49b5-eea8-4685-9047-f2688c72f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-a003f66c-65eb-473e-b660-dd7ce0792bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-6377f153-3efa-45fa-83fa-586e4b4e361a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342770878-172.17.0.6-1597700453863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-499f1b7f-ae5a-4950-b9c7-b8cecdb0aebf,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-03cda585-0cd4-4a16-8153-778b4daa006f,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-692c06ca-0904-4b14-ba72-818c41d7a6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-b9fe6319-1b6d-4100-af92-ba566bf325ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-6aea03ad-ce5d-4c1c-8115-dadbd128a663,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-71ff5050-5ab5-4a88-8d6f-c9b090a46378,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-614b0d7e-c942-45ac-b8f0-f7d9aae6fd05,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-cb0eec1e-4622-48fc-93b5-66623bf8a978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342770878-172.17.0.6-1597700453863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43805,DS-499f1b7f-ae5a-4950-b9c7-b8cecdb0aebf,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-03cda585-0cd4-4a16-8153-778b4daa006f,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-692c06ca-0904-4b14-ba72-818c41d7a6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-b9fe6319-1b6d-4100-af92-ba566bf325ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-6aea03ad-ce5d-4c1c-8115-dadbd128a663,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-71ff5050-5ab5-4a88-8d6f-c9b090a46378,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-614b0d7e-c942-45ac-b8f0-f7d9aae6fd05,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-cb0eec1e-4622-48fc-93b5-66623bf8a978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778623297-172.17.0.6-1597700487120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-6ba623e8-b112-4bb9-95f4-12f569185352,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-40b9fba1-bea4-40d4-bfdb-bd758e220ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-ebfe9517-953c-4827-bac1-55c40a5c2ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-93b7a2fb-830e-4236-9f1c-638a68832f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-38d11db5-169d-467e-8fc5-0305900b8bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-ce2365dd-5dfa-4a28-a3e5-9e779d71c023,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-8bd4229c-d6f9-4a1d-b851-4c6574edc20e,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-066c7001-e1d5-44cf-a74f-3ffb21d7240d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778623297-172.17.0.6-1597700487120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-6ba623e8-b112-4bb9-95f4-12f569185352,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-40b9fba1-bea4-40d4-bfdb-bd758e220ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-ebfe9517-953c-4827-bac1-55c40a5c2ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-93b7a2fb-830e-4236-9f1c-638a68832f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-38d11db5-169d-467e-8fc5-0305900b8bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-ce2365dd-5dfa-4a28-a3e5-9e779d71c023,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-8bd4229c-d6f9-4a1d-b851-4c6574edc20e,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-066c7001-e1d5-44cf-a74f-3ffb21d7240d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478852666-172.17.0.6-1597701431926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42266,DS-f889b820-1101-43f4-b680-c126d4020e44,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-21653f11-a9f6-4171-88ee-d86e3b73b969,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-aa8381ed-9c6c-4fd2-870f-b46d7ac0e1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-8b6e0133-bd14-4af6-9cfd-a5dffa60af03,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-fa695c7a-a1b0-40ef-b24a-221d0c12f32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-33b7da60-2092-43ff-92b4-a19cea5efba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-37982575-aaea-4059-8430-a08e7f187646,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-8f098ad9-3523-4a22-a391-43a86445cce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478852666-172.17.0.6-1597701431926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42266,DS-f889b820-1101-43f4-b680-c126d4020e44,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-21653f11-a9f6-4171-88ee-d86e3b73b969,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-aa8381ed-9c6c-4fd2-870f-b46d7ac0e1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-8b6e0133-bd14-4af6-9cfd-a5dffa60af03,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-fa695c7a-a1b0-40ef-b24a-221d0c12f32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-33b7da60-2092-43ff-92b4-a19cea5efba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-37982575-aaea-4059-8430-a08e7f187646,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-8f098ad9-3523-4a22-a391-43a86445cce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405944743-172.17.0.6-1597701545924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-753558f2-820c-46ae-aa51-307a14d78b34,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-b569765f-7dde-4c3e-a121-e203d03ce47b,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-b1dd929a-05a4-4bc7-b4a6-192f96b9ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-b427af3e-0873-40dd-a0a5-21fe6aeca5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-aff12963-8677-4b66-bd5d-da63f1b4cb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-39f8838e-829b-4e1c-b444-43d186cfcff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-108d2674-2714-48b7-b537-34f5686115e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-c77b34dd-6c19-4ef7-aa0f-5296268648ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405944743-172.17.0.6-1597701545924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-753558f2-820c-46ae-aa51-307a14d78b34,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-b569765f-7dde-4c3e-a121-e203d03ce47b,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-b1dd929a-05a4-4bc7-b4a6-192f96b9ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-b427af3e-0873-40dd-a0a5-21fe6aeca5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-aff12963-8677-4b66-bd5d-da63f1b4cb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-39f8838e-829b-4e1c-b444-43d186cfcff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-108d2674-2714-48b7-b537-34f5686115e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-c77b34dd-6c19-4ef7-aa0f-5296268648ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812517777-172.17.0.6-1597701926866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-acc13a92-90b0-41c5-9cd7-6b6f4cf7854b,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-d494a236-6f00-4d3a-a3eb-8d9ea802f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-75d867dd-9bbb-435b-9571-53b7d7e41cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-b03790ba-5b4d-4701-ae6c-a3f19804d509,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-835ab0aa-ec34-4df4-8673-06ac1df45035,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-7f7e440d-2afb-41f4-9054-0b14815e10eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-c8edba65-d0bf-475a-946e-b5f86a1b7a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-7fa9f10f-0528-40ae-9330-c36be8f7333f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812517777-172.17.0.6-1597701926866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-acc13a92-90b0-41c5-9cd7-6b6f4cf7854b,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-d494a236-6f00-4d3a-a3eb-8d9ea802f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-75d867dd-9bbb-435b-9571-53b7d7e41cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-b03790ba-5b4d-4701-ae6c-a3f19804d509,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-835ab0aa-ec34-4df4-8673-06ac1df45035,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-7f7e440d-2afb-41f4-9054-0b14815e10eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-c8edba65-d0bf-475a-946e-b5f86a1b7a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-7fa9f10f-0528-40ae-9330-c36be8f7333f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25416055-172.17.0.6-1597702094036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-a92e3c02-8309-4491-82e0-5ef78e665edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-37210ac3-ad40-44fb-815c-a8b8e3313a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-d11990a0-2e3d-47b0-bb6b-377c92367422,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-ca1deed3-93a8-42a1-b3ad-4cfda464a488,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-394ae124-1fae-4343-bc80-5b99f29a658f,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-0b946110-fece-41e3-91d5-9c2399622230,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-2e309224-e593-4b25-87de-c45c8c397956,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-e089c2fb-3a9e-4c96-ab21-6ef9a2ed72d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25416055-172.17.0.6-1597702094036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41268,DS-a92e3c02-8309-4491-82e0-5ef78e665edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-37210ac3-ad40-44fb-815c-a8b8e3313a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-d11990a0-2e3d-47b0-bb6b-377c92367422,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-ca1deed3-93a8-42a1-b3ad-4cfda464a488,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-394ae124-1fae-4343-bc80-5b99f29a658f,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-0b946110-fece-41e3-91d5-9c2399622230,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-2e309224-e593-4b25-87de-c45c8c397956,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-e089c2fb-3a9e-4c96-ab21-6ef9a2ed72d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211132286-172.17.0.6-1597702209003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37899,DS-2b06b67d-7298-486b-b1c0-627aa7a71a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-9204858f-121b-4771-9521-26900e56f0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-7886c6c0-455a-411c-80f3-da04178f8b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-cfe4c226-cc61-4586-ae75-640500de3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-b443cbcf-a076-4de3-a6a4-9dc3adfb247d,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-ed38f078-d1e0-41e7-a428-4084676f993c,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-817db728-219b-4c52-8cb7-3b609c47e45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-d9c6b402-db0a-4dd4-8f45-8dafcba2eb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211132286-172.17.0.6-1597702209003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37899,DS-2b06b67d-7298-486b-b1c0-627aa7a71a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-9204858f-121b-4771-9521-26900e56f0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-7886c6c0-455a-411c-80f3-da04178f8b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-cfe4c226-cc61-4586-ae75-640500de3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-b443cbcf-a076-4de3-a6a4-9dc3adfb247d,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-ed38f078-d1e0-41e7-a428-4084676f993c,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-817db728-219b-4c52-8cb7-3b609c47e45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-d9c6b402-db0a-4dd4-8f45-8dafcba2eb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765575758-172.17.0.6-1597702566181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-14382623-c609-4aef-ad49-3e054244104a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-b9263f1b-7fed-4ead-b128-eb2a9345767a,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-8fd4ae26-4618-4ad7-9899-6ec4ab37c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-d611b5a1-e8f9-4bc5-a3a8-44c2f813a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-1e9568a1-a3c0-46c9-acbc-1d2f1fbd54dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-aa095b96-57f4-4baa-b1d6-a5ad54bf5ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-04365a24-cf27-4725-ab75-fb2cbfef0e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-d10ac769-f733-4278-8f4c-9fb5f7c35546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765575758-172.17.0.6-1597702566181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-14382623-c609-4aef-ad49-3e054244104a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-b9263f1b-7fed-4ead-b128-eb2a9345767a,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-8fd4ae26-4618-4ad7-9899-6ec4ab37c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-d611b5a1-e8f9-4bc5-a3a8-44c2f813a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-1e9568a1-a3c0-46c9-acbc-1d2f1fbd54dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-aa095b96-57f4-4baa-b1d6-a5ad54bf5ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-04365a24-cf27-4725-ab75-fb2cbfef0e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-d10ac769-f733-4278-8f4c-9fb5f7c35546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685901630-172.17.0.6-1597703224190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-a0d1c1a3-b0cb-4d10-8f54-03f3c137a786,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-d25917b6-25f3-4b5f-8854-4d77438c9222,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-3aa6139c-debe-48af-b8fd-715e1d9985df,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-f41a0068-3acb-4ef5-968c-e08534c4efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-d580ccf5-193a-4334-ad9f-a0a63e28cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-a9bded65-c692-42b7-8415-5268567cc61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-6379df80-4c1f-42f4-94c8-9b847585f009,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-7e9211c9-3546-44ca-bebc-233d92dd73a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685901630-172.17.0.6-1597703224190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-a0d1c1a3-b0cb-4d10-8f54-03f3c137a786,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-d25917b6-25f3-4b5f-8854-4d77438c9222,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-3aa6139c-debe-48af-b8fd-715e1d9985df,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-f41a0068-3acb-4ef5-968c-e08534c4efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-d580ccf5-193a-4334-ad9f-a0a63e28cfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-a9bded65-c692-42b7-8415-5268567cc61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-6379df80-4c1f-42f4-94c8-9b847585f009,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-7e9211c9-3546-44ca-bebc-233d92dd73a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378429417-172.17.0.6-1597703432984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-5886829f-53e0-4663-b947-6a0f41936600,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-04a888a5-d4be-49b6-bdd7-f404ba38a909,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-faadb93c-9790-45b8-b35e-58cec79a41eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-7b24b56d-0da6-4bc8-a805-06f8b8d41bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-0768c7ec-3a0d-486d-bfce-15976cbbcc53,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-59db0c2c-3427-4a10-b255-240253715e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-e2e50f28-fd71-415b-862a-dafe150b3759,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-c37eae7a-4ee8-41f3-a5cb-47fabc57cccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378429417-172.17.0.6-1597703432984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40426,DS-5886829f-53e0-4663-b947-6a0f41936600,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-04a888a5-d4be-49b6-bdd7-f404ba38a909,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-faadb93c-9790-45b8-b35e-58cec79a41eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-7b24b56d-0da6-4bc8-a805-06f8b8d41bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-0768c7ec-3a0d-486d-bfce-15976cbbcc53,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-59db0c2c-3427-4a10-b255-240253715e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-e2e50f28-fd71-415b-862a-dafe150b3759,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-c37eae7a-4ee8-41f3-a5cb-47fabc57cccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511211447-172.17.0.6-1597703496256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-cc40d89c-743c-465c-a568-920c04bb1773,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-b0229023-a043-4193-a334-39a36f1728f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-43baf3dc-a5ee-4e3b-bd77-e25f9315f033,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-da92357f-1dbc-4f5f-9283-8079b9c9f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-aad4ed36-f8e8-4896-9fae-fef19b93165d,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-167c8cc6-1ad0-40de-a417-3b44530e52cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-4080c5f3-d3b1-49c0-8f8b-9401e297c843,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-4028c195-f513-4d85-9439-bccddcac03a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511211447-172.17.0.6-1597703496256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-cc40d89c-743c-465c-a568-920c04bb1773,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-b0229023-a043-4193-a334-39a36f1728f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-43baf3dc-a5ee-4e3b-bd77-e25f9315f033,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-da92357f-1dbc-4f5f-9283-8079b9c9f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-aad4ed36-f8e8-4896-9fae-fef19b93165d,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-167c8cc6-1ad0-40de-a417-3b44530e52cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-4080c5f3-d3b1-49c0-8f8b-9401e297c843,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-4028c195-f513-4d85-9439-bccddcac03a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5331
