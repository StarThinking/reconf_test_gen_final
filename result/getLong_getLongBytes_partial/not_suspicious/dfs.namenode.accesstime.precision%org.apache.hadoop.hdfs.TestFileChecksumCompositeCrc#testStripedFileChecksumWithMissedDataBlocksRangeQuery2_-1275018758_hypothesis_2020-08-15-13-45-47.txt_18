reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142788879-172.17.0.3-1597499203613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38277,DS-4d810881-84db-4acb-b2b8-8de2ee36dbae,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-f11387aa-b2b2-4ce3-86b8-1f86f69455eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-e0f10376-742c-451a-87a0-2ad6c26f0072,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-d3cad87a-5175-47af-afb2-6cd4c2e35f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-3971151f-0808-4872-b95f-4f59a6c388ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-192b3e50-88ff-4511-9d40-78161bdf8688,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-db062f36-bbdc-4c9d-a810-602bff63971c,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-ec9c82eb-561d-402f-995a-092059fa8147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142788879-172.17.0.3-1597499203613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38277,DS-4d810881-84db-4acb-b2b8-8de2ee36dbae,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-f11387aa-b2b2-4ce3-86b8-1f86f69455eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-e0f10376-742c-451a-87a0-2ad6c26f0072,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-d3cad87a-5175-47af-afb2-6cd4c2e35f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-3971151f-0808-4872-b95f-4f59a6c388ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-192b3e50-88ff-4511-9d40-78161bdf8688,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-db062f36-bbdc-4c9d-a810-602bff63971c,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-ec9c82eb-561d-402f-995a-092059fa8147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672501984-172.17.0.3-1597499384661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40931,DS-bbfdbabd-b9ff-45c6-9afb-0d299ff315e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-14f7e4d4-9ad9-45e6-8bd3-7988486c8252,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-91723f5b-f233-4ece-bab8-a7547de04d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-b9df83cc-f057-43a8-99e2-156d8c556fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-8503c008-cab2-4026-8580-908ea0047bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-32ef0fec-f679-4382-8f31-37b590cd6442,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-bc2c21ea-a002-4576-a97e-cbff0cebc1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-f28c941c-f67d-481f-9ad6-6696ad29d2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672501984-172.17.0.3-1597499384661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40931,DS-bbfdbabd-b9ff-45c6-9afb-0d299ff315e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-14f7e4d4-9ad9-45e6-8bd3-7988486c8252,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-91723f5b-f233-4ece-bab8-a7547de04d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-b9df83cc-f057-43a8-99e2-156d8c556fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-8503c008-cab2-4026-8580-908ea0047bba,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-32ef0fec-f679-4382-8f31-37b590cd6442,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-bc2c21ea-a002-4576-a97e-cbff0cebc1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-f28c941c-f67d-481f-9ad6-6696ad29d2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629892321-172.17.0.3-1597500600868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-d7ae470b-2da3-42a9-8f4c-8af1a1e9d616,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-8df5724c-966c-4025-a053-e1ee8cdaa8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-6053f71e-7f26-4a20-8b61-f7776136eac0,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-ef5207c0-6b75-4c3b-9bae-4229db4cce40,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-72c23371-ef7c-44e3-8a0a-a5b37fee9b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-516d9d16-89a7-4f3c-9576-2a07ff2220a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-aae16752-818d-4bde-8294-71596ba85255,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-38928a98-2611-4395-9e9e-d079f5526c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629892321-172.17.0.3-1597500600868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-d7ae470b-2da3-42a9-8f4c-8af1a1e9d616,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-8df5724c-966c-4025-a053-e1ee8cdaa8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-6053f71e-7f26-4a20-8b61-f7776136eac0,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-ef5207c0-6b75-4c3b-9bae-4229db4cce40,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-72c23371-ef7c-44e3-8a0a-a5b37fee9b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-516d9d16-89a7-4f3c-9576-2a07ff2220a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-aae16752-818d-4bde-8294-71596ba85255,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-38928a98-2611-4395-9e9e-d079f5526c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870585159-172.17.0.3-1597500826519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38775,DS-aa4c6abc-d5a0-4915-9c92-fbf9c6477581,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-02c58cff-66f0-4bf1-bff1-da5f0d3e4350,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-ac5c8f12-5419-4552-a99f-b6c90e9f9e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-07deedd4-bad5-4f96-9723-d75752c56821,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-08de49e2-fd80-4e1c-955c-152609714af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-04ad8763-5ea3-4177-ba60-91427b91696f,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-5831a78a-f15f-4a2d-a599-82aaa2cb440a,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-c2565905-ede6-4b30-a04a-8a7c33c51d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870585159-172.17.0.3-1597500826519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38775,DS-aa4c6abc-d5a0-4915-9c92-fbf9c6477581,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-02c58cff-66f0-4bf1-bff1-da5f0d3e4350,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-ac5c8f12-5419-4552-a99f-b6c90e9f9e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-07deedd4-bad5-4f96-9723-d75752c56821,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-08de49e2-fd80-4e1c-955c-152609714af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-04ad8763-5ea3-4177-ba60-91427b91696f,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-5831a78a-f15f-4a2d-a599-82aaa2cb440a,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-c2565905-ede6-4b30-a04a-8a7c33c51d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879822969-172.17.0.3-1597501013194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42116,DS-957b90c9-c5cc-4727-921c-239ada5582ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-5fed2062-1366-4539-9aa1-59d71b6e8c27,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-24e8304c-c66c-4081-8c4b-185d813b53b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-bb557d56-d966-45a1-8837-5d3283641210,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-17083df3-d349-46fc-95e3-8c51f5df1670,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-a3282f0b-2064-4ff1-9057-45f8c07e87b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-19804168-6a8c-4702-a873-af3e50ec8fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-0899024a-f6b1-4899-978c-695ccff850a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879822969-172.17.0.3-1597501013194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42116,DS-957b90c9-c5cc-4727-921c-239ada5582ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-5fed2062-1366-4539-9aa1-59d71b6e8c27,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-24e8304c-c66c-4081-8c4b-185d813b53b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-bb557d56-d966-45a1-8837-5d3283641210,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-17083df3-d349-46fc-95e3-8c51f5df1670,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-a3282f0b-2064-4ff1-9057-45f8c07e87b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-19804168-6a8c-4702-a873-af3e50ec8fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-0899024a-f6b1-4899-978c-695ccff850a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694543233-172.17.0.3-1597501185319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45387,DS-13701c19-ecfe-4216-82a9-4b5675ca25da,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-8b1e2ce2-04db-422b-b705-a033907f749f,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-f7bd7ce6-f029-4a08-a8d7-dc015c8969a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-d0386ddd-055a-4ef4-9134-e7b13dea9449,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-e55ec16b-9dc0-4bd9-b655-d8fae709779c,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-eda9ef93-f43e-4731-98b3-40453d6581e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-fe6dc388-820b-49e0-abd8-f4cbd8caf5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-39c2b3d9-e9a8-4a9f-b91a-05891048e640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694543233-172.17.0.3-1597501185319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45387,DS-13701c19-ecfe-4216-82a9-4b5675ca25da,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-8b1e2ce2-04db-422b-b705-a033907f749f,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-f7bd7ce6-f029-4a08-a8d7-dc015c8969a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-d0386ddd-055a-4ef4-9134-e7b13dea9449,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-e55ec16b-9dc0-4bd9-b655-d8fae709779c,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-eda9ef93-f43e-4731-98b3-40453d6581e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-fe6dc388-820b-49e0-abd8-f4cbd8caf5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-39c2b3d9-e9a8-4a9f-b91a-05891048e640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465397204-172.17.0.3-1597501570999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-561c22ea-9ded-4929-80f8-cfc6042e9f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-9d37a98a-59fe-455e-8edc-109b7a0855ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-2422cbff-b037-410f-b072-7081d6f0f301,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-dc78001f-40dc-4e53-9ca0-f05634ec5251,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-47997e96-fb4b-4ef6-af13-6cae426a669e,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-3a18ba80-63bd-4b9c-ac1c-626e327be8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-8fad501f-41e1-46bf-b21b-f450939d8fca,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-307c29a4-64ad-4da6-9b3b-0d6a79c579d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465397204-172.17.0.3-1597501570999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-561c22ea-9ded-4929-80f8-cfc6042e9f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-9d37a98a-59fe-455e-8edc-109b7a0855ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-2422cbff-b037-410f-b072-7081d6f0f301,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-dc78001f-40dc-4e53-9ca0-f05634ec5251,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-47997e96-fb4b-4ef6-af13-6cae426a669e,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-3a18ba80-63bd-4b9c-ac1c-626e327be8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-8fad501f-41e1-46bf-b21b-f450939d8fca,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-307c29a4-64ad-4da6-9b3b-0d6a79c579d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996336403-172.17.0.3-1597501952574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-3c7127f4-9dc7-4599-bb03-3d2f20964911,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-73a63bdd-aa66-4f8b-a24c-fe1d50a1d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-26f4007d-6c14-4416-8965-800feca62fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-e7a5636a-4f59-46e4-aa6d-cf1b79b7cf75,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-777116ec-40d2-4b57-ba32-4b4d997daf45,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-2cbf7682-14a3-4e72-a403-a58b2f07e475,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-36cb5db4-4d85-48ce-aa00-3d538daebdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-4985953a-0123-4841-9f62-ade4ee02557e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996336403-172.17.0.3-1597501952574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-3c7127f4-9dc7-4599-bb03-3d2f20964911,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-73a63bdd-aa66-4f8b-a24c-fe1d50a1d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-26f4007d-6c14-4416-8965-800feca62fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-e7a5636a-4f59-46e4-aa6d-cf1b79b7cf75,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-777116ec-40d2-4b57-ba32-4b4d997daf45,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-2cbf7682-14a3-4e72-a403-a58b2f07e475,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-36cb5db4-4d85-48ce-aa00-3d538daebdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-4985953a-0123-4841-9f62-ade4ee02557e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672465924-172.17.0.3-1597502043372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-51b4f870-051d-428d-8bd3-58e75a753713,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-e532b569-9c57-49c4-a289-b05a24800ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-c35fe340-c98f-4eef-8a2b-d020562d6b32,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-93829ee1-1754-4a03-9f42-ba8053726221,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-2d86fa38-4043-4e9f-8196-84a7fbce8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-929c4147-0652-4f09-9f33-3572308dad3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-57ef65e0-b230-4977-a14f-c722de76320a,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-42c7ad25-816b-4734-afb9-2d4630880cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672465924-172.17.0.3-1597502043372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-51b4f870-051d-428d-8bd3-58e75a753713,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-e532b569-9c57-49c4-a289-b05a24800ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-c35fe340-c98f-4eef-8a2b-d020562d6b32,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-93829ee1-1754-4a03-9f42-ba8053726221,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-2d86fa38-4043-4e9f-8196-84a7fbce8db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-929c4147-0652-4f09-9f33-3572308dad3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-57ef65e0-b230-4977-a14f-c722de76320a,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-42c7ad25-816b-4734-afb9-2d4630880cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388206389-172.17.0.3-1597503499596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-f27e24a4-5b14-44ac-8587-1f956875b22f,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-573b77e4-85ad-4546-9070-d97cd5f4a77b,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-b2738de4-d18e-4938-9a72-e42893f96c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-f7c4e939-a125-43f6-9c43-520431ef64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-c626f65f-fb7a-4888-a110-94163bbbb317,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-33689bef-c8fd-43ce-835e-daeddec9faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-90e647d6-c347-4de2-bcf3-f0497d9059e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-503b68b6-2a45-44d2-9a76-d7166c0b5581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388206389-172.17.0.3-1597503499596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-f27e24a4-5b14-44ac-8587-1f956875b22f,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-573b77e4-85ad-4546-9070-d97cd5f4a77b,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-b2738de4-d18e-4938-9a72-e42893f96c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-f7c4e939-a125-43f6-9c43-520431ef64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-c626f65f-fb7a-4888-a110-94163bbbb317,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-33689bef-c8fd-43ce-835e-daeddec9faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-90e647d6-c347-4de2-bcf3-f0497d9059e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-503b68b6-2a45-44d2-9a76-d7166c0b5581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431285282-172.17.0.3-1597503541956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44642,DS-639a5e16-48ac-4b48-a51d-37eb97b213b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-78c15e72-76a1-4dfb-b007-32200bcfa2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-c30026ee-ca66-4822-b79b-752b8762212d,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-e695b2ae-776d-4a69-8131-b2c9f5343ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-4def380f-185b-4877-ac96-8fdae101dcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-66c8f8ba-e61d-4dba-b580-436a8dd532a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-2de8c69f-6340-4919-b46a-a99e406f6ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-4d9550e9-b926-4f87-8cbe-77c346a1e058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431285282-172.17.0.3-1597503541956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44642,DS-639a5e16-48ac-4b48-a51d-37eb97b213b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-78c15e72-76a1-4dfb-b007-32200bcfa2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-c30026ee-ca66-4822-b79b-752b8762212d,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-e695b2ae-776d-4a69-8131-b2c9f5343ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-4def380f-185b-4877-ac96-8fdae101dcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-66c8f8ba-e61d-4dba-b580-436a8dd532a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-2de8c69f-6340-4919-b46a-a99e406f6ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-4d9550e9-b926-4f87-8cbe-77c346a1e058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917413259-172.17.0.3-1597503622597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36030,DS-d56a3983-6d66-4be9-a09d-c19ac80d1931,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-b9aa9d5d-0f76-4658-952f-b905062ef4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-a43427be-dc78-445a-99af-f83749e63b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-9aa5121b-115e-4218-81a4-53b7889bb8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-e698607d-2c75-4414-9bf0-c9fa241f097c,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-7228f576-dab6-4ff6-a122-5baf72af01c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-07c2d723-dd79-497f-b948-8cb6a9b52cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-0bc34900-0efc-4d12-9802-ffc9dcdc49e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917413259-172.17.0.3-1597503622597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36030,DS-d56a3983-6d66-4be9-a09d-c19ac80d1931,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-b9aa9d5d-0f76-4658-952f-b905062ef4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-a43427be-dc78-445a-99af-f83749e63b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-9aa5121b-115e-4218-81a4-53b7889bb8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-e698607d-2c75-4414-9bf0-c9fa241f097c,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-7228f576-dab6-4ff6-a122-5baf72af01c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-07c2d723-dd79-497f-b948-8cb6a9b52cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-0bc34900-0efc-4d12-9802-ffc9dcdc49e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397128697-172.17.0.3-1597504891246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-1a56e76a-cdc4-4fd1-941d-b1099f9d31bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-ef69e708-92ce-4716-9359-98ed7f5ee225,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-393e9529-ec1c-4056-9763-85e715df2f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-68485f44-2117-4a92-add8-433b473589e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-d0b769df-dafb-4bf9-9bd0-2745c193c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-685ae3e3-b439-4703-afa7-7345142fea53,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-fd7221e1-816e-48f9-b8ff-3471844b1b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-e4959cc7-5bbe-421a-92ed-a029a12fab48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397128697-172.17.0.3-1597504891246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-1a56e76a-cdc4-4fd1-941d-b1099f9d31bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-ef69e708-92ce-4716-9359-98ed7f5ee225,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-393e9529-ec1c-4056-9763-85e715df2f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-68485f44-2117-4a92-add8-433b473589e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-d0b769df-dafb-4bf9-9bd0-2745c193c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-685ae3e3-b439-4703-afa7-7345142fea53,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-fd7221e1-816e-48f9-b8ff-3471844b1b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-e4959cc7-5bbe-421a-92ed-a029a12fab48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026176318-172.17.0.3-1597505113281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-3bdbb12f-7dc3-4b62-9e21-f04a31e21d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-d17cea48-6580-499b-a12d-3f051c8f5d78,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-1690cabc-2b34-4043-9924-63901974f2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-750ef4d1-3bef-4c4b-baa9-c75f202f05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-a1c1de8e-5a82-4e2e-b52a-81124f6f2502,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-4d24c5be-c5dc-493e-b0ee-7f30b2f9e597,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-30932259-0729-4772-a178-b001de44c537,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-6f4d9420-e250-405a-8ee6-6ba5ece74715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026176318-172.17.0.3-1597505113281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-3bdbb12f-7dc3-4b62-9e21-f04a31e21d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-d17cea48-6580-499b-a12d-3f051c8f5d78,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-1690cabc-2b34-4043-9924-63901974f2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-750ef4d1-3bef-4c4b-baa9-c75f202f05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-a1c1de8e-5a82-4e2e-b52a-81124f6f2502,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-4d24c5be-c5dc-493e-b0ee-7f30b2f9e597,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-30932259-0729-4772-a178-b001de44c537,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-6f4d9420-e250-405a-8ee6-6ba5ece74715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761509887-172.17.0.3-1597505425111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46169,DS-c7a4fa8d-a7c8-47bb-b58e-cc237f99f513,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-7fff0ea0-1bdd-4736-afd4-3aba405698ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-1b7102ec-0e40-4e6f-8036-3536a7c3b439,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-d1a52351-c04b-4bde-bd4a-d100eb209401,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-7559bac1-e17a-4276-ac19-b89e7c5a0fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-cc1230ad-2bba-492e-a848-6ec4779cdaee,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-89f339f8-9f2c-4c9d-a8df-e837b26222d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-b215589d-3889-4be1-8177-8c78382ccf3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761509887-172.17.0.3-1597505425111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46169,DS-c7a4fa8d-a7c8-47bb-b58e-cc237f99f513,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-7fff0ea0-1bdd-4736-afd4-3aba405698ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-1b7102ec-0e40-4e6f-8036-3536a7c3b439,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-d1a52351-c04b-4bde-bd4a-d100eb209401,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-7559bac1-e17a-4276-ac19-b89e7c5a0fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-cc1230ad-2bba-492e-a848-6ec4779cdaee,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-89f339f8-9f2c-4c9d-a8df-e837b26222d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-b215589d-3889-4be1-8177-8c78382ccf3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967923618-172.17.0.3-1597505610107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-8a659f72-902c-4e44-b67f-b02c2b38032a,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-45e771b4-a2d5-41c7-954c-b2ba2c0ff986,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-ffd53c15-4562-4164-8ea9-856bb82fa2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-0c3550d7-6b7a-4cf3-886e-9a1ab51c8929,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-0ec314a7-2942-4019-94fa-dd191eb00707,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-04133fb7-7964-4724-97db-bbfe17a6c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-50507038-3814-4d0a-97e2-9adb6d3f3731,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-25338bdf-5f2a-4240-bcaf-b15db2e77e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967923618-172.17.0.3-1597505610107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-8a659f72-902c-4e44-b67f-b02c2b38032a,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-45e771b4-a2d5-41c7-954c-b2ba2c0ff986,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-ffd53c15-4562-4164-8ea9-856bb82fa2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-0c3550d7-6b7a-4cf3-886e-9a1ab51c8929,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-0ec314a7-2942-4019-94fa-dd191eb00707,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-04133fb7-7964-4724-97db-bbfe17a6c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-50507038-3814-4d0a-97e2-9adb6d3f3731,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-25338bdf-5f2a-4240-bcaf-b15db2e77e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6751
